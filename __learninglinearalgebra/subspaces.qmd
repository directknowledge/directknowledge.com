---
pagetitle: "Subspaces - Learning Linear Algebra"
---
# Subspaces


::: {#def- } 
\label{subdef}
A subset $U$ of a vector space $V$ is called a \index{subspace} **subspace**  of $V$ if it has the following three properties
 
- $U$ contains the zero vector in $V$, 
- $U$ is closed under addition: if $\vec{u}$ and 
$\vec{v}$ are in $U$ then so is $\vec{u}+\vec{v}$, and 
- $U$ is closed under scalar multiplication: 
if $\vec{v}$ is in $U$  and $a$ is any scalar, then 
$a\vec{v}$ is in $U$. 
 
::: 

::: {#exm- } 
Let $U$ be the subset of $\mathbb{R}^5$ defined by 
$$
U=\{(x_1,x_2,x_3,x_4,x_5)\in\mathbb{R}^5 \, \mid \,x_1=3x_2 \text{ and } x_3=7x_4\}.
$$
Show $U$ is a subspace of $\mathbb{R}^5.$
The zero vector $\vec{0}=(0,0,0,0,0,0)$ is in $U$ since $0=3(0)$ and $0=7(0)$. Let $\vec{u}=(u_1, u_2, u_3, u_4, u_5)$ 
and $\vec{v}=(v_1, v_2, v_3, v_4, v_5)$ be vectors in $U$ and let $a$ be a scalar. Then 
$$
\vec{u}+\vec{v}=(u_1+v_1, u_2+v_2, u_3+v_3, u_4+v_4, u_5+v_5)
$$
is in $U$ since 
$$
u_1=3 u_2 \text{ and } v_1=3 v_2 \text{ imply } u_1+v_1=3 (u_2+v_2)$$
and
$$
u_3=7 u_4 \text{ and } v_3=7 v_4 \text{ imply } u_3+v_3=7 (u_4+v_4).$$
Also, 
$a \vec{u}$ is in $U$ since 
$u_1=3u_2$ implies $a u_1=3 (a u_2)$.
By \ref{subdef}, $U$ is a subspace of $\mathbb{R}^5$.
::: 

::: {#exm- } 
Give an example of a nonempty subset $U$ of 
$\mathbb{R}^2$ such that $U$ is closed under addition and under taking additive inverses, but $U$ is not a subspace of $\mathbb{R}^2$. 
The subset $\mathbb{Z}^2$ of $\mathbb{R}^2$ is closed under additive inverses and addition, however $\mathbb{Z}^2$ is not a subspace of $\mathbb{R}^2$ since $\sqrt{2} \in \mathbb{R}, (1,1)\in \mathbb{Z}^2$ however $(\sqrt{2} , \sqrt{2})  \not \in  \mathbb{Z}^2$.
::: 

::: {#exm- } 
Give an example of a nonempty subset $U$ of $\mathbb{R}^2$ such that $U$ is closed under scalar multiplication, but $U$ is not a subspace of $\mathbb{R}^2$.
The set 
$\{(x_1,x_2)\in \mathbb{R}^2 \mid x_1 x_2=0\}=M$ is closed under scalar multiplication because, if 
$\lambda\in \mathbb{R}$ and $(x_1,x_2)\in M$, then $(\lambda  x_1, \lambda  x_2)\in M$ holds since $\lambda  x_1 \lambda  x_2=0$. 
However, $M$ is not a subspace because $(0,1)+(1,0)=(1,1)\not \in M$ even though $(0,1),(1,0)\in M$.
::: 

::: {#exm- } 
Show that the set of all solutions of an $m\times n$ homogenous linear system of equations is a subspace of $V$ (called the \index{null space} **null space** ). 
Let $A\vec{x}=\vec{0}$ be an $m\times n$ homogenous system of linear equations and let $U$ be the set of solutions to this system. Of course $A\vec{0}=\vec{0}$ and so the zero vector is in $U$. Let $\vec{u}$ and $\vec{v}$ be in $U$ and let $a$ be a scalar. Then
$$
A(\vec{u}+\vec{v})=A\vec{u}+A\vec{v}=\vec{0}+\vec{0}=\vec{0}
$$
and
$$
A(a \vec{u})=a(A\vec{u})=a\vec{0}=\vec{0}
$$
shows $\vec{u}+\vec{v}$ and $a\vec{u}$ are in $U$. By \ref{subdef}, $U$ is a subspace of $V$. 
::: 

::: {#def- } 
\label{spandef}
Let $\vec{v}_1, \vec{v}_2, ..., \vec{v}_m$ be vectors in the vector space $V$. The set of all linear combinations
$$
\text{span}(\vlist{v}{m})
=\left\{
\lincomb{c}{v}{m}
\mid \vlist{c}{m}\in k \right\}
$$ 
is called the \index{spanning set} **spanning set**  of the vectors 
$\vlist{v}{m}$.
::: 

::: {#exm- } 
Show that the spanning set of the vectors 
$\vlist{v}{m}$ in $V$ is a subspace of $V$.  
Let $U=\text{span}(\vlist{v}{m})$.
Notice $\vec{0}\in U$ since $\vec{0}=\lincomb{0}{v}{m}$ where $0\in k$. 
Let $\vec{u}$ and $\vec{v}$ be vectors in 
$U$ and let $a$ be a scalar. 
By \ref{spandef},
there exists scalars $\vlist{c}{m}$ and scalars  
$\vlist{d}{m}$ such that 
$$
\vec{u}
=\lincomb{c}{v}{m}
\quad \text{ and } \quad 
\vec{v}
=\lincomb{d}{v}{m}
$$
Then
$$
\vec{u}+\vec{v}=\sum_{i=1}^m c_i \vec{v}_i+\sum_{i=1}^m d_i \vec{v}_i=\sum_{i=1}^m (c_i+d_i) \vec{v}_i
$$
and
$$
a\vec{u}=a\left(\sum_{i=1}^m c_i \vec{v}_i\right)=
\sum_{i=1}^m (a c_i) \vec{v}_i
$$
show $\vec{u}+\vec{v}$ and $a\vec{u}$ are in $U$; and thus $U$ is a subspace of $V$. 
::: 

We say that a nonzero $\vec{v}_i$ is \index{redundant} in the list $\vec{v}_1 , \ldots, \vec{v}_i, ..., \vec{v}_m$ if $\vec v_i$ can be written as a linear combination of the other nonzero vectors in the list. 
An equation of the form $a_1 \vec{v}_1 + \cdots +a_m \vec{v}_m = \vec{0}$ is called a \index{linear relation} **linear relation** among the vectors $\vec{v}_1 , ..., \vec{v}_m$; and is called a \index{nontrivial relation} **nontrivial relation** if at least one of the $a_i$'s is nonzero.

::: {#def- } 
\label{lindepdef}
The vectors $\vlist{v}{m}$ in $V$ are called \index{linear independent} **linear independent** if the only choice for 
$$
\lincomb{a}{v}{m}= \vec{0}
$$
is $a_1 = a_2=\cdots =a_m = 0$. 
Otherwise the vectors $\vlist{v}{m}$ are called \index{linear dependent} **linear dependent**. 
::: 

::: {#lem- } 
\label{lindepothers}
Show that any set $S=\{\vlist{v}{m}\}$ of vectors in $V$ is a linearly dependent set of vectors if and only if at least one of the vectors in the set can be written as a linear combination of the others. 
::: 

::: {.proof }
Assume the vectors in the set $S$ are linearly dependent. By \ref{lindepdef}, there exists scalars 
$c_1, c_2, ..., c_m$ (not all zero) such that 
$\lincomb{c}{v}{m}=\vec{0}$. 
Let $i$ be the least index such that 
$c_i$ is nonzero. 
Thus $c_1=c_2=\cdots =c_{i-1}=0$. 
So 
$$
c_i \vec{v}_i=-c_{i+1}\vec{v}_{i+1}-\cdots -c_m \vec{v}_m
$$ 
for some $i$. Since $c_i\neq 0$ and $c_i\in k$, $c_i^{-1}$ exists and thus
$$
\vec{v}_i
=\left(\frac{-c_{i+1}}{c_i}\right)\vec{v}_{i+1}
+ \cdots +
\left(\frac{-c_m}{c_i}\right)\vec{v}_m
$$
which shows $\vec{v}_i$ is a linear combination of the others, via
$$
\vec{v}_i= 0\vec{v}_1+\cdots+0\vec{v}_{i-1}+\left(\frac{-c_{i+1}}{c_i}\right)\vec{v}_{i+1}
+ \cdots +
\left(\frac{-c_m}{c_i}\right)\vec{v}_m.
$$
Now assume one of the vectors in the set $S$ can be written as a linear combination of the others, say
$$
\vec{v}_k
=c_1 \vec{v}_1+\cdots 
+c_{k-1} \vec{v}_{k-1} 
+c_{k+1} \vec{v}_{k+1} 
+\cdots 
+ c_m \vec{v}_m
$$
where $c_1, c_2, \ldots, c_m$ are scalars. Thus,
$$
\vec{0}=c_1 \vec{v}_1+\cdots 
+ c_{k-1} \vec{v}_{k-1}
+(-1) \vec{v}_k
+c_{k+1} \vec{v}_{k+1} 
+\cdots + c_m \vec{v}_m
$$
and so by \ref{lindepdef}, $\vec{v}_1, ..., \vec{v}_m$ are linearly dependent.
::: 

For a list of vectors $\vlist{v}{m}$ in $V$ the following equivalent statements follow from the appropriate definitions: 

- vectors $\vlist{v}{m}$ are linearly independent,
- none of the vectors $\vlist{v}{m}$ are redundant,
- none of the vectors $\vlist{v}{m}$ can be written as a linear combination of the other vectors in the list, 
- there is only the trivial relation among the vectors 
$\vlist{v}{m}$, 
- the only solution to the equation $\lincomb{a}{v}{m}$ is $a_1 = a_2=\cdots =a_m= 0$, and
- $\text{rank}(A)=n$
where $A$ is the $n\times m$ matrix whose columns are the vectors $\vlist{v}{m}$.

::: {#exm- } 
Determine whether the following vectors 
$\vec{u}$, $\vec{v}$, and  $\vec{w}$ 
are linearly independent. 
$$
\vec{u}=\vectorfour{1}{1}{1}{1}
\qquad 
\vec{v}=\vectorfour{1}{2}{3}{4}
\qquad 
\vec{w}=\vectorfour{1}{4}{7}{10}
$$
Without interchanging rows, we use elementary row operations to find 
$$
\text{rref}
\begin{bmatrix}
\vec{u} & \vec{v} & \vec{w}
\end{bmatrix}
=\begin{bmatrix}1 & 0 & -2 \\ 0 & 1 & 3 \\ 0 & 0 & 0 \\ 0 & 0 & 0 \end{bmatrix}.
$$
From this we infer the nontrivial relation 
$\vec 0=(-2)\vec{u}+(3)\vec{v}+(-1)\vec{w}.$
Therefore the given vectors are linearly dependent. 
::: 

::: {#thm- } 
Let 
$$
\vec{v}_1=\vectorfour{a_{11}}{a_{21}}{\vdots}{a_{n1}}
\quad
\vec{v}_2=\vectorfour{a_{12}}{a_{22}}{\vdots}{a_{n2}}
\quad
\cdots
\quad
\vec{v}_m=\vectorfour{a_{1s}}{a_{2m}}{\vdots}{a_{nm}}
$$
be $s$ vectors in $V$. These vectors are linearly dependent if and only if there exists a solution to the system of linear equations
\begin{equation}
\label{lincomsys}
\begin{cases}
a_{11}x_1+a_{12}x_2+\cdots+a_{1m}x_m=0 \\
a_{21}x_1+a_{22}x_2+\cdots+a_{2m}x_m=0 \\
\qquad \qquad \vdots \\
a_{n1}x_1+a_{n2}x_2+\cdots+a_{nm}x_m=0 \\
\end{cases}
\end{equation}
different from $x_1=x_2=\cdots=x_m=0$.
::: 

::: {.proof }
Assume $\vlist{v}{m}$ are linear dependent. By \ref{lindepdef}, there exists scalars $\vlist{c}{m}$ such that 
\begin{equation}
\label{lincomeq}
\lincomb{c}{v}{m}=\vec{0}
\end{equation}
and not all $c_i$'s are zero. \ref{lincomeq} yields a system
$$
\begin{cases}
a_{11}c_1+a_{12}c_2+\cdots+a_{1m}c_m=0 \\
a_{21}c_1+a_{22}c_2+\cdots+a_{2m}c_m=0 \\
\qquad \qquad \vdots \\
a_{n1}c_1+a_{n2}c_2+\cdots+a_{nm}c_m=0 \\
\end{cases}
$$
with solution $x_1=c_1$, $x_2=c_2$, ..., $x_m=c_m$. Since not all $c_i$'s are zero we have a solution different from $x_1=x_2=\cdots=x_m=0$.
Assume the system in \ref{lincomsys} has a solution $\vec{x}^*$ with $\vec{x}^*\neq \vec{0}$, say $x_i^*$. By \ref{colvecmat} we can write 
\begin{equation}
\vec{0}=A\vec{x}=
\lincomb{x^*}{v}{m}
\end{equation}
Isolating the term $x_i^*\vec{v}_i$ yields 
\begin{equation}
x_i^* \vec{v}_i=-x_i^*\vec{v}_1-\cdots -x_{i-1}\vec{v}_{i-1}-x_{i+1}\vec{v}_{i+1} -\cdots -x_m^*\vec{v}_m
\end{equation}
and since $x_i^*\neq 0$, $(x_i^*)^{-1}$ exists. Therefore,
\begin{equation}
\vec{v}_1=\left(-\frac{x_1^*}{x^*_i}\right)\vec{v}_1-\cdots -\left(-\frac{x_{i-1}^*}{x^*_i}\right)\vec{v}_{i+1}-\cdots - \left(-\frac{x_{m}^*}{x^*_i}\right)\vec{v}_{m}
\end{equation}
shows the vectors $\vlist{v}{m}$ are linearly dependent. 
::: 

::: {#thm- } 
The $n\times m$ linear system of equations 
$A\vec{x}=\vec{b}$ 
has a solution if and only if the vector 
$\vec{b}$ is contained in the subspace of $V$ generated by the column vectors of $A$.
::: 

::: {.proof }
Let $\vec{x}$ be a solution to $A\vec{x}=\vec{b}$ with $A=\begin{bmatrix}\vec{v}_1 & \vec{v}_2 & \cdots & \vec{v}_m \end{bmatrix}$.
By \ref{colvecmat}, $\vec{b}=A\vec{x}=\lincomb{x}{v}{m}$ and thus $\vec{b}\in \text{span}(\vlist{v}{m})$ as needed. Conversely, assume $\vec{b}$ is in the subspace generated by the column vectors of $A$; that is assume $\vec{b}\in \text{span}(\vlist{v}{m})$. By \ref{spandef}, there exists scalars $\vlist{c}{m}$ such that $\vec{b}=\lincomb{c}{v}{m}$. By \ref{spandef}, 
$\vec{b}=\lincomb{c}{v}{m}=A\vec{c}$
where the components of $\vec{c}$ are the $c_i$'s. Thus the system $A\vec{x}=\vec{b}$ has a solution, namely $\vec{c}$. 
::: 

::: {#exm- } 
Let $U$ and $V$ be finite subsets of a vector space $V$ with $U\subseteq V$.
 
- If $U$ is linear dependent, then so is $V$.
- If $V$ is linear independent, then so is $U$.
 
Let $U=\{\vlist{u}{s}\}$ $V=\{\vlist{v}{t}\}$. 

- If $U$ is linear dependent, then thee exists a vector, say $\vec{u}_k$ such that  $\vec{u}_k$ is a linear combination of the other $\vec{u}_i$'s. Since $U\subseteq V$ all $\vec{u}_i$'s are in $V$. Thus we have a vector $\vec{u}_k$ in $V$ that is a linear combination of other vectors in $V$. Therefore, by \ref{lindepothers}, $V$ is linear dependent.
- Let $\vlist{c}{s}$ be scalars such that 
\begin{equation}
\label{lincombcus}
\lincomb{c}{u}{s}=\vec{0}.
\end{equation}
Since $U\subseteq V$, we know $u_i\in V$ for $1\leq i \leq s$. Since $V$ is linear independent, \ref{lincombcus} implies $c_1=c_2=\cdots =c_m=0$. By \ref{lindepdef}, $U$ is linear independent as well. 
::: 

::: {#cor- } 
\label{cor:explincomb}
Any vector in $V$, written as a column matrix, can be expressed (uniquely) as a linear combination of 
$\vec{v}_1, \vec{v}_2, ..., \vec{v}_m$ if and only if 
$A \vec{x}=\vec{v}$ has unique solution, where $A=\begin{bmatrix}\vec{v}_1 & \vec{v}_2 & \cdots & \vec{v}_m\end{bmatrix}$. When there is a solution, the components $x_1, x_2, ...., x_m$ of $\vec{x}$ give the coefficients for the linear combination. 
::: 

::: {.proof }
This proof is left for the reader as Exercise \ref{ex:explincomb}.
::: 

::: {#thm- } 
\label{prop:roweqtoidn}
The vectors $\vlist{v}{n}$ in $V$ form a linearly independent set of vectors if and only if 
$\begin{bmatrix}\vec{v}_1&  \vec{v}_2 &  \cdots &  \vec{v}_n \end{bmatrix}$ is row equivalent to $I_n$. 
::: 

::: {.proof }
This proof is left for the reader as Exercise \ref{ex:roweqtoidn}.
::: 

::: {#thm- } 
\label{inpspanine}
Let $V$ be a vector space and assume that the vectors $\vlist{v}{n}$ are linearly independent and $\text{span}(\vlist{s}{m})=V$. Then $n\leq m$.
::: 

::: {.proof }
We are given 
$$
\text{span}(\vlist{s}{m})=V 
\quad \text{and} \quad
\vlist{v}{n} \text{ are linearly independent.}
$$
Since $\vec{v}_1$ is a linear combination of the vectors $\vec{s}_1$,  $\vec{s}_2$, ....,  $\vec{s}_m$ we  obtain
$$
\text{span}(\vec{v}_1,\vec{s}_2,...,\vec{s}_m)=V 
\quad \text{and} \quad
\vec{v}_2, ..., \vec{v}_n \text{ are linearly independent,}
$$
respectively.
Since $\vec{v}_2$ is a linear combination of $\vec{v}_1$,  $\vec{s}_2$, ..., $\vec{s}_m$ we can obtain
$$
\text{span}(\vec{v}_1,\vec{v}_2,\vec{s}_3,...,\vec{s}_m)=V 
\quad \text{and} \quad
\vec{v}_3, ..., \vec{v}_n \text{ are linearly independent,}
$$
respectively.
Now if $m<n$ then repeating this process will eventually exhaust the $\vec{s}_i$'s and lead to 
$$
\text{span}(\vec{v}_1,\vec{v}_2,...,\vec{v}_m)=V 
\quad \text{and} \quad
\vec{v}_{m+1}, ..., \vec{v}_n \text{ are linearly independent.}
$$
This is a contradiction since $\vec{v}_n$ is not in 
$\text{span}(\vlist{v}{m});$ and whence $n\leq m$. 
::: 

::: {#thm- } 
A set $S=\{\vlist{v}{m}\}$ of vectors in $V$ is linearly independent if and only if for any vector $\vec{u}$, if $\vec{u}=\lincomb{u}{v}{m}$, then this representation is unique. 
::: 

::: {.proof }
Assume the vectors in $S$ are linearly independent and assume $\vec{u}$ is an arbitrary vector with
\begin{equation}
\vec{u}=\lincomb{a}{v}{m} 
\qquad \text{and} \qquad
\vec{u}=\lincomb{b}{v}{m} 
\end{equation}
as both representations of $\vec{u}$ as linear combinations of the vectors in $S$. 
Then
$$
\vec{0}=\vec{u}-\vec{u}
=(a_1-b_1)\vec{v}_1+(a_2-b_2)\vec{v}_2+\cdots +(a_m-b_m)\vec{v}_m.
$$
Since $S$ is linearly independent 
$a_1-b_1=a_2-b_2=\cdots =a_m-b_m=0$
and thus $a_1=b_1$, $a_2=b_2$, ..., $a_m=b_m$. 
Therefore, the representation of $\vec{u}$ as a linear combination of the vectors in $S$ is unique. 
Conversely, assume for nay vector $\vec{u}$ which can be written as a linear combination of the vectors in $S$, the representation is unique. If $\vlist{c}{m}$ are scalars such that $\lincomb{c}{v}{m}=\vec{0}$ then $c_1=c_2=\cdots =c_m=0$ much hold since 
$0\vec{v}_1+0\vec{v}_2+\cdots +0\vec{v}_m=\vec{0}$ and this representation is unique. Therefore, the vectors in $S$ are linearly independent. 
::: 

::: {#def- } 
\label{basisdef}
The vectors $\vlist{v}{m}$ in $V$ are called a \index{basis} **basis**  of a linear subspace $V$ if they span $V$ and are linearly independent. 
::: 

::: {#exm- } 
Find a basis for $V$ for $n=1,2,3,...m$.
For $n=2$, the vectors $\vectortwo{1}{0}$, 
$\vectortwo{0}{1}$ form a basis for $k^2$.
For $n=3$, the vectors $\vectorthree{1}{0}{0}$, $\vectorthree{0}{1}{0}$, $\vectorthree{0}{0}{1}$ form a basis for $k^3$.
In general, for a positive integer $n$, the following $n$ vectors of $V$ form a basis (called the \index{standard basis} **standard basis** ) of $V$. 
\begin{equation}
\label{stba}
\vec{e}_1=\vectorfour{1}{0}{\vdots}{0}
\qquad
\vec{e}_2=\vectorfour{0}{1}{\vdots}{0}
\qquad
\cdots
\qquad
\vec{e}_n=\vectorfour{0}{0}{\vdots}{1}
\end{equation}
The vectors in a standard basis are linearly independent by \ref{prop:roweqtoidn}. Given any vector $\vec{v}$ in $V$ with components $v_i$, we can write 
$$
\vec{v}=\lincomb{v}{e}{n},
$$
and thus $k^n=\text{span}(\vlist{e}{n})$ which shows that any standard basis is in fact a basis. 
::: 

::: {#exm- } 
Show the following vectors 
$\vec{v}_1$, $\vec{v}_2$,
$\vec{v}_3$, and $\vec{v}_4$ 
form a basis for $\mathbb{R}^4$. 
$$
\vec v_1=\begin{bmatrix} 1 \\ 1\\ 1 \\ 1 \end{bmatrix}
\qquad
\vec v_2=\begin{bmatrix} 1 \\ -1\\ 1 \\ -1 \end{bmatrix}
\qquad
\vec v_3=\begin{bmatrix} 1 \\ 2\\ 4 \\ 8 \end{bmatrix}\qquad
\vec v_4=\begin{bmatrix} 1 \\ -2\\ 4 \\ -8 \end{bmatrix}
$$
We determine $\text{rref}(A)=I_4$ where $A$ is the matrix with column vectors $\vec v_1, \vec v_2, \vec v_3, \vec v_4$. By \ref{prop:roweqtoidn},  $\vec v_1, \vec v_2, \vec v_3, \vec v_4$ are linearly independent. Since $\vec v_1, \vec v_2, \vec v_3, \vec v_4$  also span $\mathbb{R}^4$, they form a basis of $\mathbb{R}^4$. 
::: 

::: {#exm- } 
Let $U$ be the subspace of $\mathbb{R}^5$ defined by 
$$
U=\{(x_1,x_2,x_3,x_4,x_5)\in\mathbb{R}^5  \mid x_1=3x_2 \text{ and } x_3=7x_4\}.
$$
Find a basis of $U$.
The following vectors belong to $U$ and are linearly independent in $\mathbb{R}^5$.
$$
v_1=\vectorfive{3}{1}{0}{0}{0}
\qquad
v_2=\vectorfive{0}{0}{7}{1}{0}
\qquad
v_3=\vectorfive{0}{0}{0}{0}{1}
$$
If $u\in U$, then the representation
$$
u
=\vectorfive{u_1}{u_2}{u_3}{u_4}{u_5}
=\vectorfive{3u_2}{u_2}{7u_4}{u_4}{u_5}
=u_2\vectorfive{3}{1}{0}{0}{0}+u_4\vectorfive{0}{0}{7}{1}{0}+u_5\vectorfive{0}{0}{0}{0}{1}
$$
shows that they also span $U$, and thus form a basis of $U$ by \ref{basisdef}.
::: 

::: {#thm- } 
\label{prop:spnlinbasis}
Let $S=\{\vlist{v}{n}\}$ be a set of vectors in a  vector space $V$ and let $W=\text{span}(S)$. Then some subset  of $S$ is a basis for $W$. 
::: 

::: {.proof }
Assume $W=\text{span}(S)$ and suppose $S$ is a linearly independent set of vectors. 
Thus, in this case, $S$ is a basis of $W$, by \ref{basisdef}. So we can assume $S$ is a linearly dependent set of vectors. By \ref{lindepothers}, there exists $i$ such that $1\leq i \leq m$ and $\vec{v}_i$ is a linear combination of the other vectors in $S$. It is left for Exercise \ref{ex:spnlinbasis}  to show that 
$$
W=\text{span}(S)=\text{span}(S_1)
$$
where $S_1=S/\{\vec{v}_i\}$. If $S_1$ is linearly independent set of vectors, then $S_1$ is a basis of $W$. Otherwise, $S_1$ is a linear dependent set and we can delete a vector from $S_1$ that is a linear combination of the other vectors in $S_1$. We obtain another subset $S_2$ of $S$ with 
$$
W=\text{span}(S)=\text{span}(S_1)=\text{span}(S_2).
$$
Since $S$ is finite, if we continue, we find a linearly independent subset of $S$ and thus a basis of $W$. 
::: 

::: {#cor- } 
All bases of a subspace $U$ of a vector space $V$ consists of the same number of vectors. 
::: 

::: {.proof }
Let $S=\{\vlist{v}{n}\}$ and $T=\{\vlist{w}{m}\}$ be bases of a subspace $U$. Then $\text{span}(S)=V$  and $T$ is a lineal indecent set of vectors. By \ref{inpspanine}, $m\leq n$. Similarly, since $\text{span}(T)=V$ and $S$ is a linearly independent set of vectors, $n\leq m$. Therefore, $m=n$ as desired.  
::: 

::: {#cor- } 
\label{rrefbasis}
The vectors $\vec{v}_1, \vec{v}_2, ..., \vec{v}_n$ form a basis of $V$ if and only if the reduced row echelon form of the $n\times n$ matrix 
$\begin{bmatrix}\vec{v}_1&  \vec{v}_2 &  \cdots &  \vec{v}_n \end{bmatrix}$ is $I_n$. 
::: 

::: {.proof }
Suppose the vectors $\vlist{v}{n}$ form a basis of $V$ and consider the $n\times n$ linear system 
$$
\begin{cases}
v_{11} x_1+v_{12} x_2+\cdots +v_{1n} x_n=0 \\
v_{21} x_1+v_{22} x_2+\cdots +v_{2n} x_n=0 \\
\qquad \qquad \vdots \\
v_{n1} x_1+v_{n2} x_2+\cdots +v_{nn} x_n=0 
\end{cases}
$$
where the $v_{ij}$'s are the components of the 
$\vec{v}_j$'s. Since $\{\vlist{v}{n}\}$ is a basis, 
$\vec{v}_1=\vec{v}_2=\cdots =\vec{v}_n=\vec{0}$ and this linear system can not have another solution. 
By \ref{cor:linsystmecor2}, 
$\text{rref}(A)=I_n$ where $A=\begin{bmatrix}\vec{v}_1&  \vec{v}_2 &  \cdots &  \vec{v}_n \end{bmatrix}$.
::: 

::: {#def- } 
The number of vectors in a basis of a subspace 
$U$ of $V$ is called the \index{dimension} **dimension**  of $U$, and is denoted by $\text{dim} U$. 
::: 

::: {#exm- } 
Find a basis of the subspace of $\mathbb{R}^4$ that consists of all vectors perpendicular to both of the following vectors $\vec{v}_1$ and $\vec v_2$.
$$
\vec v_1=\vectorfour{1}{0}{-1}{1}
\qquad
\vec v_2=\vectorfour{0}{1}{2}{3}
$$
We need to find all vectors $\vec x$ in $\mathbb{R}^4$ such that $\vec x \cdot \vec v_1=0$ and $\vec x \cdot \vec v_2=0$. We solve both
$$
\vectorfour{x_1}{x_2}{x_3}{x_4}\cdot \vectorfour{1}{0}{-1}{1}=0
\qquad \text{and} \qquad
\vectorfour{x_1}{x_2}{x_3}{x_4}\cdot \vectorfour{0}{1}{2}{3}=0
$$
which leads to the system and matrix
$$
\begin{cases}
x_1-x_3+x_4 =0 \\ 
x_2+2x_3+3x_4 =0 
\end{cases}
\qquad 
\text{and}
\qquad 
A=
\begin{bmatrix}
1 & 0 & -1 & 1 \\
0 & 1 & 2 & 3
\end{bmatrix}.
$$
All solutions are given by 
$$
\vectorfour{x_1}{x_2}{x_3}{x_4}
=t \vectorfour{-1}{-3}{0}{1}+u\vectorfour{1}{-2}{1}{0} \quad \text{ where $t, u\in\mathbb{R}$}.
$$
It follows the vectors $\vectorfour{-1}{-3}{0}{1}$, $\vectorfour{1}{-2}{1}{0}$ form a basis of the desired subspace. 
::: 

::: {#thm- } 
\label{sumprop}
Let $U$ be a subspace of $k^m$ with $\dim U=n$, then 
 
- any list of linearly independent vectors contains $n$ elements, 
- any list of vectors that spans $U$ contains at least $n$ elements, 
- if $n$ vectors are linearly independent then they form a basis, and 
- if $n$ vectors span $U$, then they form a basis of $U$.
 
::: 

::: {.proof }
The proof is left for the reader as Exercise \ref{ex:sumprop}
::: 

::: {#exm- } 
Determine the values of $a$ for which the following vectors $\vec{u}_1$, $\vec{u}_2$, $\vec{u}_3$, and $\vec{u}_4$ form a basis of $\mathbb{R}^4$.
$$
\vec{u}_1=\vectorfour{1}{0}{0}{4} \qquad
\vec{u}_2=\vectorfour{0}{1}{0}{6} \qquad
\vec{u}_3=\vectorfour{0}{0}{1}{8} \qquad
\vec{u}_4=\vectorfour{4}{5}{6}{a}$$
Let $A=\begin{bmatrix}\vec{u}_1 & \vec{u}_2 & \vec{u}_3& \vec{u}_4\end{bmatrix}$. Using row operations we find the row-echelon form of $A$ to be the following matrix. 
$$
\begin{bmatrix}
1 & 0 & 0 & 4 \\
0 & 1 & 0 & 5 \\
0 & 0 & 1 & 6\\
0 & 0 & 8 & a-94
\end{bmatrix}
$$
Thus, $\text{rref}(A)=I_4$ if and only if $a=95$. Therefore, by \ref{rrefbasis}, $B=\{\vec{u}_1, \vec{u}_2, \vec{u}_3, \vec{u}_4\}$ is a basis if and only if $a=95$. 
::: 

::: {#thm- } 
The dimension of the row space of a matrix $A$ is equal to the dimension of the column space of $A$. 
::: 

::: {.proof }
Gerber pg 226.
::: 


\subsection*{Exercises}

::: {#exr- } 
Determine whether the following collection of vectors in $\mathbb{R}^3$ are linearly independent or linearly dependent.
\ 
- $(0,1,1), (1,2,1), (0,4,6), (1,0,-1)$
- $(0,1,0), (1,2,1), (0,-4,6), (-1,1,-1)$
 
::: 

::: {#exr- } 
Determine whether the following collection of vectors in  $\mathbb{R}^4$ are linearly independent or linearly dependent.
\ 
- $(0,1,1,1), (1,2,1,1), (0,4,6,2), (1,0,-1, 2)$
- $(0,1,0,1), (1,2,1,3), (0,-4,6,-2), (-1,1,-1, 2)$
 
::: 

::: {#exr- } 
Show that the given vectors do not form a basis for the vector space $V$. 
\ 
- $(21,-7), (-6, 1)$; $V=\mathbb{R}^2$ 
- $(21,-7,14), (-6, 1,-4), (1,0,0)$; $V=\mathbb{R}^3$ 
- $(48,24,108,-72), (-24, -12,-54,36), (1,0,0,0), (1,1,0,0)$; $V=\mathbb{R}^4$ 
 
::: 

::: {#exr- } 
Reduce the vectors to a basis of the vector space 
$V$. 
\ 
- $(1,0), (1,2), (2,4)$, $V=\mathbb{R}^2$ 
- $(1,2,3), (-1, -10, 15), (1, 2, -3), (2,0,6), (1, -2, 3)$, $V=\mathbb{R}^3$ 
 
::: 

::: {#exr- } 
Which of the following collection of vectors in $\mathbb{R}^3$ are linearly dependent? For those that are express one vector as a linear combination of the rest.
 
- $(1,1,0), (0,2,3), (1,2,3)$
- $(1,1,0), (3,4,2), (0,2,3)$
 
::: 

::: {#exr- } 
\label{ex:PropertiesofVectorAddition1}
Prove \ref{PropertiesofVectorAddition1}.
::: 

::: {#exr- } 
\label{ex:PropertiesofVectorAddition2}
Prove \ref{PropertiesofVectorAddition2}.
::: 

::: {#exr- } 
Let $S=\{v_1, v_2, ..., v_k\}$ be a set of vectors in a a vector space $V$. Prove that $S$ is linearly dependent if and only if one of the vectors in $S$ is a linear combination of all other vectors in $S$. 
::: 

::: {#exr- } 
Suppose that $S=\{v_1, v_2, v_3\}$ is a linearly independent set of vector in a vector space $V$. Prove that $T=\{u_1, u_2, u_3\}$ is also linearly independent where $u_1=v_1$, $u_2=v_1+v_2$, and $u_3=v_1+v_2+v_3$.
::: 

::: {#exr- } 
Which of the following sets of vectors form a basis for the vector space $V$. 
\ 
- $(1,3), (1,-1)$; $V=\mathbb{R}^2$ 
- $(1,3),(-2,6)$; $V=\mathbb{R}^2$ 
- $(3,2,2), (-1,2,1), (0,1,0)$; $V=\mathbb{R}^3$ 
- $(3,2,2), (-1,2,0), (1,1,0)$; $V=\mathbb{R}^3$ 
- $(2,2,2,2), (3,3,3,2), (1,0,0,0), (0,1,0,0)$; $V=\mathbb{R}^4$ 
- $(1,1,2,0), (2,2,4,0), (1,2,3,1), (2,1,3,-1), (1,2,3,-1) $; $V=\mathbb{R}^4$ 
 
::: 

::: {#exr- } 
Find a basis for the subspace of the vector space $V$.
\ 
- All vectors of the form $(a,b,c)$ where $b=a+c$ where $V=\mathbb{R}^3$.
- All vectors of the form $(a,b,c)$ where $b=a-c$ where $V=\mathbb{R}^3$.
- All vectors of the form $\vectorfour{b-a}{a+c}{b+c}{c}$ where 
$V=\mathbb{R}^4$.
 
::: 

::: {#exr-vecex1 } 
Let $\vec{v}_1=\vectorthree{0}{1}{1}$, $\vec{v}_2=\vectorthree{1}{0}{0}$ and $S=\text{span}(\vec{v}_1,\vec{v}_2)$. 

- Is $S$ a subspace of $\mathbb{R}^3$?
- Find a vector $\vec{u}$ in $S$ other than $\vec{v}_1$, $\vec{v}_2$.
- Find scalars which verify that $3\vec{u}$ is in $S$. 
- Find scalars which verify that $\vec{0}$ is in $S$.  
::: 

::: {#exr- } 
Let 
$\vec{u}_1=\vectorthree{0}{2}{2}$, 
$\vec{u}_2=\vectorthree{2}{0}{0}$ and 
$T=\text{span}(\vec{u}_1,\vec{u}_2)$. 
Show $S=T$ by showing 
$S\subseteq T$ and 
$T\subseteq S$
where $S$ is defined in Exercise \ref{vecex1}.
::: 

::: {#exr- } 
Prove that the non-empty intersection of two subspaces of $\mathbb{R}^3$ is a subspace of $\mathbb{R}^3$. 
::: 

::: {#exr- } 
Let $S$ and $T$ be subspaces of $\mathbb{R}^3$ defined by 
$$
S=\text{span}\left(\vectorthree{1}{0}{2},\vectorthree{0}{2}{1}\right)
\qquad \text{and} \qquad
T=\text{span}\left(\vectorthree{2}{-2}{3},\vectorthree{3}{-4}{4}\right).
$$
Show they are the same subspace of $\mathbb{R}^3$.
::: 

::: {#exr- } 
Let ${\vec{v}_1,\vec{v}_2, \vec{v}_3}$ be a linearly independent set of vectors. Show that if $\vec{v}_4$ is not a linear combination of $\vec{v}_1, \vec{v}_2, \vec{v}_3$, then ${\vec{v}_1,\vec{v}_2, \vec{v}_3},\vec{v}_4$ is a linearly independent set of vectors. 
::: 

::: {#exr- } 
If  
$\{\vec{v}_1,\vec{v}_2, \vec{v}_3\}$ 
is a linearly independent set of vectors in $V$, show that  
$\{\vec{v}_1,\vec{v}_1+\vec{v}_2, \vec{v}_1+\vec{v}_2+\vec{v}_3\}$ 
is also a linearly independent set of vectors in $V$. 
::: 

::: {#exr- } 
If  
$\{\vec{v}_1,\vec{v}_2, \vec{v}_3\}$ 
is a linearly independent set of vectors in $V$, show that  
$\{\vec{v}_1+\vec{v}_2,\vec{v}_2+\vec{v}_3, \vec{v}_3+\vec{v}_1\}$ 
is also a linearly independent set of vectors in $V$. 
::: 

::: {#exr- } 
Let $\{\vec{v}_1,\vec{v}_2, \vec{v}_3\}$ be a linearly dependent set. Show that at least one of the $\vec{v}_i$ is a linear combination of the others. 
::: 

::: {#exr- } 
Prove or provide a counterexample to the following statement. If a set of vectors $T$ spans the vector space $V$, then $T$ is linearly independent. 
::: 

::: {#exr- } 
Which of the following are not a basis for $\mathbb{R}^3$?
\ 
- $\vec{v_1}=\vectorthree{1}{0}{0}, \vec{v_2}=\vectorthree{0}{1}{1}, \vec{v_3}=\vectorthree{1}{-1}{-1}$
- $\vec{u_1}=\vectorthree{0}{0}{1}, \vec{u_2}=\vectorthree{1}{0}{1}, \vec{u_3}=\vectorthree{2}{3}{4}$
 
::: 

::: {#exr- } 
Let $S$ be the space spanned by the vectors
$$
\vec{v}_1=\vectorfour{1}{0}{1}{1}
\quad
\vec{v}_1=\vectorfour{-1}{-3}{1}{0}
\quad
\vec{v}_1=\vectorfour{2}{3}{0}{1}
\quad
\vec{v}_1=\vectorfour{2}{0}{2}{2}
$$
Find the dimension of $S$ and a subset of $T$ which could serve as a basis for $S$. 
::: 

::: {#exr- } 
Let $\{\vec{v}_1, \vec{v}_2, ..., \vec{v}_n\}$ be a basis for $V$, and suppose that 
$\vec{u}
=a_1 \vec{v_1}+a_2 \vec{v_2}+\cdots + a_n \vec{v_n}$ with $a_1\neq 0$. Prove that 
$\{\vec{u}, \vec{v}_2, ..., \vec{v}_n\}$ is also a basis for $V$.
::: 

::: {#exr- } 
Let 
$S=\text{span}(\vec{v}_1,\vec{v}_2,\vec{v}_3)$ 
and 
$T=\text{span}(\vec{u}_1,\vec{u}_2,\vec{u}_3)$ 
where $\vec{v}_i$ and $\vec{u}_i$ are defined as follows. 
$$
\vec{v}_1=\vectorfour{1}{-1}{2}{0}
\quad
\vec{v}_2=\vectorfour{2}{1}{1}{1}
\quad
\vec{v}_3=\vectorfour{3}{-1}{2}{-1}
\qquad
\vec{u}_1=\vectorfour{3}{0}{3}{1}
\quad
\vec{u}_2=\vectorfour{1}{2}{-1}{1}
\quad
\vec{u}_3=\vectorfour{4}{-1}{5}{1}
$$
Is one of these two subspaces strictly contained in the other or are they equal?
::: 

::: {#exr- } 
Let 
$S=\text{span}(\vec{v}_1,\vec{v}_2,\vec{v}_3)$ where $\vec{v}_i$ are defined as follows. 
$$
\vec{v}_1=\vectorfour{1}{2}{3}{1}
\qquad
\vec{v}_2=\vectorfour{2}{-1}{1}{-3}
\qquad
\vec{v}_3=\vectorfour{1}{3}{4}{2}
\qquad \text{and}\qquad
\vec{u}=\vectorfour{1}{2}{3}{1}
$$
Is the vector $\vec{u}$ in $S$?
::: 

::: {#exr- } 
If possible, find a value of $a$ so that the vectors 
$$
\vectorthree{1}{2}{a}
\qquad
\vectorthree{0}{1}{a-1}
\qquad
\vectorthree{3}{4}{5}
\qquad
$$
are linearly independent. 
::: 

::: {#exr- } 
Let 
$S=\text{span}(\vec{v}_1,\vec{v}_2,\vec{v}_3)$ where $\vec{v}_i$ are defined as follows. 
$$
\vec{v}_1=\vectorfour{1}{-1}{2}{3}
\qquad
\vec{v}_2=\vectorfour{1}{0}{1}{0}
\qquad
\vec{v}_3=\vectorfour{3}{-2}{5}{7}
\qquad \text{and}\qquad
\vec{u}=\vectorfour{1}{1}{0}{-1}
$$
Find a basis of $S$ which includes the vector $\vec{u}$. 
::: 

::: {#exr- } 
Find a vector $\vec{u}$ in $\mathbb{R}^4$ such that $\vec{u}$ and the vectors
$$
\vec{v}_1=\vectorfour{1}{-1}{-1}{1}
\qquad
\vec{v}_2=\vectorfour{1}{0}{1}{1}
\qquad
\vec{v}_3=\vectorfour{1}{2}{1}{1}
$$
for a basis of $\mathbb{R}^4$. 
::: 

::: {#exr- } 
Show that every subspace of $V$ has no more than $n$ linearly independent vectors. 
::: 

::: {#exr- } 
Find two bases of $\mathbb{R}^4$ that have only the vectors $\vec{e}_3$ and $\vec{e}_4$ in common.
::: 

::: {#exr- } 
Prove that if a list of vectors is linearly independent so is any sublist. 
::: 

::: {#exr- } 
Suppose $\vec{v}_1,\vec{v}_2, \vec{v}_3$ and $\vec{v}_1, \vec{v}_2, \vec{v}_4$ are two sets of linearly dependent vectors, and suppose that $\vec{v}_1$ and $\vec{v}_2$ are linearly independent. 
Prove that any set of three vectors chosen from 
$\vec{v}_1, \vec{v}_2, \vec{v}_3, \vec{v}_4$ is linearly dependent.
::: 

::: {#exr- } 
If $\vec{u}$ and $\vec{v}$ are linearly independent vectors in $V$, prove that the vectors 
$a\vec{u}+b\vec{v}$ and $c\vec{u}+d\vec{v}$ 
are also linearly independent if and only if $ad-bc\neq 0$. 
::: 

::: {#exr- } 
\label{ex:spnlinbasis}
Complete the proof of \ref{prop:spnlinbasis}.
::: 

::: {#exr- } 
Let $U$ be the collection of vectors that satisfy the equations $x+y+z=0$ and $x+2y-z=0$. Show $U$ is a subspace of $\mathbb{R}^3$, find a basis for $U$,  and find $\dim(U)$.
::: 

::: {#exr- } 
Let $U$ be the collection of vectors that satisfy the equations $x+y+z=0$, $x+2y-z=0$, and $y-2z=0$. Show $U$ is a subspace of $\mathbb{R}^3$, find a basis for $U$,  and find $\dim(U)$.
::: 

::: {#exr- } 
Show that the only subspaces of $\mathbb{R}$ are 
$\{\vec{0}\}$ and $\{\mathbb{R}\}$.
::: 

::: {#exr- } 
Show that the only subspaces of $\mathbb{R}^2$ are 
$\{\vec{0}\}$, $\{\mathbb{R}^2\}$, and any set consisting of all scalar multiples of a nonzero vector. 
Describe these subspaces geometrically. 
::: 

::: {#exr- } 
Determine the various types of subspaces of $\mathbb{R}^3$ and describe them geometrically. 
::: 

::: {#exr- } 
For $\vec{b}\neq\vec{0}$, show that the set of solutions of the $n\times m$ linear system $A \vec{x}=\vec{b}$, is not a subspace of $V$. 
::: 

::: {#exr- } 
Suppose that 
$\vec{v}_1, \vec{v}_2, ..., \vec{v}_n$ 
are linearly independent 
in $\mathbb{R}^n$. Show that if $A$ is an $n\times n$ matrix with $\text{rref}(A)=I_n$, then 
$A\vec{v}_1, A\vec{v}_2, ..., A\vec{v}_n$
are also linearly independent in $\mathbb{R}^n$.
::: 

::: {#exr- } 
Let $S=\{\vlist{v}{s}\}$ 
and
$T=\{\vlist{u}{t}\}$ 
be two sets of vectors in $V$ 
where each $\vec{u}_i$, $(i=1,2,...,t)$ is a linear combination of the vectors in $S$. 
Show that 
$\vec{w}=\lincomb{a}{u}{t}$ 
is a linear combination of the vectors in $S$. 
::: 

::: {#exr- } 
Let $S=\{\vlist{v}{m}\}$ be a set of non-zero vectors in a vector space $V$ such that every vector in $V$ can be uniquely as a linear combination of the vectors in $S$. 
Prove that $S$ is a basis for $V$. 
::: 

::: {#exr- } 
Find a basis for the solution space of the homogeneous system 
$(\lambda I_n-A)\vec{x}=\vec{0}$ 
for the given $\lambda$ and $A$.
 
- $\lambda=1, A=\begin{bmatrix} 0 & 0 & 1 \\ 1 & 0 & -3 \\ 0 & 1 & 3 \end{bmatrix}$
- $\lambda=2, A=\begin{bmatrix} -2 & 0 & 0 \\ 0 & -2 & -3 \\ 0 & 4 & 5 \end{bmatrix}$
 
::: 

::: {#exr- } 
\label{ex:roweqtoidn}
Prove \ref{prop:roweqtoidn}.
::: 

::: {#exr- } 
\label{ex:explincomb}
Prove \ref{cor:explincomb}.
::: 

::: {#exr- } 
\label{ex:sumprop}
Prove \ref{sumprop}.
::: 


