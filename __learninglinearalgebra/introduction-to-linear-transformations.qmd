---
pagetitle: "Introduction to Linear Transformations - Learning Linear Algebra"
---
# Introduction to Linear Transformations


A linear transformation is a function of the form $\vec y =A \vec x$ where $A$ is an $n\times m$ matrix.
More specifically, a linear transformation is a function that assigns to each $\vec x\in \mathbb{R}^m$, a unique $\vec y\in \mathbb{R}^n$ -- and this assignment is defined by a matrix $A$. 
When $A$ is the identity matrix and $T(\vec x)=A \vec x$ we call $T$ the \index{identity transformation} **identity transformation** .

::: {#def- } 
\label{lintrdef}
A function $T$ from $\mathbb{R}^m$ to $\mathbb{R}^n$ is called a \index{linear transformation} **linear transformation**  if there exists an $n\times m$ matrix $A$ such that $T(\vec x)=A \vec x$, for all $\vec x$ in the vector space $\vec R^m$.
::: 

::: {#lem- } 
Let $T$ be a linear transformation from $\mathbb{R}^m$ to $\mathbb{R}^n$, then the matrix of $T$ is
\begin{equation}
\label{trancol}
A=\begin{bmatrix} | &  & | \\ T(\vec e_1) & \cdots & T(\vec e_m) \\ | &  & | \end{bmatrix}
\end{equation}
where $\vec e_i$ (for $0\leq i \leq m$) are the standard vectors.
::: 

::: {.proof }
Suppose $T$ is a linear transformation from $\mathbb{R}^m$ to $\mathbb{R}^n$, then there exists an $n\times m$ matrix $A$ such that $T(\vec x)=A\vec x$ for all $\vec x\in \mathbb{R}^m$. Let $\vec e_1, ..., \vec e_m$ be the standard vectors of $\mathbb{R}^m$ and let 
$A=[a_{ij}]$, then 
$$
T(\vec e_1)=A \vec e_1=
\begin{bmatrix}
a_{11} & \cdots & a_{1m} \\ 
\vdots & \cdots & \vdots \\ 
a_{n1} & \cdots & a_{nm} 
\end{bmatrix} 
\vectorthree{1}{\vdots}{0}
=\vectorthree{a_{11}}{\vdots}{a_{n1}}
$$
$$
\vdots
$$
$$
T(\vec e_m)=A \vec e_m=
\begin{bmatrix}
a_{11} & \cdots & a_{1m} \\ 
\vdots & \cdots & \vdots \\ 
a_{n1} & \cdots & a_{nm} 
\end{bmatrix} 
\vectorthree{0}{\vdots}{1}
=\vectorthree{a_{1m}}{\vdots}{a_{nm}}
$$
which are the columns of the matrix $A$.
::: 

::: {#exm- } 
Determine the linear transformation $T$ given by the system of linear equations:
$$
\begin{array}{l}
y_1=  7x_1+3x_2-9x_3+8x_4 \\
y_2 =  6x_1+2x_2-8x_3+7x_4 \\
y_3 =  8x_1+4x_2+7x_4
\end{array}
$$
The matrix of the linear transformation is 
$A=\begin{bmatrix} 7 & 3 & -9 & 8 \\ 6 & 2 & -8 & 7 \\ 8 & 4 & 0 & 7 \end{bmatrix}$
since
$$
T(\vec e_1)=\vectorthree{7}{6}{8},  
\qquad
T(\vec e_2)=\vectorthree{3}{2}{4}, 
\qquad 
T(\vec e_3)=\vectorthree{-9}{-8}{0}, 
\qquad 
T(\vec e_4)=\vectorthree{8}{7}{7}.
$$
Notice $T$ is a linear transformation from $\mathbb{R}^4$ to 
$\mathbb{R}^3$ and $A$ is a $3\times 4$ matrix. 

::: 

::: {#exm- } 
Is the transformation $T(\vec{x})=\vec{v}\cdot \vec{x}$ from $\mathbb{R}^3$ to $\mathbb{R}$ a linear transformation? If so, find the matrix of $T$. 
Let $\vec{v}=\vectorthree{v_1}{v_2}{v_3}$. Then 
$$
T(\vec{x})=\vec{v}\cdot \vec{x}=\vectorthree{v_1}{v_2}{v_3}\cdot \vectorthree{x_1}{x_2}{x_3}=v_1 x_1+v_2 x_2+v_3 x_3 =
\begin{bmatrix}v_1 & v_2 & v_3 \end{bmatrix}\vec{x}.$$
Therefore, by \ref{lintrdef}, $T$ is a linear transformation with matrix 
$$
\begin{bmatrix}v_1 & v_2 & v_3 \end{bmatrix}.
$$

::: 

::: {#exm- } 
Is the transformation $T(\vec{x})=\vec{v}\times \vec{x}$ from $\mathbb{R}^3$ to $\mathbb{R}$ a linear transformation? If so, find the matrix of $T$. 
Let $\vec{v}=\vectorthree{v_1}{v_2}{v_3}$. Then 
$$
T(\vec{x})=\vec{v}\times \vec{x}=\vectorthree{v_1}{v_2}{v_3}\times \vectorthree{x_1}{x_2}{x_3}
=\begin{bmatrix}v_2x_3 -v_3x_2\\ v_3x_1-v_1x_3 \\ v_1 x_2-v_2x_1 \end{bmatrix}
=\begin{bmatrix}0 & -v_3 & v_2\\ v_3 & 0 & -v_1 \\ -v_2 & v_1 & 0 \end{bmatrix}\vec{x}
$$
Therefore, by \ref{lintrdef}, $T$ is a linear transformation with matrix 
$$
\begin{bmatrix}0 & -v_3 & v_2\\ v_3 & 0 & -v_1 \\ -v_2 & v_1 & 0 \end{bmatrix}.
$$
::: 

::: {#thm- } 
\label{thm:linthm}
A function $T$ from $\mathbb{R}^m$ to $\mathbb{R}^n$ is a linear transformation if and only if both of the following hold:
 
- $T(\vec v+ \vec w)=T(\vec v)+T(\vec w)$ for all vectors $\vec v$ and $\vec w$ in $\mathbb{R}^m$, and
- $T(k \vec v)=k T(\vec v)$ for all vectors $\vec v$ in $\mathbb{R}^m$ and all scalars $k$.
 
::: 

::: {.proof }
Suppose $T$ is a linear transformation from $\mathbb{R}^m$ to $\mathbb{R}^n$, then there exists an $n\times m$ matrix $A$ such that $T(\vec x)=A\vec x$ for all $\vec x\in \mathbb{R}^m$. The proof of each part follows.
 
- Let $\vec u, \vec v\in \mathbb{R}^m$, then $T(\vec v+\vec w)=A (\vec v+\vec w)=A \vec v+A \vec w=T(\vec v)+T(\vec w)$.
- Let $\vec v\in \mathbb{R}^m$ and $k\in \mathbb{R}$. Then $T(k \vec v)=A(k \vec v)=(A k) \vec v=k(A \vec v)=k T(\vec v)$.
 
Now suppose both (i) and (ii) hold. We need to find a matrix $A$ such that $Tx =A \vec x$ for all $\vec x\in \mathbb{R}^m$. We can use the standard vectors in $\mathbb{R}^m$. Then by  \ref{trancol}, 
\begin{align*}
T(\vec x)  & = T(x \vec e_1+\cdots + x_m \vec e_m)
=T(x_1\vec e_1)+\cdots +T(x_m\vec e_m) \\
& = x_1 T(\vec e_1)+\cdots +x_m T(\vec e_m) 
=
\begin{bmatrix} | &  & | \\ 
T(\vec e_1) & \cdots & T(\vec e_m) \\ 
| &  & | \end{bmatrix} 
\vectorthree{x_1}{\vdots}{x_m}=A\vec x
\end{align*}
as desired.
::: 

::: {#exm- } 
Write $\vectorthree{-1}{1}{0}$ as a linear combination of $\vectorthree{3}{-1}{2}$ and $\vectorthree{1}{0}{1}$. 
Let $T:\mathbb{R}^3\to\mathbb{R}$ be a linear transformation with 
$T\vectorthree{3}{-1}{2}=5$ 
and 
$T\vectorthree{1}{0}{1}=2$. 
Find 
$T\vectorthree{-1}{1}{0}$. 
Notice
$$
\vectorthree{-1}{1}{0}=
(-1)\vectorthree{3}{-1}{2}+2\vectorthree{1}{0}{1}.
$$
Therefore, 
$$
T\vectorthree{-1}{1}{0}
=T\left((-1)\vectorthree{3}{-1}{2}+2\vectorthree{1}{0}{1}\right)
=(-1)\, T\vectorthree{3}{-1}{2}+2 \, T\vectorthree{1}{0}{1}
=-1.
$$
::: 

::: {#exm- } 
Let $T:\mathbb{R}^2\to\mathbb{R}^2$ be defined by $T\vectortwo{x_1}{x_2}=\vectortwo{2x_1}{x_2^2}$. Is $T$ a linear transformation?
Let $\alpha=\vectortwo{x_1}{x_2}$ and $\beta=\vectortwo{y_1}{y_2}$. Then
\begin{align*}
T(\alpha+\beta) & 
=T\left(\vectortwo{x_1}{x_2}+\vectortwo{y_1}{y_2}\right) 
=T\vectortwo{x_1+y_1}{x_2+y_2}
=\vectortwo{2(x_1+y_1)}{(x_2+y_2)^2}
\end{align*}
On the other hand
\begin{align*}
T(\alpha)+T(\beta) & 
=T\vectortwo{x_1}{x_2}+T\vectortwo{y_1}{y_2} 
=\vectortwo{2x_1}{x_2^2} + \vectortwo{2y_1}{y_2^2} 
= \vectortwo{2(x_1+y_1)}{x_2^2+y_2^2}
\end{align*}
Since $T(\alpha+\beta)\neq T(\alpha)+T(\beta)$, we use \ref{thm:linthm} to conclude that $T$ is not  linear transformation. 

::: 

::: {#thm- }  
Let $T$ be a linear transformation from $\mathbb{R}^m$ to 
$\mathbb{R}^n$.
 
- If $\vec{0}_m$ is the zero vector in $\mathbb{R}^m$, then $T(\vec{0}_m)$ is the zero vector in $\mathbb{R}^n$.
- For all $\vec{v}$ in $\mathbb{R}^m$, $T(-\vec{v})=-T(\vec{v})$.
- For all $\vec{u}, \vec{v}$ in $\mathbb{R}^m$, 
$T(\vec{u}-\vec{v})=T(\vec{u})-T(\vec{v})$.
- For all $a_1,...,a_n\in \mathbb{R}$ and for all $\vec{v}_1, ...., \vec{v}_n\in \mathbb{R}^m$, 
$$
T(a_1\vec{v}_1+a_2\vec{v}_2+\cdots + a_n\vec{v}_n)
=a_1T(\vec{v}_1)+a_2T(\vec{v}_2)+\cdots+a_nT(\vec{v}_n).
$$
  
::: 

::: {.proof }
There proof is for the reader.
::: 


