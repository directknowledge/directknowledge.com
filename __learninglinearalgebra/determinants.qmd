---
pagetitle: "Determinants - Learning Linear Algebra"
---
# Determinants


The determinant function can be defined by essentially two different methods. 
The advantage of the first definition, one which uses permutations, is that it provides an actual formula for $\det(A)$, a fact of theoretical importance. 
The disadvantage is that, quite frankly, computing a determinant by this method can be cumbersome.

 
- A \index{pattern} **pattern** in an $n\times n$ matrix is a way to choose $n$ entries of the matrix so that there is one chosen entry in each row and in each column of $A$. 
- With a pattern $P$ we associate the \index{product} **product**  of all its entries, denoted by prod $P$.
- Two entries in a pattern are said to be \index{inverted} **inverted**  if one of them is located to the right and above the other in the matrix.
- The \index{signature} **signature**  of a pattern $P$ is defined as $\text{sgn} P=(-1)^{(\text{number of inversions in } P)}.$
 

::: {#def- } 
The \index{determinant} **determinant**  of an $n\times n$ matrix $A$ is defined as 
$$
\det (A)=\sum (\text{sgn } P) (\text{prod } P)
$$
where the sum is taken over all $n!$ patterns $P$.
::: 

::: {#exm- } 
Use the definition of an $n\times n$ determinant to prove the formulas for determinants for $2\times 2$ matrices and $3\times 3$ matrices.
We find
$$
\begin{vmatrix} 
a_{11} & a_{12} \\ 
a_{21} & a_{22} 
\end{vmatrix}
=a_{11}a_{22}-a_{12}a_{21}
$$
$$
\begin{vmatrix} 
a_{11} & a_{12} & a_{13} \\ 
a_{21} & a_{22} & a_{23} \\ 
a_{31} & a_{32} & a_{33} 
\end{vmatrix}
=a_{11} a_{22} a_{33} + a_{12} a_{23} a_{31} 
+ a_{13} a_{21} a_{32} - a_{11} a_{23} a_{32} 
- a_{12} a_{21} a_{33} -a_{13} a_{22} a_{31}
$$
::: 

::: {#exm- } 
Find the determinant of the following matrix using the definition of determinant
$$ 
M=\begin{bmatrix}  
0 & 0 & 1 & 0 & 2 \\
5 & 4 & 3 & 2 & 1 \\
1 & 3 & 5 & 0 & 7 \\
2 & 0 & 4 & 0 & 6 \\
0 & 0 & 3 & 0 & 4
\end{bmatrix} .
$$
There are only two patterns with a nonzero product.
Therefore 
$$
\det M= (-1)^8(2\cdot 3\cdot 3\cdot2\cdot2)+(-1)^{5}(2\cdot 3\cdot 1\cdot 2 \cdot 4)=24.
$$
::: 

::: {#lem- } 
The determinant of an (upper or lower) triangular matrix $A$ is the product of the diagonal entries of the matrix. 
::: 

::: {.proof }
Suppose 
$$
A=
\begin{bmatrix} 
a_{11} & a_{12} & \cdots & a_{1n} \\
0 & a_{22} & \ddots & \vdots \\
\vdots & \ddots & \ddots & a_{n-1,n} \\
0 & \cdots & 0 & a_{nn} & 
\end{bmatrix} 
\qquad \text{or} \qquad
A=
\begin{bmatrix} 
a_{11} & 0 & \cdots & 0 \\
a_{21} & a_{22} & \ddots & \vdots \\
\vdots & \ddots & \ddots & 0 \\
a_{n,1} & \cdots & a_{n,n-1} & a_{nn} & 
\end{bmatrix}.
$$
To have a nonzero product a pattern must contain the first component of the first column, then the second component of the second column, and so on. Thus, only the diagonal pattern $P$ makes a nonzero contribution. We conclude that 
$$
\det A = (\text{sgn } P)(\text{prod }P)=(-1)^0 a_{11} \cdots a_{nn}= a_{11} \cdots a_{nn}.
$$
::: 

::: {#thm- } 
\label{blockdetprod}
Prove that if $A$ and $C$ are square matrices (not necessarily of the same size), then 
$$
\det \begin{bmatrix}  A & B \\ 0 & C \end{bmatrix} 
= \det \begin{bmatrix}  A & 0 \\ B & C \end{bmatrix} 
= (\det A)(\det C).
$$
::: 

::: {.proof }
The proof is left for the reader.
::: 

::: {#exm- } 
Find the determinant of the matrix 
$$
M=
\begin{bmatrix} 
a_{11} & a_{12} & b_{11} & b_{12} \\
a_{21} & a_{22} & b_{21} & b_{22} \\
0 & 0 & c_{11} & c_{12} \\
0 & 0 & c_{21} & c_{22}
\end{bmatrix}.
$$
Let 
$$
A=
\begin{bmatrix} 
a_{11} & a_{12} \\
a_{21} & a_{22} 
\end{bmatrix} 
$$ 
and 
$$
C=
\begin{bmatrix} 
c_{11} & c_{12} \\
c_{21} & c_{22}
\end{bmatrix},
$$
then 
$$
\det M=(\det A)(\det B)=(a_{11}a_{22}-a_{21}a_{12})(c_{11}c_{22}-c_{21}c_{12}).
$$
::: 

::: {#exm- } 
Find $2\times 2$ matrices $A, B, C, D$ such that 
$$
\det \begin{bmatrix} A & B \\ C & D \end{bmatrix} \neq (\det A)(\det D)-(\det B)(\det C).
$$
The standard basis for $\mathbb{R}^{2 \times 2}$ works.
::: 



The \index{trace} **trace**  of an $n\times n$ matrix $A$ is defined as the sum of the diagonal entries of $A$  and is denoted by $\text{trace}(A)$. 

::: {#thm- } 
If $A$ is a square matrix then $\det (A^T)=\det (A)$ and $\text{trace}(A^T)=\text{trace}(A)$.
::: 

::: {.proof }
For each pattern $P$ in $A$ we can consider the corresponding (transposed) pattern $P^T$ in $A^T$. The two patterns $P$ and $P^T$ involve the same numbers, and they contain the same number of inversions, but the role of the two numbers in each inversion is reversed. Therefore, the two patterns make the same contribution to the respective determinant and so, $(\text{sgn} P)(\text{prod} P)=(\text{sgn} P^T)(\text{prod} P^T)$. Therefore, we conclude that $\det(A)=\det(A^T)$.
::: 

::: {#exm- } 
Find the determinant of the matrices $M$, $N$, $M^T$, and $N^T$ where 
$$
M=\begin{bmatrix} 4 & 3 & 2 & 1 \\ 0 & 5 & 6 & 7 \\ 0 & 0 & 3 & 2 \\ 0 & 0 & 0 & 4 \end{bmatrix} 
\qquad \text{and} \qquad 
N=\begin{bmatrix}  0 & 0 & 0 & 8 \\ 0 & 0 & 2 & 3 \\ 0 & 7 & 6 & 5 \\ 1 & 2 & 3 & 4  \end{bmatrix} .
$$
Since $M$ and $N$ are upper triangular and lower triangular, respectively,
$$
\det M= 4\cdot 5\cdot 3\cdot 4=240
\qquad \text{and} \qquad 
\det N= 1\cdot 7\cdot 2\cdot 8=112.
$$
Since 
$$
M^T=\begin{bmatrix}  4 & 0 & 0 & 0 \\3 & 5 & 0 & 0 \\ 2 & 6 & 3 & 0 \\1 & 7 & 2 & 4\end{bmatrix} 
\qquad \text{and} \qquad 
N^T=\begin{bmatrix}   0 & 0 & 0 & 1 \\ 0 & 0 & 7 & 2 \\ 0 & 2 & 6 & 3\\ 8 & 3 & 5 & 4 \end{bmatrix}$$
and these matrices are lower triangular and upper triangular, respectively,
$$
\det M=\det M^T 
\qquad \text{and} \qquad 
\det N= \det N^T.
$$

::: 

::: {#lem- } 
\label{detgjrlemma}
Suppose $A$ and $B$ are $n\times n$ matrices. 
 
- \label{detgjrlemmaone}
If $B$ is obtained from $A$ by dividing a row of $A$ by a scalar $k$, then $\det B=(1/k)\det (A)$.
- \label{detgjrlemmatwo}
If $B$ is obtained from $A$ by a row swap, then $\det(B)=-\det(A)$.
- \label{detgjrlemmathree}
If $B$ is obtained from $A$ by adding a multiple of a row of $A$ to another row, then $\det(B)=\det(A)$.
- \label{detgjrlemmafour}
Suppose you swap rows $s$ times as you transform $A$ into $B$, and you divide various rows by the scalars $k_1,\ldots ,k_r$, then 
$$
\det(A)=(-1)^sk_1\cdots k_r\det(B).
$$
- \label{detgjrlemmafive}
If $s$ is the number of row swaps and $k_1,\ldots ,k_r$ are the scalars used to divide rows to obtain pivots in producing $\text{rref}(A)$ when performing Gauss-Jordan elimination, then 
\begin{equation}
\label{detgjr}
\det(A)=(-1)^sk_1\cdots k_r\det(\text{rref} (A)).
\end{equation}
::: 

::: {.proof }
The proof is left for the reader.
::: 

::: {#exm- } 
Use Gauss-Jordan elimination to find the determinant of the matrix 
$$
M=
\begin{bmatrix} 
1 & 1 & 1 & 1 & 1 \\ 
1 & 2 & 3 & 4 & 5 \\ 
1 & 3 & 6 & 10 & 15 \\ 
1 & 4 & 10 & 20 & 35  \\ 
1 & 5 & 15 & 35 & 70 
\end{bmatrix} .
$$
Using elementary row operations $R_2\to R_2-R_1$, $R_3\to R_3-R_1$, $R_4\to R_4-R_1$, and $R_5\to R_5-R_1$, 
$$
M \rightarrow 
M_1=
\begin{bmatrix} 
1 & 1 & 1 & 1 & 1 \\ 
0 & 1 & 2 & 3 & 4 \\ 
0 & 2 & 5 & 9 & 14 \\ 
0 & 3 & 9 & 19 & 34  \\ 
0 & 4 & 14 & 34 & 69 
\end{bmatrix} 
\qquad \text{with} \qquad 
\det(M)=\det(M_1).
$$
Using elementary row operations $R_3\to -2R2+R_3$, $R_4\to -3R2+R_4$, and $R_5\to -4R2+R_5$,
$$
M_1 \rightarrow 
M_2=
\begin{bmatrix} 
1 & 1 & 1 & 1 & 1 \\ 
0 & 1 & 2 & 3 & 4 \\ 
0 & 0 & 1 & 3 & 6 \\ 
0 & 0 & 3 & 10 & 22  \\ 
0 & 0 & 6 & 22 & 53 
\end{bmatrix} 
\qquad \text{with} \qquad 
\det(M_1)=\det(M_2).
$$
Using elementary row operations $R_4\to -3R3+R_4$, $R_5\to -6R3+R_5$,
$$
M_2 \rightarrow 
M_3=
\begin{bmatrix} 
1 & 1 & 1 & 1 & 1 \\ 
0 & 1 & 2 & 3 & 4 \\ 
0 & 0 & 1 & 3 & 6 \\ 
0 & 0 & 0 & 1 & 4  \\ 
0 & 0 & 0 & 4 & 17 
\end{bmatrix} 
\qquad \text{with} \qquad 
\det(M_2)=\det(M_3).
$$
Using the elementary row operation $R_5\to -4R4+R_5$,
$$
M_3 \rightarrow 
M_4=
\begin{bmatrix} 
1 & 1 & 1 & 1 & 1 \\ 
0 & 1 & 2 & 3 & 4 \\ 
0 & 0 & 1 & 3 & 6 \\ 
0 & 0 & 0 & 1 & 4  \\ 
0 & 0 & 0 & 0 & 1 
\end{bmatrix} 
\qquad \text{with} \qquad 
\det(M_3)=\det(M_4).
$$
Therefore $\det(M)=\det(M_4)=1$.
::: 

::: {#thm- } 
A square matrix $A$ is invertible if and only if $\det A\neq 0$.
::: 

::: {.proof }
If $A$ is invertible, then $\text{rref}(A)=I_n$, so that by \ref{detgjr} $\det(A)\neq 0$. Conversely, by contrapositive, if $A$ is noninvertible, then the last row of $\text{rref}(A)$ contains all zeros, so that $\det(\text{rref}(A))=0$. Therefore,  \ref{detgjr} shows $\det(A)=0$.
::: 

::: {#exm- } 
Consider a $4\times 4$ matrix $A$ with rows $\vec v_1, \vec v_2, \vec v_3, \vec v_4$. If $\det (A)=8$ find the determinant of the matrix 
$$
\vectorfour{\vec v_4}{\vec v_2+9\vec v_4}{-\vec v_3}{\vec v_1}. 
$$
Switching rows 1 and 4, then multiplying row 3 by $-1$, then adding $-9 R_4$ to $R_2$ yields,
$$
\det \vectorfour{\vec v_4}{\vec v_2+9\vec v_4}{-\vec v_3}{\vec v_1}
=- \det \vectorfour{\vec v_1}{\vec v_2+9\vec v_4}{-\vec v_3}{\vec v_4}
= \det \vectorfour{\vec v_1}{\vec v_2+9\vec v_4}{\vec v_3}{\vec v_4}
= \det \vectorfour{\vec v_1}{\vec v_2}{\vec v_3}{\vec v_4}
=8.
$$
::: 

::: {#exm- } 
Determine whether the linear transformation given by the following linear equations is an isomorphism. If so, find the inverse transformation.
$$
\left\{ \begin{array}{rl}
y_1&=x_1+2x_2+3x_3 \\
y_2& =3x_2+4x_3 \\
y_3 &= x_1+6x_2 +5x_3.
\end{array}
\right.
$$
The coefficient matrix is 
$$
A=\begin{bmatrix}  
 1 & 2 & 3 \\
 0 & 3 & 4 \\
 1 & 6 & 5
\end{bmatrix} .
$$
We will form the matrix $\left[ A | I_3 \right]$ and apply row operations, thus completing two tasks at once. This process will convert the matrix $A$ into an upper-triangular matrix and thus be able to determine the determinant of $A$ (of thus of the linear transformation) before we actually find the inverse matrix. If at any time we see the determinant will be 0 we will stop and decide that the linear transformation is not an isomorphism. Otherwise we continue applying row operations until we determine $A^{-1}$. 
After completing these steps we find 
$$
A^{-1}=
\begin{bmatrix}  
9/10 & -4/5 & 1/10 \\
-2/5 & -1/5 & 2/5 \\
3/10 & 2/5 & -3/10
\end{bmatrix} .
$$
Therefore the linear transformation is an isomorphism and the inverse transformation is 
$$
\left\{ \begin{array}{rl}
x_1&= \frac{9}{10}y_1 -\frac{4}{5}y_2+\frac{1}{10}y_3 \\
x_2& = -\frac{2}{5}y_1 -\frac{1}{5}y_2+\frac{2}{5}y_3 \\
x_3 &=  \frac{3}{10} y_1+ \frac{2}{5}y_2 -\frac{3}{10}y_3.
\end{array}
\right.
$$
::: 

::: {#exm- } 
\label{vandermondematrixexercise}
The matrix defined by 
\begin{equation}
\label{vandermondematrix}
V_n=
\begin{bmatrix}
1 & x_1 & x_1^2 & \cdots & x_1^{n-1} \\
1 & x_2 & x_2^2 & \cdots & x_2^{n-1} \\
1 & x_3 & x_3^2 & \cdots & x_3^{n-1} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
1 & x_n & x_n^2 & \cdots & x_n^{n-1} \\
\end{bmatrix}
\end{equation}
is called the $n$-th \index{Vandermonde matrix} **Vandermonde matrix** . Prove 
\begin{equation}
\label{vandermondedet}
det(V_n)=\prod_{1\leq i<j\leq n} (x_j-x_i).
\end{equation}
By \ref{detgjrlemma}-\eqref{detgjrlemmathree}, we can perform the row operations 
$R_i\rightarrow R_i-R_1$ for $2\leq i \leq n$ leaving the value of the determinant unchanged, so
\begin{equation}
\det(V_n)
=
\begin{vmatrix}
1 & x_1 & x_1^2 & \cdots & x_1^{n-1} \\
1 & x_2 & x_2^2 & \cdots & x_2^{n-1} \\
1 & x_3 & x_3^2 & \cdots & x_3^{n-1} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
1 & x_n & x_n^2 & \cdots & x_n^{n-1} \\
\end{vmatrix}
=
\begin{vmatrix}
1 & x_1 & x_1^2 & \cdots & x_1^{n-1} \\
0 & x_2-x_1 & x_2^2-x_1^2 & \cdots & x_2^{n-1}-x_1^{n-1} \\
0 & x_3-x_1 & x_3^2-x_1^2 & \cdots & x_3^{n-1}-x_1^{n-1} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
0 & x_n-x_1 & x_n^2-x_1^2 & \cdots & x_n^{n-1}-x_1^{n-1} \\
\end{vmatrix}
\end{equation}
By \ref{detgjrlemma}-\eqref{detgjrlemmathree} and \ref{propdettrace}-\eqref{propdettraceone}, we can perform the column operations 
$C_i\rightarrow C_{i}-x_1C_{i-1}$ for $2< i \leq n$ leaving the value of the determinant unchanged, so
\begin{equation}
=
\begin{vmatrix}
1 & 0 & 0 & \cdots & 0 \\
0 & x_2-x_1 & (x_2-x_1)x_2 & \cdots & (x_2-x_1)x_2^{n-2} \\
0 & x_3-x_1 & (x_3-x_1)x_3 & \cdots & (x_3-x_1)x_3^{n-2} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
0 & x_n-x_1 & (x_n-x_1)x_n & \cdots & (x_n-x_1)x_n^{n-2} \\
\end{vmatrix}
=
\prod_{k=2}^n (x_k-x_1) \det(V_{n-1}).
\end{equation}
This process ends with $\det(V_2)=x_n-x_{n-1}$ and so \ref{vandermondedet} follows.
::: 

::: {#exm- } 
Show the transformation 
$$
T(\vec x )=\det \begin{bmatrix}  \vec v_1 & \cdots & \vec v_{i-1} & \vec x & \vec v_{i+1} & \cdots & \vec v_n \end{bmatrix} 
$$
from $\mathbb{R}^{n\times 1}$ to $\mathbb{R}$ is a linear transformation.
Similarly, show the transformation 
$$
T(\vec x )=\det \begin{bmatrix}  \vec v_1 & \cdots & \vec v_{i-1} & \vec x & \vec v_{i+1} & \cdots & \vec v_n \end{bmatrix} ^T
$$ 
from $\mathbb{R}^{1\times n}$ to $\mathbb{R}$ is a linear transformation.
::: 

::: {#exm- } 
Find the image and kernel of the linear transformation
$$
T(\vec x)=\det \begin{bmatrix} \vec x & \vec u & \vec v \end{bmatrix} 
$$
from $\mathbb{R}^3$ to $\mathbb{R}$, where $\vec u =\vectorthree{2}{0}{0}^T$ and $\vec v=\vectorthree{0}{1}{3}^T$.
Notice that 
\begin{align*}
T(\vec e_1) &=\det \begin{bmatrix} 1 & 2 & 0 \\ 0 & 0 & 1 \\ 0 & 0 & 3 \end{bmatrix} = 0, \\
T(\vec e_2) &=\det \begin{bmatrix} 0 & 2 & 0 \\ 1 & 0 & 1 \\ 0 & 0 & 3 \end{bmatrix} 
=- \det \begin{bmatrix} 1 & 0 & 1 \\ 0 & 2 & 0 \\ 0 & 0 & 3 \end{bmatrix}
=-6, \quad \text{and} \\
T(\vec e_3) &=\det \begin{bmatrix} 0 & 2 & 0 \\ 0 & 0 & 1 \\ 1 & 0 & 3 \end{bmatrix} 
= \det \begin{bmatrix} 1 & 0 & 3 \\ 0 & 2 & 0 \\ 0 & 0 & 1 \end{bmatrix}
=2.
\end{align*}
Therefore, the matrix of $T$ with respect to the standard basis $\vec e_1, \vec e_2, \vec e_3$ is $B=\begin{bmatrix} 0 & -6 & 2 \end{bmatrix}$, and so $T(\vec x)=B \vec x$. To find the kernel we solve the system 
$$
\begin{bmatrix} 0 & -6 & 2 \end{bmatrix} \vectorthree{x_1}{x_2}{x_3}^T=0.
$$
Thus the kernel has basis 
$$
\left ( \vectorthree{1}{0}{0}^T, \vectorthree{0}{1}{1}^T\right )
$$
which means the dimension of the kernel of $T$ is 2, and so by the rank nullity theorem the dimension of the image of $T$ is 1. 
::: 

::: {#exm- } 
Consider the linear transformation
$$
T(\vec x)=\det \begin{bmatrix} \vec x & \vec v_2 & \vec v_3 & \cdots & v_n \end{bmatrix} 
$$
from $\mathbb{R}^n$ to $\mathbb{R}$, where $\vec v_2, \vec v_3,\ldots ,\vec v_n$ are linearly independent vectors in $\mathbb{R}^n$. Describe the image and kernel of this transformation, and determine their dimensions. 
Since $\vec v_1,\ldots ,\vec v_n$ are linearly independent, $T(\vec x)=0$ only if $\vec x$ is a linear combination of the $\vec v_i$'s, (otherwise the matrix $\begin{bmatrix} \vec x & \vec v_1 & \cdots & \vec v_n\end{bmatrix}$ is invertible, and $T(\vec x)\neq 0$). Hence, the kernel of $T$ is the span of $\vec v_2,\ldots , \vec v_n$, an $(n-1)$-dimensional subspace of $\mathbb{R}^n$. The image of $T$ is the real line $\mathbb{R}$ (since it must be 1-dimensional).
::: 

::: {#exm- } 
For a fixed positive integer $n$, let $D$ be a function which assigns to any $n\times n$ matrix $A$ a number $D(A)$ such that 
 
- $D$ is linear in the rows,
- $D(B)=-D(A)$ if $B$ is obtained from $A$ by a row swap, and
- $D(I_n)=1$.
 
Show that $D(A)=\det(A)$ for all $n\times n$ matrices $A$.
First we comment that if a square matrix $A$ has two equal rows, then $D(A)=0$. Indeed, if we swap two equal rows and call the resulting matrix $B$, then $B=A$, so that $D(A)=D(B)=-D(A)$, by property (ii), and $D(A)=0$ as claimed. 

Next we need to understand how the elementary row operations affect $D$. Properties (i) and (ii) tell us about row multiplication and row swaps, but we still need to think about row additions. We will show that if $B$ is obtained from $A$ by adding $k$ times the $i$th row to the $j$th, then $D(B)=D(A)$, Let's label the row vectors of $A$ by $\vec v_1,.,,,\vec v_n$. By linearity of $D$ in the $j$th row (i) we have
$$
D(B)=D\left(\begin{bmatrix} \vdots \\ \vec v_i \\ \vdots \\ \vec v_j+k \vec v_i \\ \vdots  \end{bmatrix} \right)
=D(A)+kD\left(\begin{bmatrix} \vdots \\ \vec v_i \\ \vdots \\ \vec v_i \\ \vdots \end{bmatrix} \right)
=D(A).
$$
Note that in the last step we have used the remark made at the beginning. Now we can write 
$$
D(A)=(-1)^sk_1\cdots k_r D(\text{rref}(A))
$$ 
where $s$ is the number of row swaps and $k_1,\ldots ,k_r$ are scalars used to obtain the pivots in the Gaussian reduction. 

Next we observe that if $D(\text{rref}(A))=\det(\text{rref}(A))$ for all square matrices $A$. Indeed, if $A$ is invertible, then $\text{rref}(A)=I_n$, and $D(I_n)=1=\det(I_n)$ by property (iii). If $A$ fails to be invertible then 
$$
D(\text{rref}(A))=0=\det(\text{rref}(A)
$$ 
by linearity in the last row. 

It follows that 
$$
D(A)=(-1)^sk_1\cdots k_r D(\text{rref}(A))=(-1)^sk_1\cdots k_r \det(\text{rref}(A))=\det(A)
$$ 
as desired. 
::: 

::: {#thm- } [Properties of Determinant and Trace] \text{}
\label{propdettrace}
 
- If $A$ and $B$ are square matrices, then $\det (AB)=(\det A)(\det B)$.
- If $A$ and $B$ are square matrices of the same size, then $\text{trace}(AB)=\text{trace}(BA)$ and 
$\text{trace}(A+B)=\text{trace}(A)+\text{trace}(B)$.
- If $A$ and $B$ are similar matrices, then $\det(A)=\det(B)$ and $\text{trace}(A)=\text{trace}(B)$.
- If $A$ is an invertible matrix, then $\det (A^{-1})=(\det A)^{-1}$.
::: 

::: {.proof }
The proof of each part follows.
 
- Suppose $A=\begin{bmatrix} a_{i j} \end{bmatrix}$ and $B=\begin{bmatrix} b_{i j} \end{bmatrix}.$
The $i^\text{th}$ term on the diagonal of $A+B$ is $a_{i,i}+b_{i,i}$, thus
$$
\text{trace}(A+B)=\sum_{i=1}^n  (a_{i,i}+b_{i,i})=\sum_{i=1}^n  a_{i,i}+\sum_{i=1}^nb_{i,i}=\text{trace}(A)+\text{trace}(B).
$$ 
The $i^\text{th}$ term on the diagonal of $AB$ is $\sum_{j=1}^na_{i,j}b_{j,i}$ and the $i^\text{th}$ term on the diagonal of $BA$ is $\sum_{i=1}^n b_{j,i}a_{i,j}.$ 
Therefore, 
$$
\text{trace}(AB)
=\sum_{i=1}^n \sum_{j=1}^n a_{i,j}b_{j,i}
=\sum_{i=1}^n \sum_{j=1}^n b_{j,i}a_{i,j} 
=\text{trace}(BA)
$$
as desired.
- If matrices $A$ and $B$ are similar there exists an invertible matrix $P$ such that $B=P^{-1}AB$. Then,
$$
\text{trace}(P^{-1}AP)
=\text{trace}(P^{-1}(AP))
=\text{trace}((AP)P^{-1})
=\text{trace}(A).
$$
::: 

::: {#exm- } 
Consider an $n\times n$ matrix $A$ such that both $A$ and $A^{-1}$ have integer entries. What are the possible values of $\det(A)$?
Applying the determinant to the equation $A A^{-1}=I_n$, it follows $\det(A) \det (A^{-1})=1$. The only way the product of the two integers $\det(A)$ and $\det(A^{-1})$ can be 1 is when they are both 1 or both $-1$. Therefore, $\det(A)=\pm 1$.
::: 

Consider the $(n-1)\times (n-1)$ matrix $M_{i,j}$ obtained from an  $n\times n$ matrix $A$ by deleting the $i$-th row and $j$-th column. Then the determinant of $M_{i,j}$ is called the $(i,j)$-th \index{minor} **minor**  of $A$.

::: {#thm-laplace-expansion } 

## Laplace Expansion
The determinant of an $n\times n$ matrix $A=[a_{i,j}]$ can be evaluated by using either one of the following equations:
\begin{equation}\label{row expansion}
\det(A)=(-1)^{i+1}a_{i,1}\det(M_{i,1})+\cdots + (-1)^{i+n} a_{i,n}\det(M_{i,n}) 
\end{equation}
where $i$ is any integer such that $1\leq i \leq n$, or 
\begin{equation}\label{column expansion}
\det(A)=(-1)^{1+j}a_{1,j}\det(M_{1,j})+\cdots + (-1)^{n+j} a_{n,j}\det(M_{n,j}) 
\end{equation}
where $j$ is any integer such that $1\leq j \leq n$.
::: 

::: {.proof }
The proof is left for the reader.
::: 

::: {#exm- } 
Evaluate the determinant of the matrix 
$$
A=
\begin{bmatrix} 
3 & 2 & 6 & 4 \\
1 & -2 & -3 & 1 \\
0 & 2 & 3 & 8 \\
4 & -1 & 7 & 2
\end{bmatrix} 
$$
by using expansion of minors along the second row.
Expanding along the second row, by using \ref{row expansion} with $i=2$ and $n=4$
\begin{align*} 
\det(A)
&= - \det(M_{2,1})  -2\det(M_{2,2}) +3\det(M_{2,3})  + \det(M_{2,4}) \\
& =-(-104)-2(-6)+3(68)+27=347.
\tag*{ }
\end{align*}
::: 

The trace and determinant share come common properties, for example, they both are invariants of a linear transformation. To be more explicit, let $T$ be a linear transformation from a linear space $V$ to $V$, where $V$ is a finite-dimensional linear space. If $\mathcal{B}$ is a basis of $V$ and $B$ is the $\mathcal{B}$-matrix of $T$, then we define the \index{determinant} **determinant** and \index{trace} **trace** of the linear transformation $T$ as $\det(T)=\det(B)$ and $\text{trace}(T)=\text{trace}(B)$, respectively.

::: {#thm- } 
The determinant and trace of a linear transformation are independent of the basis chosen.
::: 

::: {#exm- } 
Compute the determinant of the linear transformation $T(f(t))=f(3t-2)$ from $\mathcal{P}_2$ to $\mathcal{P}_2$ and use it to determine whether the linear transformation is an isomorphism.
We choose to use the standard basis of $\mathcal{P}_2$, namely $(1, t, t^2)$. With respect to this basis the matrix of $T$ is $A=\begin{bmatrix} 1 & -2 & 4 \\  0 & 3 & -12 \\ 0 & 0 & 9  \end{bmatrix},$ so that $\det(T)=\det(A)=27$. Therefore, the given transformation is an isomorphism. 
::: 

::: {#exm- } 
Find the determinant of the linear transformation 
$$
T(M)=\begin{bmatrix} 1 & 2 \\ 2 & 3\end{bmatrix} M+M\begin{bmatrix} 1 & 2 \\ 2 & 3\end{bmatrix} 
$$ 
from the space $V$ of symmetric $2\times 2$ matrices to $V$ and use it to determine whether the linear transformation is an isomorphism.
A basis for the space of symmetric $2\times 2$ matrices is
$$
\left(
\begin{bmatrix}  1 & 0 \\ 0 & 0 \end{bmatrix},
\begin{bmatrix}  0 & 1 \\ 1 & 0 \end{bmatrix},
\begin{bmatrix}  0 & 0 \\ 0 & 1 \end{bmatrix} 
\right).
$$ 
The matrix of $T$ with respect to this basis is
$$
A=\begin{bmatrix} 2 & 4 & 0 \\ 2 & 4 & 2 \\ 0 & 4 & 6 \end{bmatrix} 
$$
so that $\det(T)=\det(A)=-16$. Therefore, the given transformation is an isomorphism. 
::: 

::: {#thm- } [Cramer]

Cramer's rule can be used to prove the Cayley Hamilton theorem of linear algebra, as well as Nakayama's lemma, which is fundamental in commutative ring theory.

## Cramer
Consider the system of equations $A \vec x=\vec b$ where $A$ is an $n\times n$ invertible matrix. Then the unique solution to the system is given by 
$$
x_1=\frac{\det(A_1)}{\det(A)},\qquad x_2=\frac{\det(A_2)}{\det(A)},\cdots, \qquad x_n=\frac{\det(A_n)}{\det(A)}
$$
where the matrix $A_i$ is the matrix $A$ with the $i$-th column replaced by $\vec b$.
::: 

::: {.proof }
The proof is left for the reader.
::: 

::: {#exm- } 
Solve the system using Cramer's Rule.
$$
\left\{ 
\begin{matrix}
2x_1 +3x_2-x_3 & =1 \\
4x_1+x_2+2x_3 & = 5 \\
x_1-x_2+x_3 & =2 
\end{matrix}
\right.
$$
First we compute the determinant of the coefficient matrix $A$,
and find $\det (A)=5$
Since $\det(A)\neq 0$, we can apply Cramer's rule, so we compute the required determinants and obtain, according to Cramer's rule, the solution to the system is 
$$
x_1=\frac{\det(A_1)}{\det(A)}=\frac{7}{5},\quad x_2=\frac{\det(A_2)}{\det(A)}=-\frac{3}{5}, \quad x_3=\frac{\det(A_n)}{\det(A)}=0.
$$
::: 

::: {#exm- } 
Use paper, pencil, and Cramer's rule to solve the system $A\vec x=\vec b$ where $A$ and $\vec b$ are the following matrices
$$
A=
\begin{bmatrix}
 1 & 2 & 3 & 4 \\
 -5 & -6 & -7 & -8 \\
 9 & -10 & 11 & -12 \\
 -13 & 14 & -15 & 16
\end{bmatrix} 
\qquad \text{and} \qquad 
\vec b=
\begin{bmatrix}
 1 \\ 2 \\ 3 \\ 4
\end{bmatrix} .
$$
First we find $\det(A)=-256$ and then we find the solution vector
$$
\vec x= \vectorfour{-51/8}{5}{41/8}{-9/2}.
$$ 
::: 



