[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Basic Set Theory",
    "section": "",
    "text": "Preface"
  },
  {
    "objectID": "index.html#short-description",
    "href": "index.html#short-description",
    "title": "Basic Set Theory",
    "section": "Short Description",
    "text": "Short Description\nThis book is for beginners who want to explore the fascinating world of logical reasoning, mathematical proofs, and set theory. The text is easy to follow and provides many examples that help readers understand the concepts discussed. Topics include propositional logic first-order logic, set theory, functions, and relations. Additionally, we introduce connection theory and concept theory. With the novel approach taken here, with this book as a guide, readers will soon be able to see the beauty and power of mathematical reasoning."
  },
  {
    "objectID": "index.html#other-resources",
    "href": "index.html#other-resources",
    "title": "Basic Set Theory",
    "section": "Other Resources",
    "text": "Other Resources\nThis book is paired with my YouTube channel where I discuss the main ideas in this book. These videos can be found here on this site as video embeds, so you can read, write, and watch all in one place."
  },
  {
    "objectID": "index.html#update-history",
    "href": "index.html#update-history",
    "title": "Basic Set Theory",
    "section": "Update History",
    "text": "Update History\nHere is where I keep a log of the majors changes as I finish writing the book.\n\nFirst draft of preface published on 1/27/2023.\nFirst draft published on 1/14/2023."
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "Basic Set Theory",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nIt is impossible to overstate the importance of those who helped bring this book into its completed form. I am deeply grateful for their generous contributions and would like to express my sincere appreciation.\nDavid A. Smith \\ Fort Worth, Texas"
  },
  {
    "objectID": "propositional-logic.html#logical-connectives",
    "href": "propositional-logic.html#logical-connectives",
    "title": "1  Propositional Logic",
    "section": "1.1 Logical Connectives",
    "text": "1.1 Logical Connectives\nWe will define the following seven logical connectives: \\[\n\\neg \\quad \\lor \\quad \\land \\quad \\rightarrow \\quad \\leftrightarrow \\quad \\downarrow \\quad \\uparrow\n\\]\nand in doing so, we will use these symbols to represent the follows words:\n\n\\(\\neg\\) for not or negation,\n\n\\(\\lor\\) for and/or or disjunction,\n\n\\(\\land\\) for and or conjunction,\n\\(\\rightarrow\\) for implies or if … then … ,\n\n\\(\\leftrightarrow\\) for if and only if or equivalent,\n\n\\(\\downarrow\\) for joint negation or not both, and\n\n\\(\\uparrow\\) for alternative negation or neither nor.\n\nInformally, we say a statement is simple whenever it does not use one of the seven connectives. Examples of simple statements are:\n\n\\(3+4=7\\)\nSamuel is 46 years old.\n\\(3+4=8\\)\nThe current month is December.\nIt is raining.\nRight now it is 3 o’clock.\n\nStatements that are made up of one or more simple statements using logical connectives are called compound statements.\nThe convention used here is that \\(p\\) or \\(P\\) may denote a statement. We use \\(P\\) sometimes to emphasis that \\(P\\) may be a compound statement.\nFormally, compound statements are defined as follows.\n\nAll simple statements are compound statements.\nIf \\(p\\) and \\(q\\) are compound statements, then so are \\[\n\\neg p \\quad\np \\land q \\quad\np \\lor q \\quad\np \\rightarrow q \\quad\np \\leftrightarrow q\n\\]\nNothing else is a compound statement unless it can be obtained by a finite number of applications of statement (1) and (2) above.\n\nFor instance, the propositional variables for the statement \\(p\\land (q \\lor r)\\) are \\(p, q,\\) and \\(r\\). Using this definition one can prove that every statement can be decomposed into a finite number of simple statements in a unique way. For a given statement \\(P\\), it’s corresponding simple statements are called the statement variables (or propositional variables) of \\(P\\).\nWe now consider each one of these connectives in turn, starting with the simplest first. As we do so, we illustrate truth values of statements, using T for true and F for false.\n\n\nTable 1.1: The logical connective Negation\n\n\n\\(p\\)\n\\(\\neg p\\)\n\n\n\n\n\nT\nF\n\n\n\nF\nT\n\n\n\n\n\n\nDefinition 1.1 The statement \\(\\neg p\\), read not \\(p\\) and called the negation of statement \\(p\\), is defined to be the denial of statement \\(p\\). That is, \\(\\neg p\\) is false if \\(p\\) is true, and \\(\\neg p\\) is true if \\(p\\) is false.\n\nBasically, the not connective converts true to false and false to true.\n\nDefinition 1.2 The statement \\(p\\land q\\), read \\(p\\) and \\(q\\) and called the conjunction of \\(p\\) and \\(q\\), is true when both \\(p\\) and \\(q\\) are true and is false otherwise.\n\n\n\nTable 1.2: The logical connective And\n\n\n\\(p\\)\n\\(q\\)\n\\(p\\land q\\)\n\n\n\n\nT\nT\nT\n\n\nT\nF\nF\n\n\nF\nT\nF\n\n\nF\nF\nF\n\n\n\n\nConjunction has the usually meaning of and, except that the two statements need not be related. Thus we state \\[\n1+4=5 \\quad \\text{ and}\\quad \\text{ July is a month}\n\\] as being a true conjunction. If we associate \\(1+4=5\\) with the propositional variable \\(p\\) and July is a month with \\(q\\), then we have the conjunction \\(p\\land q\\) which is easily seen to be true.\n\nDefinition 1.3 The statement \\(p\\lor q\\), read \\(p\\) or \\(q\\) and called the disjunction of \\(p\\) and \\(q\\), is false when both \\(p\\) and \\(q\\) are false and is true otherwise.\n\n\n\nTable 1.3: The logical connective Or\n\n\n\\(p\\)\n\\(q\\)\n\\(p\\lor q\\)\n\n\n\n\nT\nT\nT\n\n\nT\nF\nT\n\n\nF\nT\nT\n\n\nF\nF\nF\n\n\n\n\nDisjunction is used logically in the inclusive and/or sense. The word disjunction, as written in Latin, is and so we see that the symbol for disjunction, namely \\(\\lor\\), looks like its first letter in its Latin form. Now we see that \\[\n1+4=5 \\quad \\text{ or} \\quad \\text{ July is a month}\n\\] is a true disjunction; and that \\[\n0+4=5 \\quad \\text{ or} \\quad \\text{ July is a month}\n\\] is also a true disjunction.\n\nDefinition 1.4 The statement \\(p\\rightarrow q\\), read \\(p\\) implies \\(q\\) and called the implication (or conditional of \\(p\\) and \\(q\\), is false when \\(p\\) is true and \\(q\\) is false, and is true otherwise.\n\n\n\nTable 1.4: The logical connective Implication\n\n\n\\(p\\)\n\\(q\\)\n\\(p\\rightarrow q\\)\n\n\n\n\nT\nT\nT\n\n\nT\nF\nF\n\n\nF\nT\nT\n\n\nF\nF\nT\n\n\n\n\nIn any implication \\(p\\rightarrow q\\), \\(p\\) is called the hypothesis (or antecedent or premise) and \\(q\\) is called the consequence (or conclusion.\nNotice that an implication \\(p\\rightarrow q\\) is true when both \\(p\\) and \\(q\\) are true, and is false only in the case that \\(p\\) is true and \\(q\\) is false, and when \\(p\\) is false (no matter what truth value \\(q\\) has) the implication is true. This way of defining implication is more general than the meaning used in everyday English.\nFor example, the implication \\[\n\\text{If it is cloudy today, then we will not go back to the beach.}\n\\] is an implication used in normal language, since there is a relationship between the hypotheses and the conclusion. On the other hand, the implication \\[\n\\text{If today is Monday, then $1+4=6$.}\n\\] is true every day except Monday, from the definition of implication.\nUsing words and symbols is the usual approach the everyday mathematics. Here are some common ways to express the conditional \\(p\\rightarrow q\\).\n\n\\(p\\) implies \\(q\\)\nif \\(p\\) then \\(q\\)\nif \\(p\\), \\(q\\)\n\\(q\\), if \\(p\\)\n\\(p\\) only if \\(q\\)\n\\(p\\) is sufficient for \\(q\\)\n\\(q\\) is necessary for \\(p\\)\nwhenever \\(p\\), \\(q\\)\n\\(q\\) whenever \\(p\\)\n\n\nDefinition 1.5  The statement \\(p\\leftrightarrow q\\), read \\(p\\) if and only if \\(q\\) and called the equivalence (or biconditional) of \\(p\\) and \\(q\\), is true if and only if \\(p\\) and \\(q\\) are true or both are false.\n\n\n\nTable 1.5: The logical connective Biconditional\n\n\n\\(p\\)\n\\(q\\)\n\\(p\\leftrightarrow q\\)\n\n\n\n\nT\nT\nT\n\n\nT\nF\nF\n\n\nF\nT\nF\n\n\nF\nF\nT\n\n\n\n\nNote that the biconditional \\(p\\leftrightarrow q\\) is true precisely when both implications \\(q\\rightarrow p\\) and \\(p\\rightarrow q\\) are true. Here are some common ways to express the biconditional \\(p\\leftrightarrow q\\).\n\n\\(p\\) if and only if \\(q\\),\n\\(p\\) is necessary and sufficient for \\(q\\),\n\\(p\\) is equivalent to \\(q\\), and\n\\(p\\) and \\(q\\) are equivalent.\n\nAs a summary of the truth tables for the logical connectives see Table 1.6.\nThe connectives \\(\\downarrow\\) and \\(\\uparrow\\) will be explored in the exercises.\n\n\nTable 1.6: Summary of logical connectives\n\n\n\n\n\n\n\n\n\n\n\n\n\\(p\\)\n\\(q\\)\n\\(p\\land q\\)\n\\(p\\lor q\\)\n\\(p\\rightarrow q\\)\n\\(p\\leftrightarrow q\\)\n\\(p\\uparrow q\\)\n\\(p\\downarrow q\\)\n\n\n\n\nT\nT\nT\nT\nT\nT\nF\nF\n\n\nT\nF\nF\nT\nF\nF\nT\nF\n\n\nF\nT\nF\nT\nT\nF\nT\nF\n\n\nF\nF\nF\nF\nT\nT\nT\nT"
  },
  {
    "objectID": "propositional-logic.html#constructing-truth-tables",
    "href": "propositional-logic.html#constructing-truth-tables",
    "title": "1  Propositional Logic",
    "section": "1.2 Constructing Truth Tables",
    "text": "1.2 Constructing Truth Tables\nFrom the point of view of logic, it is the structure of a compound statement that makes it important. When constructing the truth table of a statement we will take into account this structure by parsing a statement into simpler statements.\n\n\nTable 1.7: Truth table conventions\n\n\np\nq\nr\n\n\n\n\nT\nT\nT\n\n\nT\nT\nF\n\n\nT\nF\nT\n\n\nT\nF\nF\n\n\nF\nT\nT\n\n\nF\nT\nF\n\n\nF\nF\nT\n\n\nF\nF\nF\n\n\n\n\nWhen constructing compound statements, parentheses are used to specify the order in which the various logical connectives in a compound statement are applied. In particular, the logical connectives in the innermost parentheses are applied first. For example, \\((p\\land q)\\lor (\\neg r)\\) is the disjunction of \\((p\\land q)\\) and \\(\\neg r\\). To cut down on the number of parentheses used, we specify that the negation connective is applied before all other connectives. For instance, \\(\\neg p\\lor q\\) is the disjunction of \\(\\neg p\\) and \\(q\\), namely \\((\\neg p)\\lor q\\), not the negation of the conjunction of \\(p\\) and \\(q\\). Further, when working with compound propositions the order from highest priority to lowest is \\(\\neg\\), \\(\\land\\), \\(\\lor\\), \\(\\rightarrow\\), \\(\\leftrightarrow\\).\nWe agree that, in any truth table, the symbols for the propositional variables \\(p, q, r, \\ldots\\) are in alphabetical order, and to make the rightmost column \\(T, F, T, F, \\ldots\\) the next column leftward \\(T, T, F, F, \\ldots\\), and so forth. As examples of this convention see Table 1.6 and Table 1.7."
  },
  {
    "objectID": "propositional-logic.html#tautologies-contradictions-and-contingencies",
    "href": "propositional-logic.html#tautologies-contradictions-and-contingencies",
    "title": "1  Propositional Logic",
    "section": "1.3 Tautologies, Contradictions, and Contingencies",
    "text": "1.3 Tautologies, Contradictions, and Contingencies\nWe sometimes classify statements according to whether or not they are always true, always false, or otherwise.\n\nDefinition 1.6 A proposition that is always true, regardless of what truth values are assigned to its statement variables, is called a tautology; a proposition that is always false, regardless of what truth values are assigned to its statement variables, is called a contradiction; and otherwise a proposition is called a contingency.\n\n\nExample 1.1 Determine whether or not the statement \\[\n(p\\rightarrow (q\\land p))\\lor (q\\rightarrow (p\\land q))\n\\] is a tautology.\n\n\nSolution. We begin by parsing the statement \\((p\\rightarrow (q\\land p))\\lor (q\\rightarrow (p\\land q))\\) into simpler forms, namely, \\(q\\land p\\), \\(p\\rightarrow (q\\land p)\\), and \\(q\\rightarrow (p\\land q)\\). We place these simpler forms into three columns in the table to aid in the computation of the values in the final column. The following truth table Table 1.8 shows that the statement \\((p\\rightarrow (q\\land p))\\lor (q\\rightarrow (p\\land q))\\) is a tautology because every entry in the last column is true. More precisely, regardless of what truth values are assigned to its statement variables, \\((p\\rightarrow (q\\land p))\\lor (q\\rightarrow (p\\land q))\\) has a true truth value.\n\n\n\nTable 1.8: Example of a tautology\n\n\n\n\n\n\n\n\n\n\n\\(p\\)\n\\(q\\)\n\\(q\\land p\\)\n\\(p\\rightarrow (q\\land p)\\)\n\\(q\\rightarrow (p\\land q)\\)\n\\((p\\rightarrow (q\\land p))\\lor (q\\rightarrow (p\\land q))\\)\n\n\n\n\nT\nT\nT\nT\nT\nT\n\n\nT\nF\nF\nF\nT\nT\n\n\nF\nT\nF\nT\nF\nT\n\n\nF\nF\nF\nT\nT\nT\n\n\n\n\nIn general if a proposition contains \\(n\\) variables then it takes \\(2^n\\) rows to determine whether a proposition is a tautology or not. The problem of determining whether any given proposition is a tautology is called the tautology problem.\n\nIs there a better way to solve the tautology problem than the brute force method of a truth table?\n\nWe now list several important tautologies, leaving their proofs for the reader as exercises. Each of the names of the tautologies are listed also. It is important to know their names as well, as tautologies are usually referred to by name.\n\nTheorem 1.1 (Tautologies Used in Proofs) The following statements are tautologies.\n\n\n\n\n\n\n\nStatement\nName\n\n\n\n\n\\(p \\lor \\neg p\\)\nexcluded middle\n\n\n\\((p\\land q) \\rightarrow p\\)\nsimplification\n\n\n\\(p \\rightarrow (p\\lor q)\\)\nconstruction\n\n\n\\(((p\\lor q)\\land \\neg p ) \\rightarrow q\\)\nsyllogism\n\n\n\\((p\\land (p\\rightarrow q))\\rightarrow q\\)\nmodus ponens\n\n\n\\((\\neg q\\land (p\\rightarrow q))\\rightarrow \\neg p\\)\nmodus tollens\n\n\n\\((p\\rightarrow q) \\leftrightarrow (\\neg p \\lor q)\\)\nconditional disjunction\n\n\n\\((p \\rightarrow q) \\leftrightarrow (\\neg q \\rightarrow \\neg p)\\)\ncontrapositive\n\n\n\\(((p\\rightarrow r) \\land (q\\rightarrow r))\\leftrightarrow ((p\\lor q)\\rightarrow r )\\)\nproof by cases\n\n\n\\((p\\rightarrow (q\\land \\neg q))\\leftrightarrow \\neg p\\)\nindirect proof\n\n\n\n\n\nProof. The proof is left for the reader as Exercise 1.7.\n\n\nTheorem 1.2 (Order Related Tautologies) The following statements are tautologies.\n\n\n\n\n\n\n\nStatement\nName\n\n\n\n\n\\(p \\rightarrow p\\)\nreflexive\n\n\n\\(((p\\rightarrow q)\\land (q \\rightarrow r))\\rightarrow(p\\rightarrow r)\\)\ntransitivity\n\n\n\\(((p\\leftrightarrow q)\\land (q \\leftrightarrow r))\\rightarrow(p\\leftrightarrow r)\\)\ntransitivity\n\n\n\n\n\nProof. The proof is left for the reader as Exercise 1.10."
  },
  {
    "objectID": "propositional-logic.html#contrapositive-converse-and-inverse",
    "href": "propositional-logic.html#contrapositive-converse-and-inverse",
    "title": "1  Propositional Logic",
    "section": "1.4 Contrapositive, Converse, and Inverse",
    "text": "1.4 Contrapositive, Converse, and Inverse\nThree important statements are associated with any implication \\(p\\rightarrow q\\), namely\n\nthe statement \\(\\neg q\\rightarrow \\neg p\\) is called the contrapositive of \\(p\\rightarrow q\\),\nthe statement \\(q\\rightarrow p\\) is called the converse of \\(p\\rightarrow q\\), and\nthe statement \\(\\neg p\\rightarrow \\neg q\\) is called the inverse of the implication \\(p\\rightarrow q\\).\n\nIt is easy to show that every implication is logically equivalent to its contrapositive. Try it. Notice that the inverse and converse of \\(p\\rightarrow q\\) are logically equivalent.\n\n\n\n\n\n\n\n\n\n\n\n\\(p\\)\n\\(q\\)\n\\(\\neg p\\)\n\\(\\neg q\\)\n\\(\\neg p\\rightarrow \\neg q\\)\n\\(q\\rightarrow p\\)\n\n\n\n\nT\nT\nF\nF\nT\nT\n\n\nT\nF\nF\nT\nT\nT\n\n\nF\nT\nT\nF\nF\nF\n\n\nF\nF\nT\nT\nT\nT\n\n\n\nFurther, an implication is not necessarily equivalent to its converse (inverse)."
  },
  {
    "objectID": "propositional-logic.html#modus-ponens-and-substitution",
    "href": "propositional-logic.html#modus-ponens-and-substitution",
    "title": "1  Propositional Logic",
    "section": "1.5 Modus Ponens and Substitution",
    "text": "1.5 Modus Ponens and Substitution\nIn propositional logic, modus ponendo ponens (or ), which is Latin for the way that affirms by affirming, is a valid, simple argument form and rule of inference.\n\nTheorem 1.3 (Modus Ponens) Let \\(P\\) and \\(Q\\) be statements. If the statements \\(P\\) and \\(P\\rightarrow Q\\) are tautologies, then so is the statement \\(Q\\).\n\n\nProof. Suppose the statements \\(P\\) and \\(P\\rightarrow Q\\) are tautologies. Assume for a contradiction that \\(Q\\) is not a tautology. Then it must be possible to have a truth assignment to the statement variables of \\(Q\\) which yields false.\nHowever, since \\(P\\) is a tautology and \\(P\\rightarrow Q\\) is a tautology, we now have a truth assignment of \\(P\\rightarrow Q\\) which yields false. Yet all truth assignments for \\(P\\rightarrow Q\\) yield true. This contradiction shows that the hypothesis that \\(Q\\) is not a tautology can not hold. Therefore \\(Q\\) must be a tautology.\n\n\nTheorem 1.4 (Substitution Rule) Let \\(P\\) be a tautology, and suppose that \\(P\\) contains the distinct statement variables \\(p_1, p_2, \\ldots, p_n\\) (and perhaps others as well). Suppose further that \\(Q_1, Q_2, \\ldots, Q_n\\) are statements. Then, if in the tautology \\(P\\), we replace \\(p_1\\) by \\(Q_1\\), replace \\(p_2\\) by \\(Q_2\\), and so on, then the resulting statement is also a tautology.\n\n\nProof. This proof is left as Exercise 1.22.\n\n\nExample 1.2 Show that the statement \\[\\begin{equation}\n\\label{scsex}\n(p\\land \\neg q)\\rightarrow [(\\neg p\\lor \\neg q)\\rightarrow (p\\land \\neg q)]\n\\end{equation}\\] is a tautology.\n\n\nSolution. Notice the compound statement in \\(\\eqref{scsex}\\) has the form \\[\\begin{equation}\n\\label{tauex2}\nP\\rightarrow (Q\\rightarrow P)\n\\end{equation}\\] where \\(P:=p\\land \\neg q\\) and \\(Q:=\\neg p\\lor \\neg q\\). Therefore, by Theorem 1.4, it suffices to verify that \\(\\eqref{tauex2}\\) is in fact a tautology. We leave this verification to the reader.\n\n\nExample 1.3 Show that the statement \\[\\begin{equation}\n\\label{scsex2}\n(p\\rightarrow \\neg q)\\lor \\neg (p\\rightarrow \\neg q)\n\\end{equation}\\] is a tautology.\n\n\nSolution. It is easy to see that the statement \\(P\\lor \\neg P\\) is a tautology; and thus by Theorem 1.4, we see that \\(\\eqref{scsex2}\\) is also a tautology."
  },
  {
    "objectID": "propositional-logic.html#inference-rules",
    "href": "propositional-logic.html#inference-rules",
    "title": "1  Propositional Logic",
    "section": "1.6 Inference Rules",
    "text": "1.6 Inference Rules\nBy a mathematical proof (or proof) we shall mean the assertion that a certain statement (the conclusion) follows from other statements (the premises). A proof will be said to be (logically) valid, if and only if the conjunction of the premises implies the conclusion, that is, if the premises are all true, the conclusion must also be true. In order to determine whether a mathematical proof is valid we need to be able to accomplish two goals: a valid logically argument and justifications for each statement.\nIt’s important to realize that a logically argument depends upon its form in that it does not matter what the components of the argument are. For example, is the following argument valid?\n\\[\\begin{equation}\n\\label{argument}\n\\text{If $ p\\rightarrow q$ and $q\\rightarrow r$, then $p\\rightarrow r$.}\n\\end{equation}\\]\nSince the implication \\((p\\rightarrow q)\\land (q\\rightarrow r)\\rightarrow (p\\rightarrow r)\\) is a tautology, \\(\\eqref{argument}\\) is a valid argument, as can be proven by constructing a truth table. Indeed \\(\\eqref{argument}\\) is valid as an argument regardless of the meaning of \\(p\\), \\(q\\) and \\(r\\). A proof demonstrates that the conclusion must happen and is a consequence of the premises.\n\nTheorem 1.5 Suppose the statement \\(r\\) is a consequence of the premises \\(p_1, p_2, ... p_k\\) and also suppose another statement \\(q\\) is a consequence of the same premises \\(p_1, p_2, ..., p_k\\) and \\(r\\). Then \\(q\\) is a consequence of just \\(p_1, p_2, ..., p_k\\).\n\n\nProof. Let \\(P_k\\) denote \\(p_1 \\land \\cdots \\land p_k\\). For a rigorous proof we need to show that \\[\\begin{equation}\n\\label{tautproof}\n\\left( (P_k \\rightarrow r) \\land (P_k \\land r \\rightarrow q) \\right)\n\\rightarrow \\left( P_k \\rightarrow q \\right)\n\\end{equation}\\]\nis a tautology. To understand why \\(\\eqref{tautproof}\\) is a tautology, let \\(p\\) be the variable for \\(p_1\\land p_2\\land \\cdots \\land p_k\\) and consider the truth table for \\(p\\rightarrow q\\). In any row where \\(p\\) is false, \\(p\\rightarrow q\\) is true by definition of \\(\\rightarrow\\). In any row where \\(p\\) is true, \\(r\\) must also be true, since \\(p\\rightarrow r\\) is a tautology. But since \\((p\\land r)\\rightarrow q\\) is always true, this guarantees that in every row where \\(p\\) is true, \\(q\\) must also be true. Therefore, \\(p\\rightarrow q\\) is a tautology, as desired.\n\nBefore we begin writing proofs, let’s review the following tautologies.\n\n\n\n\n\n\n\n\nInference Rule\nTautology\nName\n\n\n\n\n\\(\\begin{array}{l} p \\\\ \\hline \\therefore \\, p\\lor q \\end{array}\\)\n\\(p\\rightarrow (p\\lor q)\\)\nAddition\n\n\n\\(\\begin{array}{l} p\\land q\\\\ \\hline \\therefore \\, p \\end{array}\\)\n\\((p\\land q)\\rightarrow p\\)\nSimplification\n\n\n\\(\\begin{array}{l} p \\\\ q \\\\ \\hline \\therefore \\, p\\land q \\end{array}\\)\n\\(((p)\\land (q))\\rightarrow (p\\land q)\\)\nConjunction\n\n\n\\(\\begin{array}{l} p \\\\ p\\rightarrow q \\\\ \\hline \\therefore \\, q \\end{array}\\)\n\\([p\\land (p\\rightarrow q)]\\rightarrow q\\)\nModus ponens\n\n\n\\(\\begin{array}{l} \\neg q \\\\ p\\rightarrow q \\\\ \\hline \\therefore \\, \\neg p \\end{array}\\)\n\\([\\neg q \\land (p\\rightarrow q)]\\rightarrow \\neg p\\)\nModus tollens\n\n\n\\(\\begin{array}{l} p\\rightarrow q \\\\ q\\rightarrow r \\\\ \\hline \\therefore \\, p\\rightarrow r \\end{array}\\)\n\\([(p\\rightarrow q)\\land (q\\rightarrow r)]\\rightarrow (p\\rightarrow r)\\)\nHypothetical syllogism\n\n\n\\(\\begin{array}{l} p\\lor q \\\\ \\neg p \\\\ \\hline \\therefore \\, q \\end{array}\\)\n\\([(p\\lor q)\\land \\neg p]\\rightarrow q\\)\nDisjunctive syllogism"
  },
  {
    "objectID": "propositional-logic.html#logical-equivalence",
    "href": "propositional-logic.html#logical-equivalence",
    "title": "1  Propositional Logic",
    "section": "1.7 Logical Equivalence",
    "text": "1.7 Logical Equivalence\nIn propositional logic, statements \\(p\\) and \\(q\\) are logically equivalent if they have the same semantic meaning. In other words, two statements are equivalent if they have the same truth value for every possible assignment.\nAnother way to say this is the following: for each assignment of truth values to the simple statements which make up \\(P\\) and \\(Q\\), the statements \\(P\\) and \\(Q\\) have identical truth values. We will see that, from a practical point of view, we can replace a variable in a tautology by any logically equivalent statement and still have a tautology.\n\nDefinition 1.7 Let \\(P\\) and \\(Q\\) be statements. We say that \\(P\\) is logically equivalent to \\(Q\\), denoted by \\(P\\equiv Q\\), provided that \\(P\\) and \\(Q\\) have the same truth-value for every possible choice of truth values of the propositional variables involved in \\(P\\) and \\(Q\\).\n\n\nExample 1.4 Verify the following are logical equivalencies:\n\n\\(p\\rightarrow q \\equiv \\neg p \\lor q\\)\n\\(\\neg (p\\rightarrow q) \\equiv p\\land \\neg q\\)\n\n\n\nSolution. The following truth table clearly demonstrates that \\(p\\rightarrow q\\) and \\(\\neg p\\lor q\\) are logically equivalent (columns 5 & 6).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(p\\)\n\\(q\\)\n\\(\\neg p\\)\n\\(\\neg q\\)\n\\(p\\rightarrow q\\)\n\\(\\neg p\\lor q\\)\n\\(\\neg(p\\rightarrow q )\\)\n\\(p\\land \\neg q\\)\n\n\n\n\nT\nT\nF\nF\nT\nT\nF\nF\n\n\nT\nF\nF\nT\nF\nF\nT\nT\n\n\nF\nT\nT\nF\nT\nT\nF\nF\n\n\nF\nF\nT\nT\nT\nT\nF\nF\n\n\n\nIt also shows that \\(\\neg(p\\rightarrow q )\\) and \\(p\\land \\neg q\\) are logically equivalent (columns 7 & 8).\n\nThere are, of course, an infinite number of tautologies and logical equivalences. However, as we have seen, the method of truth tables is exponential in the number of variables. Thus we need practical methods of determining whether a given statement is a tautology or whether two given statements are logical equivalent or not.\n\nTheorem 1.6 (Logical Equivalence) Two compound statements \\(P\\) and \\(Q\\) are logically equivalent if and only if the compound statement \\(P\\leftrightarrow Q\\) is a tautology.\n\n\nProof. If \\(P\\leftrightarrow Q\\) is a tautology, then any assignment of truth values to the statement variables makes the statement \\(P\\leftrightarrow Q\\) true, that is, it gives the same truth values to both \\(P\\) and \\(Q\\). Therefore, \\(P\\) and \\(Q\\) are logically equivalent.\nConversely, if \\(P\\) and \\(Q\\) are logically equivalent, then any assignment of truth values to the statement variables of \\(P\\) and \\(Q\\) gives the same truth value to both \\(P\\) and \\(Q\\). Whence \\(P\\leftrightarrow Q\\) is a tautology.\n\n\nTheorem 1.7 (Properties of Logical Equivalence) Let \\(p\\) and \\(q\\) be statements.\n\nThe commutative properties:\n\n\\((p\\land q)\\equiv (q\\land p)\\)\n\\((p\\lor q)\\equiv (q\\lor p)\\)\n\nThe associative properties:\n\n\\(((p\\land q)\\land r) \\equiv (p\\land (q\\land r))\\)\n\\(((p\\lor q)\\lor r) \\equiv (p\\lor (q\\lor r))\\)\n\nThe distributive properties:\n\n\\((p\\land (q\\lor r)) \\equiv ((p\\land q)\\lor (p\\land r))\\)\n\\((p\\lor (q\\land r)) \\equiv ((p\\lor q)\\land (p\\lor r))\\)\n\nThe idempotent properties:\n\n\\(p\\lor p \\equiv p\\)\n\\(p\\land p \\equiv p\\)\n\n De Morgan laws:\n\n\\(\\neg (p\\land q)\\equiv \\neg p \\lor \\neg q\\)\n\\(\\neg (p\\lor q)\\equiv \\neg p \\land \\neg q\\)\n\n Law of excluded middle:\n\n\\(p\\lor \\neg p\\) is a tautology\n\\(p\\land \\neg p\\) is a contradiction\n\n\n\n\nProof. The proof is left for the reader as Exercise 1.8.\n\n\nTheorem 1.8 (Properties of Logical Equivalence II) Let \\(p\\) and \\(q\\) be statements.\n\nAn implication and contrapositive are logically equivalent: \\[\np\\rightarrow q \\equiv \\neg p \\rightarrow \\neg q. \\]\nThe converse and inverse of the implication \\(p\\rightarrow q\\) are logically equivalent: \\[q\\rightarrow p \\equiv \\neg q \\rightarrow \\neg p.\\]\nLet \\(T\\) denote a tautology and \\(F\\) denote a contradiction. Then\n\n\\(p\\lor T \\equiv T\\)\n\\(p\\land T \\equiv p\\)\n\\(p\\lor F\\equiv p\\)\n\\(p\\land F \\equiv F\\)\n\n\n\n\n\nProof. The proof is left for the reader as Exercise 1.9.\n\n\nTheorem 1.9 (Logical Equivalence/Substituton) Let \\(P\\) and \\(Q\\) be logically equivalent statements, and suppose that \\(P\\) and \\(Q\\) contain the statement variables \\(p_1, p_2, \\ldots, p_n\\) (and possible others). Suppose further that \\(Q_1, Q_2, \\ldots, Q_n\\) are statements. Then, if we replace \\(p_1\\) by \\(Q_1\\), replace \\(p_2\\) by \\(Q_2\\), and so on, in both \\(P\\) and \\(Q\\), then the resulting statements are still logically equivalent.\n\n\nProof. Denote the statements obtained by replacing \\(p_1\\) by \\(Q_1\\), \\(p_2\\) by \\(Q_2\\), and so on, in \\(P\\) and \\(Q\\) by \\(P'\\) and \\(Q'\\), respectively. We will show that \\(P'\\) and \\(Q'\\) are logically equivalent. By Theorem 1.6, \\(P'\\) and \\(Q'\\) are logically equivalent if and only if the statement \\(P'\\leftrightarrow Q'\\) is a tautology. Now since our hypothesis is that \\(P\\) and \\(Q\\) are logically equivalent we know that \\(P\\leftrightarrow Q\\) is a tautology, also by Theorem 1.6. Therefore, by Theorem 1.4} we see that \\(P'\\leftrightarrow Q'\\) is a tautology as needed.\n\n\nExample 1.5 Use properties of logical equivalence to show that \\[\\begin{equation}\n\\neg (p\\leftrightarrow q)\\equiv \\neg q\\leftrightarrow p\n\\end{equation}\\] is a tautology.\n\n\nSolution. We apply the properties of logical equivalence as follows:\n\\[\\begin{align*}\n\\neg (p\\leftrightarrow q) & \\equiv \\neg [(p\\rightarrow q)\\land (q\\rightarrow p)] \\\\\n& \\equiv \\neg (p\\rightarrow q)\\lor \\neg (q\\rightarrow p) \\\\\n& \\equiv (p\\land \\neg q) \\lor (q\\land \\neg p) \\\\\n& \\equiv [(p\\land \\neg q)\\lor q]\\land [(p\\land \\neg q)\\lor \\neg p] \\\\\n& \\equiv [(p\\lor q)\\land (\\neg q\\lor q)] \\land [(p\\lor \\neg p) \\land (\\neg q \\lor \\neg p) ] \\\\\n& \\equiv [(p\\lor q) \\land T] \\land [T\\land (\\neg q \\lor \\neg p)] \\\\\n& \\equiv (p\\lor q) \\land (\\neg q \\lor \\neg p) \\\\\n& \\equiv (q\\lor p) \\land (\\neg p \\lor \\neg q) \\\\\n& \\equiv (\\neg q\\rightarrow p)\\land (p\\rightarrow \\neg q) \\\\\n& \\equiv \\neg q \\leftrightarrow p\n\\end{align*}\\]"
  },
  {
    "objectID": "propositional-logic.html#exercises",
    "href": "propositional-logic.html#exercises",
    "title": "1  Propositional Logic",
    "section": "1.8 Exercises",
    "text": "1.8 Exercises\n\nExercise 1.1 Consider the following statement: \\[\n\\text{If $x=0$, then $x^2=0$ and if $x^2=0$, then $x=0$.}\n\\]\n\nExpress this statement in symbolic form using only conjunction and conditional.\nExpress this statement in symbolic form using only biconditional.\n\n\n\nExercise 1.2 Rewrite each statement in the form If …, then ….\n\nA nessary condition for two triangles to be congruent is that three sides of one be equal respectively to the three sides of the other.\nA sufficient condition for two triangles to be congruent is that the three sides of one be equal respectively to the three sides of the other.\nThe base angles of an isosceles triangle are equal.\n\n\n\nExercise 1.3 Construct a truth table and identify whether the proposition is either a tautology, contradiction, or a contingency.\n\n\\((p\\land q)\\rightarrow (p\\lor q)\\)\n\\((p\\lor q)\\lor (p\\rightarrow q)\\)\n\\((p\\rightarrow q)\\lor (p\\land \\neg q)\\)\n\\((\\neg p\\land q) \\land \\neg (p\\rightarrow \\neg q)\\)\n\\(\\neg (p\\lor q)\\land \\neg (p\\rightarrow q)\\)\n\\((p\\land q)\\land \\neg (p\\lor \\neg q)\\)\n\\(((p\\land q)\\lor r) \\rightarrow \\neg q\\)\n\\(((r\\land q)\\lor p) \\rightarrow \\neg q\\)\n\n\n\nExercise 1.4 Show the following statements are contingencies.\n\n\\((p\\land q)\\land (p\\rightarrow q)\\)\n\\(((p\\land q)\\rightarrow (p\\lor q))\\rightarrow p\\land q\\)\n\n\n\nExercise 1.5 Find a tautology that contains the statement \\(p\\land (q\\rightarrow \\neg p)\\). Find a contingency that contains the statement \\((p\\land q)\\land (p\\lor \\neg q)\\). Find a contradiction that contains the statement \\(p\\land (p\\land \\neg q)\\).\n\n\nExercise 1.6 Construct truth tables for each of the following and arrange them so that each compound statement implies all the following ones.\n\n\\(\\neg \\, p\\leftrightarrow q\\)\n\\(p \\rightarrow (\\neg \\, p\\rightarrow q )\\)\n\\(\\neg \\, ( p\\rightarrow (q\\rightarrow p ) )\\)\n\\(p\\lor q\\)\n\\(\\neg \\, p \\land q\\)\n\n\n\nExercise 1.7 Prove Theorem 1.1.\n\n\nExercise 1.8 Prove Theorem 1.7.\n\n\nExercise 1.9 Prove Theorem 1.8.\n\n\nExercise 1.10 Prove Theorem 1.2.\n\n\nExercise 1.11 First explain why all propositional forms with just one variable are logically equivalent with one of the following four: \\(P\\) or \\(\\neg P\\) or \\(P\\lor \\neg P\\) or \\(P\\land \\neg P\\). Now do the following:\n\nExplain why all propositional forms with two variables are logically equivalent with 1 of 16 possibilities.\nUsing only \\(\\lor\\) and \\(\\land\\), together with the variables \\(P\\) and \\(Q\\), give examples of all 16 possibilities in part (b), using the fewest number of symbols.\n\nFind a formula for the number of logically nonequivalent types of propositional forms of three variables.\n\nRepeat with \\(n\\) variables.\nExplain why your formulas are correct.\nExplain how to rewrite all of the possibilities in part (c), using only \\(\\lor\\) and \\(\\neg\\). Repeat using only \\(\\land\\) and \\(\\neg\\).\n\n\n\n\nExercise 1.12 Write the converse, contrapositive, and inverse of each statement. Further, determine whether the given statement and/or its converse is true.\n\nIf \\(x\\neq 0\\), then \\(x^2\\neq 0\\).\nIf \\(xy=0\\), then \\(x=0\\)\nIf \\(x\\) is a real number, then \\(x\\) is a rational number.\n\nIf \\(x\\) is positive and \\(x^2=4\\), then \\(x=2\\).\nIf \\(x\\neq 2\\) and \\(x^2+3x+1=0\\), then \\(x=1\\).\nIf \\(n\\) is an even integer or a prime number, then \\(n\\) is not an even nonnegative integer.\n\n\nA collection of logical connectives is called functionally complete if every compound statement is logically equivalent to a compound statement involving only these logical connectives.\n\nExercise 1.13 Show that \\(\\neg\\), \\(\\lor\\), and \\(\\land\\) form a functionally complete collection of logical connectives.\n\n\nExercise 1.14 Show that \\(\\neg\\) and \\(\\lor\\) form a functionally complete collection of logical connectives.\n\n\nExercise 1.15 Show that \\(\\neg\\) and \\(\\land\\) form a functionally complete collection of logical connectives.\n\n\nExercise 1.16 In this exercise we will show that \\(\\uparrow\\) forms a functionally complete collection of logical connectives.\n\nShow that \\(p\\downarrow p\\) is logically equivalent to \\(\\neg p\\).\nShow that \\((p\\downarrow q)\\downarrow (p\\downarrow q)\\) is logically equivalent to \\(p\\lor q\\).\nExplain how Exercise 1.14 applies.\n\n\n\nExercise 1.17 Show that \\(\\neg\\) and \\(\\rightarrow\\) form a functionally complete collection of logical connectives.\n\n\nExercise 1.18 Show that the five connectives \\(\\neg\\), \\(\\land\\), \\(\\lor\\), \\(\\rightarrow\\), \\(\\leftrightarrow\\) can each be defined in terms of only \\(\\uparrow\\). Do the same as (a) with \\(\\downarrow\\).\n\n\nExercise 1.19 Prove that if \\(P\\) is logically equivalent to \\(Q\\), and \\(Q\\) is logically equivalent to \\(R\\), then \\(P\\) is logically equivalent to \\(R\\).\n\n\nExercise 1.20 Use Exercise 1.19, to prove that any two of the following three statements are logically equivalent.\n\n\\(p\\rightarrow q\\)\n\\((p\\land \\neg q)\\rightarrow \\neg p\\)\n\\((p\\land \\neg q)\\rightarrow q\\)\n\n\n\nExercise 1.21 Use Theorem 1.9 to prove the logical equivalences.\n\n\\(\\neg[(p\\leftrightarrow q)\\lor (p\\land \\neg q)]\\equiv \\neg(p\\leftrightarrow q)\\land \\neg(p\\land \\neg q)\\)\n\\((p\\lor q)\\rightarrow (p\\land q)\\equiv [((p\\lor q)\\land \\neg(p\\land q))\\rightarrow \\neg(p\\lor q)]\\)\n\\((r\\land \\neg p)\\land ((r\\land \\neg p)\\lor (p\\land \\neg q))\\equiv r\\land \\neg p\\)\n\\((p\\land r)\\land ((p\\rightarrow q)\\lor r)\\equiv [(p\\land r)\\land (p\\rightarrow q)]\\lor [(p\\land r)\\land r]\\)\n\n\n\nExercise 1.22 Prove Theorem 1.4."
  },
  {
    "objectID": "predicate-logic.html#propositional-functions",
    "href": "predicate-logic.html#propositional-functions",
    "title": "2  Predicate Logic",
    "section": "2.1 Propositional Functions",
    "text": "2.1 Propositional Functions\nNotice that the statement\n\n\\(x\\) is less than 5\n\nhas two parts. The first is the variable \\(x\\) which is the subject of the statement. The second part, is less than 5 is called the predicate and refers to a property that the subject of the statement can have. We denote the statement “\\(x\\) is less than 5” by \\(P(x)\\), where \\(P\\) denotes the predicate and \\(x\\) is the variable. Once a value as been assigned to the variable \\(x\\), the sentence \\(P(x)\\) becomes a proposition and has a truth value. For instance, what are the truth values of \\(P(1)\\) and \\(P(2)\\)?\n\nDefinition 2.1 A propositional function in the variable \\(x\\) is a sentence \\(P(x)\\) about \\(x\\) that becomes a statement when \\(x\\) is given a particular value.\n\nIn general, a sentence involving the \\(n\\) variables \\(x_1, x_2, \\ldots, x_n\\) is denoted by \\[\nP(x_1, x_2, \\dots, x_n).\n\\] A statement of the form \\(P(a_1, a_2, \\ldots, a_n)\\) is the value of the propositional function \\(P\\) at the \\(n\\)-tuple \\((a_1, a_2, \\ldots, a_n)\\) and \\(P\\) is called the predicate.\n\nExample 2.1 Let \\(P(x,y,z)\\) denote the sentence “\\(x-y=z\\)”. What are the truth values of the propositions \\(P(2,3,-1)\\) and \\(P(5,0,7)\\)?\n\n\nSolution. The statement \\(P(2,3,-1)\\) corresponds to \\(2-3=-1\\) which is true; and the statement \\(P(5,0,7)\\) corresponds to \\(5-0=7\\) which is false."
  },
  {
    "objectID": "predicate-logic.html#universal-quantifier",
    "href": "predicate-logic.html#universal-quantifier",
    "title": "2  Predicate Logic",
    "section": "2.2 Universal Quantifier",
    "text": "2.2 Universal Quantifier\n\nDefinition 2.2  The statement \\[\n\\text{For all $x$, $P(x)$.}\n\\] is symbolized by the formula \\[\n\\forall x, P(x).\n\\] The symbol \\(\\forall\\) is called an universal quantifier and translates as “for all”.\n\nIs this statement true or false?\n\nExample 2.2 Express the statement\n\nEvery student in this class has studied calculus. as a universal quantification.\n\n\n\nSolution. Let \\(P(x)\\) denote the statement: “\\(x\\) has studied calculus”. Then the statement can be written \\(\\forall \\, x, P(x)\\) where the universe of discourse is the set of students in this class.\n\n\nExample 2.3 Let \\(P(x)\\) be the statement “\\(x>3\\)”. What is the truth value of the quantification \\(\\forall x, P(x)\\), where the universe of discourse is the set of real numbers?\n\n\nSolution. Notice that \\(P(x)\\) is not true for all real numbers \\(x\\), since we can find one value in the universe of discourse, say \\(2\\), and \\(P(2)\\) is false. Consequently \\(\\forall x, P(x)\\) is false.\n\nWhen the universe of discourse is finite, say \\(x_1, x_2, \\ldots, x_n\\), then the universal quantification \\(\\forall x, P(x)\\) has the same truth value as the conjunction \\[\\begin{equation}\nP(x_1)\\land P(x_2) \\land \\cdots \\land P(x_n)\n\\end{equation}\\] since \\(P(x_1)\\), \\(P(x_2)\\), …, \\(P(x_n)\\) are all true if and only if the conjunction is true.\n\nExample 2.4 What is the truth value of the statement \\(\\forall x, P(x)\\) where \\(P(x)\\) is the statement\n\n\\(x^2<5\\)\n\nand the universe of discourse is the set of the negative integers not less than \\(-3\\)?\n\n\nSolution. The statement \\(\\forall x, P(x)\\) is the same as the conjunction \\[\nP(-3)\\land P(-2)\\land P(-1)\n\\] since the universe of discourse consists of the integers \\(-3, -2\\), and \\(-1\\). Since \\(P(-3)\\) is false, it follows that the statement \\(\\forall x, P(x)\\) is false."
  },
  {
    "objectID": "predicate-logic.html#existential-quantifier",
    "href": "predicate-logic.html#existential-quantifier",
    "title": "2  Predicate Logic",
    "section": "2.3 Existential Quantifier",
    "text": "2.3 Existential Quantifier\n\nDefinition 2.3 The statement \\[\n\\text{There exists an $x$ such that $P(x)$.}\n\\] is symbolized by the formula \\[\n\\exists x, P(x).\n\\] The symbol \\(\\exists\\) is called an existential quantifier and translates as “there exists”.\n\nNotice that P(1) is also true and that \\(1\\) is a rational number.\n\nExample 2.5 Let \\(P(x)\\) denote the statement\n\n\\(x<5\\)\n\nWhat is the truth value of the quantification \\(\\exists x, P(x)\\), where the universe of discourse is the set of rational numbers?\n\n\nSolution. In order for the statement \\(\\exists x, P(x)\\) to be true, we need to demonstrate at least one value \\(x\\) in the universe of discourse where \\(P(x)\\) is true. Since \\(2\\) is a rational number number and \\(P(2)\\) is true, we see that \\(\\exists x, P(x)\\) is true.\n\nWhat if we change the universe of discourse to the set of complex numbers?\n\nExample 2.6 Let \\(P(x)\\) be the statement\n\n\\(x^2=-1\\)\n\nWhat is the truth value of the quantification \\(\\exists x, P(x)\\), where the universe of discourse is the set of rational numbers?\n\n\nSolution. Since \\(x^2=-1\\) is false for every rational number \\(x\\), the existential quantification of \\(P(x),\\) namely \\(\\exists x, P(x)\\) is false.\n\nWhen the universe of discourse is finite, say \\(x_1, x_2, \\ldots, x_n\\), then the existential quantification \\(\\exists x, P(x)\\) has the same truth value as the disjunction \\[\\begin{equation}\nP(x_1)\\lor P(x_2) \\lor \\cdots \\lor P(x_n)\n\\end{equation}\\] since at least one of \\(P(x_1)\\), \\(P(x_2)\\), , \\(P(x_n)\\) is true if and only if the disjunction is true.\n\nExample 2.7 What is the truth value of \\(\\exists x, P(x)\\) where \\(P(x)\\) is the statement\n\n\\(x^4<1\\)\n\nand the universe of discourse consists of the negative integers not less than \\(-5\\)?\n\n\nSolution. Since the universe of discourse is \\(\\{-5, -4, -3, -2, -1\\}\\), the proposition \\(\\exists x, P(x)\\) is the same as the disjunction \\[\nP(-5)\\lor P(-4)\\lor P(-3)\\lor P(-2)\\lor P(-1).\n\\] Since \\(P(-5), P(-4), P(-3), P(-2)\\), and \\(P(-1)\\) are all false, it follows that the statement \\(\\exists x, P(x)\\) is false."
  },
  {
    "objectID": "predicate-logic.html#uniqueness-quantifier",
    "href": "predicate-logic.html#uniqueness-quantifier",
    "title": "2  Predicate Logic",
    "section": "2.4 Uniqueness Quantifier",
    "text": "2.4 Uniqueness Quantifier\nWhat are other ways of expressing his quantifier in English?\n\nDefinition 2.4 The statement \\[\n\\text{There exists a unique $x$ such that $P(x)$.}\n\\] is symbolized by the formula \\[\n\\exists! \\, x, P(x).\n\\] The symbol \\(\\exists!\\) is called an uniqueness quantifier and translates as “there exists a unique”.\n\n\nExample 2.8 What is the truth value of \\(\\exists! \\, x, P(x)\\) where \\(P(x)\\) is the statement\n\n\\(x^4\\leq 1\\)”\n\nand the universe of discourse consists of the negative integers not less than \\(-5\\)?\n\n\nSolution. The universe of discourse is the set \\(\\{-5, -4, -3, -2, -1\\}\\) and since \\(P(-5), P(-4), P(-3), P(-2)\\) are all false and \\(P(-1)\\) is true, we see that exactly one, namely \\(P(-1)\\) is true. Hence, it follows that the statement \\(\\exists!\\, x, P(x)\\) is true."
  },
  {
    "objectID": "predicate-logic.html#negating-quantifiers",
    "href": "predicate-logic.html#negating-quantifiers",
    "title": "2  Predicate Logic",
    "section": "2.5 Negating Quantifiers",
    "text": "2.5 Negating Quantifiers\nNow we discuss the two logic rules mentioned above.\n\nTheorem 2.1 (Negating Quantifiers) Let \\(P(x)\\) be a propositional function and let \\(A\\) be a set. Then,\n\n\\(\\neg [\\forall x\\in A, P(x)]\\) is a true proposition if and only if \\(\\exists x\\in A, \\neg P(x)\\) is a true proposition.\n\\(\\neg [\\exists x\\in A, P(x)]\\) is a true proposition if and only if \\(\\forall x\\in A, \\neg P(x)\\) is a true proposition.\n\n\n\nProof. We prove (2) and leave the first part as Exercise 2.7. Suppose that \\[\\neg [\\exists x\\in A, P(x)]\\] is a true proposition. Then there is no \\(x\\) in \\(A\\) such that \\(P(x)\\) is true. Thus, for each \\(x\\in A\\), \\(P(x)\\) is false. Therefore, \\(\\neg P(x)\\) is true for every \\(x\\) in the set \\(A\\), and so \\(\\forall x\\in A, \\neg P(x)\\) is a true proposition.\nConversely, assume that \\(\\forall x\\in A, \\neg P(x)\\) is a true proposition. Then \\(\\neg P(x)\\) is a true statement for every \\(x\\) in the set \\(A\\). So \\(P(x)\\) is false for every \\(x\\) in the set \\(A\\); that is, there does not exist an element \\(x\\) of the set \\(A\\) such that \\(P(x)\\) is true. Therefore, we see that \\(\\neg [\\exists x\\in A, P(x)]\\) is a true proposition.\n\n\nExample 2.9 Write the negation of the statements\n\n\\(\\forall \\, n\\in \\mathbb{N}, n^2-n+3=0\\)\n\\(\\exists \\, n\\in \\mathbb{N}, n^2-n+3=0,\\)\n\nand for each one, explain whether it or its negation is true.\n\n\nSolution. By Theorem 2.1,\n\\[\n\\forall \\, n\\in \\mathbb{N}, n^2-n+3=0\n\\quad \\text{ has negation: } \\quad\n\\exists \\, n\\in \\mathbb{N}, n^2-n+3\\neq 0\n\\] and \\[\\begin{equation}\n\\exists \\, n\\in \\mathbb{N}, n^2-n+3=0\n\\quad \\text{ has negation: } \\quad\n\\forall \\, n\\in \\mathbb{N}, n^2-n+3\\neq 0\n\\end{equation}\\] The first statement \\(\\forall \\, n\\in \\mathbb{N}, n^2-n+3=0\\) is not true simply note that when \\(n=2\\), then \\((2)^2-(2)+3=5\\neq 0\\). Therefore its negation must be true. The second statement \\(\\exists \\, n\\in \\mathbb{N}, n^2-n+3=0\\) is false since there does not exist \\(n\\in \\mathbb{N}\\) such that \\(n^2-n+3=0\\).\n\n\nExample 2.10 Write the negation of the statement \\[\n\\exists !\\, n\\in \\mathbb{N}, n^2-n+3=0.\n\\]\n\n\nSolution. We want to write negation of the statement\n\nThere is one and only one \\(n\\in \\mathbb{N}\\) such that \\(n^2-n+3=0\\).\n\nThe negation is “There is no \\(n\\in \\mathbb{N}\\) such that \\(n^2-n+3=0\\) or there is more than one \\(n\\in \\mathbb{N}\\) such that \\(n^2-n+3=0\\)”. Another way of saying this is “For each \\(n\\in \\mathbb{N}\\), \\(n^2-n+3\\neq 0\\) or there exists at least two natural numbers \\(n\\) such that \\(n^2-n+3=0\\).”"
  },
  {
    "objectID": "predicate-logic.html#counterexamples",
    "href": "predicate-logic.html#counterexamples",
    "title": "2  Predicate Logic",
    "section": "2.6 Counterexamples",
    "text": "2.6 Counterexamples\nHow can we show that a statement of the form \\(\\forall x, P(x)\\) is false? Or equivalently, how can we show that the negation of \\(\\forall x, P(x)\\) is true? By Theorem 2.1, this simply means we need to show that \\(\\exists x, \\neg P(x)\\) is true. If we can find a value for \\(x\\) such that \\(\\neg P(x)\\) is true, then we have a ounterexample and have shown that \\(\\forall x, P(x)\\) is false. Intuitively for example, suppose that \\(P\\) is the predicate “is wearing a red shirt”, then a counterexample to the statement “everyone is wearing a red shirt” is the statement “found someone, not wearing a red shirt”.\n\nDefinition 2.5 If \\(P(x)\\) is a propositional function and \\(x\\) is a member of the set \\(A\\), then a counterexample to \\(\\forall x\\in A, P(x)\\) is a member \\(c\\) of the set \\(A\\) such that \\(P(c)\\) is false.\n\n\nExample 2.11 Show that the statement “All primes are odd” is false.\n\n\nSolution. The statement “All primes are odd” is written in universal quantification form as \\(\\forall x, P(x)\\) where \\(p\\) is the predicate “is odd” and the universe of discourse is the set of primes. It is easy to see that \\(2\\) is a counterexample because \\(2\\) is in the domain of discourse and is not prime."
  },
  {
    "objectID": "predicate-logic.html#combining-quantifiers",
    "href": "predicate-logic.html#combining-quantifiers",
    "title": "2  Predicate Logic",
    "section": "2.7 Combining Quantifiers",
    "text": "2.7 Combining Quantifiers\nOf course quantifiers can be nested, that is, it is possible to have a statement involving several quantifiers. Consider the following two statements:\n\nThere exists an integer \\(x\\) such that for every integer \\(y\\), \\(x+y=5\\).\nFor every integer \\(y\\) there exists an integer \\(x\\) such that \\(x+y=5\\).\n\nThese statements represented in symbolic form are, respectively,\n\n\\(\\exists x\\in \\mathbb{Z}, [ \\forall y\\in \\mathbb{Z}, (x+y=5) ]\\)\n\\(\\forall x\\in \\mathbb{Z}, [ \\exists y\\in \\mathbb{Z}, (x+y=5) ]\\)\n\nThese statements have very different meanings. In order for statement (1)), to be true we need to demonstrate at least one \\(x\\) such that for any given \\(y\\) (in the domain of discourse) that \\(x+y=5\\) is true. Since we can not specify an integer \\(x\\) such that \\(x+y=5\\) is true for all integers \\(y\\) we see that statement (1) is false.\nIn order for (2) to be true, we need to be able to specify an integer \\(y\\) once a given integer \\(x\\) has been specified, such that \\(x+y=5\\) is true. For example, if \\(x=3\\), then \\(y=2\\), then \\(3+2+5\\) is true. However this is just one value for \\(x\\), in order for (2) to be true, we need to specify an integer \\(y\\) for any given integer \\(x\\). We can specify an integer \\(y\\) when \\(x\\) is given just use \\(y=5-x\\). Since, if we are given an integer \\(x\\), we know that \\(y=5-x\\) is also an integer and \\(x+y=x+(5-x)=5\\). Thus we see that statement (2) is true.\nThe reader is encourage to practice writing out the negation of the definition of a limit.\n\nExample 2.12 (Definition of Limit) Recall from calculus, that the definition of a limit of a real-valued function is:\n\nFor every real number \\(\\epsilon>0\\) there exists a real number \\(\\delta>0\\) such that \\(|f(x)-L|<\\epsilon\\) whenever \\(0<|x-a|<\\delta\\).\n\nExpress the definition of a limit using quantifiers.\n\n\nSolution. This definition of limit can be phrased in term of quantifiers by \\[\n\\forall \\epsilon, \\exists \\delta, \\forall x, (0<|x-a|<\\delta \\rightarrow |f(x)-L|<\\epsilon)\n\\] where the universe of discourse for the variables \\(\\epsilon\\) and \\(\\delta\\) is the set of positive real numbers and for \\(x\\) is the set of real numbers.\n\n\nExample 2.13 Find the negation of the statement \\[\\begin{equation}\n\\label{negformone}\n\\exists x\\in \\mathbb{N}, \\forall y\\in \\mathbb{N}, (xy=y)\n\\end{equation}\\]\n\n\nSolution. This statement has the form \\[\n\\exists x, [\\forall y, P(x,y)]\n\\] where \\(P(x,y)\\) represents the propositional function \\(xy=y\\). We find the negation to be:\n\\[\\begin{align*}\n\\neg [\\exists x, [\\forall y, P(x,y)]]\n& \\equiv \\forall x, [\\neg [\\forall y, P(x,y)]]  \\\\\n& \\equiv \\forall x, [\\exists y, [\\neg P(x,y)]\n\\end{align*}\\]\nSo the negation of \\(\\eqref{negformone}\\) is \\[\\begin{equation*}\n\\forall x\\in \\mathbb{N}, [\\exists y\\in N, (xy\\neq y)].\n\\end{equation*}\\]\n\nThe next example uses the logical equivalence \\(p\\rightarrow q \\equiv p\\land \\neg q\\) and DeMorgan’s Law.\n\nExample 2.14 Find the negation of the statement \\[\\begin{equation}\n\\label{negformonea}\n\\forall x, \\forall y, [ x < y \\rightarrow \\exists z, (x < z \\land z < y) ]\n\\end{equation}\\]\n\nIf the domain of discourse for \\(x\\), \\(y\\) and \\(z\\) is \\(\\mathbb{R}\\), then is this statement true or false?\n\nSolution. This statement has the form \\[\n\\forall x, \\forall y, [ P(x,y)\\rightarrow \\exists z, [Q(x,z)\\land R(y,z)]\n\\] where \\(P(x,y)\\), \\(Q(x,z)\\), and \\(R(x,y)\\) represent the propositional functions \\(x<y\\), \\(x<z\\), and \\(z<y\\), respectively. We find the negation to be: \\[\\begin{align*}\n&\n\\neg \\big{[}\\forall x, \\forall y, [ P(x,y)\\rightarrow \\exists z, [Q(x,z)\\land R(y,z)] \\big{]}\n\\\\\n& \\qquad\n\\equiv\n\\exists x, \\neg \\big{[} \\forall y, [ P(x,y)\\rightarrow \\exists z, [Q(x,z)\\land R(y,z)] \\big{]}\n\\\\\n& \\qquad\n\\equiv\n\\exists x, \\exists y, \\neg [ P(x,y)\\rightarrow \\exists z, [Q(x,z)\\land R(y,z)]  \n\\\\\n& \\qquad\n\\equiv\n\\exists x, \\exists y, [ P(x,y)\\land \\neg [\\exists z, [Q(x,z)\\land R(y,z)]  \n\\\\\n& \\qquad\n\\equiv\n\\exists x, \\exists y, [ P(x,y)\\land [\\forall z, \\neg [Q(x,z)\\land R(y,z)]  \n\\\\\n& \\qquad\n\\equiv\n\\exists x, \\exists y, [ P(x,y)\\land [\\forall z, [\\neg Q(x,z)\\lor \\neg R(y,z)]  \n\\end{align*}\\] So the (working) negation of \\(\\eqref{negformonea}\\) is \\[\\begin{equation*}\n\\exists x, \\exists y, [ (x < y) \\land (\\forall z, (x\\geq z \\lor z\\geq y )]  \n\\end{equation*}\\]\n\n\n\n\nFigure 2.1: The sine function on \\([-\\pi/2,\\pi,2]\\).\n\n\n\nExample 2.15 Let \\(P(x,y)\\) be the statement \\[\n\\text{If $x<y$, then $\\sin x < \\sin y$.}\n\\] The domain of discourse is the closed interval \\(I=\\left[-\\frac{\\pi}{2},\\frac{\\pi}{2}\\right]\\). Determine which of the following statements \\[\n\\exists x, \\exists y, P(x,y) \\quad\n\\exists x, \\forall y, P(x,y) \\quad\n\\forall x, \\exists y, P(x,y) \\quad\n\\forall x, \\forall y, P(x,y)\n\\] are true and which are false.\n\n\nSolution. The first statement \\(\\exists x\\in I, \\exists y\\in I, P(x,y)\\) is true. To see this simply let \\(x=0\\) and \\(y=\\pi/2\\) because \\(0<1\\) and \\(\\sin 0=0<1 =\\sin \\pi/2\\).\nThe second statement \\(\\exists x\\in \\mathbb{R}, \\forall y\\in \\mathbb{R}, P(x,y)\\) is true. To see this let \\(x=-\\pi/2\\), and then notice that \\(\\forall y\\in I, P(-\\pi/2,y)\\) is a true statement. That is, \\[\n\\forall y\\in I, \\text{ if $-\\frac{\\pi}{2}<y$, then $-1<\\sin y$}\n\\] is true. Recall the graph of the sine function restricted to the domain of \\(I\\) (see Figure 2.1).\nThe third statement \\(\\forall x\\in I, \\exists y\\in I, P(x,y)\\) is true. We can not prove this statement is true with one value for \\(x\\). Let \\(x\\in I\\) be an arbitrary element in \\(I\\). Now that \\(x\\) is given we can set \\(y=x\\). Then \\(P(x,y)\\) is a true implication since it has a false hypothesis.\nThe fourth statement \\(\\forall x\\in I, \\forall y\\in I, P(x,y)\\) is true. Again we can not prove this statement is true with one value for \\(x\\). Moreover, for any given value of \\(x\\), the value of \\(y\\) must also be arbitrary. Let \\(x\\in I\\) be an arbitrary element in \\(I\\). If \\(y\\leq x\\), then the implication \\(P(x,y)\\) is true by a false hypothesis; and thus the statement \\(\\forall x\\in I, \\exists y\\in I, P(x,y)\\) is true in this case. If \\(x<y\\), then the hypothesis in the implication \\(P(x,y)\\) is true, but in fact the conclusion in \\(P(x,y)\\) is also true since the sine function is increasing on \\(I\\). Therefore, no matter what \\(x\\) in \\(I\\) is given we see that \\(P(x,y)\\) is true for all \\(y\\) in \\(I\\)."
  },
  {
    "objectID": "predicate-logic.html#inference-rules-for-quantified-statements",
    "href": "predicate-logic.html#inference-rules-for-quantified-statements",
    "title": "2  Predicate Logic",
    "section": "2.8 Inference Rules for Quantified Statements",
    "text": "2.8 Inference Rules for Quantified Statements\nBefore we begin proving theorems, we need to discuss the inference rules for quantified statements. However, before we do so, the reader is encourage to complete Exercise 3.29, that is, write out each incidence axiom in symbolic form and also write the negation of each one in both symbolic and English form.\nSuppose that \\(\\exists x\\in U\\), \\(P(x)\\) is true, where \\(U\\) is the domain of discourse. By Definition 2.3, \\(P(x)\\) is true for some \\(x\\) in \\(U\\). Thus, there exists \\(c\\in U\\) such that \\(P(c)\\) is true. Hence we have shown that the argument \\[\n\\begin{array}{l}\n\\exists x, P(x)\n\\\\ \\hline\n\\therefore \\, \\text{$P(c)$ for some element $c\\in U$}\n\\end{array}\n\\] is valid. Now suppose that \\(\\forall x\\in U\\), \\(P(x)\\) is true. By Definition 2.4, \\(P(x)\\) is true for every \\(x\\) in \\(U\\). In particular, if \\(c\\in U\\), then \\(P(c)\\) is true. Hence we have shown that the argument \\[\n\\begin{array}{l}\n\\forall x, P(x)\n\\\\ \\hline\n\\therefore \\, \\text{$P(c)$ if $c\\in U$}\n\\end{array}\n\\] is valid. The reader should write careful arguments to justify the other two inference rules. All four are listed below.\n\n\nTable 2.1: Inference Rules for Universe\n\n\n\n\n\n\nInference Rules for Universe \\(U\\)\nName\n\n\n\n\n\\(\\begin{array}{l} \\forall x, P(x) \\\\ \\hline \\therefore \\, \\text{$P(c)$ if $c\\in U$} \\end{array}\\)\nUniversal instantiation\n\n\n\\(\\begin{array}{l} P(c) \\text{ for an arbitrary $c\\in U$} \\\\ \\hline \\therefore \\, \\forall x, P(x) \\end{array}\\)\nUniversal generalization\n\n\n\\(\\begin{array}{l} \\exists x, P(x) \\\\ \\hline \\therefore \\, \\text{$P(c)$ for some element $c\\in U$} \\end{array}\\)\nExistential instantiation\n\n\n\\(\\begin{array}{l} P(c) \\text{ for some element $c\\in U$} \\\\ \\hline \\therefore \\, \\exists x, P(x) \\end{array}\\)\nExistential generalization"
  },
  {
    "objectID": "predicate-logic.html#exercises",
    "href": "predicate-logic.html#exercises",
    "title": "2  Predicate Logic",
    "section": "2.9 Exercises",
    "text": "2.9 Exercises\n\nExercise 2.1 Write the negation for each statement.\n\n\\(\\forall x, p(x) \\land q(x)\\)\n\\(\\forall x, p(x)\\lor q(x)\\)\n\\(\\forall x, p(x)\\rightarrow q(x)\\)\n\\(\\forall x, p(x)\\leftrightarrow q(x)\\)\n\\(\\forall x, \\neg p(x)\\)\n\n\n\nExercise 2.2 Write the negation for each statement.\n\n\\(\\exists x, p(x) \\land q(x)\\)\n\\(\\exists x, p(x)\\lor q(x)\\)\n\\(\\exists x, p(x)\\rightarrow q(x)\\)\n\\(\\exists x, p(x)\\leftrightarrow q(x)\\)\n\\(\\exists x, \\neg p(x)\\)\n\n\nLet \\(\\mathbb{N}\\), \\(\\mathbb{Z}\\), \\(\\mathbb{Q}\\), \\(\\mathbb{R}\\), and \\(\\mathbb{C}\\) denote the natural numbers, integers, the rational numbers, the real numbers and the complex numbers, respectively.\n\nExercise 2.3 Decide which of the following propositions are true and which are false.\n\n\\(\\exists \\ x\\in \\mathbb{Q}, x^3+3=0.\\)\n\\(\\exists \\ x\\in \\mathbb{R}, x^3+3=0.\\)\n\\(\\exists \\ x\\in \\mathbb{C}, x^3+3=0.\\)\n\\(\\exists! \\ x\\in \\mathbb{Q}, x^3+3=0.\\)\n\\(\\exists! \\ x\\in \\mathbb{R}, x^3+3=0.\\)\n\\(\\exists! \\ x\\in \\mathbb{C}, x^3+3=0.\\)\n\n\n\nExercise 2.4 Decide which of the following propositions are true and which are false.\n\n\\(\\forall \\ x\\in \\mathbb{N}, \\exists \\ y\\in \\mathbb{N}, x\\leq y\\)\n\\(\\forall \\ x\\in \\mathbb{Z}, \\exists \\ y\\in \\mathbb{Z}, x\\leq y\\)\n\\(\\exists \\ x\\in \\mathbb{Q}, \\exists \\ y\\in \\mathbb{N}, x\\leq y\\)\n\\(\\exists \\ x\\in \\mathbb{N}, \\forall \\ y\\in \\mathbb{N}, x\\leq y\\)\n\\(\\forall \\ x\\in \\mathbb{Z}, \\forall \\ y\\in \\mathbb{Z}, x\\leq y\\)\n\\(\\exists \\ x\\in \\mathbb{Q}, \\forall \\ y\\in \\mathbb{N}, x\\leq y\\)\n\n\n\nExercise 2.5 Rewrite the following propositions symbolically with the quantifiers explicit and in the correct place.\n\nFor every two distinct points \\(A\\) and \\(B\\) there exists a unique line \\(l\\) incident with \\(A\\) and \\(B\\).\nFor every line \\(l\\) there exist at least two distinct points incident with \\(l.\\)\nThere exist three distinct points with the property that no line is incident with all three of them.\n\n\n\nExercise 2.6 If the statement is written in symbols, then rewrite the statement using words; and conversely. For each also write its negation in both symbols and words.\n\n\\((\\exists \\, x\\in \\mathbb{Z})(\\forall \\, y\\in \\mathbb{Z})(x+y=0)\\)\nThere exists an integer \\(x\\) such that for all real numbers \\(y\\) the sum of \\(x\\) and \\(y\\) is zero.\nThere exists an integer \\(y\\) such that for all rational numbers \\(x\\) the sum of \\(x\\) and \\(y\\) is zero.\nThere exists a natural number \\(x\\) such that for all integers \\(y\\) the sum of \\(x\\) and \\(y\\) is zero.\nThere exists an natural number \\(y\\) such that for all natural numbers \\(x\\) the sum of \\(x\\) and \\(y\\) is zero.\n\\((\\forall \\, x\\in \\mathbb{N})(\\exists \\, y\\in \\mathbb{N})(x y=x)\\)\nThere exists an integer \\(x\\) such that for all real numbers \\(y\\) the product of \\(x\\) and \\(y\\) is \\(x\\).\nThere exists an integer \\(y\\) such that for all real numbers \\(x\\) the product of \\(x\\) and \\(y\\) is \\(x\\).\nThere exists a natural number \\(x\\) such that for all integers \\(y\\) the product of \\(x\\) and \\(y\\) is \\(x\\).\nThere exists an natural number \\(y\\) such that for all rational numbers \\(x\\) the product of \\(x\\) and \\(y\\) is \\(x\\).\nGiven any two distinct real numbers, some rational number lies strictly between them.\n\\(\\forall \\, x,y\\in \\mathbb{R}, (x\\neq y\\rightarrow \\exists \\, z\\in \\mathbb{Q}, x<z<y)\\)\n\\(\\exists \\, x,y\\in \\mathbb{R}, (x\\neq y\\rightarrow \\exists \\, z\\in \\mathbb{Q}, x<z<y)\\)\n\\(\\exists \\, x,y\\in \\mathbb{R}, (x\\neq y\\rightarrow \\forall \\, z\\in \\mathbb{Q}, x<z<y)\\)\n\\(\\forall \\, x,y\\in \\mathbb{R}, (x\\neq y\\rightarrow \\forall \\, z\\in \\mathbb{Q}, x<z<y)\\)\n\\(\\exists \\, x,y\\in \\mathbb{R}, (x\\neq y \\rightarrow \\exists \\, z\\in \\mathbb{Q}, x<z<y)\\)\n\\((\\exists \\, x\\in \\mathbb{Z})(\\forall \\, y\\in \\mathbb{Q})(x+y=0)\\)\n\\((\\forall \\, y\\in \\mathbb{Z})(\\exists \\, x\\in \\mathbb{Z})(x+y=0)\\)\n\\((\\forall \\, x\\in \\mathbb{N})(\\exists \\, y\\in \\mathbb{N})(x y=x)\\)\n\\((\\exists \\, y\\in \\mathbb{N})(\\forall \\, x\\in \\mathbb{N})(x y=x)\\)\n\\((\\forall \\, x\\in \\mathbb{N})(\\exists \\, y\\in \\mathbb{N})(x=y-7)\\)\n\\((\\exists \\, y\\in \\mathbb{N})(\\forall \\, x\\in \\mathbb{N})(x=y-7)\\)\n\\((\\forall \\, y\\in \\mathbb{N})(\\forall \\, x\\in \\mathbb{N})(y=x-7)\\)\n\\((\\exists \\, x\\in \\mathbb{N})(\\exists \\, y\\in \\mathbb{N})(y=x-7)\\)\nFor all integers \\(x\\) and \\(y\\), the numbers \\(x y\\) and \\(y x\\) are equal.\nGiven any real number \\(x,\\) there exists a natural number \\(n\\) such that \\(x<n\\)\nGiven any real number \\(x,\\) there exists a natural number \\(y\\) such that \\(x+y=0.\\)\nGiven any nonnegative real number \\(x,\\) there exists a natural number \\(y\\) such that \\(y^2=x.\\)\nGiven any nonzero real number \\(x,\\) there exists a natural number \\(y\\) such that \\(x y=1.\\)\nThere exists a smallest natural number.\nThere is no largest integer.\nGiven any two distinct real numbers, some rational number lies strictly between them.\nGiven any positive real number \\(\\epsilon ,\\) there exists a natural number \\(k\\) such that \\(\\frac{1}{n} < \\epsilon\\) whenever \\(n\\) is a natural number greater than \\(k.\\)\nFor each real number \\(\\epsilon ,\\) if \\(\\epsilon >0\\) then there exists a positive real number \\(\\delta\\) such that for each number \\(x,\\) if \\(|x-2|<\\delta\\) then \\(\\left|x^2-4\\right|<\\epsilon .\\)\n\n\n\nExercise 2.7 Finish the proof of Theorem 2.1."
  },
  {
    "objectID": "mathematical-proofs.html#logical-discourse",
    "href": "mathematical-proofs.html#logical-discourse",
    "title": "3  Mathematical Proofs",
    "section": "3.1 Logical Discourse",
    "text": "3.1 Logical Discourse\nThe pattern of logical discourse goes as follows:\n\nA collection of primitive (undefined terms) is given.\nA collection of axioms (unproven statements) about the primitive terms is also given.\n\nThen all of the terms of the discourse are defined by means of the primitive terms or by previously defined terms that were defined using primitive terms.\n\nAll other statements in the system are logically deduced from the axioms. These are the theorems of the system.\n\nIn mathematical exposition, we often communicate by distinguishing different types of theorems. For example, a theorem is sometimes called a result. There is an air of humility in calling a theorem merely a result. Other alternatives to theorem are listed below.\nFact. A very minor theorem, but important enough to number and refer to latter, i.e., the statement \\(1+1=2\\) is a fact.\nProposition. Also a minor theorem, but more important (usually more general) than a fact –but not as prestigious as a theorem.\nLemma. Often a technical theorem, which is used to help prove another more important theorem. Stating lemmas, before proving a difficult complicated theorem, is functional.\nClaim. Similar to lemma but less formal. A claim will often be referred to only a small number of times, whereas a lemma may be referenced many times and is a useful result in itself. For example, stating a claim inside the proof theorem is a great way to help organize key steps in a proof.\nCorollary. An important enough result to state on its own whose proof requires a previously proved theorem as its main step."
  },
  {
    "objectID": "mathematical-proofs.html#writing-proofs",
    "href": "mathematical-proofs.html#writing-proofs",
    "title": "3  Mathematical Proofs",
    "section": "3.2 Writing Proofs",
    "text": "3.2 Writing Proofs\n\n3.2.1 Direct Proofs\nBasically, direct proofs are proofs that do not use the Law of Excluded middle tautology. In each of the following examples, we use inference rules to write a proof in column format – and we also write a paragraph proof.\n\nExample 3.2 Given the three previously proven theorems:\n\nTheorem 1: \\(p\\rightarrow q\\),\nTheorem 2: \\(q\\rightarrow r\\), and\nTheorem 3: \\(r\\rightarrow s\\).\n\nWe can now prove the next theorem. \\[\n\\text{Theorem: If $p$ then $s$.}\n\\]\n\n\nSolution. We begin with a column proof.\n\n\n\nConclusions\nJustifications\n\n\n\n\n\n\\(p\\)\npremise\n\n\n\n\\(p\\rightarrow q\\)\ntheorem 1\n\n\n\n\\(q\\)\nsteps 1 and 2, modus ponens\n\n\n\n\\(q\\rightarrow r\\)\ntheorem 2\n\n\n\n\\(r\\)\nsteps 3 and 4, modus ponens\n\n\n\n\\(r\\rightarrow s\\)\ntheorem 3\n\n\n\n\\(s\\)\nsteps 5 and 6, modus ponens\n\n\n\n\nWe end with a paragraph proof.\n\nAssume \\(p\\). By Theorem 1, we know \\(q\\), and so by Theorem 2, we now have \\(r\\). Hence by Theorem 3, we have \\(s\\) as needed.\n\n\n\nExample 3.3 Prove: if \\(p\\lor q\\) and \\(\\neg \\, q\\), then \\(p\\).\n\n\nSolution. We begin with a column proof.\n\n\n\nConclusions\nJustifications\n\n\n\n\n\\(\\neg q\\)\npremise\n\n\n\\(p\\lor q\\)\npremise\n\n\n\\(p\\)\ndisjunctive syllogism\n\n\n\nWe end with a paragraph proof:\n\nAssume \\(\\neg q\\) and \\(p\\lor q\\). We can not have \\(q\\) and \\(\\neg q\\), thus \\(p\\) follows immediately.\n\n\n\nExample 3.4 Assume the following:\n\nDefinition: \\(a\\) is said to be \\(b\\) iff \\(r\\rightarrow s\\),\nAxiom 1: \\(r\\rightarrow q\\),\nTheorem 1: If \\(a\\) is \\(c\\) then \\(q\\rightarrow t\\),\nTheorem 2: \\(t\\rightarrow s\\).\n\nProve the following theorem. \\[\n\\text{Theorem: If $a$ is $c$ then $a$ is $b.$}\n\\]\n\n\nSolution. We begin with a column proof.\n\n\n\nConclusions\nJustifications\n\n\n\n\n\\(a\\) is \\(c\\)\npremise\n\n\nif \\(a\\) is \\(c\\) then \\(q\\rightarrow t\\)\ntheorem 1\n\n\n\\(q\\rightarrow t\\)\nsteps 2 and 3, modus ponens\n\n\n\\(r\\)\npremise\n\n\n\\(r\\rightarrow q\\)\naxiom 1\n\n\n\\(q\\)\nsteps 4 and 5, modus ponens\n\n\n\\(t\\)\nsteps 3 and 6, modus ponens\n\n\n\\(t\\rightarrow s\\)\ntheorem 2\n\n\n\\(s\\)\nsteps 7 and 8, modus ponens\n\n\n\\(r\\rightarrow s\\)\nsteps 4 through 9\n\n\n\\(a \\text{ is } b\\)\ndefinition of \\(a\\) is \\(b\\)\n\n\n\nWe end with a paragraph proof:\n\nAssume \\(a\\) is \\(c\\). By Theorem 1, we have \\(q\\rightarrow t\\). To prove that \\(a\\) is \\(b\\) we assume \\(r\\). Then by Axiom 1, we have \\(q\\), which now yields \\(t\\). By Theorem 2, it follows that \\(s\\). Therefore we have shown \\(r\\rightarrow s\\) as needed.\n\n\n\n\n3.2.2 Indirect Proofs\n\nExample 3.5 Given the two previously proven theorems:\n\nTheorem 1: \\(\\neg q\\rightarrow r\\),\nTheorem 2: If \\(r\\) then either \\(\\neg p\\) or \\(q\\).\n\nProve the following theorem. \\[\n\\text{Theorem: $p\\rightarrow q.$}\n\\]\n\n\nSolution. We begin with a column proof.\n\n\n\n\n\n\n\nConclusions\nJustifications\n\n\n\n\n\\(p\\)\npremise\n\n\n\\(q \\lor \\neg q\\)\nexcluded middle\n\n\n\\(\\neg\\)\npremise\n\n\n\\(\\neg q\\rightarrow r\\)\ntheorem 1\n\n\n\\(r\\)\nsteps 3 and 4, modus ponens\n\n\n\\(r\\rightarrow (\\neg p \\lor q)\\)\ntheorem 2\n\n\n\\(\\neg p \\lor q\\)\nsteps 5 and 6, modus ponens\n\n\n\\(p\\land \\neg q\\)\nsteps 1 and 3\n\n\n\\(\\neg(\\neg p)\\land \\neg q\\)\ndouble negation\n\n\n\\(\\neg (\\neg p \\lor q)\\)\nstep 9, De Morgan\n\n\n\\((\\neg p \\lor q) \\land \\neg (\\neg p \\lor q)\\)\nsteps 7 and 10, contradiction\n\n\n\\(q\\)\nsteps 3 and 11, indirect proof\n\n\n\nWe end with a paragraph proof:\n\nAssume \\(p\\). Suppose \\(\\neg q\\) for otherwise we are finished. Then \\(r\\) by Theorem 1. By hypothesis we cannot have \\(\\neg p\\), and so by Theorem 2, we have \\(q\\) as needed.\n\n\n\nExample 3.6 Prove: if \\(p\\leftrightarrow q\\) and \\(q\\rightarrow \\neg \\, p\\), then \\(\\neg \\, p\\).\n\n\nSolution. We begin with a column proof.\n\n\n\n\n\n\n\nConclusions\nJustifications\n\n\n\n\n\\(p\\leftrightarrow q\\)\npremise\n\n\n\\((p\\rightarrow q) \\land (q\\rightarrow p\\)\ndefinition of \\(\\leftrightarrow\\)\n\n\n\\(p\\rightarrow q\\)\nsimplification\n\n\n\\(q\\rightarrow \\neg p\\)\npremise\n\n\n\\(p\\lor \\neg p\\)\nexcluded middle\n\n\n\\(p\\)\npremise\n\n\n\\(q\\)\nsteps 3 and 6, modus ponens\n\n\n\\(\\neg p\\)\nsteps 4 and 7, modus ponens\n\n\n\\(p\\land \\neg p\\)\nsteps 6 and 9, contradiction\n\n\n\\(\\neg p\\)\nsteps 5-9, indirect proof\n\n\n\nWe end with a paragraph proof:\n\nAssume for a contradiction \\(p\\). Since \\(p\\) and \\(q\\) are equivalent, we have \\(q\\). By hypothesis, we then have \\(\\neg p\\). Since \\(\\neg p\\) and \\(p\\) is a contradiction, our original premise of \\(p\\) can not happen. Whence \\(\\neg p\\).\n\n\n\nExample 3.7 Assume the following:\n\nAxiom 1: \\(p\\) implies either \\(r\\) or \\(s\\),\nTheorem 1: \\(y\\rightarrow \\neg p\\),\nTheorem 2: \\(r\\rightarrow x\\),\nTheorem 3: \\(s\\rightarrow y\\),\nTheorem 4: \\(x\\rightarrow q\\).\n\nProve the following theorem. \\[\n\\text{Theorem: $p\\rightarrow q.$}\n\\]\n\n\nSolution. We begin with a column proof.\n\n\n\nConclusions\nJustifications\n\n\n\n\n\\(p\\)\npremise\n\n\n\\(p\\rightarrow (r\\lor s)\\)\naxiom 1\n\n\n\\(r\\lor s\\)\nsteps 1 and 2, modus ponens}\n\n\n\\(s\\)\npremise\n\n\n\\(s\\rightarrow y\\)\ntheorem 3\n\n\n\\(y\\)\nsteps 4 and 5, modus ponens\n\n\n\\(y\\rightarrow \\neg p\\)\ntheorem 1\n\n\n\\(\\neg p\\)\nsteps 6 and 7, modus ponens\n\n\n\\(p\\land \\neg p\\)\nsteps 1 and 8, contradiction\n\n\n\\(\\neg s\\)\nsteps 4-9, indirect proof\n\n\n\\(r\\)\nsteps 3 and 10, disjunctive syllogism\n\n\n\\(r\\rightarrow x\\)\ntheorem 2\n\n\n\\(x\\)\nsteps 11 and 12, modus ponens\n\n\n\\(x\\rightarrow q\\)\ntheorem 4\n\n\n\\(q\\)\nsteps 13 and 14, modus ponens\n\n\n\nWe end with a paragraph proof:\n\nAssume \\(p\\). If we have \\(s\\), then by Theorem 3, we have \\(y\\); yet by Theorem 1 this yields \\(\\neg p\\). Since we can not have both \\(\\neg p\\) and \\(p\\) we see that we can not have \\(s\\). Hence we have \\(\\neg s\\). By Axiom 1, we must have \\(r\\). By Theorem 2, we now have \\(x\\), and so by Theorem 4, we conclude with \\(q\\) as needed.\n\n\n\n\n3.2.3 Proof by Contrapositive\n\nExample 3.8 Assume the following:\n\nAxiom 1: \\(p\\rightarrow \\neg y\\).\nAxiom 2: \\(\\neg q\\rightarrow r\\).\nTheorem 1: \\(p\\rightarrow \\neg z\\).\nTheorem 2: \\(x\\rightarrow \\text{ either } q \\text{ or } z.\\).\nTheorem 3: \\(r\\rightarrow \\text{ either } x \\text{ or } y\\). \\[\n\\text{Theorem: $\\neg p\\rightarrow \\neg q.$}\n\\]\n\n\n\nSolution. We prove the (logical equivalent) contrapositive statement \\(p\\rightarrow q\\).\nWe begin with a column proof.\n\n\n\nConclusions\nJustifications\n\n\n\n\n\\(p\\)\npremise\n\n\n\\(p\\rightarrow \\neg y\\)\naxiom 1\n\n\n\\(\\neg y\\)\nsteps 1 and 2, modus ponens\n\n\n\\(q \\lor \\neg q\\)\nexcluded middle\n\n\n\\(\\neg q\\)\npremise\n\n\n\\(\\neg q\\rightarrow r\\)\naxiom 2\n\n\n\\(r\\)\nsteps 5 and 6, modus ponens\n\n\n\\(r\\rightarrow x \\lor y\\)\ntheorem 3\n\n\n\\(x \\lor y\\)\nsteps 7 and 8, modus ponens\n\n\n\\(x\\)\nsteps 3 and 9, disjunctive syllogism\n\n\n\\(x\\rightarrow q\\lor z\\)\ntheorem 2\n\n\n\\(q\\lor z\\)\nsteps 10 and 11, modus ponens\n\n\n\\(z\\)\npremise\n\n\n\\(p\\rightarrow \\neg z\\)\ntheorem 1\n\n\n\\(z \\rightarrow \\neg p\\)\ncontrapositive\n\n\n\\(\\neg p\\)\nsteps 13 and 15, modus ponens\n\n\n\\(p\\land \\neg p\\)\nsteps 1 and 16, contradiction\n\n\n\\(\\neg z\\)\nsteps 13 and 17, indirect proof\n\n\n\\(q\\)\nsteps 12 and 18, disjunctive syllogism\n\n\n\\(\\neg (\\neg q)\\)\nsteps 5 and 19, contradiction\n\n\n\\(q\\)\nsteps 4 and 20, disjunctive syllogism\n\n\n\nWe end with a paragraph proof:\n\nAssume \\(p\\). Then by Axiom 1 we have \\(\\neg y\\). Assume for a contradiction that \\(\\neg q\\). Then by Axiom 2 we have \\(r\\), and so either \\(x\\) or \\(y\\) by Theorem 3. In case we have \\(x\\), then by Theorem 2 we have \\(z\\). Now \\(\\neg p\\) follows by Theorem 1 and so this contradiction show that \\(x\\) can not happen. Hence \\(y\\) follows. Yet now we have \\(y\\) and \\(\\neg y\\) and so it fact we cannot have \\(\\neg q\\). Therefore \\(q\\) as needed.\n\n\n\n\n3.2.4 Proof by Cases\n\nExample 3.9 Assume the following:\n\nTheorem 1: \\(r\\rightarrow \\, \\neg p\\),\nTheorem 2: \\(s\\rightarrow \\, \\neg p\\),\nTheorem 3: A complete set of logical possibilities is: \\(r, s,\\) and \\(q;\\) that is, one of the statements \\(r, s,\\) and \\(q\\) is true and only one.\n\nProve the following theorem. \\[\n\\text{Theorem: If $p$ then $q$.}\n\\]\n\n\nSolution. We begin with a column proof.\n\n\n\nConclusions\nJustifications\n\n\n\n\n\\(p\\)\npremise\n\n\none and only one holds: \\(r, s, q\\)\ntheorem 3\n\n\n\\(r\\)\npremise (case 1)\n\n\n\\(r\\rightarrow \\neg p\\)\ntheorem 1\n\n\n\\(\\neg p\\)\nsteps 3 and 4, modus ponens\n\n\n\\(p \\land \\neg p\\)\nsteps 1 and 5, contradiction\n\n\n\\(\\neg r\\)\nsteps 3 and 6, indirect proof\n\n\n\\(s\\)\npremise (case 2)\n\n\n\\(s\\rightarrow \\neg p\\)\ntheorem 2\n\n\n\\(\\neg p\\)\nsteps 8 and 9, modus ponens\n\n\n\\(p \\land \\neg p\\)\nsteps T and 10, contradiction\n\n\n\\(\\neg s\\)\nsteps 8 and 11, indirect proof\n\n\n\\(q\\)\nstep 2\n\n\n\nWe end with a paragraph proof:\n\nAssume \\(p\\). By Theorem 3, there are exactly three cases two consider. If \\(r\\), then we have \\(\\neg p\\) by Theorem 1 which is contrary to hypothesis. Similarly, \\(s\\) is contrary to hypothesis. Hence we have \\(q\\) as needed.\n\n\nWe end this section with a short discussion on how you might have seen these types of arguments (proofs) before in precalculus. We will demonstrate three ways to prove the statement: \\[\n\\text{If  $x^3-x^2+x-1=0$, then $x=1$.}\n\\]\n\n(Direct Proof) Assume \\(x^3-x^2+x-1=0\\). Then \\((x-1)(x^2+1)=0\\), which implies that either \\(x-1=0\\) or \\(x^2+1=0\\). But we know that \\(x^2+1\\neq 0\\) (since \\(x\\) is real), and so it must be the case that \\(x-1\\)=0. Hence \\(x=1\\).\n(Proof by Contrapositive) Assume \\(x\\neq 1\\). Then \\(x-1\\neq 0\\). Also, since \\(x\\) is real, \\(x^2+1\\neq 0\\). It follows that \\((x-1)(x^2+1)\\neq 0\\). Upon multiplication we obtain the result \\(x^3-x^2+x-1\\neq 0\\).\n(Proof by Contradiction) Suppose \\(x^3-x^2+x-1\\) and assume for a contradiction that \\(x\\neq 1\\). Then \\(x-1\\neq 0\\). Since \\(x^4-x^2+x-1=(x-1)(x^2+1))\\) and \\(x-1\\neq 0\\), it must be that \\(x^2+1=0\\). This is a contradiction because \\(x\\) is a real number. Therefore, we conclude \\(x=1\\)."
  },
  {
    "objectID": "mathematical-proofs.html#axiomatic-systems",
    "href": "mathematical-proofs.html#axiomatic-systems",
    "title": "3  Mathematical Proofs",
    "section": "3.3 Axiomatic Systems",
    "text": "3.3 Axiomatic Systems\nIn this chapter we discuss axiomatic systems and inference rules for quantified statements. To give an example of this process, we carry out a simple logical discourse for incidence geometry involving points, lines, and incidence.\nAn axiomatic (or formal) system must contain a set of technical terms that are deliberately chosen as undefined, called undefined terms, and are subject to the interpretation (an intuition) of the reader. All other technical terms of the system are ultimately defined by means of the undefined terms, and are called definitions. An axiomatic system contains a set of statements, dealing with undefined terms and definitions, that are chosen to remain unproved, and are called axioms.\n\n3.3.1 Incidence Geometry\nBelow is an example of a simple axiomatic system where the terms , , and only have the meaning given by a small collection of axioms.\nWe assume that we have a collection of points and a collection of lines. The only other assumptions we make about these points and lines, and their behavior, is given solely by the axioms.\n\nThe goal is not to say what a point is or what a line is, but rather to discover how they behave, relatively to each other.\n\nAxioms. Let point, line, and incidence be undefined terms. Collectively the following three axioms are called the Incidence Axioms.\n(A1) For every two distinct points \\(A\\) and \\(B\\) there exists a unique line \\(l\\) incident with \\(A\\) and \\(B\\), and is denoted by \\(l(A,B)\\).\n(A2) For every line \\(l\\) there exist at least two distinct points incident with \\(l.\\)\n(A3) There exist three distinct points with the property that no line is incident with all three of them.\nWe will use the following convention: uppercase letters denote points, i.e. \\(A\\), \\(B\\), \\(P\\), \\(Q\\), etc, and lowercase letters denote lines, i.e. \\(l, m, n\\).\n\nDefinition 3.2 Three or more points are called collinear if there exists a line incident with all of them. Three or more lines are called concurrent if there exists a point incident with all of them.\n\nNotice the definitions of collinear and concurrent are dual notions, in the sense that they are defined the same way except that the roles of point and line are interchanged. We use the terms noncollinear and nonconcurrent to mean not collinear and not concurrent, respectively.\nLines \\(l\\) and \\(m\\) are called equal lines , denoted by \\(l=m\\), if every point incident with \\(l\\) is also incident with \\(m\\), and conversely. Lines \\(l\\) and \\(m\\) are called parallel lines if \\(l=m\\) or if no point is incident with both of them. The notation \\(l\\parallel m\\) means line \\(l\\) is parallel to line \\(m\\).\n\nTheorem 3.1 If \\(l\\) and \\(m\\) are distinct lines that are not parallel, then \\(l\\) and \\(m\\) have a unique point in common.\n\n\n\n\nFigure 3.1: Unique point in common.\n\n\n\nProof. We begin with a column proof.\n\n\n\n\n\n\n\n\nNo.\nConclusions\nJustifications\n\n\n\n\n1\nLines \\(l\\) and \\(m\\) are distinct lines that are not parallel.\nHypothesis\n\n\n2\nExactly one must hold: \\(l\\) and \\(m\\) either have no points in common or not\nLaw of Excluded Middle\n\n\n3\nThere does not exists any points incident with both \\(l\\) and \\(m\\).\nCase 1\n\n\n4\nLines \\(l\\) and \\(m\\) are parallel.\nDefinition of parallel\n\n\n5\n\\(\\rightarrow\\leftarrow\\)\nSteps 1, 4\n\n\n6\nLines \\(l\\) and \\(m\\) have points in common.\nCase 2\n\n\n7\nExactly one must hold: lines \\(l\\) and \\(m\\) have exactly one point in common or more.\nLaw of Excluded Middle\n\n\n8\nThere exists distinct points \\(P\\) and \\(Q\\) that are both incident with both lines \\(l\\) and \\(m\\).\nCase 2.1\n\n\n9\n\\(l=m\\)\nAxiom 1\n\n\n10\n\\(\\rightarrow\\leftarrow\\)\nStep 1\n\n\n11\nThere exists exactly one point incident with lines \\(l\\) and \\(m\\).\nCase 2.2\n\n\n\nWe end with a paragraph proof.\n\nAssume \\(l\\) and \\(m\\) are distinct lines that are not parallel. By definition of parallel lines, these lines must have at least one point in common. If they have another point in common, then they are the same line by Axiom 1. Therefore, they have a unique point in common.\n\n\n\nTheorem 3.2 There exist three distinct lines that are nonconcurrent.\n\n\n\n\nFigure 3.2: Nonconcurrent lines.\n\n\n\nProof. We begin with a column proof.\n\n\n\n\n\n\n\n\nNo.\nConclusions\nJustifications\n\n\n\n\n1\n\\(A\\), \\(B\\), and \\(C\\) are distinct noncollinear points.\nAxiom 3\n\n\n2\nThere exists a line \\(\\overleftrightarrow{AB}\\) incident with \\(A\\) and \\(B\\).\nAxiom 1\n\n\n3\nThere exists a line \\(\\overleftrightarrow{BC}\\) incident with \\(B\\) and \\(C\\).\nAxiom 1\n\n\n4\nThere exists a line \\(\\overleftrightarrow{AC}\\) incident with \\(A\\) and \\(C\\).\nAxiom 1\n\n\n5\n\\(\\overleftrightarrow{AB}=\\overleftrightarrow{BC}\\)\nRAA Hypothesis\n\n\n6\n\\(A\\) is incident with \\(\\overleftrightarrow{BC}\\)\nDefinition of equality\n\n\n7\n\\(A\\), \\(B\\), and \\(C\\) are collinear points.\nDefinition of collinear\n\n\n8\n\\(\\rightarrow\\leftarrow\\)\nSteps 1, 7\n\n\n9\n\\(\\overleftrightarrow{AB}\\neq\\overleftrightarrow{BC}\\)\nRAA Conclusion\n\n\n10\n\\(\\overleftrightarrow{AB}=\\overleftrightarrow{AC}\\)\nRAA Hypothesis\n\n\n11\n\\(B\\) is incident with \\(\\overleftrightarrow{AC}\\)\nDefinition of equality\n\n\n12\n\\(A\\), \\(B\\), and \\(C\\) are collinear points.\nDefinition of collinear\n\n\n13\n\\(\\rightarrow\\leftarrow\\)\nSteps 1, 12\n\n\n14\n\\(\\overleftrightarrow{AB}\\neq\\overleftrightarrow{AC}\\)\nRAA Conclusion\n\n\n15\n\\(\\overleftrightarrow{AC}=\\overleftrightarrow{BC}\\)\nRAA Hypothesis\n\n\n16\n\\(A\\) is incident with \\(\\overleftrightarrow{BC}\\)\nDefinition of equality\n\n\n17\n\\(A\\), \\(B\\), and \\(C\\) are collinear points.\nDefinition of collinear\n\n\n18\n\\(\\rightarrow\\leftarrow\\)\nSteps 1, 17\n\n\n19\n\\(\\overleftrightarrow{AC}\\neq\\overleftrightarrow{BC}\\)\nRAA Conclusion\n\n\n20\nLines \\(\\overleftrightarrow{AB}\\), \\(\\overleftrightarrow{BC}\\), \\(\\overleftrightarrow{AC}\\) are three distinct lines.\nSteps 9, 14, 19\n\n\n21\nThere exists a point \\(X\\) incident with all three lines \\(\\overleftrightarrow{AB}\\), \\(\\overleftrightarrow{BC}\\), \\(\\overleftrightarrow{AC}\\).\nRAA Hypothesis\n\n\n22\nOne and only one must hold: \\(X=A\\) or \\(X\\neq A\\).\nLaw of Excluded Middle\n\n\n23\n\\(X=A\\)\nCase 1\n\n\n24\nPoint \\(A\\) is incident with all three lines \\(\\overleftrightarrow{AB}\\), \\(\\overleftrightarrow{BC}\\), and \\(\\overleftrightarrow{AC}\\).\nSteps 21, 23\n\n\n25\n\\(A\\), \\(B\\), \\(C\\) are collinear points.\nDefinition of Collinear\n\n\n26\n\\(\\rightarrow\\leftarrow\\)\nSteps 1, 25\n\n\n27\n\\(X\\neq A\\)\nCase 2\n\n\n28\nLines \\(\\overleftrightarrow{AB}\\) and \\(\\overleftrightarrow{AC}\\) are not parallel.\nDef. of Parallel Lines\n\n\n29\n\\(X=A\\)\nTheorem 2\n\n\n30\n\\(\\rightarrow\\leftarrow\\)\nSteps 27, 29\n\n\n31\nThere does not exist a point \\(X\\) incident with all three lines \\(\\overleftrightarrow{AB}\\), \\(\\overleftrightarrow{BC}\\), \\(\\overleftrightarrow{AC}\\).\nRAA Conclusion\n\n\n32\nlines \\(\\overleftrightarrow{AB}\\), \\(\\overleftrightarrow{BC}\\), \\(\\overleftrightarrow{AC}\\) are nonconcurrent.\nDef. of nonconcurrent\n\n\n\nWe end with a paragraph proof.\n\nBy Axiom 3, there exists three distinct points \\(A\\), \\(B\\), and \\(C\\) and by axiom 1, we have lines \\(l(A,B)\\), \\(l(B,C)\\), and \\(l(A,C)\\). If \\(l(A,B)=l(B,C)\\), then points \\(A\\), \\(B\\), and \\(C\\) are collinear, contrary to hypothesis. Hence \\(l(A,B)\\neq l(B,C)\\). Similarly, it follows \\(l(B,C)\\neq l(A,C)\\) and \\(l(A,B)\\neq l(A,C)\\). Thus we have three distinct lines. Assume these lines are concurrent with point \\(X\\). If \\(X=A\\), then \\(A\\) is on all three lines and again we contradict the hypothesis. Hence \\(X\\neq A\\), and so the nonparallel lines \\(l(A,B)\\) and \\(l(A,C)\\) have more than one point in common. This contradicts Theorem 2, and so \\(X\\) can not exist. Whence these three distinct lines are nonconcurrent.\n\n\n\nTheorem 3.3 For every point, there is at least one line not passing through it.\n\n\n\n\nFigure 3.3: Point not on line.\n\n\n\nProof. We begin with a column proof.\n\n\n\n\n\n\n\n\nNo.\nConclusions\nJustifications\n\n\n\n\n1\n\\(A\\) is a point\nHypothesis\n\n\n2\n\\(A\\) is incident with every line.\nRAA Hypothesis\n\n\n3\nThere exists 3 noncollinear points \\(E\\), \\(D\\), \\(F\\).\nAxiom 3\n\n\n4\nThere exists a line \\(\\overleftrightarrow{ED}\\) incident with \\(E\\) and \\(D\\).\nAxiom 1\n\n\n5\nThere exists a line \\(\\overleftrightarrow{DF}\\) incident with \\(D\\) and \\(F\\).\nAxiom 1\n\n\n6\nOne and only one must hold: \\(A=D\\) or \\(A\\neq D\\).\nLaw of Excluded Middle\n\n\n7\n\\(A\\neq D\\)\nCase 1\n\n\n8\n\\(A\\) and \\(D\\) are incident with \\(\\overleftrightarrow{ED}\\) and \\(\\overleftrightarrow{DF}\\).\nSteps 2, 4, 5\n\n\n9\n\\(\\overleftrightarrow{ED}\\)= \\(\\overleftrightarrow{DF}\\)\nAxiom 1\n\n\n10\n\\(F\\) is incident with \\(\\overleftrightarrow{ED}\\).\nDefinition of Equal Lines\n\n\n11\n\\(E\\), \\(D\\), and \\(F\\) are collinear points.\nDefinition of collinear\n\n\n12\n\\(\\rightarrow\\leftarrow\\)\nSteps 3 and 11\n\n\n13\n\\(A=D\\)\nCase 2\n\n\n14\n\\(D\\) is incident with every line.\nSteps 2, 13\n\n\n15\nThere exists a line \\(\\overleftrightarrow{EF}\\) incident with \\(E\\) and \\(F\\).\nAxiom 1\n\n\n16\n\\(D\\) is incident with \\(\\overleftrightarrow{EF}\\).\nStep 1\n\n\n17\n\\(E\\), \\(D\\), and \\(F\\) are collinear points.\nDefinition of Collinear\n\n\n18\n\\(\\rightarrow\\leftarrow\\)\nSteps 3, 17\n\n\n19\nThere exists a line not incident with \\(A\\).\nRAA conclusion\n\n\n\nWe end with a paragraph proof.\n\nLet \\(A\\) be an arbitrary point. Assume every line is incident with \\(A\\). By Axiom 3, there exists three distinct points, say \\(D\\), \\(E\\), and \\(F\\). Point \\(A\\) is not one of these points, say \\(D\\). By Axiom 1, we have lines \\(l(E,D)\\) and \\(l(D,F)\\). Further, since \\(A\\) and \\(D\\) are distinct points and both are on \\(l(E,D)\\) and \\(l(D,F)\\) we have \\(l(E,D)=l(D,F)\\), by Axiom 1. Hence \\(E, D\\), and \\(F\\) are collinear. Therefore, point \\(A\\) is not incident with at least one line.\n\n\n\n\n3.3.2 Peano’s Axioms\nPeano’s Axioms \\(\\mathbb{N}\\) is a set with the following properties.\n\n\\(\\mathbb{N}\\) has a distinguished element which we call 1.\nThere exists a distinguished set map \\(s: \\mathbb{N} \\to \\mathbb{N}\\).\nThe mapping \\(s\\) is injective.\nThere does not exists an element \\(n\\in \\mathbb{N}\\) such that \\(s(n)=1\\).\nIf \\(S\\) is a subset of \\(\\mathbb{N}\\) with the properties: \\(1\\in S\\) and if \\(n\\in S\\), then \\(s(n)\\in S\\), then \\(S=\\mathbb{N}\\).\n\nWe call such a set \\(\\mathbb{N}\\) to be the set of natural numbers and elements of this set to be natural numbers.\n\nTheorem 3.4 If \\(n\\in\\mathbb{N}\\) and \\(n\\neq 1\\), then there exists a unique \\(m\\in \\mathbb{N}\\) such that \\(s(m)=n\\).\n\n\nProof. Consider the subset \\[\\begin{equation}\nS=\\{n\\in \\mathbb{N} \\mid n=1 \\text{ or } n=s(m), \\text{ for some } m\\in \\mathbb{N}\\}.\n\\end{equation}\\] By definition, \\(1\\in S\\). If \\(n\\in S\\), clearly \\(s(n)\\in S\\), again by definition of \\(S\\). Thus by induction, we see that \\(S=\\mathbb{N}\\). Further injectivity of \\(s\\) implies uniqueness as claimed.\n\nBy \\(\\ref{wdef}\\), the following definition of addition is well-defined.\n\nDefinition 3.3 Let be the operation \\(+:X\\times X\\to X\\) recursively defined on \\(y\\) by \\[\\begin{equation}\nx+y:=\n\\begin{cases}\nx & \\text{if $y=0$} \\\\\ns(x+z) & \\text{if $y\\in s(X)$ and $y=s(z)$} \\\\\n\\end{cases}\n\\end{equation}\\]\n\nNotice \\(0+0=0\\) and that \\(x+0=x\\), for all \\(x\\in X\\).\n\nLemma 3.1  For all \\(x\\in X\\), \\(x+1=s(x)\\).\n\n\nProof. Let \\(x\\in X\\). Immediately, \\(x+1=x+s(0)=s(x+0)=s(x)\\).\n\n\nLemma 3.2  For all \\(x\\in X\\), \\(0+x=x\\).\n\n\nProof. We use induction on \\(x\\). First, \\(0+1=0+s(0)=s(0+0)=s(0)=1\\). Assume that \\(0+y=y\\). We must show that \\(0+s(y)=s(y)\\). We have \\(0+s(y)=s(0+y)=s(y)\\). Therefore, \\(0+x=x\\), for all \\(x\\in X\\).\n\n\nLemma 3.3  For all \\(x,y\\in X\\), \\(s(x+y)=s(x)+y\\).\n\n\nProof. Let \\(x\\in X\\). We use induction on \\(y\\). First, \\(s(x+0)=s(x)=s(x)+0\\). Let \\(z\\in X\\) and assume that \\(s(x+z)=s(x)+z\\). We must show that \\(s(x+s(z))=s(x)+s(z)\\). We have \\(s(x+s(z))=s(s(x+z))=s(s(x)+z)=s(x)+s(z)\\). Therefore, \\(s(x+y)=s(x)+y\\), for all \\(x,y\\in X\\).\n\n\nLemma 3.4  For all \\(x,y\\in X\\), \\(x+y=y+x\\).\n\n\nProof. Let \\(x\\in X\\). We use induction on \\(y\\). The case \\(y=0\\) follows from \\(\\ref{prop2}\\). Let \\(z\\in X\\) and assume that \\(x+z=z+x\\). We must show that \\(x+s(z)=s(z)+x\\). We have \\(x+s(z)=s(x+z)=s(z+x)=s(z)+x\\), where the last equality follows by \\(\\ref{prop3}\\). Therefore, \\(x+y=y+x\\), for all \\(x,y\\in X\\).\n\n\nLemma 3.5 For all \\(x,y,z\\in X\\), \\((x+y)+z=x+(y+z)\\).\n\n\nProof. Let \\(x,y\\in X\\). We use induction on \\(z\\). First, \\((x+y)+0=x+y=x+(y+0)\\). Let \\(w\\in X\\) and assume \\((x+y)+w=x+(y+w)\\), we must show \\(s(w)\\) has the same property. In fact, \\((x+y)+s(w)=s((x+y)+w)=s(x+(y+w))=x+s(y+w)=x+(y+s(w))\\) as we needed. Therefore, \\((x+y)+z=x+(y+z)\\), for all \\(x,y,z\\in X\\).\n\n\nLemma 3.6  For all \\(x,y,z\\in X\\), \\[\\begin{equation}\n\\label{canadd}\nx+y=z+y\\implies x=z.\n\\end{equation}\\]\n\n\nProof. Let \\(x,z\\in X\\). We use induction on \\(y\\). If \\(y=0\\), then \\(\\eqref{canadd}\\) holds. Let \\(w\\in X\\) and assume that \\(\\eqref{canadd}\\) holds for \\(w\\).\nWe must show that \\(x+s(w)=z+(w)\\) implies \\(x=z\\). Notice \\(x+s(w)=z+s(w)\\) is equivalent to \\(s(x+w)=s(z+w)\\). Since \\(s\\) is injective, this implies \\(x+w=z+w\\) as needed.\n\nBy \\(\\ref{wdef}\\), the following definition of multiplication is well-defined.\n\nDefinition 3.4 We define \\(x\\cdot y\\), recursively on \\(y\\), by \\[\\begin{equation}\nx\\cdot 0=0, \\qquad x\\cdot s(y)=x\\cdot y +x.\n\\end{equation}\\]\n\n\nLemma 3.7 For all \\(x\\in X\\), \\(x\\cdot 1=x\\).\n\n\nProof. Let \\(x\\in X\\). Immediately, \\(x\\cdot 1=x\\cdot s(0)=x\\cdot 0+x=0+x=x\\).\n\n\nLemma 3.8 For all \\(y\\in X\\), \\(0\\cdot y=0\\).\n\n\nProof. We use induction on \\(y\\). First, \\(0\\cdot 0=0\\). Let \\(z\\in X\\) and assume \\(0\\cdot z=0\\). We must show that \\(0\\cdot s(z)=0\\). We have \\(0\\cdot s(z)=0\\cdot z +0=0+0=0\\). Therefore, \\(0\\cdot y=0\\), for all \\(y\\in X\\).\n\n\nLemma 3.9 For all \\(x,y\\in X\\), \\(s(x)\\cdot y=x\\cdot y+y\\).\n\n\nProof. Let \\(x\\in X\\). We use induction on \\(y\\). First, \\(s(x)\\cdot 0=0=0+0=x\\cdot 0+0\\). Let \\(z\\in X\\) and assume \\(s(x)\\cdot z=x\\cdot z+z\\). We must show that \\(s(x)\\cdot s(z)=x\\cdot s(z)+s(z)\\). We have \\(s(x)\\cdot s(z) =s(x)\\cdot z +s(x) =x\\cdot z+z +(x+1) =x\\cdot z+x +(z+1)=x\\cdot s(z)+s(z)\\). Therefore, \\(s(x)\\cdot y=x\\cdot y+y\\), for all \\(x,y\\in X\\).\n\n\nLemma 3.10 For all \\(x,y\\in X\\), \\(x\\cdot y = y\\cdot x\\).\n\n\nProof. Let \\(x\\in X\\). We use induction on \\(y\\). First, \\(x\\cdot 0 =0= 0\\cdot x\\). Let \\(z\\in X\\) and assume \\(x\\cdot z = z\\cdot x\\). We must show that \\(x\\cdot s(z) = s(z)\\cdot x\\). We have \\(x\\cdot s(z) = x\\cdot z+x=z\\cdot x+x=s(z)\\cdot x\\). Therefore, \\(x\\cdot y = y\\cdot x\\), for all \\(x,y\\in X\\).\n\n\nLemma 3.11 For all \\(x,y,z\\in X\\), \\((x+y)\\cdot z=x\\cdot z+y\\cdot z\\).\n\n\nProof. Let \\(x,y\\in X\\). We use induction on \\(z\\). Clearly, \\((x+y)\\cdot 0=x\\cdot 0+y\\cdot 0\\). Let \\(w\\in X\\) and assume \\((x+y)\\cdot w=x\\cdot w+y\\cdot w\\). We must show that \\((x+y)\\cdot s(w)=x\\cdot s(w)+y\\cdot s(w)\\). We have \\[\\begin{align*}\n(x+y)\\cdot s(w) & =(x+y) \\cdot w+(x+y) = x\\cdot w+y \\cdot w+(x+y) \\\\\n& = (x\\cdot w+x)+(y \\cdot w+y) =x\\cdot s(w)+y\\cdot s(w)\n\\end{align*}\\] which follow by the commutative and associative laws for addition. Therefore, \\((x+y)\\cdot z=x\\cdot z+y\\cdot z\\), for all \\(x,y,z\\in X\\).\n\n\nLemma 3.12 For all \\(x,y,z\\in X\\), \\((x\\cdot y)\\cdot z=x\\cdot (y\\cdot z)\\).\n\n\nProof. Let \\(x,y\\in X\\). We use induction on \\(z\\). Clearly, \\((x\\cdot y)\\cdot 0=x\\cdot (y\\cdot 0)\\). Let \\(w\\in X\\) and assume \\((x\\cdot y)\\cdot w=x\\cdot (y\\cdot w)\\). We must show that \\((x\\cdot y)\\cdot s(w)=x\\cdot (y\\cdot s(w))\\). We have \\[\\begin{align*}\n(x\\cdot y)\\cdot s(w)\n& =(x\\cdot y)\\cdot w+(x\\cdot y)\n=x\\cdot (y\\cdot w)+(x\\cdot y) \\\\\n& =x\\cdot (y\\cdot w+ y)\n=x\\cdot (y\\cdot s(w))\n\\end{align*}\\] which follow from the commutative law of multiplication and the distributive law. Therefore, \\((x\\cdot y)\\cdot z=x\\cdot (y\\cdot z)\\), for all \\(x,y,z\\in X\\).\n\n\nLemma 3.13  For all \\(x,y\\in X\\), \\[\\begin{equation}\n\\label{greadd}\nx> y \\text{ if and only if } x=y+u \\text{ for some } 0\\neq u\\in X.\n\\end{equation}\\]\n\n\nProof. We use induction on \\(y\\). The case for \\(y=0\\) is clear. Let \\(z\\in X\\). Assume \\(\\ref{greadd}\\) holds for \\(z\\), for all \\(x\\in X\\). We will prove that \\[\nt>s(z) \\Leftrightarrow t=s(z)+v \\text{ for some } 0\\neq v\\in X.\n\\] Assume \\(t>s(z)\\). Then \\(t>s(z)>z\\) and so by hypothesis, there exists \\(0\\neq v\\in X\\) such that \\(t=z+v\\). Since \\(s\\) is onto, let \\(v=s(u)\\). Then \\(t=z+v=z+s(u)=s(z+u)=s(z)+u\\). If \\(u=0\\), then \\(t=s(z)\\) contrary to hypothesis.\nTo prove conversely, assume \\(t=s(z)+v\\) for some nonzero element \\(v\\). If \\(t=s(z)\\), then \\(v=0\\) contrary to hypothesis. Suppose \\(t<s(z)\\). Case: \\(t>z\\). Then \\(z<t<s(z)\\) which can not happen. Case: \\(t=z\\). Then \\(z=s(z)+v\\) and so \\(s(z)=z+1=s(z)+v+1\\). Hence \\(0=v+1=v+s(0)=s(v+0)=s(v)\\) which implies \\(v=1\\) since \\(s\\) is injective. Hence \\(0=1+1\\), this absurdity implies that this case can not happen. Case: \\(t>z\\). Then \\(s(z)+v<z\\) and so \\(x=z+v<s(z+v)=s(z)+v<z\\). By induction hypothesis \\(x>z\\). Therefore, this case cannot happen either. All cases considered, it now follows that \\(t>s(z)\\). Whence, \\(\\ref{greadd}\\) holds for all \\(x,y\\in X\\).\n\n\nLemma 3.14 For all \\(w,x,y,z\\in X\\), if \\(w<x\\) and \\(y<z\\), then \\(w+y<x+z\\).\n\n\nProof. Assume \\(w<x\\) and \\(y<z\\). Then there exists nonzero \\(s\\) and \\(t\\) such that \\(x=w+s\\) and \\(z=y+t\\). Then \\(x+z=w+y+(s+t)\\) and so by \\(\\ref{lemorder}\\), \\(w+y<x+z\\).\n\n\nLemma 3.15  For all \\(x,y,z\\in X\\), \\[\\begin{equation}\n\\label{canmult}\nx\\cdot y=x\\cdot z, x\\neq 0 \\implies y=z.\n\\end{equation}\\]\n\n\nProof. Assume \\(x\\cdot y = x\\cdot z.\\) If \\(y<z\\) then there exists \\(w>0\\) such that \\(z=y+w\\). Then \\(x\\cdot y=x\\cdot z=x\\cdot (y+w)=x\\cdot y+x\\cdot w\\). By \\(\\ref{addcan}\\), we have \\(x\\cdot w=0\\). Since \\(x\\neq0\\) and \\(w\\neq 0\\), let \\(x=s(u)\\) and \\(w=s(t)\\). Then \\(x\\cdot w=x\\cdot s(t)=x\\cdot t+s(u)=s(x\\cdot t+u)\\neq 0\\). Hence, we find that \\(y<z\\) cannot happen. Similarly, the case for \\(y>z\\) cannot happen, and thus \\(y=z\\).\n\n\nLemma 3.16 For all \\(x,y,z\\in X\\), if \\(x<y\\) and \\(0<z\\), then \\(xz<yz\\).\n\n\nProof. Assume \\(x<y\\) and \\(0<z.\\) Then there exist nonzero \\(s\\) such that \\(y=x+s\\). Then \\(yz=(x+s)z=xz+sz\\) If \\(sz=0\\), then \\(yz=xz\\). By \\(\\ref{canlemma}\\), we have \\(y=x\\), contrary to hypothesis. Therefore, \\(sx\\neq 0\\) and so we have \\(xz<yz\\)."
  },
  {
    "objectID": "mathematical-proofs.html#exercises",
    "href": "mathematical-proofs.html#exercises",
    "title": "3  Mathematical Proofs",
    "section": "3.4 Exercises",
    "text": "3.4 Exercises\n\nExercise 3.1 Using the Incidence Axioms do each of the following.\n\nWrite each Incidence Axiom in symbolic form.\nWrite the negation of each Incidence Axiom in symbolic form.\nWrite the negation of each Incidence Axiom in words.\n\n\n\nExercise 3.2 Write careful arguments to explain why each inference rule Table 2.1 for quantified statements is valid.\n\n\nExercise 3.3 Prove each of the following statements using the Incidence Axioms. First write a column proof and then write a paragraph proof.\n\nFor every line \\(l\\), \\(l=l\\).\nFor every line \\(l\\) and every line \\(m\\), if \\(l=m\\) then \\(m=l\\).\nFor every line \\(l\\), \\(m\\), and \\(n\\), if \\(l=m\\) and \\(m=n\\), then \\(l=n\\).\n\n\n\nExercise 3.4 Prove each of the following statements using the Incidence Axioms. First write a column proof and then write a paragraph proof.\n\nThere exists at least one line.\nThere exists at least two lines.\nThere exists at least three points.\nThere exists at least three lines.\nEvery point is on at least one line.\n\n\n\nExercise 3.5 Prove each of the following statements using the Incidence Axioms. First write a column proof and then write a paragraph proof.\n\nFor every line \\(l\\), there is at least one point not lying on \\(l\\).\nFor every point \\(A\\), there exist at least two distinct lines through \\(A.\\)\nIf \\(C\\) is on \\(l(A,B)\\) and distinct from \\(A\\) and \\(B\\), then \\(l(C,A) = l(B,C) = l(A,B)\\)\nIf \\(l(A,B) = l(A,C)\\) and \\(B\\) and \\(C\\) are distinct, then \\(l(A,B) = l(B,C)\\).\nIf \\(l\\) is any line, then there exists lines \\(m\\) and \\(n\\) such that \\(l\\), \\(m\\), and \\(n\\) are distinct and both \\(m\\) and \\(n\\) have a point in common with \\(l\\).\nIf \\(A\\) is any point, then there exist points \\(B\\) and \\(C\\) such that \\(A\\), \\(B\\), and \\(C\\) are noncollinear.\nIf \\(A\\) and \\(B\\) are two distinct points, then there exists a point \\(C\\) such that \\(A\\), \\(B\\), and \\(C\\) are noncollinear.\n\n\n\nExercise 3.6 Determine which of the following sentences or pairs of sentences are propositions. For those that are not, explain why not.\n\nA bird has two legs or an insect has six legs.\nThe lake water is boiling hot.\nDoes ice float?\nDo pigs tell lies?\nThis sentence has four errors.\nThe following sentence is false. The preceding sentence is true.\n\n\n\nExercise 3.7 Write a truth table for each of the following propositional forms.\n\n\\(p\\lor (q \\land \\neg p)\\)\n\\(p\\land \\neg(p\\land p)\\)\n\\((p\\lor q)\\land (p\\land c)\\)\n\\((\\neg p\\lor q)\\land (r\\lor \\neg q)\\)\n\\((p\\lor \\neg (r\\land \\neg q))\\land \\neg p\\)\n\\((p \\lor \\neg q)\\land (q\\land \\neg r)\\)\n\n\n\nExercise 3.8 Determine whether the following given propositional forms is a tautology, a contradiction, or neither. Justify.\n\n\\((p\\land \\neg q)\\land (q\\lor \\neg p)\\)\n\\((q\\lor \\neg p)\\lor(r\\land \\neg q)\\)\n\\((p\\land \\neg r)\\lor (r\\land \\neg q)\\)\n\\(\\neg(q\\lor r\\lor \\neg p)\\land (p\\land r\\land \\neg q)\\)\n\\((p\\lor (q\\land r))\\lor (q\\lor \\neg r)\\)\n\n\n\nExercise 3.9 Decide which of the following propositions that follow are true and which are false. If a proposition is false, provide a counterexample to it.\n\n\\(\\forall x \\in \\mathbb{N}, x^2+3x+2\\geq 0\\)\n\\(\\forall x \\in \\mathbb{Z}, x^2+3x+2\\geq 0\\)\n\\(\\forall x \\in \\mathbb{Q}, x^2+3x+2\\geq 0\\)\n\\(\\forall x \\in \\mathbb{R}, x^2+3x+2\\geq 0\\)\n\n\n\nExercise 3.10 Write a working negation of each of the following statements. If the statement is in words, write the negation in words; if it is symbols, write the negation in symbols.\n\nEvery integer is even or odd.\nEvery line segment has a unique midpoint.\n\\(\\forall \\epsilon>0, \\exists \\ K\\in \\mathbb{N}, \\forall n,m\\in \\mathbb{N} \\text{ s.t. } ((n>K \\land m>K)\\rightarrow |x_n -x_m|<\\epsilon)\\)\nEvery natural number has a prime divisor.\nThere is no largest integer.\n\\(\\forall n\\in \\mathbb{N}, \\exists m\\in \\mathbb{N} \\text{ s.t. } m>n\\)\n\n\n\nExercise 3.11 Let \\(x\\) be a positive integer and define the following propositional functions: \\[\np(x): \\,  x \\text{ is prime,}\n\\qquad\nq(x): \\, x \\text{ is even,}\n\\qquad\nr(x): \\, x>2.\n\\] Write out each statement in words.\n\n\\(\\exists x, p(x)\\)\n\\(\\exists x, [p(x)\\land q(x)]\\)\n\\(\\forall x, r(x)\\)\n\\(\\forall x, [r(x)\\rightarrow (p(x)\\lor q(x))]\\)\n\\(\\forall x, [(p(x)\\land q(x))\\rightarrow \\neg r(x)]\\)\n\\(\\exists x, [p(x)\\land (q(x)\\lor r(x))]\\)\n\n\n\nExercise 3.12 Find the working negation (negation in simplest form) of each formula.\n\n\\(\\forall x, [p(x)\\lor q(x)]\\)\n\\(\\forall x, [\\exists y, (p(x,y)\\rightarrow q(x,y))]\\)\n\\(\\exists x, [(\\forall x, p(x,y)\\rightarrow q(x,y))\\land \\exists z, r(x,z)]\\)\n\\(\\forall x, \\forall y, [p(x,y)\\rightarrow q(x,y)]\\)\n\n\n\nExercise 3.13 Let \\(x\\) be an integer and use the following propositional functions\n\n\\(p(x)\\): \\(x \\text{ is even }\\)\n\\(q(x)\\): \\(x \\text{ is odd }\\)\n\\(r(x)\\): \\(x^2<0\\)\n\nto show that formulas \\(u\\) and \\(v\\) are not logically equivalent.\n\n\\(u: \\forall x, [p(x)\\lor q(x)]\\); \\(v: [\\forall x, p(x)] \\lor [\\forall x, q(x)]\\)\n\\(u: \\exists x, [p(x)\\land q(x)]\\); \\(v: [\\exists x, p(x)] \\land [\\exists x, q(x)]\\)\n\\(u: \\forall x, [p(x)\\rightarrow q(x)]\\); \\(v: [\\forall x, p(x)] \\rightarrow [\\forall x, q(x)]\\)\n\\(u: \\exists x, [p(x)\\rightarrow r(x)]\\); \\(v: [\\exists x, p(x)] \\rightarrow [\\exists x, r(x)]\\)\n\n\n\nExercise 3.14 Let \\(A\\) be a set. Verify that\n\n\\(\\exists x\\in A,[p(x)\\lor q(x)]\\equiv [\\exists x\\in A, p(x)]\\lor [\\exists x\\in A, q(x)]\\)\n\\(\\forall x\\in A,[p(x)\\land q(x)]\\equiv [\\forall x\\in A, p(x)]\\land [\\forall x\\in A, q(x)]\\)\n\\(\\exists x\\in A,[p(x)\\rightarrow q(x)]\\equiv [\\exists x\\in A, P(x)]\\rightarrow [\\exists x\\in A, q(x)]\\)\n\n\n\nExercise 3.15 Assume the domain of discourse is the set of integers and determine which of the following statements are true and which are false. Explain your answers.\n\n\\(\\forall x, \\forall y, x=y\\)\n\\(\\forall x, \\exists y, xy=1\\)\n\\(\\exists x, \\forall y, xy=y\\)\n\\(\\forall x, \\forall y, \\exists z, xy=z\\)\n\\(\\forall x, \\forall y, xy=yx\\)\n\\(\\forall x, \\exists y , xy=x\\)\n\\(\\forall x, \\exists x, \\forall z, xy=z\\)\n\n\n\nExercise 3.16 Assume the domain of discourse is the set of integers and write the negation of the statement without using any negative words. Then explain if the statement is true or not.\n\n\\(\\exists!\\, n, n^2=4\\)\n\\(\\exists! n, n \\text{ has exactly two positive divisors}\\)\n\\(\\exists ! n, n<100 \\text{ and } n^2>50\\)\n\n\n\nExercise 3.17 Verify the following argument is valid by constructing a truth table. Write a column proof. Write a paragraph proof.\n\\[\n\\begin{array}{l} p \\lor q \\\\ \\neg \\, q \\rightarrow r \\\\  \\neg \\, p \\lor \\neg \\, r \\\\ \\hline \\therefore \\, p \\end{array}\n\\]\n\n\nExercise 3.18 Another logical connective is called the and is denoted by \\(\\underline{\\lor}\\). It is defined by the following table:\n\n\n\n\\(p\\)\n\\(q\\)\n\\(p\\underline{\\lor} q\\)\n\n\n\n\nT\nT\nF\n\n\nT\nF\nT\n\n\nF\nT\nT\n\n\nF\nF\nF\n\n\n\n\nProve that \\(\\underline{\\lor}\\) obeys the commutative and associative properties.\nProve that \\(p\\underline{\\lor}q\\equiv (p\\land \\neg q)\\lor ((\\neg q)\\land y)\\).\nProve that \\(p\\underline{\\lor}q\\equiv (p\\lor q)\\land (\\neg (q\\land y))\\).\nExplain why (2) and (3) are important to know.\n\nExplain why \\(\\underline{\\lor}\\) is called the exclusive or.\n\n\nExercise 3.19 Use the method of contradiction to prove the following.\n\n\\(\\sqrt{3}\\) is irrational,\n\\(\\sqrt[5]{3}\\) is irrational.\n\n\n\nExercise 3.20 Let \\(x\\) be a real number. Use the method of contradiction to prove: \\[\n\\text{If $x^3+4x=0$, then $x=0$.}\n\\]\n\n\nExercise 3.21 Use a counterexample to disprove the statement \\[\n\\text{If $p$ is an odd prime, then $p^2+4$ is prime.}\n\\]\n\n\nExercise 3.22 Let \\(q\\), \\(q\\), and \\(r\\) denote the following statements:\n\n\\(p\\): Sam knows who to write proofs.\n\\(q\\): Sam knows who to find counterexamples.\n\\(r\\): Sam has taken Math 3300.\n\nExpress, as simple as possible, each formula in words.\n\n\\(r\\leftrightarrow (p\\lor q)\\)\n\\(r\\rightarrow \\neg q\\)\n\\(r\\land \\neg p\\)\n\\(q\\leftrightarrow (r\\land \\neg p)\\)\n\\((p\\land q)\\lor \\neg r\\)\n\\(p\\land (r\\rightarrow q)\\)\n\n\n\nExercise 3.23 Find and simplify the negation of each formula.\n\n\\(p\\land q \\land r\\)\n\\(p\\rightarrow (q\\rightarrow r)\\)\n\\(p\\rightarrow (q\\lor r)\\)\n\\(p\\land (p\\rightarrow q)\\land (q\\rightarrow r)\\)\n\\([p\\land (q\\rightarrow r)]\\lor (\\neg q\\land p)\\)\n\\(p\\leftrightarrow q\\)\n\\(p\\land (q\\lor r)\\)\n\\(\\neg p \\land (q\\rightarrow p)\\)\n\n\n\nExercise 3.24 Verify each of the following logical equivalencies.\n\n\\([(p\\land q)\\rightarrow r]\\equiv [p\\rightarrow (q\\rightarrow r)]\\)\n\\([(p\\lor q)\\rightarrow r]\\equiv[(p\\rightarrow r)\\land (q\\rightarrow r)]\\)\n\\([p\\rightarrow (q\\land r)]\\equiv[(p \\rightarrow q)\\land (p\\rightarrow r)]\\)\n\\([p\\rightarrow (q\\lor r)]\\equiv[(p\\land \\neg r)\\rightarrow q]\\)\n\n\n\nExercise 3.25 Verify if the argument is valid.\n\\(\\begin{array}{ll} 1. \\qquad \\begin{array}{l} p \\rightarrow q \\\\ \\neg \\, r \\rightarrow \\neg \\, q \\\\ \\hline \\therefore \\, \\neg \\, r \\rightarrow \\neg \\, p \\end{array} & \\qquad \\qquad 2. \\qquad \\begin{array}{l} p\\longleftrightarrow q\\\\ p \\\\ \\hline \\therefore \\, q \\end{array} \\end{array}\\)\n\\(\\begin{array}{ll} 3. \\qquad \\begin{array}{l} \\\\ p\\lor q\\\\ \\neg \\, p \\\\ \\hline \\therefore \\, q \\end{array} & \\qquad \\qquad \\qquad \\qquad 4. \\qquad \\begin{array}{l} \\\\ p\\land q\\\\ \\neg \\, p \\rightarrow q \\\\ \\hline \\therefore \\, \\neg \\, q \\end{array} \\end{array}\\)\n\\(\\begin{array}{ll} 5. \\qquad \\begin{array}{l} \\\\ p\\rightarrow q \\\\ p \\\\ \\hline \\therefore \\, q \\end{array} & \\qquad \\qquad \\qquad \\qquad 6. \\qquad \\begin{array}{l} \\\\ p\\rightarrow q \\\\ \\neg \\, q \\\\ \\hline \\therefore \\, p\\rightarrow r \\end{array} \\end{array}\\)\n\\(\\begin{array}{ll} 7. \\qquad \\begin{array}{l} \\\\ p\\rightarrow q \\\\ q \\\\ \\hline \\therefore \\, p \\end{array} & \\qquad \\qquad \\qquad \\qquad 8. \\qquad \\begin{array}{l} \\\\ p\\rightarrow q \\\\ \\neg \\, p \\\\ \\hline \\therefore \\, \\neg \\, q \\end{array} \\end{array}\\)\n\\(\\begin{array}{ll} 9. \\qquad \\begin{array}{l} \\\\ p\\rightarrow q\\\\ \\neg \\, q \\rightarrow \\neg \\, r \\\\ \\hline \\therefore \\, r \\rightarrow p \\end{array} & \\qquad \\qquad \\qquad 10. \\qquad \\begin{array}{l} p \\rightarrow q \\\\ \\neg \\, p \\rightarrow \\neg \\, q \\\\ p \\land \\neg \\, r \\\\ \\hline \\therefore \\, s \\end{array} \\end{array}\\)\n\n\nExercise 3.26 Write a column proof for each of the arguments in Exercise 3.25 that are valid.\n\n\nExercise 3.27 Write a paragraph proof for each of the arguments in Exercise 3.25 that are valid.\n\n\nExercise 3.28 Write both a column proof and a paragraph proof.\n\nGiven the four previously proven theorems:\n\nTheorem 1: \\(\\neg p \\land q\\),\n\nTheorem 2: \\(r\\rightarrow p\\),\n\nTheorem 3: \\(\\neg r \\rightarrow s\\).\nTheorem 4: \\(s\\rightarrow t\\).\n\n\nProve the next theorem: Theorem: \\(t\\).\n\nGiven the three previously proven theorems:\n\nTheorem 1: \\(p\\rightarrow q\\),\nTheorem 2: \\(\\neg p \\rightarrow r\\), and\nTheorem 3: \\(r\\rightarrow s\\).\n\n\nProve the next theorem: Theorem: \\(\\neg q \\rightarrow s\\).\n\n\nExercise 3.29 Using the Incidence Axioms do each of the following.\n\nWrite each Incidence Axiom in symbolic form.\nWrite the negation of each Incidence Axiom in symbolic form.\nWrite the negation of each Incidence Axiom in words.\n\n\n\nExercise 3.30 Write careful arguments to explain why each inference rule Table 2.1 for quantified statements is valid.\n\n\nExercise 3.31 Prove each of the following statements using the Incidence Axioms. First write a column proof and then write a paragraph proof.\n\nFor every line \\(l\\), \\(l=l\\).\nFor every line \\(l\\) and every line \\(m\\), if \\(l=m\\) then \\(m=l\\).\nFor every line \\(l\\), \\(m\\), and \\(n\\), if \\(l=m\\) and \\(m=n\\), then \\(l=n\\).\n\n\n\nExercise 3.32 Prove each of the following statements using the Incidence Axioms. First write a column proof and then write a paragraph proof.\n\nThere exists at least one line.\nThere exists at least two lines.\nThere exists at least three points.\nThere exists at least three lines.\nEvery point is on at least one line.\n\n\n\nExercise 3.33 Prove each of the following statements using the Incidence Axioms. First write a column proof and then write a paragraph proof.\n\nFor every line \\(l\\), there is at least one point not lying on \\(l\\).\nFor every point \\(A\\), there exist at least two distinct lines through \\(A.\\)\nIf \\(C\\) is on \\(l(A,B)\\) and distinct from \\(A\\) and \\(B\\), then \\(l(C,A) = l(B,C) = l(A,B)\\)\nIf \\(l(A,B) = l(A,C)\\) and \\(B\\) and \\(C\\) are distinct, then \\(l(A,B) = l(B,C)\\).\nIf \\(l\\) is any line, then there exists lines \\(m\\) and \\(n\\) such that \\(l\\), \\(m\\), and \\(n\\) are distinct and both \\(m\\) and \\(n\\) have a point in common with \\(l\\).\nIf \\(A\\) is any point, then there exist points \\(B\\) and \\(C\\) such that \\(A\\), \\(B\\), and \\(C\\) are noncollinear.\nIf \\(A\\) and \\(B\\) are two distinct points, then there exists a point \\(C\\) such that \\(A\\), \\(B\\), and \\(C\\) are noncollinear.\n\n\n\nExercise 3.34 Determine which of the following sentences or pairs of sentences are propositions. For those that are not, explain why not.\n\nA bird has two legs or an insect has six legs.\nThe lake water is boiling hot.\nDoes ice float?\nDo pigs tell lies?\nThis sentence has four errors.\nThe following sentence is false. The preceding sentence is true.\n\n\n\nExercise 3.35 Write a truth table for each of the following propositional forms.\n\n\\(p\\lor (q \\land \\neg p)\\)\n\\(p\\land \\neg(p\\land p)\\)\n\\((p\\lor q)\\land (p\\land c)\\)\n\\((\\neg p\\lor q)\\land (r\\lor \\neg q)\\)\n\\((p\\lor \\neg (r\\land \\neg q))\\land \\neg p\\)\n\\((p \\lor \\neg q)\\land (q\\land \\neg r)\\)\n\n\n\nExercise 3.36 Determine whether the following given propositional forms is a tautology, a contradiction, or neither. Justify.\n\n\\((p\\land \\neg q)\\land (q\\lor \\neg p)\\)\n\\((q\\lor \\neg p)\\lor(r\\land \\neg q)\\)\n\\((p\\land \\neg r)\\lor (r\\land \\neg q)\\)\n\\(\\neg(q\\lor r\\lor \\neg p)\\land (p\\land r\\land \\neg q)\\)\n\\((p\\lor (q\\land r))\\lor (q\\lor \\neg r)\\)\n\n\n\nExercise 3.37 Decide which of the following propositions that follow are true and which are false. If a proposition is false, provide a counterexample to it.\n\n\\(\\forall x \\in \\mathbb{N}, x^2+3x+2\\geq 0\\)\n\\(\\forall x \\in \\mathbb{Z}, x^2+3x+2\\geq 0\\)\n\\(\\forall x \\in \\mathbb{Q}, x^2+3x+2\\geq 0\\)\n\\(\\forall x \\in \\mathbb{R}, x^2+3x+2\\geq 0\\)\n\n\n\nExercise 3.38 Write a working negation of each of the following statements. If the statement is in words, write the negation in words; if it is symbols, write the negation in symbols.\n\nEvery integer is even or odd.\nEvery line segment has a unique midpoint.\n\\(\\forall \\epsilon>0, \\exists \\ K\\in \\mathbb{N}, \\forall n,m\\in \\mathbb{N} \\text{ s.t. } ((n>K \\land m>K)\\rightarrow |x_n -x_m|<\\epsilon)\\)\nEvery natural number has a prime divisor.\nThere is no largest integer.\n\\(\\forall n\\in \\mathbb{N}, \\exists m\\in \\mathbb{N} \\text{ s.t. } m>n\\)\n\n\n\nExercise 3.39 Let \\(x\\) be a positive integer and define the following propositional functions: \\[\np(x): \\,  x \\text{ is prime,}\n\\qquad\nq(x): \\, x \\text{ is even,}\n\\qquad\nr(x): \\, x>2.\n\\] Write out each statement in words.\n\n\\(\\exists x, p(x)\\)\n\\(\\exists x, [p(x)\\land q(x)]\\)\n\\(\\forall x, r(x)\\)\n\\(\\forall x, [r(x)\\rightarrow (p(x)\\lor q(x))]\\)\n\\(\\forall x, [(p(x)\\land q(x))\\rightarrow \\neg r(x)]\\)\n\\(\\exists x, [p(x)\\land (q(x)\\lor r(x))]\\)\n\n\n\nExercise 3.40 Find the working negation (negation in simplest form) of each formula.\n\n\\(\\forall x, [p(x)\\lor q(x)]\\)\n\\(\\forall x, [\\exists y, (p(x,y)\\rightarrow q(x,y))]\\)\n\\(\\exists x, [(\\forall x, p(x,y)\\rightarrow q(x,y))\\land \\exists z, r(x,z)]\\)\n\\(\\forall x, \\forall y, [p(x,y)\\rightarrow q(x,y)]\\)\n\n\n\nExercise 3.41 Let \\(x\\) be an integer and use the following propositional functions\n\n\\(p(x)\\): \\(x \\text{ is even }\\)\n\\(q(x)\\): \\(x \\text{ is odd }\\)\n\\(r(x)\\): \\(x^2<0\\)\n\nto show that formulas \\(u\\) and \\(v\\) are not logically equivalent.\n\n\\(u: \\forall x, [p(x)\\lor q(x)]\\); \\(v: [\\forall x, p(x)] \\lor [\\forall x, q(x)]\\)\n\\(u: \\exists x, [p(x)\\land q(x)]\\); \\(v: [\\exists x, p(x)] \\land [\\exists x, q(x)]\\)\n\\(u: \\forall x, [p(x)\\rightarrow q(x)]\\); \\(v: [\\forall x, p(x)] \\rightarrow [\\forall x, q(x)]\\)\n\\(u: \\exists x, [p(x)\\rightarrow r(x)]\\); \\(v: [\\exists x, p(x)] \\rightarrow [\\exists x, r(x)]\\)\n\n\n\nExercise 3.42 Let \\(A\\) be a set. Verify that\n\n\\(\\exists x\\in A,[p(x)\\lor q(x)]\\equiv [\\exists x\\in A, p(x)]\\lor [\\exists x\\in A, q(x)]\\)\n\\(\\forall x\\in A,[p(x)\\land q(x)]\\equiv [\\forall x\\in A, p(x)]\\land [\\forall x\\in A, q(x)]\\)\n\\(\\exists x\\in A,[p(x)\\rightarrow q(x)]\\equiv [\\exists x\\in A, P(x)]\\rightarrow [\\exists x\\in A, q(x)]\\)\n\n\n\nExercise 3.43 Assume the domain of discourse is the set of integers and determine which of the following statements are true and which are false. Explain your answers.\n\n\\(\\forall x, \\forall y, x=y\\)\n\\(\\forall x, \\exists y, xy=1\\)\n\\(\\exists x, \\forall y, xy=y\\)\n\\(\\forall x, \\forall y, \\exists z, xy=z\\)\n\\(\\forall x, \\forall y, xy=yx\\)\n\\(\\forall x, \\exists y , xy=x\\)\n\\(\\forall x, \\exists x, \\forall z, xy=z\\)\n\n\n\nExercise 3.44 Assume the domain of discourse is the set of integers and write the negation of the statement without using any negative words. Then explain if the statement is true or not.\n\n\\(\\exists!\\, n, n^2=4\\)\n\\(\\exists! n, n \\text{ has exactly two positive divisors}\\)\n\\(\\exists ! n, n<100 \\text{ and } n^2>50\\)\n\n\n\nExercise 3.45 Verify the following argument is valid by constructing a truth table. Write a column proof. Write a paragraph proof.\n\\[\n\\begin{array}{l} p \\lor q \\\\ \\neg \\, q \\rightarrow r \\\\  \\neg \\, p \\lor \\neg \\, r \\\\ \\hline \\therefore \\, p \\end{array}\n\\]\n\n\nExercise 3.46 Another logical connective is called the and is denoted by \\(\\underline{\\lor}\\). It is defined by the following table:\n\n\n\n\\(p\\)\n\\(q\\)\n\\(p\\underline{\\lor} q\\)\n\n\n\n\nT\nT\nF\n\n\nT\nF\nT\n\n\nF\nT\nT\n\n\nF\nF\nF\n\n\n\n\nProve that \\(\\underline{\\lor}\\) obeys the commutative and associative properties.\nProve that \\(p\\underline{\\lor}q\\equiv (p\\land \\neg q)\\lor ((\\neg q)\\land y)\\).\nProve that \\(p\\underline{\\lor}q\\equiv (p\\lor q)\\land (\\neg (q\\land y))\\).\nExplain why (2) and (3) are important to know.\n\nExplain why \\(\\underline{\\lor}\\) is called the exclusive or.\n\n\nExercise 3.47 Use the method of contradiction to prove the following.\n\n\\(\\sqrt{3}\\) is irrational,\n\\(\\sqrt[5]{3}\\) is irrational.\n\n\n\nExercise 3.48 Let \\(x\\) be a real number. Use the method of contradiction to prove: \\[\n\\text{If $x^3+4x=0$, then $x=0$.}\n\\]\n\n\nExercise 3.49 Use a counterexample to disprove the statement \\[\n\\text{If $p$ is an odd prime, then $p^2+4$ is prime.}\n\\]\n\n\nExercise 3.50 Let \\(q\\), \\(q\\), and \\(r\\) denote the following statements:\n\n\\(p\\): Sam knows who to write proofs.\n\\(q\\): Sam knows who to find counterexamples.\n\\(r\\): Sam has taken Math 3300.\n\nExpress, as simple as possible, each formula in words.\n\n\\(r\\leftrightarrow (p\\lor q)\\)\n\\(r\\rightarrow \\neg q\\)\n\\(r\\land \\neg p\\)\n\\(q\\leftrightarrow (r\\land \\neg p)\\)\n\\((p\\land q)\\lor \\neg r\\)\n\\(p\\land (r\\rightarrow q)\\)\n\n\n\nExercise 3.51 Find and simplify the negation of each formula.\n\n\\(p\\land q \\land r\\)\n\\(p\\rightarrow (q\\rightarrow r)\\)\n\\(p\\rightarrow (q\\lor r)\\)\n\\(p\\land (p\\rightarrow q)\\land (q\\rightarrow r)\\)\n\\([p\\land (q\\rightarrow r)]\\lor (\\neg q\\land p)\\)\n\\(p\\leftrightarrow q\\)\n\\(p\\land (q\\lor r)\\)\n\\(\\neg p \\land (q\\rightarrow p)\\)\n\n\n\nExercise 3.52 Verify each of the following logical equivalencies.\n\n\\([(p\\land q)\\rightarrow r]\\equiv [p\\rightarrow (q\\rightarrow r)]\\)\n\\([(p\\lor q)\\rightarrow r]\\equiv[(p\\rightarrow r)\\land (q\\rightarrow r)]\\)\n\\([p\\rightarrow (q\\land r)]\\equiv[(p \\rightarrow q)\\land (p\\rightarrow r)]\\)\n\\([p\\rightarrow (q\\lor r)]\\equiv[(p\\land \\neg r)\\rightarrow q]\\)"
  },
  {
    "objectID": "set-theory.html#what-is-a-set",
    "href": "set-theory.html#what-is-a-set",
    "title": "4  Set Theory",
    "section": "4.1 What is a set?",
    "text": "4.1 What is a set?\nWe leave the term set undefined. We also leave the term belonging undefined. We say \\(x\\) belongs to a set \\(A\\) and we write \\(x\\in A\\). We instead, sometimes say \\(x\\) is an element of \\(A\\), or even \\(x\\) is a member of a set \\(A\\). We will say that a set is a collection of objects. The universe, or universal set, usually denoted by \\(U,\\) is the set of all elements under discussion.\nFor example, if \\(U\\) consists of the elements: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, and 10, then the equation \\[\nA=\\{0,1,2,3,4,5\\}\n\\] describes a set \\(A\\) made up of the six elements \\(0,\\) 1, 2, 3, 4, and \\(5.\\)\nA set is determined by its elements and not by any particular order. In other words, set \\(A\\) is just as easily specified by \\[\nA=\\{5,4,3,2,1,0\\}.\n\\]\nSets are often described by properties of the elements using the set-builder notation\n\\[\n\\{ \\qquad  \\mid \\qquad  \\qquad \\}\n\\qquad  \\text{ or } \\qquad  \n\\{ \\qquad  :  \\qquad  \\qquad \\}\n\\]\nA variable is indicated before the colon, and the properties are given after the colon. For example,\n\\[\\begin{equation}\n\\label{setbuilder}\n\\{n \\mid n\\in \\mathbb{N} \\text{ and $n$ is odd}\\}.\n\\end{equation}\\]\nrepresents the set of nonnegative odd integers, i.e. the set \\(\\{0,1,3,5,7,\\ldots \\}.\\) The colon is alway read and so \\(\\eqref{setbuilder}\\) can be read as “the set of all \\(n\\) such that \\(n\\) is a natural number and is odd”.\nThroughout we use \\(\\mathbb{N}\\), \\(\\mathbb{Z}\\), and \\(\\mathbb{Q}\\) to denote the set of natural numbers, the set of integers, and the set of rational numbers, respectfully. Note that we include 0 among the natural numbers: \\[\n\\mathbb{N}=\\{0,1,2,3,4,5,6,\\ldots\\}.\n\\]\nThe set of all positive, zero, or negative numbers, are called the integers. Numbers of the form \\(m/n,\\) where \\(m,n\\) are integers and \\(n\\neq 0\\) are called the rational numbers since they are ratios of integers. The set of real numbers, rational or not, contains all the numbers in \\(\\mathbb{Q},\\) and many others as well such as \\(\\sqrt{2},\\) \\(\\sqrt{3},\\) \\(\\sqrt[3]{3},\\) \\(\\sqrt[5]{3},\\) \\(\\pi,\\) and \\(e\\) and so on.\nThe most basic property of belonging is that of equality. For example, if \\[\nA=\\{x\\in \\mathbb{R} \\mid -9+21 x-10 x^2=0\\}, \\quad\nB=\\left\\{\\frac{3}{5},\\frac{3}{2}\\right\\}\n\\] then \\(A=B.\\) To see this notice that \\(-9+21 x-10 x^2=(2x-3)(3-5x)=0\\) precisely when \\(x=3/5\\) or \\(x=3/2.\\)"
  },
  {
    "objectID": "set-theory.html#principle-of-extension",
    "href": "set-theory.html#principle-of-extension",
    "title": "4  Set Theory",
    "section": "4.2 Principle of Extension",
    "text": "4.2 Principle of Extension\nExtension. Two sets are equal if and only if they contain the same elements.\n\nDefinition 4.1 Two sets \\(A\\) and \\(B\\) are called equal, denoted by \\(A=B,\\) provided they consist of the same elements. If \\(A\\) and \\(B\\) are not equal we write \\(A\\neq B.\\)\n\nLet \\(A\\) and \\(B\\) be sets. If every element of \\(A\\) is an element of \\(B,\\) we say \\(A\\) is a subset of \\(B,\\) or \\(B\\) contains \\(A,\\) and we write \\(A\\subseteq B,\\) or \\(B\\supseteq A.\\) Notice that set inclusion \\(\\subseteq\\) has a few nice properties. It is reflexive, meaning \\(A\\subseteq A\\) for any set \\(A\\); and is transitive, meaning, if \\(A \\subseteq B\\) and \\(B\\subseteq C\\) then \\(A\\subseteq C\\) for all sets \\(A, B, C.\\)\nBy the principle of extension, set inclusion is also meaning \\(A\\subseteq B\\) and \\(B\\subseteq A\\) together imply \\(A=B.\\) You might have noticed that equality is also reflexive and transitive. Equality is also symmetric, meaning if \\(A=B\\) then \\(B=A,\\) for all sets \\(A, B.\\)"
  },
  {
    "objectID": "set-theory.html#specification",
    "href": "set-theory.html#specification",
    "title": "4  Set Theory",
    "section": "4.3 Specification",
    "text": "4.3 Specification\nThe next principle is designed to produce new sets out of known ones. We use the notation \\(P(x)\\) to mean a mathematical statement \\(P\\) which depends on the free variable \\(x.\\)\nSpecification. To every set \\(A\\) and to every condition \\(P(x)\\) there corresponds a set \\(B\\) whose elements are exactly those elements \\(x\\) of \\(A\\) for which \\(P(x)\\) holds.\nBy Extension, the set \\(B\\) in the Specification is uniquely determined. Also by Specification, the set \\(\\{x\\in A \\mid x\\neq x \\},\\) denoted by \\(\\emptyset,\\) exists and is called the empty set. This of course assumes that there exists a set \\(A\\) in the first place, as we have assumed all along. Of course the empty set is a subset of every set. The next question that comes to mind is: are there enough sets to ensure that every set belongs to some set?\nLet \\(A\\) and \\(B\\) be sets. If every element of \\(A\\) is an element of \\(B\\), we say \\(A\\) is a subset of \\(B\\), or sometimes we say \\(B\\) contains \\(A\\), and we write \\(A\\subseteq B\\), or \\(B\\supseteq A\\). For example, \\(\\{1,4,a\\}\\subseteq \\{0,1,3,4,a,b\\}\\) or as another example the inclusions hold \\(\\mathbb{N} \\subseteq \\mathbb{Z} \\subseteq \\mathbb{Q}\\subseteq \\mathbb{R}.\\)\n\nDefinition 4.2 A set \\(A\\) is called a subset of a set \\(B,\\) denoted by \\(A\\subseteq B,\\) provided every element of \\(A\\) is also an element of \\(B.\\)\n\nThe symbol \\(\\emptyset\\) is the last letter in the Danish-Norwegian alphabet.\n\nDefinition 4.3 The unique set that has no elements is called the empty set and is denoted by \\(\\emptyset.\\)\n\nRecall the tautologies \\(p\\rightarrow p\\) and \\(((p\\rightarrow q)\\land (q\\rightarrow r))\\rightarrow (p\\rightarrow r).\\)\n\nTheorem 4.1 Let \\(A\\), \\(B\\), and \\(C\\) be subsets of a universal set \\(U.\\)\n\n\\(A\\subseteq A\\)\n\\((A\\subseteq B \\land B\\subseteq C) \\rightarrow A\\subseteq C.\\)\n\n\n\n\nProof. Let \\(x\\) be an arbitrary element of \\(A.\\) Then \\(x\\) is in \\(A\\) and so \\(A\\subseteq A.\\) For the second statement, assume \\(x\\) be an arbitrary element of \\(A.\\) Since \\(A\\subseteq B,\\) we have \\(x\\in B\\) by definition of subset. Since \\(B\\subseteq C,\\) we have \\(x\\in C\\) by definition of subset, whence \\(A\\subseteq C.\\)\n\nTo show that \\(A=B\\) one must prove that \\(x\\in A\\leftrightarrow x\\in B\\); that is, \\(x\\in A\\) if and only if \\(x\\in B.\\) This is equivalent to proving that \\(x\\in A\\rightarrow x\\in B\\) and \\(x\\in B\\rightarrow x\\in A.\\) There are two parts to such a proof: first assume that \\(x\\in A\\) and show that \\(x\\in B\\) follows. Then assume, independently, that \\(x\\in B\\) and show that \\(x\\in A\\) follows.\nThe reader is encourage to justify each step in this proof.\n\nTheorem 4.2 For any two subsets \\(A\\) and \\(B\\) of a universal set \\(U,\\) \\[\\begin{equation}\n\\label{eqsetsone}\nA=B \\leftrightarrow (A\\subseteq B \\land B\\subseteq A).\n\\end{equation}\\]\n\n\nProof. We proceed as follows \\[\\begin{align*}\nA=B & \\leftrightarrow\n\\forall x, (x\\in A \\leftrightarrow x\\in B) \\\\\n& \\leftrightarrow\n\\forall x, [(x\\in A\\rightarrow x\\in B)\\land (x\\in B\\rightarrow x\\in A)] \\\\\n& \\leftrightarrow [\\forall x, x\\in A \\rightarrow x\\in B]\\land [\\forall x, (x\\in B\\rightarrow x\\in A)]\\\\\n& \\leftrightarrow (A\\subseteq B) \\land (B\\subseteq A)\n\\end{align*}\\] as needed.\n\n\nTheorem 4.3 For any two subsets \\(A\\) and \\(B\\) of a universal set \\(U,\\) \\[\\begin{equation}\n\\label{subsetsmean}\nA\\subseteq B \\leftrightarrow \\forall C (C\\subseteq A \\rightarrow C\\subseteq B).\n\\end{equation}\\]\n\n\nProof. First we show that \\[\\begin{equation}\n\\forall C, (C\\subseteq A\\rightarrow C\\subseteq B)\\rightarrow A\\subseteq B.\n\\end{equation}\\] Assume that for any set \\(C,\\) if \\(C\\subseteq A,\\) then \\(C\\subseteq B.\\) Since \\(A\\subseteq A,\\) it follows that \\(A\\subseteq B\\) as needed. Next it must be shown that \\[\\begin{equation}\nA\\subseteq B \\rightarrow \\forall C, (C\\subseteq A \\rightarrow C\\subseteq B).\n\\end{equation}\\] Assume \\(A\\subseteq B\\) and let \\(C\\) be any set such that \\(C\\subseteq A.\\) Then we have \\(C\\subseteq A\\) and \\(A\\subseteq B,\\) and so we have \\(C\\subseteq B.\\)\n\n\nTheorem 4.4 Let \\(A\\) be a subset of a universal subset \\(U.\\) Then for all \\(x\\in U,\\) \\[\\begin{equation}\n\\label{elesubst}\nx\\in A \\leftrightarrow \\{x\\}\\subseteq A.\n\\end{equation}\\]\n\n\nProof. The proof is left for the reader as Exercise 4.20.\n\nSet inclusion is also antisymmetric meaning \\(A\\subseteq B\\) and \\(B\\subseteq A\\) together imply \\(A=B\\). Equality is also symmetric, meaning if \\(A=B\\) then \\(B=A\\), for all sets \\(A, B\\).\n\nTheorem 4.5 For any two subsets \\(A\\) and \\(B\\) of a universal set \\(U,\\)\n\n\\(A=B \\leftrightarrow B=A,\\) and\n\\((A\\subseteq B \\land B\\subseteq A) \\rightarrow A=B.\\)\n\n\n\nProof. The proof is left for the reader as Exercise 4.21."
  },
  {
    "objectID": "set-theory.html#proper-subset",
    "href": "set-theory.html#proper-subset",
    "title": "4  Set Theory",
    "section": "4.4 Proper Subset",
    "text": "4.4 Proper Subset\nA subset \\(B\\) of a set \\(A\\) is said to be a proper subset of \\(A\\) if it is not equal to \\(A\\) itself. Thus all subsets of \\(A\\) are proper subsets except the set \\(A\\) itself, which is referred to as the improper subset of \\(A.\\)\n\nDefinition 4.4 A set \\(A\\) is called a proper subset of a set \\(B\\) provided \\(A\\subseteq B\\) and \\(A\\neq B.\\) We write \\(A\\subset B\\) to denote that \\(A\\) is a proper subset of \\(B.\\)\n\n\nTheorem 4.6 For any two subsets \\(A\\) and \\(B\\) of a universal set \\(U,\\) \\[\\begin{equation}\nA\\subset B \\leftrightarrow [A\\subseteq B \\land \\exists x, (x\\in B \\land x\\notin A)].\n\\label{eqsets}\n\\end{equation}\\]\n\n\nProof. Assume \\(A\\subset B.\\) Then \\(A\\subseteq B\\) and \\(A\\neq B.\\) By definition of \\(A\\neq B,\\) one must hold \\[\n\\exists x, (x\\in A\\land x\\notin B)\n\\quad \\text{ or }\\quad\n\\exists x, (x\\in B \\land x\\notin A).\n\\]\nIf the first one holds, then we have \\(x\\in B\\) and \\(x\\notin B,\\) a contradiction. Hence the former holds as needed. Conversely, assume \\(A\\subseteq B\\) and \\({\\exists x, (x\\in B \\land x\\notin A).}\\) Then by definition of \\(A\\neq B,\\) since \\(B\\) contains an element not in \\(A,\\) we have \\(A\\neq B.\\) Therefore we have \\(A\\subseteq B\\) and \\(A\\neq B,\\) and thus \\(A\\subset B.\\)"
  },
  {
    "objectID": "set-theory.html#why-elelmentary-set-theory",
    "href": "set-theory.html#why-elelmentary-set-theory",
    "title": "4  Set Theory",
    "section": "4.5 Why elelmentary set theory?",
    "text": "4.5 Why elelmentary set theory?\nIn the foundations of mathematics, Russell’s paradox, discovered by Bertrand Russell in 1901, showed that the naive set theory created by Georg Cantor leads to a contradiction. According to naive set theory, any definable collection is a set.\nLet \\(R\\) be the set of all sets that are not members of themselves. If \\(R\\) is not a member of itself, then its definition dictates that it must contain itself, and if it contains itself, then it contradicts its own definition as the set of all sets that are not members of themselves.\nThis contradiction is called Russell’s paradox. Symbolically: \\[\n\\text{If $R = \\{ x \\mid x \\notin x \\},$ then $R \\in R \\leftrightarrow R \\not \\in R$.}\n\\] In 1908, two ways of avoiding the paradox were proposed, Russell’s type theory and the Zermelo set theory. There is a long interesting history of this problem and the reader is encourage to explore."
  },
  {
    "objectID": "set-theory.html#axiom-of-choice",
    "href": "set-theory.html#axiom-of-choice",
    "title": "4  Set Theory",
    "section": "4.6 Axiom of Choice",
    "text": "4.6 Axiom of Choice\nIn 1904, Ernst Zermelo formulated the Axiom of Choice to prove the Well-Ordering Theorem . Of course, we now know that these two statements are logically equivalent and in fact, there are many equivalents forms Adamson (1998).\n\nTheorem 4.7 In Zermelo-Fraenkel set theory, the following statements are equivalent:\n\n(Axiom of Choice) Given any set \\(X\\) of pairwise disjoint non-empty sets, there exists at least one set \\(B\\) that contains exactly one element in common with each of the sets in \\(X\\). Suppes (1972)\n(Well-Ordering) Every set can be well-ordered. (Cantor 1883)\n\n\nSaid differently, and in particular, the Axiom of Choice guarantees that every finite collection of nonempty sets has a choice function. However, in Zermelo-Fraenkel set theory, this is easily proven using mathematical induction (Tourlakis 2003). The following statements are also weaker than the Axiom of Choice.\nHarzheim (2005)\n\nTheorem 4.8 Every partial order can be extended to a total order and every well-founded partial order can be extended to a well-order."
  },
  {
    "objectID": "set-theory.html#set-operations",
    "href": "set-theory.html#set-operations",
    "title": "4  Set Theory",
    "section": "4.7 Set Operations",
    "text": "4.7 Set Operations\n\n4.7.1 Power Sets\nThe next question that comes to mind is: is the collection of subsets of a set, a set itself? In other words, given a set \\(A\\) does there exist a set \\(\\mathcal{P}\\) such that if \\(X\\subseteq A\\) then \\(X\\in \\mathcal{P}\\,\\)?\n\nDefinition 4.5 The set consisting of all subsets of a given set \\(A\\) is called the power set of \\(A\\) and is denoted by \\(\\mathcal{P}(A).\\)\n\n\nTheorem 4.9 If \\(A\\) is a set, then \\(\\emptyset \\in \\mathcal{P}(A)\\) and \\(A\\in \\mathcal{P}(A).\\)\n\n\nProof. Notice that the empty set is a subset of every set (including itself). Thus, \\(\\emptyset \\in \\mathcal{P}(A)\\) is immediate. The second statement follows immediately; that is, \\(A\\subseteq A\\) implies \\(A\\in \\mathcal{P}(A).\\)\n\n\nTheorem 4.10 If \\(A\\) has \\(n\\) elements, then \\(\\mathcal{P}(A)\\) has \\(2^n\\) elements.\n\n\nProof. If \\(n=0,\\) then \\(A\\) is the empty set. The only subset of the empty set is the set itself; thus the number of elements in \\(\\mathcal{P}(A)\\) is \\(1\\) which is \\(2^0\\) as needed to verify the basis step.\nAssume that the statement holds for \\(n.\\) Let \\(X\\) be a set with \\(n+1\\) elements and assume \\(x\\in X.\\) We claim that exactly half of the subsets of \\(X\\) contain \\(x,\\) and half do not. To see this, notice that each subset of \\(X\\) that contains \\(x\\) can be paired uniquely with a subset obtained by removing \\(x\\). \\[\n\\begin{matrix}\n\\text{ subsets of $A$ that contain $x$ }\n&\n\\text{ subsets of $A$ that do not contain $x$ }\n\\\\ \\hline\n\\{x\\} & \\emptyset \\\\\n\\{x,y\\} & \\{y\\} \\\\\n\\{x,z\\} & \\{z\\} \\\\\n\\{x,y,z\\} & \\{y,z\\}\n\\end{matrix}\n\\] If we let \\(Y\\) be the set obtained from \\(X\\) by deleting \\(x,\\) \\(Y\\) has \\(n\\) elements. By the inductive hypothesis \\(\\mathcal{Y}\\) has exactly \\(2^n\\) elements. But the subsets of \\(Y\\) are precisely the subsets of \\(X\\) that do not contain \\(x.\\) It follows that the number of elements in \\(\\mathcal{Y}\\) is one-half the number of elements in \\(\\mathcal{X}.\\) Therefore, the number of elements in \\(\\mathcal{X}\\) is twice the number of elements in \\(\\mathcal{Y}.\\) Whence the number of elements in \\(\\mathcal{X}\\) is \\(2^{n+1}.\\)\n\n\nTheorem 4.11 If \\(A\\) is an infinite set, then \\(\\mathcal{P}(A)\\) is also.\n\n\nProof. The proof is left for the reader as Exercise 4.1.\n\n\n\n4.7.2 Principle of Unions\nUnion. For every collection of sets there exists a set that contains all the elements that belong to at least one set of the given collection.\nGiven a collection of sets \\(\\mathcal{C}\\) we want their union to consist of only those elements that belong to at least one of the subsets in the collection. So we apply the principle of specification to the set \\(U\\) and define the union of a collection of sets as \\[\n\\bigcup_{X\\in \\mathcal{C}}X=\\{x\\in U \\mid x\\in X \\text{ for some $X$ in $\\mathcal{C}$\\}}.\n\\] This set exists by the principle of specification and is unique by the principle of extension. In the case \\(\\mathcal{C}=\\{A, B\\}\\) we usually write \\[\nA\\cup B=\\{x \\mid x\\in A \\text{ or } x\\in B\\}.\n\\]\n\nTheorem 4.12 Let \\(A,\\) \\(B,\\) and \\(C\\) be sets. Then\n\n\\(A\\cup \\emptyset =A ,\\)\n\\(A\\cup B=B\\cup A,\\)\n\\(A\\cup (B \\cup C) =(A\\cup B)\\cup C,\\)\n\\(A \\cup A =A,\\) and\n\\(A\\subseteq B\\) if and only if \\(A\\cup B=B.\\)\n\n\n\nProof. The proof is left for the reader as Exercise 4.2.\n\nIf \\(A\\) and \\(B\\) are sets we then define, using the principle of specification, their intersection as the set \\(A \\cap B=\\{x\\in A \\mid x\\in B\\}.\\) It is very easy to show the more familiar form, \\(A\\cap B=\\{x \\mid x\\in A \\text{ or } x\\in B\\}.\\) More generally, let \\(\\mathcal{C}\\) be a non-empty collection of sets, the principle of specification allows us to define a set \\[\nI=\\{x \\in A \\mid x\\in X \\text{ for every $X$ in $\\mathcal{C}$}\\}\n\\] where \\(A\\) is some set in \\(\\mathcal{C}.\\) In fact the use of a set \\(A\\) is arbitrary (but necessary in order to use the principle of specification). Thus we are lead to the definition of the intersection of a collection of sets \\[\n\\bigcap_{X\\in \\mathcal{C}} X=\\{x\\mid x\\in X \\text{ for all $X$ in\n$\\mathcal{C}$ }\\}\n\\] where uniqueness is guaranteed by the principle of extension.\n\nTheorem 4.13 Let \\(A\\), \\(B\\), and \\(C\\) be sets. Then\n\n\\(A\\cap \\emptyset =\\emptyset ,\\)\n\\(A\\cap B=B\\cap A,\\)\n\\(A\\cap (B \\cap C) =(A\\cap B)\\cap C,\\)\n\\(A \\cap A =A,\\) and\n\\(A\\subseteq B\\) if and only if \\(A\\cap B=A.\\)\n\n\n\nProof. The proof is left for the reader as Exercise 4.3.\n\nLet \\(A\\) and \\(B\\) be subsets of a set \\(C.\\) The between \\(A\\) and \\(B,\\) known as the of \\(B\\) in \\(A,\\) is the set defined by \\(A-B=\\{x\\in A \\mid x\\not\\in B \\}\\); and the difference} between \\(A\\) and \\(B,\\) known as the of \\(B\\) in \\(A,\\) is the set defined by \\(A-B=\\{x\\in A \\mid x\\not\\in B \\}\\); and the \\index{symmetric difference of \\(A\\) and \\(B\\) is defined by \\(A+B=(A-B)\\cup (B-A).\\) Notice that the principle of specification guarantees existence and the principle of extension guarantees uniqueness of these sets for a given \\(A\\) and \\(B.\\) These sets are of course, by definition, also subsets of \\(C.\\)\nThe next question that comes to mind is: is the collection of subsets of \\(C\\) a set itself? In other words, given a set \\(C\\) does there exist a set \\(\\mathcal{P}\\) such that if \\(X\\subseteq S\\) then \\(X\\in \\mathcal{P}\\,\\)?\n\n\n4.7.3 Principle of Powers\nPrinciple of Powers. For each set there exists a collection of sets that contains among its elements all the subsets of the given set.\nThus, given a set \\(C\\) we can form a collection of sets, denoted by \\(\\mathcal{P},\\) that contains the subsets of \\(C.\\) We can use the principle of specification to ensure that this set will consist only of subsets of \\(C\\) and the principle of extension to ensure that this set is unique. We call this set the power set of \\(C,\\) and denote it by \\(\\mathcal{P}(S)=\\{X \\mid X\\subseteq S\\}\\) or sometimes even \\(2^S.\\)\nThe fundamental most frequently used operations of set theory are union, intersection, and difference.\nIn this section we discuss these operations and some of their properties.\nThe union of a collection of sets is the set of all distinct elements in the collection.\n\nDefinition 4.6 Let \\(A\\) and \\(B\\) be subsets of some universal set \\(U.\\) The union of \\(A\\) and \\(B\\) is the set \\(A\\cup B\\) defined by \\[\nA\\cup B =\\{x\\mid x\\in A \\lor x\\in B\\}.\n\\]\n\nRecall that \\(p\\rightarrow (p\\lor q)\\) is a tautology. This immediately yields that for any sets \\(A\\) and \\(B,\\) \\[\\begin{equation}\n\\label{subsetcup}\nA\\subseteq A\\cup B\n\\qquad \\text{ and } \\qquad\nB\\subseteq A\\cup B.\n\\end{equation}\\] This follows because \\(A\\subseteq A\\cup B\\) is equivalent to \\(\\forall x, x\\in A\\rightarrow (x\\in A \\lor x\\in B)\\) by definition of subset. Similarly for \\(B\\subseteq A\\cup B.\\)\n\nExample 4.1 Let \\(U=\\{1,2,3,\\ldots, 10\\},\\) \\(A=\\{2,4,6\\},\\) \\(B=\\{1,3,5,7,9\\}\\) and \\(C=\\{5,10\\}.\\) Find and compare the sets: \\(A\\cup (B \\cup C)\\) and \\((A\\cup B)\\cup C\\)\n\n\nProof. We find \\(B\\cup C=\\{1,3,5,7,9,10\\}\\) and so \\[\nA\\cup(B\\cup C)=\\{1,2,3,4,5,6,7,9,10\\}.\n\\] Also, \\(A\\cup B=\\{1,2,3,4,5,6,7,9\\}\\) and so \\[\n(A\\cup B)\\cup C)=\\{1,2,3,4,5,6,7,9,10\\}.\n\\] Therefore we find that \\(A\\cup (B \\cup C)=(A\\cup B)\\cup C\\).\n\n\nTheorem 4.14 Let \\(A\\) and \\(B\\) be subsets of some universal set \\(U.\\)\n\n\\(A\\cup \\emptyset =A\\)\n( commutativity) \\(A\\cup B=B\\cup A\\)\n( associativity) \\(A\\cup (B \\cup C) =(A\\cup B)\\cup C\\)\n( idempotence) \\(A \\cup A =A\\)\n\\(A\\subseteq B\\) if and only if \\(A\\cup B=B\\).\n\n\n\nProof. We prove (1) and (5) and leave the remainder of the proof for the reader as Exercise 4.5.\n(1): Let \\(x\\) be an arbitrary element of \\(A\\cup \\emptyset.\\) Then, by definition of union, either \\(x\\in A\\) or \\(x\\in \\emptyset.\\) Since there are no elements in \\(\\emptyset,\\) we must have \\(x\\in A\\); hence \\(A\\cup \\emptyset\\subseteq A.\\) Conversely, follows from \\(\\eqref{subsetcup}\\).\n(5): Assume \\(A\\subseteq B.\\) We must show that \\(A\\cup B=B.\\) By \\(\\eqref{subsetcup}\\) we immediately see that \\(B\\subseteq A\\cup B.\\) To show the remaining inclusion, let \\(x\\in A\\cup B.\\) Then either \\(x\\in A\\) or \\(x\\in B.\\) In the case that \\(x\\in A,\\) then we have \\(x\\in B\\) by hypothesis. Thus, in either case we have \\(x\\in B,\\) and so \\(A\\cap B\\subseteq B.\\) Therefore, we have shown that if \\(A\\subseteq B,\\) then \\(A\\cap B=B.\\)\nConversely, we now assume that \\(A\\cup B=B\\) and we wish to conclude that \\(A\\subseteq B.\\) To do so, let \\(x\\) be an arbitrary element of \\(A.\\) Then \\(x\\in A\\cup B\\) by \\(\\eqref{subsetcup}\\), and so \\(x\\in A\\cup B=B.\\) Hence \\(A\\subseteq B\\) as needed.\n\nThe intersection of a collection of sets is the set that contains all elements, each of which are in each of the sets in the collection, and no other elements.\n\n\n4.7.4 Principle of Intersections\n\nDefinition 4.7 Let \\(A\\) and \\(B\\) be subsets of some universal set \\(U.\\) The intersection of \\(A\\) and \\(B\\) is the set \\(A\\cap B\\) defined by \\[\nA\\cap B =\\{x\\mid x\\in A \\land x\\in B\\}.\n\\]\n\n\nTheorem 4.15 Let \\(A\\) and \\(B\\) be subsets of some universal set \\(U.\\)\n\n\\(A\\cap \\emptyset =\\emptyset\\)\n( commutativity) \\(A\\cap B=B\\cap A\\)\n( associativity) \\(A\\cap (B \\cap C) =(A\\cap B)\\cap C\\)\n( idempotence) \\(A \\cap A =A\\)\n\\(A\\subseteq B\\) if and only if \\(A\\cap B=A\\).\n\n\n\nProof. We prove (2) and (3) and leave the remainder of the proof for the reader as Exercise 4.6.\n(2): Let \\(x\\) be an arbitrary element in \\(A\\cap B.\\) Then \\[\\begin{align*}\n& x\\in A \\cap B & \\qquad & \\\\\n& \\quad \\rightarrow  x\\in A\\land x\\in B & &  \\text{by Definition of $\\cap$} \\\\\n& \\quad \\rightarrow x\\in B\\land x\\in A & &  \\text{by commutativity of $\\land$} \\\\\n& \\quad \\rightarrow x\\in B \\cap A  & &  \\text{by Definition of $\\cap$}\n\\end{align*}\\] Thus \\(x\\in A\\cap B\\rightarrow x\\in B\\cap A\\) and consequently \\[\nA\\cap B\\subseteq B\\cap A.\n\\]\nIn a similar fashion (simply reverse the implications) one may prove that \\(B\\cap A\\subseteq A\\cap B.\\) Therefore, \\(A\\cap B=B\\cap A\\).\n(3): Let \\(x\\) be an arbitrary element in \\((A \\cap B)\\cap C.\\) Then \\[\\begin{align*}\n& x\\in (A \\cap B)\\cap C & \\qquad & \\\\\n& \\quad \\rightarrow [ x\\in (A \\cap B) \\land x\\in C ] & & \\text{by Definition of $\\cap$} \\\\\n& \\quad \\rightarrow [ (x\\in A \\land x\\in B)\\land x\\in C ]& & \\text{by Definition of $\\cap$} \\\\\n& \\quad \\rightarrow [ x\\in A \\land ( x\\in B \\land x\\in C) ] & &\n\\text{by associativity of $\\land$} \\\\\n& \\quad \\rightarrow [ x\\in A \\land ( x\\in B \\cap C) ]& &\n\\text{by Definition of $\\cap$} \\\\\n& \\quad \\rightarrow [ x\\in (A \\cap B) \\cap C ] & &\n\\text{by Definition of $\\cap$}\n\\end{align*}\\]\nThus \\(x\\in (A\\cap B)\\cap C \\rightarrow x\\in A\\cap (B\\cap C)\\) and consequently \\[\n(A\\cap B)\\cap C\\subseteq A\\cap (B\\cap C).\n\\] In a similar fashion (simply reverse the implications) one may prove that \\(A\\cap (B\\cap C)\\subseteq (A\\cap B)\\cap C.\\) Therefore, \\(A\\cap (B\\cap C)=(A\\cap B)\\cap C.\\)\n\n\nTheorem 4.16 Let \\(A\\), \\(B\\), \\(C\\) be subsets of some universal set \\(U.\\)\n\n\\(A\\cap (B \\cup C) = (A\\cap B)\\cup (A\\cap C)\\)\n\\(A\\cup (B \\cap C) = (A\\cup B)\\cap (A\\cup C)\\)\n\n\n\nProof. We prove (1) and leave the remainder of the proof for the reader as Exercise 4.7.\n(1): Let \\(x\\) be an arbitrary element in \\(A\\cap (B \\cup C).\\) Then \\[\\begin{align*}\n& x\\in A\\cap (B \\cup C) & \\qquad & \\\\\n& \\quad \\rightarrow [ x\\in A \\land x\\in B\\cup C ] & &  \\text{by Definition of $\\cap$} \\\\\n& \\quad \\rightarrow [ x\\in A \\land (x\\in B \\lor x\\in C) ]& &  \\text{by Definition of $\\cup$} \\\\\n& \\quad \\rightarrow [ (x\\in A \\land x\\in B) \\lor (x\\in A \\land x\\in C) ] & &  \\text{by distributivity of $\\land$} \\\\\n& \\quad \\rightarrow [ (x\\in A \\cap B) \\lor (x\\in A \\cap C) ] & &  \\text{by Definition of $\\cap$} \\\\\n& \\quad \\rightarrow [ (x\\in A \\cap B) \\cup (A \\cap C) ] & &  \\text{by Definition of $\\cup$}\n\\end{align*}\\]\nThus \\(x\\in A\\cap (B \\cup C) \\rightarrow x\\in (A\\cap B)\\cup (A\\cap C)\\) and consequently \\[\nA\\cap (B \\cup C) \\subseteq (A\\cap B)\\cup (A\\cap C).\n\\]\nIn a similar fashion (simply reverse the implications) one may prove that \\((A\\cap B)\\cup (A\\cap C) \\subseteq A\\cap (B \\cup C).\\) Therefore, \\(A\\cap (B \\cup C)=(A\\cap B)\\cup (A\\cap C).\\)\n\n\n\n4.7.5 Relative Complement\nThe relative complement of \\(B\\) with respect to a set \\(A\\) is the set of elements in \\(A\\) but not in \\(B.\\)\n\nDefinition 4.8 Let \\(A\\) and \\(B\\) be subsets of some universal set \\(U.\\) The relative complement of \\(B\\) in \\(A\\) is the set \\(A-B\\) defined by \\[\nA-B =\\{x\\mid x\\in A \\land x\\notin B\\}.\n\\] The relative complement of \\(B\\) in \\(A\\) is also denoted by \\(A\\setminus B.\\)\n\nWhen all sets under consideration are considered to be subsets of a given set \\(U,\\) the absolute complement of \\(A\\) is the set of all elements in \\(U\\) but not in \\(A,\\) and is denoted by \\(A',\\) that is, the complement of a set \\(A\\) is defined by \\[\nA'=\\{x\\in U \\mid x\\not\\in A\\}.\n\\] To be redundant, by definition \\(A'=U-A.\\)\n\nExample 4.2 Let \\(S=\\{a,b,c\\},\\) \\(T=\\{1,a\\},\\) and \\(V=\\{1,2,3,c\\}.\\) Find and compare the sets, \\((S-T)-V\\) and \\(S-(T-V).\\)\n\n\nProof. We find \\(S-T=\\{b,c\\}\\) and \\(T-V=\\{a\\},\\) and so \\((S-T)-V=\\{b\\}\\) and \\(S-(T-V)=\\{b,c\\}.\\) Thus, \\((S-T)-V\\subseteq S-(T-V).\\)\n\n\n\n4.7.6 De Morgan’s Laws\n\nTheorem 4.17 Let \\(A\\) and \\(B\\) be subsets of some universal set \\(U.\\)\n\n\\((A \\cup B)'=A' \\cap B'\\)\n\\((A \\cap B)'=A' \\cup B'\\).\n\n\n\nProof. We prove (1) and leave the remainder of the proof for the reader as Exercise 4.8. Let \\(x\\) be an arbitrary element in \\((A \\cup B)'.\\) Then \\[\\begin{align*}\n& x\\in (A \\cup B)' & \\qquad & \\\\\n& \\quad \\rightarrow [x\\notin A \\cup B] & &  \\text{by Definition of complement} \\\\\n& \\quad \\rightarrow [\\neg(x\\in A \\cup B)] & &  \\text{by Definition of $\\notin$} \\\\\n& \\quad \\rightarrow [\\neg(x\\in A \\lor x\\in B)] & &  \\text{by Definition of $\\cup$} \\\\\n& \\quad \\rightarrow [\\neg(x\\in A) \\land \\neg(x\\in B)] & &  \\text{DeMorgan's Law} \\\\\n& \\quad \\rightarrow [x\\notin A \\land x\\notin B] & &  \\text{by Definition of $\\notin$} \\\\\n& \\quad \\rightarrow [x\\in A' \\land x\\in B'] & &  \\text{by Definition of complement} \\\\\n& \\quad \\rightarrow [x\\in A' \\cap B'] & &  \\text{by Definition of $\\cap$}\n\\end{align*}\\]\nThus \\(x\\in (A \\cup B)' \\rightarrow x\\in A' \\cap B'\\) and consequently \\((A \\cup B)' \\subseteq x\\in A' \\cap B'.\\) In a similar fashion (simply reverse the implications) one may prove that \\(A' \\cap B' \\subseteq (A \\cup B)'.\\) Therefore, \\((A \\cup B)'=A' \\cap B'\\).\n\n\nTheorem 4.18 Let \\(A\\) and \\(B\\) be subsets of some universal set \\(U.\\)\n\n\\((A')'=A\\)\n\\(\\emptyset '=U\\)\n\\(U'=\\emptyset\\)\n\\(A \\cap A'=\\emptyset\\)\n\\(A \\cup A' =U\\)\n\\(A-B=A\\cap B'\\)\n\n\n\nProof. The proof is left for the reader as Theorem 4.18.\n\n\nTheorem 4.19 Let \\(A\\) and \\(B\\) be subsets of some universal set \\(U.\\)\n\n\\(A \\subseteq B\\) if and only if \\(B'\\subseteq A'\\)\n\\(A\\subseteq B\\) if and only if \\(A-B=\\emptyset\\)\n\n\n\nProof. We prove (1) and leave the remainder of the proof for the reader as Exercise 4.9. Assume \\(A\\subseteq B\\) and let \\(x\\) be an arbitrary element in \\(B'.\\) Thus, \\(x\\notin B.\\) Assume for a contradiction that \\(x\\in A.\\) By hypothesis, we have \\(x\\in B\\) and \\(x\\notin B.\\) Thus, \\(x\\in A'\\) must occur. Conversely, assume \\(B'\\subseteq A'\\) and let \\(x\\) be an arbitrary element of \\(A.\\) Assume for a contradiction that \\(x\\in B'.\\) By hypothesis, we have \\(x\\in A\\) and \\(x\\notin A.\\) Thus, \\(x\\in B\\) must occur.\n\n\n\n4.7.7 Symmetric Difference\nThe symmetric difference of two sets is the set of elements which are in either of the sets and not in their intersection.\n\nDefinition 4.9 If \\(A\\) and \\(B\\) are sets, we define the symmetric difference of \\(A\\) and \\(B\\) by \\[\nA\\bigtriangleup B=(A-B)\\cup (B-A).\n\\]\n\n\nTheorem 4.20 Let \\(A\\) and \\(B\\) be subsets of some universal set \\(U.\\) Then \\[\\begin{equation}\n\\label{symmdiff}\nA\\bigtriangleup B=(A\\cup B)-(A\\cap B).\n\\end{equation}\\]\n\n\nProof. Let \\(x\\) be an arbitrary element of \\(A\\bigtriangleup B.\\) Then \\[\\begin{align*}\n& x\\in A\\bigtriangleup B & \\\\\n& \\qquad  \\rightarrow x\\in (A-B) \\cup (B-A) &  \\\\\n& \\qquad  \\rightarrow x\\in A-B \\lor x\\in B-A &  \\\\\n& \\qquad  \\rightarrow (x\\in A \\land x\\notin B) \\lor (x\\in B\\land x\\notin A) & \\\\\n& \\qquad  \\rightarrow (x\\in B\\land x\\notin A)  \\lor (x\\in A \\land x\\notin B) &  \\\\\n& \\qquad  \\rightarrow [(x\\in A\\land x\\notin A) \\lor (x\\in B\\land x\\notin A)]  \\\\\n& \\qquad \\qquad  \\qquad \\lor [(x\\in A \\land x\\notin B)\\lor (x\\in B \\land x\\notin B)]  \\\\\n& \\qquad  \\rightarrow [(x\\in A \\lor x\\in B)\\land x\\notin A)]  \\lor [(x\\in A \\lor x\\in B) \\land x\\notin B)] &  \\\\\n& \\qquad  \\rightarrow (x\\in A \\lor x\\in B) \\land (x \\notin A \\lor x\\notin B) &  \\\\\n& \\qquad  \\rightarrow (x\\in A \\lor x\\in B) \\land \\neg (x\\in A \\land x\\in B) &  \\\\\n& \\qquad  \\rightarrow  x\\in (A\\cup B) \\land \\neg (x\\in A \\cap B) &  \\\\\n& \\qquad  \\rightarrow  x\\in (A\\cup B) \\land x\\notin A\\cap B &  \\\\\n& \\qquad  \\rightarrow  x\\in (A\\cup B) -(A\\cap B) &\n\\end{align*}\\] The justification of the above steps and the remainder of the proof is left for the reader as Exercise 4.10.\n\n\nTheorem 4.21 Let \\(A\\), \\(B\\), and \\(C\\) be subsets of some universal set \\(U.\\)\n\n\\(A\\bigtriangleup B=B\\bigtriangleup A\\)\n\\(A\\bigtriangleup (B\\bigtriangleup C)=(A\\bigtriangleup B)\\bigtriangleup C\\)\n\\(A\\bigtriangleup \\emptyset = A\\)\n\\(A\\bigtriangleup A=\\emptyset\\)\n\n\n\nProof. The proof is left for the reader as Exercise 4.11.\n\n\nTheorem 4.22 Let \\(A\\) and \\(B\\) be sets. Then\n\n\\(A+B=B+A,\\)\n\\(A+(B+C)=(A+B)+C,\\)\n\\(A+\\emptyset = A,\\) and\n\\(A+A=\\emptyset .\\)\n\n\n\nProof. The proof is left for the reader as Exercise 4.12.\n\nA collection of sets is called disjoint if they have no elements in common.\n\nDefinition 4.10 If \\(A\\) and \\(B\\) are sets and \\(A\\cap B=\\emptyset,\\) then \\(A\\) and \\(B\\) are disjoint sets .\n\n\nTheorem 4.23 Let \\(A\\) and \\(B\\) be subsets of some universal set \\(U.\\) Then \\(A\\) and \\(B\\) are disjoint if and only if \\(A\\cup B=A\\bigtriangleup B.\\)\n\n\nProof. The proof is left for the reader as Exercise 4.13.\n\n\n\n4.7.8 Principle of Pairing\nPrinciple of Pairing. For any two sets there exists a set that they both belong to.\nFor example, suppose \\(a\\) and \\(b\\) are sets that are elements of the set \\(A,\\) then by the principle of specification the set \\(\\{a, b\\}:=\\{x\\in A \\mid x=a \\text{ or } x=b \\}\\) exists, and by the principle of extension is unique. This set is called the pair (or unordered pair) formed by \\(a\\) and \\(b.\\) Given any set \\(a\\) we have the pair \\(\\{a,a\\}\\) which is usually just denoted by \\(\\{a\\},\\) and is called the singleton set of \\(a.\\)\nLet \\(\\mathcal{C}\\) denote a collection of sets. By the following principle we can define the set \\(U\\) consisting of those elements \\(x\\) such that if \\(x\\in X\\) for some \\(X\\in \\mathcal{C},\\) then \\(x\\in U.\\)\nAn ordered pair \\((a, b)\\) is a pair of mathematical objects. The order in which the objects appear in the pair is significant: the ordered pair \\((a, b)\\) is different from the ordered pair \\((b, a)\\) unless \\(a = b.\\) (In contrast, the unordered pair \\(\\{a, b\\}\\) equals the unordered pair \\(\\{b, a\\}.\\))\n\n\n4.7.9 Cartesian Product\n\nDefinition 4.11 Given any two sets \\(A\\) and \\(B,\\) the Cartesian product of \\(A\\) and \\(B\\) is the set \\(A\\times B\\) defined by \\[\nA\\times B =\\{(a,b)\\mid a\\in A \\land b\\in B)\\}.\n\\]\n\n\nTheorem 4.24 If \\(A\\), \\(B\\), and \\(C\\) are sets, then\n\n\\(A\\times (B\\cup C)=(A\\times B)\\cup (A\\times C)\\)\n\\(A\\times (B\\cap C)=(A\\times B)\\cap (A\\times C)\\)\n\\(A\\times (B- C)=(A\\times B)- (A\\times C)\\)\n\\(A\\times (B\\bigtriangleup C)=(A\\times B)\\bigtriangleup (A\\times C)\\)\n\n\n\nProof. The proof is left for the reader as Exercise 4.14.\n\nThe idea of ordered pair can be extended to more than two elements. Given \\(n\\) elements \\(a_1, a_2, \\ldots, a_n,\\) where \\(n\\geq 3,\\) we can define the ordered \\(n\\)-tuple \\((a_1, a_2, \\ldots a_n),\\) in which \\(a_1\\) is the first element, \\(a_2\\) is the second element, and so on, and \\(a_n\\) is the \\(n\\)-th element. We can now generalize the idea of Cartesian product.\n\nDefinition 4.12 Given any \\(n\\) sets \\(A_1, A_2, \\ldots, A_n,\\) the Cartesian product of \\(A_1, A_2, \\ldots, A_n\\) is the set defined by \\[\nA_1\\times A_2 \\times \\cdots \\times A_n\n=\\{(a_1, a_2, \\ldots, a_n) \\mid a_i\\in A_i \\text{ for each $i,$ $1\\leq i \\leq n$}\\}.\n\\]\n\nIt follows immediately, \\[\n(a_1, a_2, \\ldots, a_n)=(b_1, b_2, \\ldots, b_n)\n\\text{ if and only if $a_i=b_i$ for each $i,$ $1\\leq i \\leq n.$}\n\\] Also notice that \\(A_1\\times A_2 \\times \\cdots \\times A_n=\\emptyset\\) if and only if \\(A_i=\\emptyset\\) for some \\(i,\\) \\(1\\leq i \\leq n.\\) For this reason, when working with Cartesian products of sets, it is normally the case that each of the sets is nonempty.\n\nExample 4.3 Prove or disprove that \\[\n\\mathcal{P}(A\\times B)=\\mathcal{P}(A)\\times \\mathcal{P}(B),\n\\] for any sets \\(A\\) and \\(B.\\)\n\nThe ordered pair of \\(a\\) and \\(b,\\) with first coordinate \\(a\\) and second coordinate \\(b\\) is defined as the set \\(\\{\\{a\\},\\{a,b\\}\\}\\) and is denoted more naturally by \\((a,b).\\) The reader should show that this definition is well-defined by proving the following lemma.\n\nLemma 4.1 If \\((a,b)\\) and \\((x,y)\\) are ordered pairs and if \\((a,b)=(x,y)\\) then \\(x=a\\) and \\(y=b.\\)\n\n\nProof. The proof is left as an exercise for the reader as Exercise 4.16.\n\nThe next question that comes to mind is: if \\(A\\) and \\(B\\) are sets, does there exist a set that contains all the ordered pairs \\((a,b)\\) with \\(a\\in A\\) and \\(b\\in B.\\) Surely so; for example, \\(\\{a\\}\\subseteq A\\) and \\(\\{b\\}\\subseteq B,\\) and therefore \\(\\{a,b\\}\\subseteq A\\cup B.\\) Thus, by definition, \\((a,b)=\\{\\{a\\},\\{a,b\\}\\}\\subseteq \\mathcal{P}(A\\cup B).\\) It follows that \\({(a,b)\\in \\mathcal{P}(\\mathcal{P}(A\\cup B)).}\\) We can do much better than this though.\nThe Cartesian product of two sets is a set of ordered pairs. Conversely, every set of ordered pairs is a subset of the Cartesian product of two sets. By the above argument, every set of ordered pairs is contained in some subset, via \\[\n(a,b)\\in  \\mathcal{P}(\\mathcal{P}(A\\cup B)) \\quad \\text{whenever } \\quad a\\in A, b\\in B.\n\\] By the principle of specification, we define a set \\[\nA\\times B = \\{x \\in \\mathcal{P}(\\mathcal{P}(A\\cup B)) \\mid x=(a,b) \\text{ for some $a\\in A$ and $b\\in B$}\\}.\n\\] By the principle of extension, this set is unique; and is called the Cartesian product of \\(A\\) and \\(B.\\) Thus, as desired, the Cartesian product of two sets is a set of ordered pairs. Conversely, let \\(P\\) be a set that consists of ordered pairs and let \\(x\\in P.\\) Then by definition of ordered pair \\(x=\\{\\{a\\},\\{a,b\\}\\}\\) for some \\(a\\) and for some \\(b.\\) Since \\(P\\) is a set consisting of sets, we form the union and observe \\(\\{a,b\\}\\in \\cup_{X\\in P} P.\\)\nObserve further that \\({\\cup_{X\\in P} P:=P'}\\) is a set consisting of sets, so it follows both \\(a\\) and \\(b\\) are elements of \\[\nU:=\\bigcup_{Y\\in P'} \\bigcup_{X\\in P} P.\n\\] Let \\(A\\) and \\(B\\) be such that \\(A=B=U.\\) Thus \\(P,\\) a set of ordered pairs, is a subset of the Cartesian product of two sets, namely \\(U\\times U.\\) We can use the principle of specification to refine the sets \\(A\\) and \\(B,\\) namely \\[\nA=\\{ a \\in U \\mid (a,b) \\in P \\text{ for some } b \\}\n\\] and \\[\nB=\\{ b \\in U \\mid (a,b) \\in P \\text{ for some } a \\}.\n\\] These sets are unique by the principle of extension and are called the projections of \\(P\\) onto the first and second coordinates, respectively.\n\nTheorem 4.25 Let \\(A\\), \\(B\\), \\(X\\), and \\(Y\\) be sets. Then\n\n\\((A \\cup B)\\times X=(A\\times X)\\cup (B\\times X),\\)\n\\((A \\cap B)\\times (X\\cap Y)=(A\\times X)\\cap (B\\times Y),\\)\n\\((A-B)\\times X=(A\\times X)-(B\\times X),\\)\n\\(\\left( A=\\emptyset \\text{ or } B=\\emptyset \\right)\\) if and only if \\(A\\times B=\\emptyset,\\) and\nIf \\(A\\times B\\neq \\emptyset\\) then, \\(\\left( A\\subseteq X \\text{ and } B\\subseteq Y \\right)\\) if and only if \\(A\\times B \\subseteq X\\times Y.\\)\n\n\n\nProof. The proof is left for the reader as Exercise 4.15.\n\n\n\n4.7.10 Finite Families\nGiven any \\(n\\) sets \\(A_1, A_2, \\ldots, A_n,\\) we define their union to be the set \\[\nA_1 \\cup A_2 \\cup \\cdots \\cup A_n\n=\\{x\\mid x\\in A_i \\text{ for some } i, 1\\leq i \\leq n\\}.\n\\] and their intersection to the the set \\[\nA_1 \\cap A_2 \\cap \\cdots \\cap A_n\n=\\{x\\mid x\\in A_i \\text{ for all } i, 1\\leq i \\leq n\\}.\n\\] These sets can be written as \\[\n\\bigcup_{i=1}^n A_i\n\\qquad \\text{and}\\qquad  \n\\bigcap_{i=1}^n A_i\n\\] respectively.\n\nExample 4.4 For \\(i\\in \\{1,2,3,\\ldots, 10\\},\\) define \\[\nA_i=[-i,10-i].\n\\] Find \\(A_1,\\) \\(A_2, \\ldots, A_{10}\\) and then find \\(\\bigcup_{i=1}^{10} A_i\\) and \\(\\bigcap_{i=1}^{10} A_i.\\)\n\n\nSolution. We find that \\[\nA_1=[-1,9], \\quad\nA_2=[-2,8], \\quad\n\\ldots, \\quad\nA_{10}=[-10,0].\n\\] Hence \\[\\begin{equation}\n\\bigcup_{i=1}^{10} A_i=[-10,9]\n\\qquad  \\text{and} \\qquad\n\\bigcap_{i=1}^{10} A_i=[-1,0].\n\\end{equation}\\] as needed.\n\n\nExample 4.5 For \\(k\\in \\{1,2,\\ldots, 100\\},\\) define \\[\nB_k=\\{r\\in \\mathbb{Q} \\mid -1\\leq k \\cdot r \\leq 1\\}.\n\\] Find \\(B_k\\) for \\(1\\leq k\\leq 100,\\) compare these sets, and then find \\(\\bigcup_{k=1}^{100} B_k\\) and \\(\\bigcap_{k=1}^{100} B_k.\\)\n\n\nSolution. We find \\[\\begin{align*}\n& B_1=\\{r\\in \\mathbb{Q} \\mid -1 \\leq r \\leq 1\\}, \\\\\n& \\qquad & B_2=\\left\\{\\{r\\in \\mathbb{Q} \\mid -\\frac{1}{2} \\leq r \\leq \\frac{1}{2}\\right\\}, \\\\\n& \\qquad \\cdots \\qquad \\cdots \\\\\n& & B_{100}=\\left\\{r\\in \\mathbb{Q} \\mid -\\frac{1}{100} \\leq r \\leq \\frac{1}{100}\\right\\},  \n\\end{align*}\\] and so \\[\nB_{100}\\subseteq B_{99} \\subseteq B_{98} \\subseteq \\cdots \\subseteq B_2 \\subseteq B_1.\n\\] It follows that \\[\n\\bigcup_{k=1}^{100} B_k=B_1\n\\qquad \\text{and} \\qquad\n\\bigcap_{k=1}^{100} B_k=B_{100}.\n\\] as needed.\n\n\n\n4.7.11 Families of Sets\nLet \\(I\\) be a nonempty set, and suppose that for each element \\(i\\in I\\) there is associated a set \\(A_i.\\) We then call \\(I\\) an index set for the collection of sets \\(\\mathcal{P}(A)=\\{ A_i \\mid i\\in I\\}.\\)\n\nDefinition 4.13 Let \\(I\\) be an indexed set and suppose that \\(\\mathcal{P}(A)=\\{A_i\\mid i\\in I\\}\\) is a collection of sets. Then\n\nthe \\(\\mathcal{P}(A)\\) union of the collection is defined to be the set \\[ \\bigcup_{i\\in I} A_i  =\\{x\\mid x\\in A_i \\text{ for some } i\\in I\\},  \\]\nthe \\(\\mathcal{P}(A)\\) intersection of the collection is defined to be the set \\[ \\bigcap_{i\\in I} A_i  =\\{x\\mid x\\in A_i \\text{ for each } i\\in I\\}. \\]\n\n\n\nTheorem 4.26 Given the collection of sets \\(\\{A_i \\mid i\\in \\mathbb{N}\\}\\) the following properties hold.\n\nIf \\(A_i \\subseteq A_{i+1}\\) for all \\(i\\in \\mathbb{N},\\) then \\(\\bigcap_{i=1}A_i=A_1.\\)\nIf \\(A_i \\supseteq A_{i+1}\\) for all \\(i\\in \\mathbb{N},\\) then \\(\\bigcup_{i=1}A_i=A_1.\\)\n\n\n\nProof. We prove (1) and leave (2) for the reader as Exercise 4.17. Let \\(T=\\cap_{i=1}A_i=A_0\\) and let \\(x\\) be an arbitrary element of \\(T.\\) Then \\(x\\in A_i\\) for each \\(i\\in \\mathbb{N},\\) and this certainly implies that \\(x\\in A_1.\\) So \\(T\\in A_1.\\) Conversely, assume \\(x\\in A_1.\\) Since \\(A_i \\subseteq A_{i+1}\\) for all \\(i\\in \\mathbb{N},\\) we have that \\(A_1\\subseteq A_i\\) for every \\(i\\in \\mathbb{N},\\) and hence \\(x\\in T.\\) This shows that \\(A_1\\subseteq T\\); hence we conclude that \\(T=A_1.\\)\n\n\nExample 4.6 Let \\(n\\in \\mathbb{N}\\) and let \\[\nA_n=\\{m\\in \\mathbb{Z} \\mid -n \\leq m \\land 2^m\\leq n\\}.\n\\] Use Theorem 4.26 to find \\(\\bigcap_{i=1}^{\\infty} A_i\\) and \\(\\bigcup_{i=1}^{\\infty} A_i.\\)\n\n\nSolution. We find that \\[\\begin{align*}\n& A_1=\\{-1,0\\},  \n& & A_2=\\{-2,-1,0,1\\}, \\\\\n& A_3=\\{-3,-2,-1,0,1\\},\n& & A_4=\\{-3,-2,-1,0,1,2\\}\n\\end{align*}\\] and so on. Note that \\(A_1\\subseteq A_2 \\subseteq A_3 \\subseteq \\cdots.\\) Hence by Theorem 4.26, we have \\[\n\\bigcap_{n=1}^\\infty A_n=A_1\n\\] The reader should verify that \\(\\bigcup_{n=1}^\\infty A_n=\\mathbb{Z}.\\)\n\n\nExample 4.7 Let \\(I=(0,1),\\) and for \\(i\\in I,\\) define \\(A_i=(-i,i).\\) Find \\(\\bigcap_{i\\in I} A_i\\) and \\(\\bigcup_{i\\in I} A_i.\\)\n\n\nSolution. For example, \\[\nA_{1/2}=\\left(-\\frac{1}{2},\\frac{1}{2}\\right)\n\\qquad \\text{and}\\qquad\nA_{\\sqrt{2}/3}=\\left(-\\frac{\\sqrt{2}}{3},\\frac{\\sqrt{2}}{3}\\right).\n\\] Notice that if \\(0<i<j<1,\\) then \\(\\{0\\}\\subset A_i \\subset A_j \\subset (-1,1).\\) It follows that \\[\n\\label{intexatwo}\n\\bigcup_{i\\in I} A_i =(-1,1)\n\\qquad \\text{and} \\qquad\n\\bigcap_{i\\in I} A_i =\\{0\\}\n\\] by Theorem 4.26.\n\n\nTheorem 4.27 (Extended DeMorgan Laws) Let \\(\\{A_i \\mid i\\in I\\}\\) be a collection of sets indexed by \\(I.\\) Then\n\n\\(\\left(\\bigcup_{i\\in I} A_i\\right)' =\\bigcap_{i\\in I} A_i'\\)\n\\(\\left(\\bigcap_{i\\in I} A_i\\right)' =\\bigcup_{i\\in I} A_i'\\)\n\n\n\nProof. We prove(1) and leave (2) for the reader as Exercise 4.18. Let \\(x\\) be an arbitrary element in \\(\\left(\\cup_{i\\in I} A_i\\right)'.\\) Then \\[\\begin{align*}\n& x\\in \\left(\\cup_{i\\in I} A_i\\right)' & \\qquad & \\\\\n& \\quad \\rightarrow [x\\notin \\cup_{i\\in I} A_i] & &  \\text{by Definition of complement} \\\\\n& \\quad \\rightarrow [\\neg(x\\in \\cup_{i\\in I} A_i)] & &  \\text{by Definition of $\\notin$} \\\\\n& \\quad \\rightarrow [\\neg(\\exists i\\in I, x\\in A_i)] & &  \\text{by Definition of $\\cup$} \\\\\n& \\quad \\rightarrow [\\forall i\\in I, x\\notin A_i] & &  \\text{by logic rule} \\\\\n& \\quad \\rightarrow [\\forall i\\in I, x\\in A_i'] & &  \\text{by Definition of complement} \\\\\n& \\quad \\rightarrow [x\\in \\cap_{i\\in I} A_i'] & &  \\text{by Definition of $\\cap$}\n\\end{align*}\\]\nThus \\(x\\in \\cap_{i\\in I} A_i'\\) and consequently \\[\n\\left(\\cup_{i\\in I} A_i\\right)' \\subseteq x\\in \\cap_{i\\in I} A_i'.\n\\] In a similar fashion (simply reverse the implications) one may prove the reverse containment. Therefore, we conclude \\[\n\\left(\\cup_{i\\in I} A_i\\right)' = \\cap_{i\\in I} A_i'.\n\\] as desired.\n\nLet \\(I\\) be a nonempty set, and suppose that for each element \\(i\\in I\\) there is associated a set \\(A_i\\). We then call \\(I\\) an index set for the collection of sets \\(\\mathcal{A}=\\{A_i \\mid i\\in I\\}\\).\n\nDefinition 4.14 Let \\(I\\) be an indexed set and suppose that \\(\\mathcal{A}=\\{A_i\\mid i\\in I\\}\\) is a collection of sets. Then\n\nthe union of the collection \\(\\mathcal{A}\\) is defined to be the set \\[\n\\bigcup_{i\\in I} A_i =\\{x\\mid x\\in A_i \\text{ for some } i\\in I\\},\n\\]\nthe intersection of the collection \\(\\mathcal{A}\\) is defined to be the set \\[\n\\bigcap_{i\\in I} A_i  =\\{x\\mid x\\in A_i \\text{ for each } i\\in I\\}.\n\\]\n\n\n\nTheorem 4.28 (Ascending and Descending Chains of Sets) Given the collection of sets \\(\\{A_i \\mid i\\in \\mathbb{N}\\}\\) the following properties hold.\n\nIf \\(A_i \\subseteq A_{i+1}\\) for all \\(i\\in \\mathbb{N}\\), then \\(\\bigcap_{i=1}A_i=A_1\\).\nIf \\(A_i \\supseteq A_{i+1}\\) for all \\(i\\in \\mathbb{N}\\), then \\(\\bigcup_{i=1}A_i=A_1\\).\n\n\n\nProof. We prove (1) and leave (2) for the reader as Exercise 4.19.\nLet \\(T=\\cap_{i=1}A_i=A_0\\) and let \\(x\\) be an arbitrary element of \\(T\\). Then \\(x\\in A_i\\) for each \\(i\\in \\mathbb{N}\\), and this certainly implies that \\(x\\in A_1\\). Sp \\(T\\in A_1\\).\nConversely, assume \\(x\\in A_1\\). Since \\(A_i \\subseteq A_{i+1}\\) for all \\(i\\in\\mathbb{N}\\), we have that \\(A_1\\subseteq A_i\\) for every \\(i\\in \\mathbb{N},\\) and hence \\(x\\in T.\\) This shows that \\(A_1\\subseteq T\\); hence we conclude that \\(T=A_1\\)."
  },
  {
    "objectID": "set-theory.html#exercises",
    "href": "set-theory.html#exercises",
    "title": "4  Set Theory",
    "section": "4.8 Exercises",
    "text": "4.8 Exercises\n\nExercise 4.1 Prove Theorem 4.11.\n\n\nExercise 4.2 Prove Theorem 4.12.\n\n\nExercise 4.3 Prove Theorem 4.13.\n\n\nExercise 4.4 Prove Theorem 4.18.\n\n\nExercise 4.5 Finish the proof of Theorem 4.14.\n\n\nExercise 4.6 Finish the proof of Theorem 4.15.\n\n\nExercise 4.7 Finish the proof of Theorem 4.16.\n\n\nExercise 4.8 Finish the proof of Theorem 4.17.\n\n\nExercise 4.9 Finish the proof of Theorem 4.19.\n\n\nExercise 4.10 Finish the proof of Theorem 4.20.\n\n\nExercise 4.11 Prove Theorem 4.21.\n\n\nExercise 4.12 Prove Theorem 4.22.\n\n\nExercise 4.13 Prove Theorem 4.23.\n\n\nExercise 4.14 Finish the proof of Theorem 4.24.\n\n\nExercise 4.15 Finish the proof of Theorem 4.25.\n\n\nExercise 4.16 Prove Lemma 4.1.\n\n\nExercise 4.17 Finish the proof of Theorem 4.26.\n\n\nExercise 4.18 Finish the proof of Theorem 4.27.\n\n\nExercise 4.19 Finish the proof of Theorem 4.28.\n\n\nExercise 4.20 Prove Theorem 4.4.\n\n\nExercise 4.21 Prove Theorem 4.5.\n\n\n\n\n\nAdamson, Iain T. 1998. “Equivalents of the Axiom of Choice.” In A Set Theory Workbook, 59–62. Springer.\n\n\nCantor, Georg. 1883. “Ueber Unendliche, Lineare Punktmannichfaltigkeiten.” Math. Ann. 21 (4): 545–91. https://doi.org/10.1007/BF01446819.\n\n\nHalmos, Paul R. 1974. Naive Set Theory. Springer-Verlag, New York-Heidelberg.\n\n\nHarzheim, Egbert. 2005. Ordered Sets. Vol. 7. Advances in Mathematics (Springer). New York: Springer.\n\n\nJech, Thomas J. 2008. The Axiom of Choice. Courier Corporation.\n\n\nMoore, Gregory H. 2012. Zermelo’s Axiom of Choice: Its Origins, Development, and Influence. Courier Corporation.\n\n\nRubin, Herman, and Jean E Rubin. 1985. Equivalents of the Axiom of Choice, II. Elsevier.\n\n\nSuppes, Patrick. 1972. “Axiomatic Set Theory, 1960.” Dover edn., New York.\n\n\nSzpilrajn, Edward. 1930. “Sur l’extension de l’ordre Partiel.” Fundamenta Mathematicae 16 (1): 386–89.\n\n\nTourlakis, George. 2003. Lectures in Logic and Set Theory: Volume 2, Set Theory. Vol. 83. Cambridge University Press."
  },
  {
    "objectID": "functions-and-relations.html#domain-and-codomain",
    "href": "functions-and-relations.html#domain-and-codomain",
    "title": "5  Functions and Relations",
    "section": "5.1 Domain and Codomain",
    "text": "5.1 Domain and Codomain\nLet \\(X\\) and \\(Y\\) be sets, we say \\(f\\) is a function from \\(X\\) to \\(Y\\) if \\(f\\) is a subset of \\(X\\times Y\\) such that the domain of \\(f\\) is \\(X\\) and \\(f\\) has the property: if \\((x,y)\\in f\\) and \\((x,z)\\in f\\) then \\(x=z\\). For each \\(x\\in X\\), the unique \\(y\\in Y\\) such that \\((x,y)\\in f\\) is denoted by \\(f(x)\\). The element \\(y\\) is called the value of \\(f\\) at the argument \\(x\\).\nIf we do not specify a function with the notation \\(f:X\\to Y\\) we will use \\(D(f)\\) and \\(R(f)\\) to denote the domain and range of \\(f\\), respectively."
  },
  {
    "objectID": "functions-and-relations.html#image-and-preimage",
    "href": "functions-and-relations.html#image-and-preimage",
    "title": "5  Functions and Relations",
    "section": "5.2 Image and Preimage",
    "text": "5.2 Image and Preimage\n\nDefinition 5.1 Let \\(X\\) and \\(Y\\) be sets. The image of \\(A\\subseteq X\\) is the set \\[f(A) = \\{y\\in Y : \\exists x\\in A, y=f(x)\\}.\\]\n\n\nTheorem 5.1 Let \\(f:X\\to Y\\) be a function. If \\(A_1, A_2\\subseteq X\\), then \\[\nf(A_1)\\cup f(A_2)=f(A_1\\cup A_2).\n\\]\n\n\nProof. \\(f(A_1)\\cup f(A_2)=f(A_1\\cup A_2)\\): \\[\\begin{align*}\n& y\\in f(A_1)\\cup f(A_2)\n\\Leftrightarrow y\\in f(A_1) \\lor y\\in f(A_2)\n\\\\& \\qquad\n\\Leftrightarrow \\exists x_1\\in A_1, y=f(x_1) \\lor \\exists x_2\\in A_2, y=f(x_2)\n\\\\& \\qquad\n\\Leftrightarrow \\exists x\\in X, (x\\in A_1 \\lor x\\in A_2) \\land y=f(x)\n\\\\& \\qquad\n\\Leftrightarrow \\exists x \\in A_1 \\cup A_2, y=f(x)\n\\Leftrightarrow y\\in f(A_1\\cup A_2)\n\\end{align*}\\]\n\n\nTheorem 5.2 Let \\(f:X\\to Y\\) be a function. If \\(A_1, A_2\\subseteq X\\), then \\[\nf(A_1\\cap A_2) \\subseteq f(A_1)\\cap f(A_2).\n\\]\n\n\nProof. \\(f(A_1\\cap A_2) \\subseteq f(A_1)\\cap f(A_2)\\) \\[\\begin{align*}\n& y\\in f(A_1 \\cap  A_2)\n\\Longrightarrow \\exists x\\in A_1 \\cap A_2, y=f(x)\n\\\\& \\qquad\n\\Longrightarrow  \\exists x\\in A_1, y=f(x) \\land \\exists x\\in A_2, y=f(x)\n\\\\& \\qquad\n\\Longrightarrow  y\\in f(A_1)\\land y\\in f(A_2)\n\\Longrightarrow  y\\in f(A_1)\\cap f(A_2)\n\\end{align*}\\]\n\n\nTheorem 5.3 Let \\(f:X\\to Y\\) be a function. If \\(A_1, A_2\\subseteq X\\), then \\[\nf(A_2)\\setminus f(A_1) \\subseteq f(A_2\\setminus A_1).\n\\]\n\n\nProof. \\(f(A_2)\\setminus f(A_1) \\subseteq f(A_2\\setminus A_1)\\) \\[\\begin{align*}\n& y\\in f(A_2)\\setminus f(A_1) \\Leftrightarrow y\\in f(A_2) \\land y\\notin f(A_1) \\\\\n& \\qquad \\Leftrightarrow (\\exists x\\in A_2, y=f(x) )\\land \\neg (y\\in f(A)) \\\\\n& \\qquad \\Leftrightarrow (\\exists x\\in A_2, y=f(x) )\\land \\neg (\\exists z\\in A_1, y=f(z)) \\\\\n& \\qquad \\Leftrightarrow (\\exists x\\in A_2, y=f(x) )\\land (\\forall z\\in A_1, y\\neq f(z)) \\\\\n& \\qquad \\Longrightarrow \\exists x\\in A_2\\setminus A_1, y=f(x) \\Leftrightarrow y\\in f(A_2\\setminus A_1)\n\\end{align*}\\]\n\n\nDefinition 5.2 Let \\(X\\) and \\(Y\\) be sets. The preimage of \\(B\\subseteq Y\\) is the set \\[\nf^{-1}(B)=\\{x\\in X : f(x)\\in B\\}.\n\\]\n\n\nTheorem 5.4 Let \\(f:X\\to Y\\) be a function. If \\(B_1, B_2\\subseteq Y\\), then \\[\nf^{-1}(B_1\\cup B_2)=f^{-1}(B_1)\\cup f^{-1}(B_2).\n\\]\n\n\nProof. \\(f^{-1}(B_1\\cup B_2)=f^{-1}(B_1)\\cup f^{-1}(B_2)\\) \\[\\begin{align*}\n& x\\in f^{-1}(B_1\\cup B_2) \\Leftrightarrow   f(x)\\in B_1 \\cup B_2  \\\\\n& \\qquad \\Leftrightarrow f(x) \\in B_1 \\lor f(x)\\in B_2 \\\\\n& \\qquad \\Leftrightarrow x\\in f^{-1}(B_1) \\lor x\\in f^{-1}(B_2)  \\\\\n& \\qquad \\Leftrightarrow x\\in f^{-1}(B_1)\\cup f^{-1}(B_2)\n\\end{align*}\\]\n\n\nTheorem 5.5 Let \\(f:X\\to Y\\) be a function. If \\(B_1, B_2\\subseteq Y\\), then \\[\nf^{-1}(B_1\\cap B_2)=f^{-1}(B_1)\\cap f^{-1}(B_2).\n\\]\n\n\nProof. \\(f^{-1}(B_1\\cap B_2)=f^{-1}(B_1)\\cap f^{-1}(B_2)\\) \\[\\begin{align*}\n& x\\in f^{-1}(B_1\\cup B_2) \\Leftrightarrow f(x)\\in B_1\\cup B_2 \\\\\n& \\qquad \\Leftrightarrow f(x)\\in B_1 \\land f(x)\\in B_2 \\\\\n& \\qquad \\Leftrightarrow f(x)\\in B_1 \\land f(x)\\in B_2 \\\\\n& \\qquad \\Leftrightarrow x\\in f^{-1}(B_1) \\land x\\in f^{-1}(B_2) \\\\\n& \\qquad \\Leftrightarrow x\\in f^{-1}(B_1)\\cap f^{-1}(B_2)\n\\end{align*}\\]\n\n\nTheorem 5.6 Let \\(f:X\\to Y\\) be a function. If \\(B_1, B_2\\subseteq Y\\), then \\[\nf^{-1}(B_2\\setminus B_1)=f^{-1}(B_2)\\setminus f^{-1}(B_1).\n\\]\n\n\nProof. \\(f^{-1}(B_2\\setminus B_1)=f^{-1}(B_2)\\setminus f^{-1}(B_1)\\) \\[\\begin{align*}\n& x\\in f^{-1}(B_2\\setminus B_1)\n\\Leftrightarrow   f(x)\\in B_2\\setminus B_1\n\\\\ & \\qquad\n\\Leftrightarrow  f(x)\\in B_2 \\land \\neg(f(x)\\in B_1)\n%\\\\ & \\qquad\n\\Leftrightarrow   x\\in f^{-1}(B_2) \\land \\neg (x\\in f^{-1}(B_1))\n\\\\ & \\qquad\n\\Leftrightarrow   x\\in f^{-1}(B_2) \\land x\\not\\in f^{-1}(B_1)\n%\\\\ & \\qquad\n\\Leftrightarrow   x\\in f^{-1}(B_2) \\setminus f^{-1}(B_1)\n\\end{align*}\\]\n\n\nTheorem 5.7 Let \\(f:X\\to Y\\) be a function. Then \\[\nA_1\\subseteq A_2\\subseteq X\\implies f(A_1)\\subseteq f(A_2).\n\\]\n\n\nProof. \\(A_1\\subseteq A_2\\implies f(A_1)\\subseteq f(A_2)\\) \\[\\begin{align*}\n& y\\in f(A_1) \\Leftrightarrow \\exists x\\in A_1, y=f(x)\n\\\\ & \\qquad\n\\implies \\exists x\\in A_2, y=f(x) \\implies y\\in f(A_2)\n\\end{align*}\\]\n\n\nTheorem 5.8 Let \\(f:X\\to Y\\) be a function. Then \\[\nA_1\\subseteq A_2\\subseteq X\\implies f(A_1)\\subseteq f(A_2).\n\\]\n\n\nProof. \\(B_1\\subseteq B_2\\implies f^{-1}(B_1)\\subseteq f^{-1}(B_2)\\) \\[\\begin{align*}\nx\\in f^{-1}(B_1)\n\\Leftrightarrow   f(x)\\in B_1\n\\Longrightarrow   f(x)\\in B_2\n\\Leftrightarrow   x\\in f^{-1}(B_2)\n\\end{align*}\\]\n\n\nTheorem 5.9 Let \\(f:X\\to Y\\) be a function. Then \\[\nB\\subseteq Y  \\implies  f(f^{-1}(B))\\subseteq B\n\\]\n\n\nProof. \\(B\\subseteq Y \\implies f(f^{-1}(B))\\subseteq B\\) \\[\\begin{align*}\n& y\\in f(f^{-1}(B))\n\\Leftrightarrow   \\exists x\\in f^{-1}(B), y=f(x)\n\\\\ & \\qquad\n\\Longrightarrow   \\exists x\\in X, f(x)\\in B \\land y=f(x)\n\\Longrightarrow  y\\in B\n\\end{align*}\\]\n\n\nTheorem 5.10 Let \\(f:X\\to Y\\) be a function. Then \\[\nA\\subseteq X \\implies A\\subseteq f^{-1}(f(A)).\n\\]\n\n\nProof. \\(A\\subseteq X \\implies A\\subseteq f^{-1}(f(A))\\) \\[\\begin{align*}\nx\\in A \\implies \\exists y\\in Y, y=f(x) \\Leftrightarrow y\\in f(A) \\implies x\\in f^{-1}(f(A))\n\\end{align*}\\]"
  },
  {
    "objectID": "functions-and-relations.html#injective-and-surjective",
    "href": "functions-and-relations.html#injective-and-surjective",
    "title": "5  Functions and Relations",
    "section": "5.3 Injective and Surjective",
    "text": "5.3 Injective and Surjective\nA one-to-one function is a function in which each element in the domain corresponds to a unique element in the codomain. In other words, no two elements in the domain have the same image. An onto function is a function in which each element in the codomain has at least one pre-image. In other words, for every element in the codomain, there is at least one element in the domain that maps to it. One-to-one and onto functions are important because they allow us to uniquely identify each element in the domain, and to know that every element in the codomain has a pre-image.\n\nDefinition 5.3 Let \\(X\\) and \\(Y\\) be sets. A function \\(f:X\\to Y\\) is called injective if \\[\n\\forall x_1,x_2\\in X, f(x_1)=f(x_2)\\implies x_1=x_2.\n\\]\n\n\nTheorem 5.11 Let \\(f:X\\to Y\\) be a function. If \\(f\\) is injective and \\(A\\subseteq X\\), then \\(f|_A\\) is injective.\n\n\nProof. Let \\(x_1, x_2\\in A\\). Then \\[\nf|_A(x_1)=f|_A(x_2)\n\\Longrightarrow f(x_1)=f(x_2)\n\\Longrightarrow x_1=x_2\n\\] shows that \\(f|_A\\) is injective.\n\n\nTheorem 5.12 Let \\(f:X\\to Y\\) be a function. Then \\(f\\) is injective if and only if \\(f(A_1\\cap A_2) = f(A_1)\\cap f(A_2)\\) for all \\(A_1, A_2\\subseteq X.\\)\n\n\nProof. Assume \\(f\\) is injective. It suffices to show \\(f(A_1)\\cap f(A_2)\\subseteq f(A_1\\cap A_2)\\) for all \\(A_1, A_2\\subseteq X\\). Let \\(A_1, A_2\\subseteq X\\). Then \\[\\begin{align*}\n& y\\in f(A_1)\\cap f(A_2) \\Leftrightarrow y\\in f(A_1)\\land y\\in f(A_2) \\\\\n& \\qquad \\Leftrightarrow [\\exists x\\in A_1, y=f(x)] \\land [\\exists z\\in A_2, y=f(z)] \\\\\n& \\qquad \\Longrightarrow \\exists x\\in A_1, \\exists z\\in A_2, f(x)=y=f(z) \\\\\n& \\qquad \\Longrightarrow \\exists x\\in A_1, \\exists z\\in A_2, x=z, y=f(x)  \\\\\n& \\qquad \\Longrightarrow \\exists x\\in A_1\\cap A_2, y=f(x) \\Longrightarrow  y\\in f(A_1\\cap A_2)\n\\end{align*}\\]\nConversely, assume \\(f(A_1\\cap A_2)=f(A_1)\\cap f(A_2)\\), for all \\(A_1, A_2\\subseteq X\\). Let \\(x_1, x_2\\in X\\) and assume \\(x_1\\neq x_2\\). Then \\(\\{x_1\\}\\cap \\{x_2\\}=\\emptyset\\). Then \\[\nf(\\{x_1\\}\\cap \\{x_2\\})=\\emptyset=f(\\{x_1\\})\\cap f(\\{x_2\\}).\n\\] If \\(f(x_1)=f(x_2)\\), then \\(f(x_2)\\in f(\\{x_1\\})\\) and \\(f(x_1)\\in f(\\{x_2\\})\\), and so \\(f(\\{x_1\\})\\cap f(\\{x_2\\}) \\neq \\emptyset.\\) Thus, \\(f(x_1)\\neq f(x_2)\\) and so \\(f\\) is injective.\n\n\nTheorem 5.13 Let \\(f:X\\to Y\\) be a function. Then \\(f\\) is injective if and only if \\(f(A_2\\setminus A_1)=f(A_2)\\setminus f(A_1)\\) for all \\(A_1, A_2\\subseteq X.\\)\n\n\nProof. Assume \\(f\\) is injective. Let \\(A_1, A_2\\subseteq X\\). It suffices to show \\(f(A_2\\setminus A_1)\\subseteq f(A_2)\\setminus f(A_1)\\). Assume \\(y\\in f(A_2\\setminus A_1)\\). Then \\(y=f(x)\\) for some \\(x\\in A_2\\setminus A_1\\). Thus, \\(x\\in A_2\\) and so \\(y\\in f(A_2)\\). We claim \\(y\\not\\in f(A_1)\\). Suppose \\(y\\in f(A_1)\\). Then, there exists \\(z\\in A_1\\) such that \\(f(z)=y\\). Since \\(f\\) is injective, \\(x=z\\). However, \\(x\\not\\in A_1\\), and so the claim follows. Thus, \\(y\\in f(A_2)\\setminus f(A_1)\\) as desired.\nConversely, assume \\(f(A_2\\setminus A_1)=f(A_2)\\setminus f(A_1)\\) holds for all \\(A_1, A_2\\in X\\). Let \\(x_1, x_2\\in X\\) and assume \\(x_1\\neq x_2\\). Then \\(\\{x_2\\}\\setminus \\{x_1\\}=\\{x_2\\}\\) and so \\[\nf(\\{x_2\\}\\setminus \\{x_1\\})=f(\\{x_2\\})=f(\\{x_2\\})\\setminus f(\\{x_1\\}).\n\\] If \\(f(x_1)=f(x_2)\\), then \\(f(\\{x_2\\})\\setminus f(\\{x_1\\})=\\emptyset\\), contrary to \\(f(\\{x_2\\})\\setminus f(\\{x_1\\})=f(\\{x_2\\})\\). Thus \\(f(x_1)\\neq f(x_2)\\) and so \\(f\\) is injective.\n\n\nTheorem 5.14 Let \\(f:X\\to Y\\) be a function. Then \\(f\\) is injective if and only if \\(f(A_1)\\cap f(A_2)=\\emptyset\\) for all \\(A_1, A_2\\subseteq X\\) such that \\(A_1\\cap A_2=\\emptyset\\).\n\n\nProof. Assume \\(f\\) is injective. Let \\(A_1, A_2\\in X\\) with \\(A_1\\cap A_2=\\emptyset\\). Assume \\(y\\in f(A_1)\\cap f(A_2)\\). Then there exists \\(x_1\\in A_1\\) and \\(x_2\\in A_2\\) such that \\(y=f(x_1)\\) and \\(y=f(x_2)\\). Since \\(f\\) is injective, \\(x_1=x_2\\). Thus, \\(A_1\\cap A_2\\neq \\emptyset\\) contrary to hypothesis. Thus, \\(f(A_1)\\cap f(A_2)\\) is empty. Conversely, assume \\(f(A_1)\\cap f(A_2)=\\emptyset\\) for all \\(A_1, A_2\\subseteq X\\) with \\(A_1\\cap A_2=\\emptyset\\). Let \\(x_1, x_2\\in X\\) and assume \\(x_1\\neq x_2\\). Then \\(\\{x_1\\}\\cap \\{x_2\\}=\\emptyset\\). By hypothesis, \\(f(\\{x_1\\})\\cap f(\\{x_2\\})=\\emptyset\\). Thus \\(f(x_1)\\neq f(x_2)\\) and so \\(f\\) is injective.\n\n\nTheorem 5.15 Let \\(f:X\\to Y\\) be a function. Then \\(f\\) is injective if and only if \\(A=f^{-1}(f(A))\\) for all \\(A\\subseteq X\\).\n\n\nProof. Assume \\(f\\) is injective. Let \\(A\\subseteq X\\). It suffices to show \\(f^{-1}(f(A))\\). Let \\(x\\in f^{-1}(f(A))\\). Then \\(f(x)\\in f(A)\\). Then there exists \\(x_1\\in A\\) such that \\(f(x_1)=f(x)\\). Since \\(f\\) is injective, \\(x_1=x\\) and so \\(x\\in A\\). Conversely, assume \\(A=f^{-1}(f(A))\\) for all \\(A\\subseteq X\\). Let \\(x_1, x_2\\in X\\). Assume \\(f(x)1=f(x_2)\\). Then \\[\n\\{x_1\\}=f^{-1}(f(\\{x_1\\}))=f^{-1}(f(\\{x_2\\}))=\\{x_2\\}\n\\] implies \\(x_1=x_2\\) and so \\(f\\) is injective.\n\n\nDefinition 5.4 Let \\(X\\) and \\(Y\\) be sets. A function \\(f:X\\to Y\\) is called surjective if \\[\n\\forall y\\in Y, \\exists x\\in X, y=f(x).\n\\]\n\n\nTheorem 5.16 Let \\(f:X\\to Y\\) be a function. If \\(f\\) is surjective and \\(A\\supseteq X,\\) then \\(f|^A\\) is surjective.\n\n\nProof. Let \\(t\\in Y\\). Since \\(f\\) is surjective there exists \\(x\\in X\\) such that \\(f(x)=y\\). Since \\(X\\subseteq A\\), \\(x\\in A\\) and so \\(f(x)=y\\) with \\(x\\in A\\) implies \\(f|^A\\) is surjective.\n\n\nTheorem 5.17 Let \\(f:X\\to Y\\) be a function. Then \\(f\\) is surjective if and only if \\(B=f(f^{-1}(B))\\) for all \\(B\\subseteq Y.\\)\n\n\nProof. Assume \\(f\\) is surjective. It suffices to show \\(B\\subseteq f(f^{-1}(B))\\). Let \\(y\\in B\\). Since \\(f\\) is surjective. there exists \\(x\\in X\\) such that \\(y=f(x)\\). Since \\(f(x)\\in B\\) we have \\(x\\in f^{-1}(B)\\). It follows \\(y=f(x)\\in f(f^{-1}(B)).\\)\nConversely, assume \\(B=f(f^{-1}(B))\\) for all \\(B\\subseteq Y\\). Since \\(\\{y\\}=f(f^{-1}(\\{y\\}))\\), it follows \\(y=f(x)\\) for some \\(x\\in f^{-1}(\\{y\\})\\). Let \\(y\\in Y\\). Thus, \\(f\\) is surjective.\n\n\nTheorem 5.18 If \\(f:X\\rightarrow P(X)\\) is a function, then \\(f\\) is not surjective.\n\n\nProof. Let \\(A=\\{x\\in X : x\\notin f(x)\\}\\). Assume for a contradiction that \\(f\\) is onto. Then there exists \\(x\\in X\\) such that \\(f(x)=A\\). Consider both cases \\(x\\in f(x)\\) and \\(x\\not\\in f(x)\\):\n\\[\\begin{align*}\n& x\\in f(x) \\implies x\\in A \\implies x\\not\\in f(x)\n\\implies\\Longleftarrow \\\\\n& x\\notin f(x) \\implies x\\in A=f(x) \\implies x\\not\\in f(x)\n\\implies\\Longleftarrow\n\\end{align*}\\]\nThus, \\(x\\) can not exist with \\(f(x)=A\\). Therefore, no \\(f:X\\rightarrow P(X)\\) is onto."
  },
  {
    "objectID": "functions-and-relations.html#composition-and-inverse",
    "href": "functions-and-relations.html#composition-and-inverse",
    "title": "5  Functions and Relations",
    "section": "5.4 Composition and Inverse",
    "text": "5.4 Composition and Inverse\nThe composition of functions is a way to combine two or more functions into a single function. This can be done by combining the domain and range of the functions, or by using the functions to compute new outputs. The composition of functions is a powerful tool that can be used to simplify complex problems. It is also a useful way to create new functions from existing functions. To compose two functions \\(f\\) and \\(g\\), we apply f to the output of \\(g.\\) That is, we first apply \\(g\\) to its input, and then apply \\(f\\) to the resulting output. The composition of functions is denoted by \\(f \\circ g\\).\nThe inverse of a function is a function that “undoes” the original function. In other words, it is a function that maps each element in the codomain back to its corresponding element in the domain. It’s important to note that not all functions have inverse functions. For example, the function that takes in an age and outputs whether or not the person is tall has no inverse. This is because there are many people who are the same age but have different heights. So, there is no way to take in a height and produce an age. However, functions like this are still useful; they just can’t be “undone”.\n\nTheorem 5.19 Let \\(f:X\\to Y\\) be a function. If \\(g:Y\\to Z\\) and \\(g\\circ f\\) is injective, then \\(f\\) is injective.\n\n\nProof. Let \\(x_1, x_2\\in X.\\) Then \\[\nf(x_1)=f(x_2) \\Longrightarrow (g\\circ f)(x_1)=(g\\circ f)(x_2) \\Longrightarrow x_1=x_2\n\\] shows that \\(f\\) is injective.\n\n\nTheorem 5.20 Let \\(f:X\\to Y\\) be a function. Then following are equivalent.\n\ngiven any functions \\(g,h:Y\\to X\\), if \\(f\\circ g=f\\circ h\\), then \\(g=h\\)\nthere exists a function \\(g:Y\\to X\\) with \\(g\\circ f=I_X\\) (\\(f\\) has a left inverse)\n\n\n\nProof. (1)\\(\\Leftrightarrow\\)(2): Assume \\(f\\) is injective. Let \\(g,h:Y\\to X\\) and assume \\(f\\circ g= f\\circ h\\). Let \\(y\\in Y\\). Then \\((f\\circ g)(y)=(f\\circ h)(y)\\). Since \\(f\\) is injective it follows \\(g(y)=h(y)\\) for all \\(y\\in Y.\\) Conversely, assume \\(g,h:Y\\to X\\), \\(f\\circ g=f\\circ h \\implies g=h\\) holds. Let \\(x_1, x_2\\in X\\) and assume \\(x_1\\neq x_2\\). Assume, for a contradiction, \\(f(x_1)=f(x_2)\\). Let \\(g:Y\\to X\\) be defined by \\(g(y)=x_1\\) for all \\(y\\in Y\\). Let \\(h:Y\\to X\\) be defined by \\(h(y)=x_2\\) for all \\(y\\in Y\\). Notice \\[\n(f\\circ g)(y)=f(g(y))=f(x_1)=f(x_2)=(f\\circ h)(y)\n\\] for all \\(y\\in Y\\). Thus, \\(f\\circ g=f\\circ h\\), yet \\(g\\neq h\\) since \\(g(y)=x_1\\neq x_2=h(y)\\). Therefore, \\(f(x_1)\\neq f(x_2)\\) and so \\(f\\) is injective.\n(2)\\(\\Leftrightarrow\\)(1): Assume \\(X\\neq \\emptyset\\) and also assume \\(f:X\\to Y\\) is injective. Let \\(y\\in Y\\). Either \\(y\\in f(X)\\) or \\(y\\notin f(X)\\). Define \\(g:Y\\to X\\) as follows \\[\\begin{equation}\ng(y)=\n\\begin{cases}\nx & y\\in f(X) \\text{ and } f(x)=y \\\\\nx_0 & y \\notin f(X)\n\\end{cases}\n\\end{equation}\\] where \\(x_0\\) is a fixed element of \\(X\\neq \\emptyset\\). Then \\(g\\) is defined for all \\(y\\in Y\\). If \\(y'\\in Y\\) with \\(x_1=g(y')\\neq g(y')=x_2\\), then \\(y'=f(x_1)\\neq f(x_2)=y'\\), since \\(f\\) is injective. Thus, \\(f\\) is injective implies \\(g\\) is a function. If \\(x\\in X\\), then \\[\n(g\\circ f)(x)=g(f(x))=g(y)=x, \\qquad \\text{ for some $y\\in f(X)$}\n\\] which shows \\(g\\circ f=I_X\\). Conversely, assume \\(f:X\\to Y\\) and there exists \\(g:Y\\to X\\) such that \\(g\\circ f=I_X\\). Let \\(x_1,x_2\\in X\\) and assume \\(f(x_1)=f(x_2)\\). Then \\[\nx_1=(g\\circ f)(x_1)=g(f(x_1))=g(f(x_2))=(g\\circ f)(x_2)=x_2\n\\] which shows \\(f\\) is injective.\n\n\nTheorem 5.21 Let \\(f:X\\to Y\\) be a function. If \\(f\\) is injective and \\(g:Y\\to Z\\) is injective, then \\(g\\circ f\\) is injective.\n\n\nProof. Let \\(x_1, x_2\\in X\\). Then \\[\n(g\\circ f)(x_1)=(g\\circ f)(x_2)\n\\Longrightarrow f(x_1)=f(x_2)\n\\Longrightarrow x_1= x_2\n\\] shows that \\(g\\circ f\\) is injective.\n\n\nTheorem 5.22 Let \\(f:X\\to Y\\) be a function. If \\(g:Y\\to Z\\) and \\(g\\circ f\\) is surjective, then \\(g\\) is surjective.\n\n\nProof. Let \\(z\\in Z\\). Then there exists \\(x\\in X\\) such that \\((g\\circ f)(x)=z\\). Thus it follows \\(g(f(x))=z\\) shows, for all \\(z\\in Z\\) there exists \\(y\\) (namely \\(y=f(x)\\)) such that \\(g(y)=z\\) and so \\(g\\) is surjective.\n\n\nTheorem 5.23 Let \\(f:X\\to Y\\) be a function. If \\(f\\) is surjective and \\(g:Y\\to Z\\) is surjective, then \\(g\\circ f\\) is surjective.\n\n\nProof. Let \\(z\\in Z\\). Since \\(g\\) is surjective there exists \\(y\\in Y\\) such that \\(g(y)=z\\). Since \\(f\\) is surjective there exists \\(x\\in X\\) such that \\(f(x)=y\\). Thus \\((g\\circ f)(x)=z\\) and so \\(g\\circ f\\) is surjective.\n\n\nTheorem 5.24 Let \\(f:X\\to Y\\) be a function. Then \\(f\\) is surjective if and only if given any functions \\(g,h:Y\\to X\\), if \\(g\\circ f=h\\circ f\\), then \\(g=h\\)\n\n\nProof. Assume \\(f\\) is surjective and let \\(g:Y\\to Z\\) and \\(h:Y\\to Z\\) be functions such that \\(g\\circ f=h\\circ f\\). Let \\(y\\in Y\\). Since \\(f\\) is surjective, there exists \\(x\\in X\\) such that \\(y=f(x)\\). Then \\(g(y)=g(f(X))=h(f(x))=h(y)\\) as needed to show \\(g=h\\).\nConversely, and for contrapositive, suppose \\(f\\) is not surjective. Then there exists \\(y_1\\in Y\\) such that \\(y_1=f(x)\\) does not hold for all \\(x\\in X\\). Let \\(Z=\\{a,b\\}\\) and let \\(g\\) and \\(h\\) be defined by \\(g(y)=a\\) for all \\(a\\in Y\\) and \\[\nh(y)=\\begin{cases}\na & \\text{ if } y\\neq y_1 \\\\\nb & \\text{ if } y=y_1.\n\\end{cases}\n\\] Then we have \\(g\\neq h\\) such that \\(g\\circ f=h\\circ f\\). Thus \\(f\\) is not right cancelable.\n\n\nTheorem 5.25 Let \\(f:X\\to Y\\) be a function. Then \\(f\\) is surjective if and only if there exists a function \\(h:Y\\to X\\) with \\(f\\circ h = I_Y\\) (\\(f\\) has a right inverse).\n\n\nProof. Then \\(f\\) is surjective if and only if there exists a function \\(h:Y \\to X\\) with \\(f \\circ h = I_Y.\\) Assume there exist \\(h:Y\\to X\\) with \\(f \\circ h=I_Y\\). Let \\(b\\in Y\\). Then \\(b=(f\\circ h)(b)=f(h(b))=f(a)\\) where \\(a\\in X\\), shows \\(f\\) is surjective.\nConversely, follows using the Axiom of Choice. Suppose \\(f\\) is surjective. Then \\(f^{-1}(b)\\subseteq X\\) is a nonempty set for every \\(b\\in Y\\). For each \\(b\\in Y\\) choose \\(a_b\\in f^{-1}(b)\\). Then the map \\(h:Y\\to X\\) defined by \\(h(b)=a_b\\) is such that \\(f\\circ h=I_Y\\) since \\((f\\circ h)(y)=f(h(y))=f(a_y)=y\\).\n\nIf the inverse relation \\(f^{-1}\\) is also a function, then we say \\(f\\) is an invertible function, or just invertible function.\n\nTheorem 5.26 A function \\(f:X\\to Y\\) is invertible if and only if it is injective. If \\(f\\) is invertible then \\(f^{-1}\\) is also invertible and \\((f^{-1})^{-1}=f\\).\n\n\nProof. Let \\(f\\) be invertible, then \\(f^{-1}\\) is a function. It follows that \\(f^{-1}(f(x))=x\\) for all \\(x\\in X\\). If \\(x_1, x_2\\in X\\) and \\(f(x_1)=f(x_2)\\), we get \\(f^{-1}(f(x_1))=f^{-1}(f(x_2))\\) and \\(x_1=x_2\\). So \\(f\\) is injective. Let \\(f\\) be injective. If \\(a=f^{-1}(y_1)\\) and \\(a=f^{-1}(y_2)\\) we have \\(y_1 = f(a)\\) and \\(y_2 =f(a)\\). Therefore, \\(y_1=y_2\\) and we have proven that \\(f^{-1}\\) is a function. We know that \\((f^{-1})^{-1}=f\\) by previous theorem and so \\(f^{-1}\\) is also invertible.\n\n\nDefinition 5.5 Let \\(X\\) and \\(Y\\) be sets. A function \\(f\\) is called bijective, if \\(f\\) is both injective and surjective.\n\n\nTheorem 5.27 Let \\(f:X\\to Y\\) be a function. Then \\(f\\) is bijective if and only if there exists a unique function \\(f':Y\\to X\\) such that both \\(f'\\circ f=I_X\\) and \\(f \\circ f' = I_Y.\\)\n\n\nProof. If \\(f\\) is bijective, then \\(f\\) is injective and surjective; and thus there exists functions \\(g\\) and \\(h\\) such that \\(g\\circ f=I_X\\) and \\(f \\circ h = I_Y.\\) Notice \\[\ng=g \\circ I_Y=g \\circ (f \\circ h)=(g\\circ f)\\circ h=I_X\\circ h=h\n\\] showing \\(f':=g=h\\) as needed. Conversely, follows from the statements above.\n\n\nTheorem 5.28 Let \\(f:X\\to Y\\) be a function. If \\(f\\) and \\(g:Y\\to Z\\) are bijections, then \\(g\\circ f\\) is a bijection and \\[\n(g\\circ f)^{-1}=f^{-1}\\circ g^{-1}.\n\\]\n\n\nProof. If \\(f\\) and \\(f\\) are bijections, then \\(g\\circ f\\) is a bijection and \\((g\\circ f)^{-1}=f^{-1}\\circ g^{-1}\\). Therefore, the inverse of a function \\(f:X\\to Y\\) is a function \\(f^{-1}:Y\\to X\\) if and only if \\(f\\) is a bijection. Since \\(f\\) and \\(g\\) are bijections, \\(f^{-1}:Y\\to X\\) and \\(g^{-1}:Z\\to Y\\) are functions. Hence, \\(f^{-1}\\circ g^{-1}:Z\\to X\\) is a function. It follows that, \\(g\\circ f\\) is injective and surjective, and so a bijection. Thus \\((g\\circ f)^{-1}:Z\\to X\\) is also a function. Let \\(z\\in Z\\). Since \\(f\\) and \\(g\\) are surjections there exists \\(x\\in X\\) and \\(y\\in Y\\) such that\n\\[\\begin{equation}\n\\label{surjcomp}\ng(y)=z\n\\qquad \\text{and} \\qquad\nf(x)=y,\n\\end{equation}\\]\nrespectively. Written in inverse function notation, \\(y=g^{-1}(z)\\) and \\(x=f^{-1}(y)\\). By substitution, \\(x=f^{-1}(g^{-1}(z))=(f^{-1}\\circ g^{-1})(z)\\). Notice it also follows from \\(\\eqref{surjcomp}\\) that \\((g\\circ f)(x)=g(f(x))=g(y)=z\\). Written in inverse function notation we obtain \\((g\\circ f)^{-1}(z)=x\\)."
  },
  {
    "objectID": "functions-and-relations.html#relations",
    "href": "functions-and-relations.html#relations",
    "title": "5  Functions and Relations",
    "section": "5.5 Relations",
    "text": "5.5 Relations\nBinary relations are defined as a set of ordered pairs, where each element in the pair is from a set. In other words, binary relations involve set(s) of elements, which we will call the left set and the right set. The relationship between the two elements in each ordered pair is what we call the relation.\nBinary relations allow us to study the relationships between sets.\nFor example, let’s say we have a set of all the countries in the world, which we will call C, and a set of all the capitals of those countries, which we will call P. We can then define a binary relation R between C and P as follows:\n\\[\nR = \\{(c,p) \\mid c \\in C \\text{ and } p \\in P \\text{ and $c$ is the capital of $p$}\\}.\n\\]\nIn other words, \\(R\\) is the set of all ordered pairs \\((c,p)\\) such that \\(c\\) is a country and \\(p\\) is its capital.\nBinary relations can be classified according to various properties. The most common properties are composition, inverse, image, and preimage.\nImage. Given a relation \\(R\\) and a set \\(A\\), the image of \\(A\\) under \\(R\\) is the set \\[\n\\{y \\mid \\exists x\\in A \\text{ such that } (x,y)\\in R\\}.\n\\]\nPreimage. Given a relation \\(R\\) and a set \\(B\\), the preimage of \\(B\\) under \\(R\\) is the set \\[\n\\{x \\mid \\exists y\\in B \\text{ such that } (x,y)\\in R\\}.\n\\]\nComposition. Given two relations \\(R\\) and \\(S\\), their composition \\(RS\\) is the relation that consists of all ordered pairs \\((x,z)\\) such that there exists a \\(y\\) such that \\((x,y)\\in R\\) and \\((y,z)\\in S\\).\nInverse. Given a relation \\(R\\), the inverse of \\(R\\) is the relation that consists of all ordered pairs \\((y,x)\\) such that \\((x,y)\\in R\\).\nBinary relations can be represented in various ways, such as tables, graphs, and sets of ordered pairs. In order to understand binary relations, it is important to be familiar with all the different representations.\nTables. A binary relation can be represented using a table with two columns, where the left column represents the left set and the right column represents the right set. The entries in the table are the ordered pairs that make up the relation.\nGraphs. A binary relation can also be represented using a graph, where the left set is represented by the vertices and the right set is represented by the edges. The edges are labeled with the elements of the right set, and each edge goes from the vertex that represents the left element of the ordered pair to the vertex that represents the right element.\nSets of ordered pairs. Finally, a binary relation can also be represented as a set of ordered pairs. This is the most common way to represent a binary relation, and it is the representation we will use most often in this book.\nBinary relations are a fundamental concept in mathematics, and they can be used to model many different situations. For example, in computer science, binary relations are used to represent many different types of relationships. They can be used to represent the relationship between two pieces of data, or the relationship between two nodes in a graph. They can also be used to represent the relationship between two points in space, or the relationship between two people in a social network. Binary relations are also used in physics to represent the interactions between particles. For example, the gravitational force between two masses is a binary relation.\nNow it’s time to become familiar with the basic terminology and notation.\nLet \\(X\\) be a set and let \\(X\\times X=\\{(a,b): a,b \\in X\\}.\\) A (binary) relation relation \\(R\\) is a subset of \\(X\\times X\\). If \\((a,b)\\in R\\), then we say \\(a\\) is related to \\(b\\) by \\(R\\). It is possible to have both \\((a,b)\\in R\\) and \\((a,b')\\in R\\) where \\(b'\\neq b\\); that is any element in \\(X\\) could be related to any number of other elements of \\(X\\). It is also possible to have some element that is not related to any element in \\(X\\) at all. We say a relation \\(S\\) is an extension of a relation \\(R\\), denoted by \\(R\\subseteq S\\), whenever \\(aRb\\) implies \\(aSb\\), for all \\(a,b\\in X\\). Just as we would with sets, we say relations \\(R\\) and \\(S\\) are equal whenever \\(R\\subseteq S\\) and \\(S\\subseteq R\\).\n\nDefinition 5.6 Let \\(R\\) and \\(S\\) be relations on \\(X\\).\n\nThe image of \\(A\\subseteq X\\) under \\(R\\) is the set \\[R(A)=\\{y\\in X : \\exists \\, x\\in A, (x,y)\\in R\\}.\\]\nThe preimage of \\(B\\subseteq X\\) under \\(R\\) is the set \\[R^{-1}(B)=\\{x\\in X : \\exists \\, y\\in B, (x,y)\\in R\\}.\\]\nThe composition of \\(R\\) and \\(S\\) is the relation \\[S\\circ R = \\{(a,c)\\in X\\times X : \\exists \\, b\\in X, (a,b)\\in R \\land (b,c)\\in S\\}.\\]\nThe inverse of \\(R\\) is the relation \\[R^{-1}=\\{(b,a)\\in X\\times X : (a,b)\\in R\\}.\\]\n\n\n\n5.5.1 Union, Intersection, and Complement of Relations\nWe define the union, intersection, and complement of two relations just as one would expect knowing elementary set theory. So the union of two relations consists of those ordered pairs of elements that are related under at least one of the two relations, and the intersection of two relations consists of those ordered pairs of elements which are related under both relations.\n\nDefinition 5.7 Let \\(R\\) and \\(S\\) be relations on a set \\(X\\).The union and intersection of \\(R\\) and \\(S\\) are the relations prescribed (respectively) by \\[\nR\\cup S  = \\{(a,b) : aRb \\text{ or } aSb\\}\n\\quad \\text{and} \\quad\nR\\cap S  = \\{(a,b) :  aRb \\text{ and } aSb\\}.\n\\] The of \\(R\\) is the relation prescribed by \\(R^c = \\{(a,b): \\neg (aRb)\\}\\).\n\nWe now demonstrate one way of proving a proposition holds using elementary set theory. Suppose we wish to show that \\[\\begin{equation}\n\\label{subeq}\nR\\subseteq S\n\\Leftrightarrow\nR\\cap S=R\n\\end{equation}\\] for relations \\(R\\) and \\(S\\) defined on a set \\(X\\). To do so, we will prove that \\(R\\subseteq S\\) implies \\(R\\cap S=R\\), and conversely that \\(R\\cap S=R\\) implies \\(R\\subseteq S\\).\n\nThis type of reasoning illustrates the process of using basic logic and unwrapping definitions.\n\nTheorem 5.29 If \\(R\\), \\(S\\), and \\(T\\) be relations on a set \\(X\\), there holds\n\n\\({R\\cup(S\\cup T)=(R\\cup S)\\cup T}\\)\n\\(R \\cup S = S \\cup R\\)\n\\(R \\cup (R \\cap S) = R\\)\n\\(R \\cup \\emptyset = R\\)\n\\({R \\cup (S \\cap T) = (R \\cup S) \\cap (R \\cup T)}\\)\n\\(R \\cup R^c = X\\times X\\)\n\\(R\\cap(S\\cap T)=(R\\cap S)\\cap T\\)\n\\(R \\cap S = S \\cap R\\)\n\\(R \\cap (R \\cup S) = R\\)\n\\(R \\cap \\, (X\\times X) = R\\)\n\\({R \\cap (S \\cup T) = (R \\cap S) \\cup (R \\cap T)}\\)\n\\(R \\cap R^c = \\emptyset\\)\n\n\n\nProof. For the first statement, let \\((x,y)\\) be an arbitrary element of \\(X\\times X\\), then \\[\\begin{align*}\nx\\big(R\\cup(S\\cup T)\\big)y & \\Leftrightarrow xRy \\lor x(S\\cup T)y  \\Leftrightarrow x Ry \\lor \\Big(xSy \\lor xTy \\Big) \\\\\n& \\Leftrightarrow \\Big( xRy \\lor xSy \\Big) \\lor xTy  \\Leftrightarrow x(R\\cup S)y \\lor xTy  \\Leftrightarrow x\\big(( R\\cup S) \\cup T\\big)y.\n\\end{align*}\\] We leave the remainder of the proof for Exercise 5.1.\n\n\n\n5.5.2 Relative Complement and Symmetric Difference\nOther operations on \\(\\mathcal{X\\times X}\\) can be defined using logical connectives. For example, let \\(\\oplus\\) denote the logical XOR symbol (defined by \\(p\\oplus q\\) is true if and only if \\(p\\) and \\(q\\) have different truth values), then \\(R\\bigtriangleup S = \\{(a,b) : aRb \\oplus aSb\\}\\) prescribes the symmetric difference of relations \\(R\\) and \\(S\\) defined on a set \\(X\\).\n\nDefinition 5.8 Let \\(R\\) and \\(S\\) be relations on a set \\(X\\). The relative complement and symmetric difference of \\(R\\) and \\(S\\) are the relations prescribed (respectively) by \\[\nR - S = R\\cap S^c \\qquad \\text{and} \\qquad R\\bigtriangleup S = (R-S)\\cup (S-R).\n\\]\n\nThere are several equivalent formulations of the symmetric difference, some of which will be seen in the exercises.\n\nTheorem 5.30 For any relations \\(R\\), \\(S\\), and \\(T\\) on a set \\(X\\), there holds 1. \\(R\\bigtriangleup S = S\\bigtriangleup R\\) 2. \\(R\\bigtriangleup (S\\bigtriangleup T)=(R\\bigtriangleup S)\\bigtriangleup T\\) 3. \\(R\\bigtriangleup \\emptyset = R\\) 4. \\(R\\bigtriangleup R=\\emptyset\\) 5. \\(R\\cap (S\\bigtriangleup T)=(R\\cap S)\\bigtriangleup (R\\cap T)\\) 6. \\((S\\bigtriangleup T)\\cap R=(S\\cap R)\\bigtriangleup (T\\cap R)\\)\n\n\nProof. When we consider the triple \\((\\mathcal{X\\times X},\\bigtriangleup,\\cap)\\) as an algebraic structure, it is an example of a Boolean ring with identity . More precisely, \\((\\mathcal{X},\\bigtriangleup)\\) is an abelian group with identity \\(\\emptyset\\) and \\((\\mathcal{X\\times X},\\bigtriangleup,\\cap)\\) is a commutative ring with identity that is Boolean.\n\n\nTheorem 5.31 For any relations \\(R\\), \\(S\\), and \\(T\\) on a set \\(X\\), there holds\n\n\\(R\\bigtriangleup S\\subseteq R\\cup S\\),\n\\(R\\cap S=\\emptyset\\) if and only if \\(R\\cup S=R\\bigtriangleup S\\), and\n\\((R\\bigtriangleup S)\\bigtriangleup (S\\bigtriangleup T)=R\\bigtriangleup T\\).\n\n\n\nProof. (1): Since \\(R-S\\subseteq R\\) and \\(S-R\\subseteq S\\), we have \\(R\\bigtriangleup S \\subseteq R\\cup S\\).\n(2): If \\(R\\) and \\(S\\) are disjoint, then \\(R=R-S\\) and \\(S=S-R\\) and so \\(R\\bigtriangleup S = R\\cup S\\). Conversely, assume that \\(R\\bigtriangleup S = R\\cup S\\). If \\({R\\cap S\\neq \\emptyset}\\), then both \\({R-S\\subset R}\\) and \\({S-R\\subset S}\\) (proper containment); whence \\(R\\bigtriangleup S \\neq R\\cup S\\) contrary to hypothesis.\n(3):By Theorem 5.30 we have \\[\\begin{equation}\n{(R\\bigtriangleup S)\\bigtriangleup (S\\bigtriangleup T)} = {R\\bigtriangleup S\\bigtriangleup S\\bigtriangleup T}\n= {R\\bigtriangleup \\emptyset \\bigtriangleup T} = {R \\bigtriangleup T}\n\\end{equation}\\] as needed.\n\n\n\n5.5.3 Composition and Inverse Relations\nIn particular, relations are sets and, so are the image and preimage of a relation. Here are some basic properties of relations on a set regarding image, union, intersection, and compositon.\n\nTheorem 5.32 Let \\(R\\), \\(S\\) and \\(T\\) be relations on \\(X\\). Then the following hold.\n\n\\(R\\circ (S\\circ T)=(R\\circ S)\\circ T\\)\n\\(R\\circ (S\\cup T)=(R\\circ S)\\cup (R\\circ T)\\)\n\\((S\\cup T)\\circ R=(S\\circ R)\\cup (T\\circ R)\\)\n\\(R\\circ (S\\cap T) \\subseteq (R\\circ S)\\cap (R\\circ T)\\)\n\\(R\\subseteq S \\implies R\\circ T \\subseteq S\\circ T\\)\n\\(R\\subseteq S \\implies T\\circ R \\subseteq T\\circ S\\)\n\n\n\nProof. The proof of each part follows.\n\n\\(R\\circ (S\\circ T)=(R\\circ S)\\circ T\\): \\[\\begin{align*}\n(x,y)\\in & R\\circ (S\\circ T) \\\\\n& \\Longleftrightarrow \\exists z\\in X, (x,z)\\in S\\circ T \\land (z,y)\\in R\\\\\n& \\Longleftrightarrow \\exists z\\in X, [ \\exists w\\in X, (x,w)\\in T \\land (w,z)\\in S ] \\land  (z,y)\\in R \\\\\n& \\Longleftrightarrow \\exists w, z\\in X, (x,w)\\in T \\land (w,z)\\in S \\land (z,y)\\in R\\\\\n& \\Longleftrightarrow \\exists w\\in X, [\\exists z\\in X, (w,z)\\in S \\land (z,y)\\in R] \\land (x,w)\\in T\\\\\n& \\Longleftrightarrow \\exists w\\in X, (x,w)\\in T \\land (w,y)\\in R\\circ S \\\\\n& \\Longleftrightarrow (x,y)\\in (R\\circ S) \\circ T\n\\end{align*}\\]\n\\(R\\circ (S\\cup T)=(R\\circ S)\\cup (R\\circ T)\\): \\[\\begin{align*}\n(x,y) & \\in R\\circ (S\\cup T) \\\\\n& \\Longleftrightarrow \\exists z\\in X, (x,z)\\in S \\cup T \\land (z,y)\\in R \\\\\n& \\Longleftrightarrow \\exists z\\in X, [(x,z)\\in S \\lor (x,z)\\in T ]  \\land (z,y)\\in R \\\\\n& \\Longleftrightarrow \\exists z\\in X, [(x,z)\\in S \\land (z,y)\\in R] \\lor [(x,z)\\in T \\land (z,y)\\in R]\\\\\n& \\Longleftrightarrow (x,y)\\in R\\circ S \\lor (x,y)\\in R\\circ T\\\\\n& \\Longleftrightarrow (x,y)\\in (R\\circ S)\\cup (R \\circ T)\n\\end{align*}\\]\n\\((S\\cup T)\\circ R=(S\\circ R)\\cup (T\\circ R)\\): \\[\\begin{align*}\n(x,y) & \\in (S\\cup T)\\circ R \\\\\n& \\Longleftrightarrow \\exists z\\in X, (x,z)\\in R \\land (z,y)\\in S\\cup T\\\\\n& \\Longleftrightarrow \\exists z\\in X, (x,z)\\in R \\land [(z,y)\\in S\\lor (z,y)\\in T] \\\\\n& \\Longleftrightarrow \\exists z\\in X, [(x,z)\\in R \\land (z,y)\\in S] \\lor  [(x,z)\\in R \\land (z,y)\\in T] \\\\\n& \\Longleftrightarrow (x,y)\\in (S\\circ R) \\lor (x,y)\\in (T\\circ R)\\\\\n& \\Longleftrightarrow (x,y)\\in (S\\circ R)\\cup (T\\circ R)\n\\end{align*}\\]\n)\\(R\\circ (S\\cap T) \\subseteq (R\\circ S)\\cap (R\\circ T)\\): \\[\\begin{align*}\n\\qquad \\quad  & (x,y) \\in R\\circ (S\\cap T)  \\\\\n& \\qquad \\Longleftrightarrow \\exists z\\in X, (x,z)\\in S\\cap T \\land (z,y)\\in R \\\\\n& \\qquad \\Longleftrightarrow \\exists z\\in X, [(x,z)\\in S \\land (x,z)\\in T] \\land (z,y)\\in R \\\\\n& \\qquad \\Longleftrightarrow \\exists z\\in X, [(x,z)\\in S \\land (z,y)\\in R] \\land (x,z)\\in T\\\\\n& \\qquad \\Longleftrightarrow \\exists z\\in X, [(x,z)\\in S \\land (z,y)\\in R] \\land [(x,z)\\in T \\land (z,y)\\in R] \\\\\n& \\qquad \\Longrightarrow [\\exists z\\in X, [(x,z)\\in S \\land (z,y)\\in R] \\land [ \\exists w\\in X, (x,w)\\in T \\land (w,y)\\in R]\\\\\n& \\qquad \\Longleftrightarrow (x,y)\\in R\\circ S \\land (x,y)\\in R\\circ T \\\\\n& \\qquad \\Longleftrightarrow (x,y)\\in (R\\circ S) \\cap (R\\circ T)\n\\end{align*}\\]\n\\(R\\subseteq S \\implies R\\circ T \\subseteq S\\circ T\\): \\[\\begin{align*}\n& (x,y)\\in R\\circ T \\Longleftrightarrow \\exists z\\in X, (x,z)\\in T \\land (z,y)\\in R \\\\\n& \\qquad \\Longrightarrow \\exists z\\in X, (x,z)\\in T \\land (z,y)\\in S \\Longleftrightarrow (x,y)\\in S\\circ T\n\\end{align*}\\]\n\\(R\\subseteq S \\implies T\\circ R \\subseteq T\\circ S\\): \\[\\begin{align*}\n& (x,y)\\in T\\circ R \\Longleftrightarrow \\exists z\\in X, (x,z)\\in R \\land (z,y)\\in T \\\\\n& \\qquad \\Longrightarrow \\exists z\\in X, (x,z)\\in S \\land (z,y)\\in T \\Longleftrightarrow (x,y)\\in T\\circ S\n\\end{align*}\\] The proof is now complete.\n\n\nHere are some basic properties of relations on a set regarding preimage, union, intersection, set difference, and compositon.\n\nTheorem 5.33 Let \\(R\\) and \\(S\\) be relations on \\(X\\). Then the following hold.\n\n\\((R^{-1})^{-1}=R\\)\n\\((R\\cup S)^{-1}=R^{-1}\\cup S^{-1}\\)\n\\((R\\cap S)^{-1}=R^{-1}\\cap S^{-1}\\)\n\\((R\\circ S)^{-1}=S^{-1}\\circ R^{-1}\\)\n\\(R\\subseteq S \\implies R^{-1}\\subseteq S^{-1}\\).\n\\((R^c)^{-1}=(R^{-1})^c\\)\n\\((R\\setminus S)^{-1}=R^{-1}\\setminus S^{-1}\\)\n\n\n\nProof. The proof of each part follows.\n\n\\((R^{-1})^{-1}=R\\): \\[\n(x,y)\\in (R^{-1})^{-1} \\Longleftrightarrow (y,x)\\in R^{-1} \\Longleftrightarrow (x,y)\\in R\n\\]\n\\((R\\cup S)^{-1}=R^{-1}\\cup S^{-1}\\): \\[\\begin{align*}\n& (x,y)\\in (R\\cup S)^{-1}  \\Longleftrightarrow (y,x)\\in R\\cup S \\Longleftrightarrow (y,x)\\in R \\lor (y,x)\\in S \\\\\n& \\qquad \\Longleftrightarrow (x,y)\\in R^{-1} \\lor (x,y)\\in S^{-1} \\Longleftrightarrow (x,y)\\in R^{-1}\\cup S^{-1}\n\\end{align*}\\]\n\\((R\\cap S)^{-1}=R^{-1}\\cap S^{-1}\\): \\[\\begin{align*}\n& (x,y)\\in (R\\cap S)^{-1}  \\Longleftrightarrow (y,x)\\in R\\cap S \\Longleftrightarrow (y,x)\\in R \\land (y,x)\\in S\\\\\n&  \\qquad \\Longleftrightarrow (x,y)\\in R^{-1} \\land (x,y)\\in S^{-1} \\Longleftrightarrow (x,y)\\in R^{-1}\\cap S^{-1}\n\\end{align*}\\]\n\\((R\\circ S)^{-1}=S^{-1}\\circ R^{-1}\\): \\[\\begin{align*}\n& (x,y)\\in (R\\circ S)^{-1} \\Longleftrightarrow (y,x)\\in R\\circ S\\\\\n& \\qquad \\Longleftrightarrow \\exists z\\in X, (y,z)\\in S \\land (z,x)\\in R\\\\\n&  \\qquad \\Longleftrightarrow \\exists z\\in X, (z,y)\\in S^{-1} \\land (x,z)\\in R^{-1}\\\\\n& \\qquad \\Longleftrightarrow \\exists z\\in X, (x,z)\\in R^{-1} \\land (z,y)\\in S^{-1} \\\\\n&  \\qquad \\Longleftrightarrow (x,y)\\in S^{-1} \\circ R^{-1}\n\\end{align*}\\]\nIf \\(R\\subseteq S\\), then \\(R^{-1}\\subseteq S^{-1}\\): \\[\\begin{align*}\n(x,y)\\in & R^{-1} \\Longleftrightarrow (y,x)\\in R \\Longrightarrow (y,x)\\in S \\Longleftrightarrow (x,y) \\in S^{-1}\n\\end{align*}\\]\n\\((R^c)^{-1}=(R^{-1})^c\\): \\[\\begin{align*}\n& (x,y)\\in (R^c)^{-1} \\Longleftrightarrow (y,x)\\in R^c \\Longleftrightarrow (y,x)\\in X\\times X \\land (y,x)\\notin R\\\\\n& \\qquad \\Longleftrightarrow (x,y)\\in X\\times X \\land (x,y)\\notin R^{-1} \\Longleftrightarrow (x,y)\\in (R^{-1})^c\n\\end{align*}\\]\n\\((R\\setminus S)^{-1}=R^{-1}\\setminus S^{-1}\\) \\[\\begin{align*}\n& (x,y)\\in (R\\setminus S)^{-1} \\Longleftrightarrow (y,x)\\in R\\setminus S \\Longleftrightarrow (y,x)\\in R \\land (y,x)\\notin S\\\\\n& \\qquad \\Longleftrightarrow (x,y)\\in R^{-1} \\land (y,x)\\notin S \\Longleftrightarrow (x,y)\\in R^{-1} \\land (x,y)\\notin S^{-1} \\\\\n& \\qquad \\Longleftrightarrow (x,y)\\in R^{-1}\\setminus S^{-1}\n\\end{align*}\\]\n\n\nIn the next two theorems we have basic properties involving the image, union, intersection, and set difference. And exactly when two relations are equal.\n\nTheorem 5.34 Let \\(R\\) and \\(S\\) be a relations on \\(X\\) and \\(A, B\\subseteq X\\). Then the following hold.\n\n\\(A\\subseteq B \\implies R(A)\\subseteq R(B)\\)\n\\(R(A\\cup B)=R(A)\\cup R(B)\\)\n\\(R(A\\cap B)\\subseteq R(A)\\cap R(B)\\)\n\\(R(A)\\setminus R(B)\\subseteq R(A\\setminus B)\\)\nIf \\(R(x)=S(x)\\) for all \\(x\\in X\\), then \\(R=S\\).\n\n\n\nProof. The proof of each part follows.\n\nIf \\(A\\subseteq B\\), then \\(R(A)\\subseteq R(B)\\): \\[\\begin{align*}\n\\qquad y\\in R(A) \\Longleftrightarrow \\exists x\\in A, (x,y)\\in R \\implies \\exists x\\in B, (x,y)\\in R \\Longleftrightarrow y\\in R(B)\n\\end{align*}\\]\n\\(R(A\\cup B)=R(A)\\cup R(B)\\): \\[\\begin{align*}\n\\qquad & y\\in R(A\\cup B) \\Longleftrightarrow \\exists x\\in X, x\\in A\\cup B \\land (x,y)\\in R  \\\\\n& \\qquad \\Longleftrightarrow  \\exists x\\in X, (x\\in A \\lor x\\in B) \\land (x,y)\\in R \\\\\n& \\qquad \\Longleftrightarrow  \\exists x\\in A, (x,y)\\in R \\lor \\exists x\\in B, (x,y)\\in R \\Longleftrightarrow  y\\in R(A) \\cup R(B)\n\\end{align*}\\]\n\\(R(A\\cap B)\\subseteq R(A)\\cap R(B)\\): \\[\\begin{align*}\n\\qquad & y\\in R(A\\cap B) \\Longleftrightarrow \\exists x\\in X, x\\in A\\cap B \\land (x,y)\\in R \\\\\n& \\qquad \\Longleftrightarrow  \\exists x\\in X, (x\\in A \\land x\\in B) \\land (x,y)\\in R \\\\\n& \\qquad \\Longrightarrow  \\exists x\\in A, (x,y)\\in R \\land \\exists x\\in B, (x,y)\\in R \\Longleftrightarrow  y\\in R(A) \\cap R(B)\n\\end{align*}\\]\n\\(R(A)\\setminus R(B)\\subseteq R(A\\setminus B)\\): \\[\\begin{align*}\ny\\in R(A)\\setminus R(B) & \\Longleftrightarrow y\\in R(A)\\land y\\not\\in R(B) \\\\\n& \\Longleftrightarrow \\exists x\\in A, (x,y)\\in R \\land \\forall z\\in B, (z,y)\\not\\in R \\\\\n& \\Longleftrightarrow \\exists x\\in A\\setminus B, (x,y)\\in R \\Longleftrightarrow y\\in R(A\\setminus B)\n\\end{align*}\\]\nAssume \\(R(x)=S(x)\\) for all \\(x\\in X\\), then \\[\n(x,y)\\in R \\Longleftrightarrow y\\in R(x)  \\Longleftrightarrow y\\in S(x)  \\Longleftrightarrow (x,y)\\in S\n\\] which completes the proof.\n\n\nWhy is there not a part (5) to the next theorem? Can you state and prove a part (5)? If not, can you provide a counterexample?\n\nTheorem 5.35 Let \\(R\\) be a relation on \\(X\\) with \\(A, B\\subseteq X\\). Then the following hold.\n\n\\(A\\subseteq B \\implies R^{-1}(A)\\subseteq R^{1-}(B)\\)\n\\(R^{-1}(A\\cup B)=R^{-1}(A)\\cup R^{-1}(B)\\)\n\\(R^{-1}(A\\cap B)\\subseteq R^{-1}(A)\\cap R^{-1}(B)\\)\n\\(R^{-1}(A)\\setminus R^{-1}(B)\\subseteq R^{-1}(A\\setminus B)\\)\n\n\n\nProof. The proof of each part follows.\n\n\\(A\\subseteq B \\implies R^{-1}(A)\\subseteq R^{-1}(B)\\): \\[\\begin{align*}\nx\\in R^{-1}(A) & \\Longleftrightarrow \\exists y\\in A, (x,y)\\in R \\\\\n& \\implies \\exists y\\in B, (x,y)\\in R  \\Longleftrightarrow x\\in R^{-1}(B)\n\\end{align*}\\]\n\\(R^{-1}(A\\cup B)=R^{-1}(A)\\cup R^{-1}(B)\\): \\[\\begin{align*}\n& x\\in R^{-1}(A\\cup B)  \\Longleftrightarrow \\exists y \\in A\\cup B, (x,y)\\in R \\\\\n& \\qquad \\Longleftrightarrow \\exists y\\in A, (x,y)\\in R \\lor \\exists y\\in B, (x,y)\\in R \\\\\n& \\qquad  \\Longleftrightarrow x\\in R^{-1}(A)\\lor R^{-1}(B) \\Longleftrightarrow x\\in R^{-1}(A)\\cup R^{-1}(B)\n\\end{align*}\\]\n\\(R^{-1}(A\\cap B)\\subseteq R^{-1}(A)\\cap R^{-1}(B)\\): \\[\\begin{align*}\n& x\\in R^{-1}(A\\cap B) \\Longleftrightarrow \\exists y\\in A \\cap B, (x,y)\\in R \\\\\n& \\qquad \\Longleftrightarrow \\exists y\\in X, y\\in A \\land y\\in B \\land (x,y)\\in R \\\\\n& \\qquad \\Longrightarrow  x\\in R^{-1}(A) \\land x\\in R^{-1}(B) \\Longleftrightarrow x\\in R^{-1}(A) \\cap x\\in R^{-1}(B)\n\\end{align*}\\]\n\\(R^{-1}(A)\\setminus R^{-1}(B)\\subseteq R^{-1}(A\\setminus B)\\): \\[\\begin{align*}\n& x\\in R^{-1}(A)\\setminus R^{-1}(B) \\Longleftrightarrow  x\\in R^{-1}(A) \\land \\neg(x\\in R^{-1}(B)) \\\\\n& \\qquad \\Longleftrightarrow  x\\in R^{-1}(A)\\land [\\forall y\\in B, (x,y)\\not\\in R] \\\\\n& \\qquad \\Longleftrightarrow  \\exists y\\in A, (x,y)\\in R \\land [\\forall y\\in B, (x,y)\\not\\in R] \\\\\n& \\qquad \\Longrightarrow \\exists y\\in A\\setminus B, (x,y)\\in R \\Longleftrightarrow x\\in R^{-1}(A\\setminus B)\n\\end{align*}\\]\n\n\n\n\n5.5.4 Families of Relations\nIn the next theorem we have a family of relations and we see how they interact with composition.\n\nTheorem 5.36 Let \\(R\\) and \\(R_i\\) be relations on \\(X\\) for \\(i\\in I\\) where \\(I\\) is an indexed set. Then the following hold.\n\n\\(R\\circ \\left(\\bigcup_{i\\in I} R_i\\right)=\\bigcup_{i\\in I}(R\\circ R_i)\\)\n\\(\\left(\\bigcup_{i\\in I} R_i\\right)\\circ R=\\bigcup_{i\\in I}(R_i\\circ R)\\)\n\n\n\nProof. The proof of each part follows.\n\n\\(R\\circ \\left(\\bigcup_{i\\in I} R_i\\right)=\\bigcup_{i\\in I}(R\\circ R_i)\\) \\[\\begin{align*}\n(x,y)\\in R\\circ \\left(\\bigcup_{i\\in I} R_i\\right) & \\Longleftrightarrow \\exists z\\in X, (x,z)\\in \\bigcup_{i\\in I} R_i \\land (z,y)\\in R \\\\\n& \\Longleftrightarrow \\exists z\\in X, \\exists i\\in I, (x,z)\\in R_i \\land (z,y)\\in R \\\\\n& \\Longleftrightarrow \\exists i\\in I, (x,y)\\in R\\circ R_i  \\\\\n& \\Longleftrightarrow (x,y) \\in \\bigcup_{i\\in I}(R\\circ R_i)\n\\end{align*}\\]\n\\(\\left(\\bigcup_{i\\in I} R_i\\right)\\circ R=\\bigcup_{i\\in I}(R_i\\circ R)\\): \\[\\begin{align*}\n(x,y)\\in \\left(\\bigcup_{i\\in I} R_i\\right)\\circ R\n& \\Longleftrightarrow \\exists z\\in X, (x,z)\\in R \\land (z,y)\\in \\bigcup_{i\\in I} R_i \\\\\n& \\Longleftrightarrow \\exists z\\in X, \\exists i\\in I, (x,z)\\in R \\land (z,y)\\in R_i \\\\\n& \\Longleftrightarrow (x,y)\\in \\bigcup_{i\\in I}(R_i\\circ R)\n\\end{align*}\\]\n\n\n\n\n5.5.5 The Powers of a Relation\nIn the next theorem we see how powers of a relation interacts with preimage and unions.\n\nTheorem 5.37 Let \\(R\\) be a relation on \\(X\\). Then the following hold.\n\n\\((R^n)^{-1}=(R^{-1})^n\\) for all \\(n\\geq 1\\)\n\\(R^n \\cup S^n\\subseteq (R\\cup S)^n\\) for all \\(n\\geq 1\\)\n\\(\\left( \\bigcup_{n\\geq 1} R^n \\right)^{-1} = \\bigcup_{n\\geq 1} (R^{-1})^{n}\\)\n\n\n\nProof. The proof of each part follows.\n\nBy induction. The basis step is obvious: \\((R^{1})^{-1}=(R^{-1})^1\\). In fact, \\[\n(R^2)^{-1} = (R\\circ R)^{-1} = R^{-1}\\circ R^{-1} = (R^{-1})^2.\n\\] The induction step is \\[\n(R^n)^{-1}=(R^{-1})^n\\implies (R^{n+1})^{-1}=(R^{-1})^{n+1}.\n\\] The result now follows from the argument: \\[\\begin{align*}\n(x,y)\\in (R^{n+1})^{-1}\n& \\Longleftrightarrow (y,x)\\in R^{n+1} \\\\\n& \\Longleftrightarrow \\exists z\\in X, (y,z)\\in R \\land (z,x)\\in R^n \\\\\n& \\Longleftrightarrow \\exists z\\in X, (z,y)\\in R^{-1} \\land (x,z)\\in (R^n)^{-1}\\\\\n& \\Longleftrightarrow \\exists z\\in X, (x,z)\\in (R^n)^{-1} \\land (z,y)\\in R^{-1}\\\\\n& \\Longleftrightarrow \\exists z\\in X, (x,z)\\in (R^{-1})^n \\land (z,y)\\in R^{-1} \\\\\n& \\Longleftrightarrow (x,y)\\in (R^{-1})^{n+1}\n\\end{align*}\\]\n\\(\\left( \\bigcup_{n\\geq 1} R^n \\right)^{-1} = \\bigcup_{n\\geq 1} (R^{-1})^{n}\\) \\[\\begin{align*}\n(x,y)\\in & \\left( \\bigcup_{n\\geq 1} R^n \\right)^{-1}\n\\Longleftrightarrow (y,x)\\in \\bigcup_{n\\geq 1} R^n \\\\\n& \\Longleftrightarrow \\exists n\\geq 1, (y,x)\\in R^n =R^{n-1}\\circ R \\\\\n& \\Longleftrightarrow \\exists n\\geq 1, \\exists z\\in X, (y,z)\\in R \\land (z,x)\\in R^{n-1} \\\\\n& \\Longleftrightarrow \\exists n\\geq 1, \\exists z\\in X, (z,y)\\in R^{-1} \\land (x,z)\\in (R^{n-1})^{-1}\\\\\n& \\Longleftrightarrow \\exists n\\geq 1, \\exists z\\in X, (x,z)\\in (R^{n-1})^{-1} \\land (z,y)\\in R^{-1}  \\\\\n& \\Longleftrightarrow \\exists n\\geq 1, \\exists z\\in X, (x,z)\\in (R^{-1})^{n-1} \\land (z,y)\\in R^{-1} \\\\\n& \\Longleftrightarrow \\exists n\\geq 1, (x,y)\\in (R^{-1})^n \\Longleftrightarrow (x,y)\\in \\bigcup_{n\\geq 1}(R^{-1})^n\n\\end{align*}\\]\n\\(R^n \\cup S^n\\subseteq (R\\cup S)^n\\) for all \\(n\\geq 1.\\) The basis step is obvious. The induction step is: \\[\nR^n \\cup S^n\\subseteq (R\\cup S)^n \\implies R^{n+1} \\cup S^{n+1}\\subseteq (R\\cup S)^{n+1}\n\\] The result holds by \\[\\begin{align*}\n(R\\cup S)^{n+1} & =(R\\cup S)^n\\circ (R\\cup S)  \\\\\n& \\supseteq (R^n\\cup S^n) \\circ (R \\cup S) \\\\\n& = [(R^n\\cup S^n)\\circ R] \\cup (R^n\\cup S^n) \\circ S \\\\\n& = R^{n+1} \\cup (S^n \\circ R) \\cup (R^n\\circ S) \\cup S^{n+1}  \\\\\n& \\supseteq R^{n+1}\\cup S^{n+1}.\n\\end{align*}\\]\n\n\nThe next theorem will be very useful when we discuss transtive relations.\n\nTheorem 5.38 Let \\(R\\) be a relation on \\(X\\). Then \\((x,y)\\in R^n\\) if and only if there exists \\(x_1, x_2, x_3, \\ldots, x_{n-1}\\in X\\) such that \\((x,x_1)\\in R, (x_1,x_2)\\in R , ...., (x_{n-1},y)\\in R\\).\n\n\nProof. Bases case, \\(i=1\\) is obvious. We assume the claim is true for \\(j\\). Then \\[\\begin{align*}\n& (x,y)\\in R^{j+1} \\Longleftrightarrow (x,y)\\in R^j\\circ R \\\\\n& \\Longleftrightarrow \\exists x_1\\in X, (x,x_1)\\in R \\land (x_1,y)\\in R^j \\\\\n& \\Longleftrightarrow \\exists x_1\\in X, (x,x_1)\\in R \\land \\exists x_2, ..., x_{j-1}\\in X, (x_2, x_3), ..., (x_{j-1},y)\\in R \\\\\n& \\Longleftrightarrow  \\exists x_1\\in X, x_2, ..., x_{j-1}\\in X, (x,x_1), (x_2, x_3), ..., (x_{j-1},y)\\in R\n\\end{align*}\\] as needed to complete induction."
  },
  {
    "objectID": "functions-and-relations.html#exercises",
    "href": "functions-and-relations.html#exercises",
    "title": "5  Functions and Relations",
    "section": "5.6 Exercises",
    "text": "5.6 Exercises\n\nExercise 5.1 Finish proving Theorem 5.29."
  },
  {
    "objectID": "well-founded-confluence.html#well-founded-relations",
    "href": "well-founded-confluence.html#well-founded-relations",
    "title": "6  Well-founded Confluence",
    "section": "6.1 Well-Founded Relations",
    "text": "6.1 Well-Founded Relations\n\nDefinition 6.1 Let \\(X\\) be a set.\n\nA relation \\(R\\) on \\(X\\) is called irreflexive if it satisfies the property \\[\\forall a\\in X, (a,a)\\notin R.\\]\nA relation \\(R\\) on \\(X\\) is called asymmetric if it satisfies the property \\[\\forall a,b\\in X, (a,b)\\in R \\implies (b,a)\\notin R.\\]\nA relation \\(R\\) on \\(X\\) is called antisymmetric if it satisfies the property \\[\n\\forall a,b\\in X, (a,b)\\in R \\land (b,a)\\in R\\implies a=b.\\]\n\n\nA \\(\\longrightarrow\\)-minimal element need not be smaller than the other elements of \\(X.\\) For example, singleton sets of \\(X\\) all have \\(\\longrightarrow\\)-minimal elements, namely \\(a\\) is a \\(\\longrightarrow\\)-minimal element of \\(\\{a\\}\\subseteq X\\) since there does not exist \\(b\\in\\{a\\}\\) such that \\(a\\longrightarrow b\\) whenever \\(\\longrightarrow\\) is irreflexive.\n\nLemma 6.1 If \\(\\longrightarrow\\) is a well-founded relation on \\(X,\\) then \\(\\longrightarrow\\) is irreflexive and antisymmetric; and hence also asymmetric.\n\n\nProof. Assume \\(\\longrightarrow\\) is a well-founded relation on \\(X.\\) If \\(a\\longrightarrow a,\\) then \\(A=\\{a\\}\\neq\\emptyset\\) does not have an \\(\\longrightarrow\\)-minimal element, country to hypothesis. If \\(a\\longrightarrow b\\) and \\(b\\longrightarrow a,\\) then \\(X=\\{a,b\\}\\neq\\emptyset\\) does not have a \\(\\longrightarrow\\)-minimal element, contrary to hypothesis. Thus, if \\(\\longrightarrow\\) is well-founded and \\(a\\longrightarrow b,\\) then \\(b\\longrightarrow a\\) can not hold and so \\(\\longrightarrow\\) is asymmetric. A relation is asymmetric if and only if it is both antisymmetric and irreflexive.\n\n\nLemma 6.2 If \\(\\longrightarrow\\) is a well-founded relation on \\(X\\) and \\(\\longrightarrow'\\) is a subrelation of \\(\\longrightarrow,\\) then \\(\\longrightarrow'\\) is well-founded on \\(X.\\)\n\n\nProof. Assume \\(\\longrightarrow\\) is well-founded on \\(X\\) and let \\(\\longrightarrow'\\) be a subrelation of \\(\\longrightarrow.\\) Let \\(A\\neq\\emptyset\\) be a subset of \\(X.\\) Suppose \\(A\\) does not have a \\(\\longrightarrow'\\)-minimal element. Thus for all \\(a\\in A\\) there exists \\(b\\in A\\) that \\(a\\longrightarrow' b\\) holds. Since \\(\\longrightarrow'\\) is a subrelation of \\(\\longrightarrow,\\) it follows that for all \\(a\\in A\\) there exists \\(b\\in A\\) such that \\(a\\longrightarrow b.\\) Thus \\(A\\) does not have a \\(\\longrightarrow\\)-minimal element, contrary to hypothesis.\n\n\nDefinition 6.2 Let \\(\\longrightarrow\\) be a relation on \\(X.\\)\n\nIf \\(A\\subseteq X\\) and \\(a\\in A,\\) then \\(a\\) is called a \\(\\longrightarrow\\)- minimal element of \\(A\\) if there does not exist \\(b\\in A\\) such that \\(a\\longrightarrow b.\\)\nIf each nonempty subset of \\(X\\) has a \\(\\longrightarrow\\)-minimal element, then \\(\\longrightarrow\\) is called a well-founded relation on \\(X.\\)\nIf \\(x\\in X,\\) then the set \\[\\overrightarrow{x\\,}=\\{y\\in X : x\\longrightarrow y \\land x\\neq y\\}\\] is called the initial segment of \\(x.\\)\n\n\nClearly, \\(b\\) is a \\(\\longrightarrow\\)-minimal element of \\(A\\) if and only if \\(\\overrightarrow{b\\,}\\cap A=\\emptyset.\\)\n\n6.1.1 Well-Founded Induction\n\nLemma 6.3 A relation \\(\\longrightarrow\\) on \\(X\\) is well-founded if and only if the principle of \\(\\longrightarrow\\)-induction holds: \\[\n\\forall \\, A\\subseteq X,\n\\forall x\\in X, (\\overrightarrow{x\\,}\\subseteq A \\implies x\\in A)\n\\implies  A=X.\n\\]\n\n\nProof. Assume \\(\\longrightarrow\\) is well-founded on \\(X.\\) Let \\(A\\subseteq X\\) and assume the following holds \\[\\begin{equation}\n\\label{wellfind}\n\\forall x\\in X, \\overrightarrow{x\\,}\\subseteq A \\implies x\\in A\n\\end{equation}\\] Assume for a contradiction that \\(X\\setminus A\\) is nonempty with \\(\\longrightarrow\\)-minimial element \\(b.\\) Thus \\(\\overrightarrow{b\\,}\\cap X\\setminus A=\\emptyset\\) and so it follows \\(\\overrightarrow{b\\,}\\subseteq A.\\) By \\(\\eqref{wellfind}\\) we have \\(b\\in A\\) and thus \\(X\\setminus A\\) is empty. Hence \\(A=X.\\)\nConversely, assume the principle of induction holds and suppose \\(A\\) is a nonempty subset of \\(X\\) with no \\(\\longrightarrow\\)-minimal element. We will apply the principle of \\(\\longrightarrow\\) induction to the set \\(X\\setminus A.\\) Let \\(x\\in X\\) and assume \\(\\overrightarrow{x\\,}\\subseteq X\\setminus A.\\) Suppose \\(x\\in A.\\) Since \\(\\overrightarrow{x\\,}\\cap A=\\emptyset\\) it follows \\(x\\) is a \\(\\longrightarrow\\)-minimal element of \\(A\\) contrary to hypothesis. Thus, it follows \\(x\\not\\in A\\) and so \\(x\\in X\\setminus A.\\) We have shown \\[\n\\forall x\\in X, \\overrightarrow{x\\,}\\subseteq X\\setminus A \\implies x\\in X\\setminus A\n\\] By the principle of \\(\\longrightarrow\\)-induction it follows \\(X\\setminus A=X.\\) Therefore, \\(A\\) is empty as desired.\n\n\n\n6.1.2 Well-Founded Recursion\n\nDefinition 6.3 Let \\(Y\\) be a set and let \\(h:X\\times P(Y)\\to Y\\) be a function. We call a function \\(f:X\\to Y\\) a \\(\\longrightarrow\\)- recursively defined function if \\[\\begin{equation}\nf(x)=h(x,f(\\overrightarrow{x\\,}))\n\\end{equation}\\] for all \\(x\\in X.\\)\n\n\nLemma 6.4 (Well-Founded Recursion) Let \\(\\longrightarrow\\) be a relation on \\(X.\\) Then the following are equivalent. 1. \\(\\longrightarrow\\) is well founded on \\(X\\) 2. for every set \\(Y,\\) there exists \\(\\longrightarrow\\)-recursively defined functions from \\(X\\) to \\(Y\\) 3. \\(\\longrightarrow\\)-recursively defined functions on \\(X\\) are unique\n\n\nProof. This proof is not completely rigorous not finished.\n\\((1)\\Leftrightarrow(2)\\): Assume \\(\\longrightarrow\\) is well-founded on \\(X.\\) Let \\(Y\\) be a set and let \\(h:X\\times P(Y)\\to Y.\\) Consider functions \\(g\\) defined on subsets of \\(X\\) with values in \\(Y.\\) We say \\(R(g)\\) holds if both conditions are satisfied:\n\nfor all \\(x\\in D(g),\\) \\(\\overrightarrow{x\\,} \\subseteq D(g)\\)\nfor all \\(x\\in D(g),\\) \\(g(x)=h(x,g(\\overrightarrow{x\\,}))\\)\n\nClaim: If \\(R(g_1)\\) and \\(R(g_2)\\) hold, then \\(x\\in D(g_1)\\cap D(g_2)\\) implies \\(g_1(x)=g_2(x).\\) The proof of this claim follows by \\(\\longrightarrow\\)-induction.\nClaim: Let \\(f=\\cup \\{g : R(g) \\text{ holds}\\}.\\) Clearly \\(f\\) is a relation with domain included in \\(X.\\) We claim \\(f\\) is a function. To prove this we have to show that if \\(g_1,g_2\\in \\{g : R(g) \\text{ holds}\\}\\) and \\(x\\in D(g_1)\\cap D(g_2),\\) then \\(g_1(x)=g_2(x).\\) Now \\(Z=D(g_1)\\cap D(g_2)\\) is an initial segment of \\(\\longrightarrow\\) and \\(\\longrightarrow'=\\longrightarrow\\cap(Z\\times Z)\\) is well-founded on \\(Z.\\) It follows by induction on \\(\\longrightarrow'\\) that if \\(x\\in Z,\\) then \\(g_1(x)=g_2(x).\\)\nClaim: \\(f\\) is maximal such that \\(R(f)\\) holds. Next we claim that \\[\\begin{equation}\n\\label{fmaxp}\nx\\in D(f) \\implies f(x)=g(x,f(\\overrightarrow{x\\,})).\n\\end{equation}\\] To prove \\(\\eqref{fmaxp}\\) assume \\(x\\in D(f).\\) Then \\(x\\in D(g)\\) for some \\(g\\) such that \\(R(g)\\) holds. It follows that \\[\nf(x)=g(x)=h(x,\\{g(\\overrightarrow{x\\,}))=h(x,\\{f(\\overrightarrow{x\\,})\\}).\n\\]\nClaim: \\(D(f)=X.\\) The proof of this claim follows by \\(\\longrightarrow\\)-induction. Let \\(x\\) be such that \\(\\overrightarrow{x\\,}\\subseteq D(f).\\) Since \\(D(f)\\) is an initial segment of \\(\\longrightarrow,\\) so is \\(D(f)\\cup \\{x\\}.\\) Let \\[\nf'=f\\cup \\{x,g(x,f(\\overrightarrow{x\\,}))\\}.\n\\] Then \\(R(f')\\) holds and hence \\(x\\in D(f).\\)\nConversely, we assume the principle of definition of recursion to hold. We define a rank function \\[\n\\mathop{rk}(x)=\\mathop{sup}_{x\\longrightarrow y} \\mathop{rk}(y).\n\\] It then follows that \\(\\longrightarrow\\) is well-founded since \\[\nx\\longrightarrow y \\Leftrightarrow \\mathop{rk} (y)\\in \\mathop{rk}(x).\n\\] Alternatively, we can simplify the proof by assuming \\(\\longrightarrow\\) is transitive. Suppose \\(A\\) is a subset of \\(X\\) that has no minimal element, and define (by recursion applied to the characteristic function of \\(M\\)): \\[\n\\textrm{\n$x$ belongs to $M$ if and only if for every $x\\longrightarrow y,$ if $y$ is in $A$ then $y$ is not in $M.$\n}\n\\] Then for \\(x\\) in \\(A,\\) if \\(x\\) is in \\(M\\) there is a \\(x\\longrightarrow y\\) in \\(A\\) (since \\(A\\) has no minimal element) which is not in \\(M.\\) But then there is a \\(y\\longrightarrow z\\) in \\(A\\) which is in \\(M,\\) and since \\(x\\longrightarrow z\\) we have a contradiction. So no \\(x\\) in \\(A\\) is in \\(M.\\) But then every \\(x\\) in \\(A\\) is in \\(M,\\) so \\(A\\) must be empty. We thus see that given the defining property of \\(M,\\) the assumption that \\(A\\) has no minimal element, and the transitivity of \\(\\longrightarrow,\\) logical manipulation allows us to conclude that \\(A\\) is empty.\n\\((1)\\Leftrightarrow(3)\\): Assume \\(\\longrightarrow\\) is well-founded on \\(X.\\) We say that \\(\\phi:Z\\to Y\\) is an attempt if \\(Z\\) is an initial segment of \\(X,\\) and \\[\n\\phi(x)=g(x,\\{\\phi(z):x \\longrightarrow z\\}) \\quad \\text{for all $x\\in Z.$}\n\\] If \\(\\phi_1:Z_1\\to Y\\) and \\(\\phi_2: Z_2\\to Y\\) are two attempts, they agree on \\(Z_1\\cap Z_2\\) namely \\(\\phi_1|_{Z_1 \\cap Z_2}=\\phi_2|_{Z_1 \\cap Z_2}.\\) Because \\(X_1\\cap X_2\\) is clearly an initial segment of \\(X\\) and if as attempts that do not agree there is some \\(x_0\\) which is \\(\\longrightarrow\\)-minimal in \\(\\{x\\in Z_1 \\cap Z_2 : \\phi_1(x)\\neq \\phi_2(x)\\}.\\) But in that case we have \\[\n\\phi_1(x_0)\n=g(x_0,\\{\\phi_0(x) : x_0\\longrightarrow x\\})\n=g(x_0, \\{\\phi_1(x) | x_0\\longrightarrow x\\})\n\\] a contradiction.\nConversely, we will show uniqueness implies well-foundedness. Assume \\(X\\) is nontrivial by having two elements, say \\(a_0\\) and \\(a_1.\\)\n\n\n\n6.1.3 Chains\nThe next proposition asserts that every relation \\(\\longrightarrow\\) on \\(X\\) is well-founded if and only if every \\(\\longrightarrow\\)-chain in \\(X\\) is finite.\n\nLemma 6.5 Let \\(\\longrightarrow\\) be a relation on \\(X.\\) Then \\(\\longrightarrow\\) is well-founded if and only there are no infinitely descending \\(\\longrightarrow\\)-chains.\n\n\nProof. Assume there exists an infinite descending \\(\\longrightarrow\\)-chain \\(B.\\) Then \\(B\\subseteq A\\) has no \\(\\longrightarrow\\)-minimal element and thus \\(\\longrightarrow\\) is not well-founded. The result follows by contrapositive.\nConversely, assume for a contradiction that \\(B\\) is a nonempty subset of \\(X\\) with no \\(\\longrightarrow\\)-minimal element. Then the set \\(A_a=\\{b\\in B : b \\longrightarrow a\\}\\) is nonempty for each \\(a\\in B,\\) for otherwise \\(a\\) would be an \\(\\longrightarrow\\)-minimal element of \\(B.\\) The principle of choice, applied to the family \\(\\{A_a\\}_{a\\in B},\\) provides a function \\[\nf: B\\longrightarrow \\bigcup_{a\\in B} A_a\\subseteq B \\text{ with } f(a) \\longrightarrow a,  \\text{ for all } a\\in B.\n\\] Since \\(B\\) is nonempty, fix \\(a_0\\in B.\\) Define the sequence \\(\\{a_n\\}_{n\\in \\mathbb{N}}\\) recursively by \\(a_{n+1}=f(a_n)\\) and notice this sequence forms a strictly descending \\(\\longrightarrow\\)-chain. This contradicts the assumption that there are no strictly descending \\(\\longrightarrow\\)-chains in \\(X.\\) Thus every nonempty subset of \\(B\\) must have a \\(\\longrightarrow\\)-minimal element.\n\n::: {#lem-well-founded-relation-unique function } Let \\(X\\) and \\(Y\\) be sets. Let \\(\\longrightarrow\\) be a well-founded relation on \\(X,\\) and let \\(g:X\\times P(Y)\\to Y\\) be a function. Then there exists a unique function \\(f:X\\to Y\\) such that \\[\nf(x)=g(x,\\{f(z): x\\longrightarrow z\\})\n\\] for all \\(x\\in X.\\) :::\n\nProof. We say that \\(\\phi:Z\\to Y\\) is an attempt if \\(Z\\) is an initial segment of \\(X,\\) and \\[\n\\phi(x)=g(x,\\{\\phi(z):x \\longrightarrow z\\}) \\quad \\text{for all $x\\in Z.$}\n\\] If \\(\\phi_1:Z_1\\to Y\\) and \\(\\phi_2: Z_2\\to Y\\) are two attempts, they agree on \\(Z_1\\cap Z_2\\) namely \\(\\phi_1|_{Z_1 \\cap Z_2}=\\phi_2|_{Z_1 \\cap Z_2}.\\) Because \\(X_1\\cap X_2\\) is clearly an initial segment of \\(X\\) and if as attempts that do not agree there is some \\(x_0\\) which is \\(\\longrightarrow\\)-minimal in \\(\\{x\\in Z_1 \\cap Z_2 : \\phi_1(x)\\neq \\phi_2(x)\\}.\\) But in that case we have \\[\n\\phi_1(x_0)\n=g(x_0,\\{\\phi_0(x) : x_0\\longrightarrow x\\})\n=g(x_0, \\{\\phi_1(x) | x_0\\longrightarrow x\\})\n\\] a contradiction.\nNow let \\(f=\\cup \\{\\phi : \\phi \\text{ is an attempt}\\},\\) so \\(f(x)=\\phi(x)\\) if there is an attempt \\(\\phi\\) with \\(x\\in D(\\phi).\\) It is clear that \\(D(f)=\\cup \\{D(\\phi) : \\phi \\text{ is an attempt} \\}\\) is an initial segment of \\(X,\\) and that \\(f\\) satisfies \\(f(x)=g(x,f(z)|x \\longrightarrow z)\\}\\) for all \\(x\\in D(f).\\) So all that remains to be shown is that \\(D(f)=X.\\)\nBut if \\(D(f)\\neq X\\) there is some \\(x_0\\) that is \\(\\longrightarrow\\) minimal in \\(\\{x\\in X : x\\not\\in D(f)\\}.\\) For such an \\(x\\) define \\(\\overline{f}:D(f)\\cup \\{x_0\\}\\to Y\\) by \\[\n\\overline{f}(x)=\n\\begin{cases}\nf(x) & \\text{ if } x\\in D(f) \\\\\ng(x_0,\\{f(x) : x_0 \\longrightarrow x\\}) & \\text{ if } x=x_0.\n\\end{cases}\n\\] Then one would clearly have that \\(\\overline{f}\\) is an attempt, but is not a subset of \\(f.\\) Hence a contradiction and so \\(f:X\\to Y\\) as desired.\n\n\nLemma 6.6 Let \\(f:X\\to Y\\) be a function. If \\(\\longrightarrow_Y\\) is a well-founded relation on \\(Y,\\) then the relation defined on \\(X\\) by \\(x \\longrightarrow_X y \\Leftrightarrow f(x)\\longrightarrow_Y f(y)\\) is well-founded.\n\n\nProof. Any infinite descending \\(\\longrightarrow_X\\)-chain leads to an infinite descending \\(\\longrightarrow_Y\\)-chain.\n\n\nLemma 6.7 Let \\(\\longrightarrow\\) be a relation on \\(X.\\) Then \\(\\longrightarrow\\) is well-founded if and only if \\(\\longrightarrow^+\\) is well-founded.\n\n\nProof. Clearly any infinite descending chain \\[\nx_0 \\longrightarrow^+ x_1 \\longrightarrow^+ x_2 \\longrightarrow^+ \\cdots\n\\] would induce an infinite descending chain with respect to \\(\\longrightarrow.\\) This follows easily since \\(\\longrightarrow\\subseteq \\longrightarrow^+\\) and that any subrelation of a well-founded relation is a well-founded relation. Conversely, in order to show \\(\\longrightarrow^+\\) is well-founded, assume \\[\nx_1 \\longrightarrow^+ x_2 \\longrightarrow^+ x_3  \\longrightarrow^+\\cdots\n\\] is an infinite descending \\(\\longrightarrow^+\\)-chain. Then there exists \\(i_j\\geq 1\\) such that \\(x_j\\longrightarrow^{i_j} x_{j+1}\\) for all \\(j\\geq 1.\\) This implies that \\[\nx_1 \\longrightarrow^{i_1} x_2 \\longrightarrow^{i_2} x_3 \\longrightarrow^{i_3} \\cdots\n\\] is an infinite \\(\\longrightarrow\\)-chain. But this contradicts the well-foundedness of \\(\\longrightarrow.\\)"
  },
  {
    "objectID": "well-founded-confluence.html#confluent-relations",
    "href": "well-founded-confluence.html#confluent-relations",
    "title": "6  Well-founded Confluence",
    "section": "6.2 Confluent Relations",
    "text": "6.2 Confluent Relations\nThis chapter is covers reduction relations, Newmann’s Lemma, Buchberger-Winkler’s Property, and more.\n\n6.2.1 Reduction Relation\nA reduction relation is a binary relation with additional properties that allow us to model the idea of reduction. In particular, we will consider well-founded relations as a starting point. Moreover, since the transitive closure of a well-founded relation is also well-founded relation, we will also study partial order relations.\nA conﬂuent relation is a binary relation that is both left-conﬂuent and right-conﬂuent. In other words, for every element in the relation, there is a unique element that it can be reduced to on the left side and a unique element that it can be reduced to on the right side.\nConﬂuent relations are used in a variety of different contexts, including computer science, mathematics, and physics. In computer science, they are used to define algorithms; in mathematics, they are used to study equations and systems of equations; in physics, they are used to model physical phenomena. Further, they are used in the study of abstract data types, formal language theory, automata theory, and compiler design.\nNewman’s lemma is a result in confluent relations that suggests a local confluence and confluence are equivalent whenever the relation is well-founded. The lemma is named for Max Newmann, who proved the result in 1936.\nA confluent relation is one in which every pair of connected elements can be brought into a common cluster. In other words, if you have two elements that are related by the confluent relation, there must be a third element that is related to both of them. Local confluence is a weaker form of confluence that only requires every pair of connected elements to be brought into a common cluster if they share a certain property.\nThe lemma has important implications for confluent relations, as it provides a way to check whether a given relation is confluent or not.\nNewmann’s lemma has many applications in different areas of mathematics and computer science. In particular, it is used in the study of abstract data types, formal language theory, automata theory, and compiler design.\nIn this chapter, you’ll learn about the Buchberger-Winkler Property (also called the generalized Newman’s Lemma) and about abstract reduction systems.\nIn short, under well-foundedness, confluent means that given any two “paths” emanating from some element in the set, there is always a unique way to combine those paths so as to get back to the original element. Moreover, an abstract reduction system is simply a confluent and well-founded reduction relation on some set. The importance of abstract reduction systems lies in the fact that they can be used to model a wide variety of systems, ranging from computational systems to biological systems.\n\n\n6.2.2 Confluence\nConfluent relations are important in the study of rewriting systems, as they ensure that any two equivalent elements can be transformed into each other by repeatedly applying the rules of the system. Moreover, confluent relations have the property that any two elements that are related by R can be “reached” from each other by following a path through the relation. As a result, confluent relations play an important role in the study of rewriting systems.\nWe discuss confluent relations; in particular, we prove Newman’s Lemma: that local confluence, confluence, the Church-Rosser property, and the unique normal forms property are all equivalent for a well-founded relation. We also give a generalization of Newman’s lemma based on the Buchberger-Winkler’s Property.\nLet \\(\\longrightarrow\\) be a relation on \\(X.\\) If there exists \\(c\\in X\\) such that \\(a\\stackrel{*}{\\longrightarrow} c\\) and \\(b\\stackrel{*}{\\longrightarrow} c,\\) then \\(a\\) and \\(b\\) are said to have a common successor, denoted by \\(a \\downarrow b.\\) If there does not exist \\(b\\in X\\) such that \\(a\\longrightarrow b,\\) then \\(a\\) is called a normal form of \\(\\longrightarrow.\\) If \\(a\\stackrel{*}{\\longrightarrow} b\\) and \\(b\\) is a normal form, then \\(b\\) is called a normal form of \\(X.\\)\n\nTheorem 6.1 Well-founded implies every element has a normal form.\n\n\nDefinition 6.4 Let \\(\\longrightarrow\\) be a relation on \\(X.\\)\n\nA relation \\(\\longrightarrow\\) is called locally confluent whenever \\(a \\longrightarrow b\\) and \\(a \\longrightarrow c\\) implies \\(b \\downarrow c,\\) for all \\(a,b,c\\in X.\\)\nA relation \\(\\longrightarrow\\) is called confluent whenever \\(a \\stackrel{*}{\\longrightarrow} b\\) and \\(a \\stackrel{*}{\\longrightarrow} c\\) implies \\(b \\downarrow c,\\) for all \\(a,b,c\\in X.\\)\nA relation \\(\\longrightarrow\\) is said to satisfy the unique normal forms property if \\(a \\stackrel{*}{\\longrightarrow} b\\) and \\(a \\stackrel{*}{\\longrightarrow} c\\) with \\(b\\) and \\(c\\) in \\(\\longrightarrow\\)-normal form implies \\(b=c,\\) for all \\(a,b,c\\in X.\\)\nA relation \\(\\longrightarrow\\) is said to have the Church-Rosser property whenever \\(b\\stackrel{*}{\\longleftrightarrow} c\\) implies \\(b\\downarrow c,\\) for all \\(a,b,c\\in X.\\)\n\n\n\n\n\n6.2.3 Newman’s Lemma\n\nTheorem 6.2 Let \\(\\longrightarrow\\) be a well-founded relation on \\(X.\\) Then the following properties are equivalent.\n\nlocal confluence\nconfluence\nunique normal forms\nChurch-Rosser property\n\n\n\nProof. \\((1)\\Rightarrow(2)\\): Assume for a contradiction that \\(\\longrightarrow\\) is locally confluent but that the set \\[\nT=\\left\\{ a \\in X  : \\exists \\, \\, b, c \\in X \\text{ with } a \\stackrel{*}{\\longrightarrow} b \\text{ and } a \\stackrel{*}{\\longrightarrow} c \\text{ but not } b \\downarrow c\\right \\}\n\\] is non-empty. Since \\(\\longrightarrow\\) is well-founded, \\(T\\) has a \\(\\longrightarrow\\)-minimial element \\(a.\\) Let \\(b,c \\in X\\) with \\(a \\stackrel{*}{\\longrightarrow} b\\) and \\(a \\stackrel{*}{\\longrightarrow} c,\\) but not \\(b \\downarrow c.\\) If \\(a=b\\) or \\(a=c,\\) then it trivially follows \\(b \\downarrow c.\\) Otherwise there must exist \\(b', c'\\in X\\) (possibly \\(b'=b\\) or \\(c'=c\\)) with \\[\na \\longrightarrow b' \\stackrel{*}{\\longrightarrow} b\n\\quad \\text{and} \\quad\na \\longrightarrow c' \\stackrel{*}{\\longrightarrow} c.\n\\] By the local confluence of \\(\\longrightarrow,\\) there exists \\(d\\in X\\) with \\[\na \\longrightarrow b' \\stackrel{*}{\\longrightarrow} d\n\\quad \\text{and} \\quad\na \\longrightarrow c' \\stackrel{*}{\\longrightarrow} d.\n\\] By the minimality of \\(a\\) in \\(T\\) it follows \\(b'\\not\\in T,\\) and so there exists \\(e\\in X\\) with \\[\na\\longrightarrow b' \\stackrel{*}{\\longrightarrow} b \\stackrel{*}{\\longrightarrow} e\n\\quad \\text{and} \\quad\na\\longrightarrow b' \\stackrel{*}{\\longrightarrow} d \\stackrel{*}{\\longrightarrow} e.\n\\] Then \\(a\\longrightarrow c' \\stackrel{*}{\\longrightarrow} d \\stackrel{*}{\\longrightarrow} e\\) and again by the minimality of \\(a\\) in \\(T\\) it follows \\(c'\\not\\in T.\\) Thus there exists \\(f \\in X\\) with \\[\na \\longrightarrow c' \\stackrel{*}{\\longrightarrow} d \\stackrel{*}{\\longrightarrow} e \\stackrel{*}{\\longrightarrow} f\n\\quad \\text{and} \\quad\na \\longrightarrow c' \\stackrel{*}{\\longrightarrow} c \\stackrel{*}{\\longrightarrow} f.\n\\] Therefore we have shown \\[\na \\longrightarrow b' \\stackrel{*}{\\longrightarrow} b \\stackrel{*}{\\longrightarrow} e \\stackrel{*}{\\longrightarrow} f\n\\quad \\text{and} \\quad\na \\longrightarrow c' \\stackrel{*}{\\longrightarrow} c \\stackrel{*}{\\longrightarrow} f.\n\\] and so \\(b \\downarrow c\\) which is contrary to assumption.\n\\((2)\\Rightarrow(3)\\): Let \\(a \\stackrel{*}{\\longrightarrow} b\\) and \\(a \\stackrel{*}{\\longrightarrow} c,\\) and suppose \\(b\\) and \\(c\\) are in \\(\\longrightarrow\\)-normal form. There exists \\(d \\in X\\) with \\(b \\stackrel{*}{\\longrightarrow} d\\) and \\(c \\stackrel{*}{\\longrightarrow} d,\\) and thus \\(b=d=c.\\)\n\\((3)\\Rightarrow(4)\\): Claim: by induction on \\(k\\in \\mathbb{N}\\) that for all \\(a, b \\in X\\) with \\(a \\stackrel{k}{\\longleftrightarrow} b\\) it follows that \\(a \\downarrow b.\\) The case \\(k=0\\) is trivial. Now let \\(a \\stackrel{k+1}{\\longleftrightarrow} b,\\) say \\(a \\stackrel{k}{\\longleftrightarrow} c \\longleftrightarrow b.\\) Then by induction hypothesis there exists \\(d \\in X\\) with \\(a \\stackrel{*}{\\longrightarrow} d\\) and \\(c \\stackrel{*}{\\longrightarrow} d.\\) If \\(b \\longrightarrow c,\\) then \\(a \\stackrel{*}{\\longrightarrow} d\\) and \\(b \\stackrel{*}{\\longrightarrow} d\\) and so \\(a \\downarrow b.\\)\nFor the other case, assume \\(c \\longrightarrow b.\\) Let \\(d'\\) be a normal form of \\(d\\) and let \\(b'\\) be a normal form of \\(b\\) with respect to \\(\\longrightarrow.\\) Then \\(c \\stackrel{*}{\\longrightarrow} b'\\) and \\(c \\stackrel{*}{\\longrightarrow} d',\\) and so \\(d'\\) and \\(b'\\) are normal forms of \\(c\\) and hence equal. Thus we have \\(a \\stackrel{*}{\\longrightarrow} d'\\) and \\(b \\stackrel{*}{\\longrightarrow} d',\\) which means \\(a \\downarrow b.\\)\n\\((4)\\Rightarrow(1)\\): If \\(a \\longrightarrow b\\) and \\(a \\longrightarrow c,\\) then \\(b \\stackrel{*}{\\longleftrightarrow} c,\\) and so it follows \\(b \\downarrow c.\\)\n\n\nCorollary 6.1 If \\(\\longrightarrow\\) is confluent and \\(a\\stackrel{*}{\\longleftrightarrow} b,\\) then\n\nif \\(b\\) is in normal form, then \\(a\\stackrel{*}{\\longrightarrow} b,\\) and\nif \\(a\\) and \\(b\\) are in normal form, then \\(a=b.\\)\n\n\n\nProof. This proof is left as an exercise.\n\nThus we know that for confluent relations, two elements are equivalent if and only if they have a common successor.\n\n\n6.2.4 Connected Below\nIn this part we follows the ideas in buchberger1983criterion.\n\nDefinition 6.5 Let \\(\\longrightarrow\\) be a relation on \\(X.\\)\n\nIf there exists \\(c_1,c_2,\\ldots,c_n\\in X\\) such that \\[b_1=c_1\\longleftrightarrow c_2\\longleftrightarrow \\cdots \\longleftrightarrow c_n=b_2\\] and \\(a\\longrightarrow^+ c_i\\) for \\(i=1,2,\\ldots,n,\\) then \\(b_1\\) and \\(b_2\\) are said to be connected below \\(a,\\) denoted by \\(b_1 \\stackrel{a}{\\longleftrightarrow} b_2.\\)\nA relation \\(\\longrightarrow\\) on \\(X\\) is said to have the Buchberger-Winkler property whenever \\(a\\longrightarrow b\\) and \\(a\\longrightarrow c\\) implies \\(b \\stackrel{a}{\\longleftrightarrow} c\\) for all \\(a,b,c\\in X.\\)\n\n\n\nTheorem 6.3 Let \\(\\longrightarrow\\) be a well-founded relation on \\(X.\\) Then \\(\\longrightarrow\\) is confluent if and only if the Buchberger-Winkler property holds.\n\n\nProof. Suppose \\(\\longrightarrow\\) is confluent and \\(a \\longrightarrow b\\) and \\(a \\longrightarrow c\\) for \\(a, b, c \\in X.\\) Then there exists \\(d\\) such that \\(b\\stackrel{*}{\\longrightarrow} d\\) and \\(c\\stackrel{*}{\\longrightarrow} d.\\) It follows that \\(b \\stackrel{a}{\\longleftrightarrow} c.\\)\nConversely, assume \\(a, b, c\\) are arbitrary, but fixed such that \\(a \\stackrel{*}{\\longrightarrow} b\\) and \\(a \\stackrel{*}{\\longrightarrow} c.\\) The proof follows by induction on \\(\\longrightarrow.\\) The first induction hypothesis is:\n\\[\n\\forall \\, a' \\, (a\\longrightarrow^+ a'), \\forall \\, b', c' \\, (\\text{if }  a' \\stackrel{*}{\\longrightarrow} c'  \\text{ and } a' \\stackrel{*}{\\longrightarrow} b'  \\text{, then } b' \\downarrow c').\n\\] It is required to show \\(b \\downarrow c,\\) that is \\(b \\stackrel{*}{\\longrightarrow} d\\) and \\(c \\stackrel{*}{\\longrightarrow} d\\) for some \\(d.\\) The cases \\(a=b\\) or \\(a=c\\) are trivial. Assume \\(a \\neq b\\) and \\(a \\neq c.\\) Then there exist \\(b_1\\) and \\(c_1\\) such that \\(a \\longrightarrow b_1 \\stackrel{*}{\\longrightarrow} b\\) and \\(a \\longrightarrow c_1 \\stackrel{*}{\\longrightarrow} c.\\) By assuming \\(\\longrightarrow\\) has the Buchberger property, there exists \\(e_1, e_2, \\ldots , e_n\\) such that \\(b_1=e_1 \\longleftrightarrow e_2 \\longleftrightarrow \\cdots \\longleftrightarrow e_n=c_1\\) and \\(a\\longrightarrow^+ e_i.\\) we will proceed by induction on \\(n\\) and show: for all \\(n,\\) for all \\(e_1, e_2, \\ldots,e_n\\):\n\\[\\begin{equation}\n\\label{conflutwo}\n\\text{if} \\quad  e_1 \\longleftrightarrow e_2 \\longleftrightarrow \\cdots  \\longleftrightarrow e_n \\quad \\text{with} \\quad   a\\longrightarrow^+ e_i , \\qquad \\text{then } \\qquad e_1\\downarrow e_n.\n\\tag{*}\n\\end{equation}\\]\nNotice \\(\\eqref{conflutwo}\\) is clear for \\(n=1.\\) Our second induction hypothesis is: \\(\\eqref{conflutwo}\\) is true for some \\(n.\\) Assume \\(e_1\\longleftrightarrow e_2 \\longleftrightarrow \\cdots \\longleftrightarrow e_n \\longleftrightarrow e_{n+1}\\) and \\(a\\longrightarrow^+ e_i\\) for \\(i=1, 2, \\ldots,n+1.\\) By induction hypothesis 2, there exists \\(d_1\\) such that \\(e_1\\stackrel{*}{\\longrightarrow} d_1\\) and \\(e_n\\stackrel{*}{\\longrightarrow} d_1.\\) If \\(e_{n+1}\\longrightarrow e_n\\) then \\(e_{n+1} \\stackrel{*}{\\longrightarrow} d_1\\) and so \\(e_1\\downarrow e_{n+1}.\\) If \\(e_n \\longrightarrow e_{n+1},\\) then by induction hypothesis 1, there exists \\(d_1'\\) such that \\(d_1\\stackrel{*}{\\longrightarrow} d_1'\\) and \\(e_{n+1} \\stackrel{*}{\\longrightarrow} d_1'.\\) Thus, it follows \\(e_1\\downarrow e_{n+1}\\) in this case as well. Therefore, \\(\\eqref{conflutwo}\\) is proven by induction and so \\(d_1\\) exists such that \\(e_1\\stackrel{*}{\\longrightarrow} d_1\\) and \\(e_n\\stackrel{*}{\\longrightarrow} d_1\\) for all \\(n.\\) Then, \\(b_1 \\stackrel{*}{\\longrightarrow} d_1,\\) \\(b_1 \\stackrel{*}{\\longrightarrow} b,\\) and \\(a\\longrightarrow b_1\\) implies, by induction hypothesis 1, that there exists \\(f\\) such that \\(b \\stackrel{*}{\\longrightarrow} f\\) and \\(d_1 \\stackrel{*}{\\longrightarrow} f.\\) It follows that, \\(c_1 \\stackrel{*}{\\longrightarrow} c\\) and \\(c_1 \\stackrel{*}{\\longrightarrow} f.\\) Again by induction hypothesis 1, there exists \\(d\\) such that \\(f \\stackrel{*}{\\longrightarrow} d\\) and \\(c \\stackrel{*}{\\longrightarrow} d.\\) Therefore, it follows \\(b \\stackrel{*}{\\longrightarrow} d\\) and \\(c \\stackrel{*}{\\longrightarrow} d.\\)\n\n\n\n6.2.5 Terminating\nLet \\(X\\) be a set and \\(\\to\\) a reduction (binary relation) on \\(X.\\) A chain with respect to \\(\\to\\) is a sequence of elements \\(x_1,x_2,x_3,\\ldots\\) in \\(X\\) such that \\(x_1\\to x_2,\\) \\(x_2\\to x_3,\\) etc. A chain with respect to \\(\\to\\) is usually written \\[x_1\\to x_2 \\to x_3 \\to \\cdots \\to x_n \\to \\cdots.\\] The length of a chain is the cardinality of its underlying sequence. A chain is finite if its length is finite. Otherwise, it is infinite.\n\nDefinition 6.6 A reduction \\(\\to\\) on a set \\(X\\) is said to be terminating if it has no infinite chains. In other words, every chain terminates.\n\nHere are a few examples.\n\nIf \\(\\to\\) is reflexive, or non-trivial symmetric, then it is never terminating.\nLet \\(X\\) be the set of all positive integers greater than \\(1.\\) Define \\(\\to\\) on \\(X\\) so that \\(a\\to b\\) means that \\(a=bc\\) for some \\(c\\in X.\\) Then \\(\\to\\) is a terminating reduction. By the way, \\(\\to\\) is also a normalizing reduction.\nIn fact, it is easy to see that a terminating reduction is normalizing: if \\(a\\) has no normal form, then we may form an infinite chain starting from \\(a.\\)\nOn the other hand, not all normalizing reduction is terminating. A canonical example is the set of all non-negative integers with the reduction \\(\\to\\) defined by \\(a\\to b\\) if and only if either \\(a,b\\ne 0,\\) \\(a\\ne b,\\) and \\(aj,\\) and \\(j\\) arbitrary.\nThe reflexive transitive closure of a terminating relation is a partial order.\n\nA closely related concept is the descending chain condition (DCC). A reduction \\(\\to\\) on \\(X\\) is said to satisfy the descending chain condition (DCC) if the only infinite chains on \\(X\\) are those that are eventually constant. A chain \\(x_1\\to x_2 \\to x_3 \\to \\cdots\\) is eventually constant if there is a positive integer \\(N\\) such that for all \\(n\\ge N,\\) \\(x_n=x_N.\\) Every terminating relation satisfies DCC. The converse is obviously not true, as a reflexive reduction illustrates.\nAnother related concept is acyclicity. Let \\(\\to\\) be a reduction on \\(X.\\) A chain \\(x_0\\to x_1 \\to \\cdots x_n\\) is said to be cyclic if \\(x_i=x_j\\) for some \\(0\\le i < j\\le n.\\) This means that there is a “closed loop’’ in the chain. The reduction \\(\\to\\) is said to be acyclic if there are no cyclic chains with respect to \\(\\to.\\) Every terminating relation is acyclic, but not conversely. The usual strict inequality relation on the set of positive integers is an example of an acyclic but non-terminating relation."
  },
  {
    "objectID": "well-founded-confluence.html#exercises",
    "href": "well-founded-confluence.html#exercises",
    "title": "6  Well-founded Confluence",
    "section": "6.3 Exercises",
    "text": "6.3 Exercises"
  },
  {
    "objectID": "connect-everything.html#preorders",
    "href": "connect-everything.html#preorders",
    "title": "7  Connect Everything",
    "section": "7.1 Preorders",
    "text": "7.1 Preorders"
  },
  {
    "objectID": "connect-everything.html#equivalence-relations",
    "href": "connect-everything.html#equivalence-relations",
    "title": "7  Connect Everything",
    "section": "7.2 Equivalence Relations",
    "text": "7.2 Equivalence Relations\n\n7.2.1 The Reflexive, Symmetric, and Transitive Properties\n\nDefinition 7.1 Let \\(X\\) be a set.\n\nA relation \\(R\\) on \\(X\\) is called reflexive if it satisfies the property \\[\\forall a\\in X, (a,a)\\in R.\\]\nA relation \\(R\\) on \\(X\\) is called symmetric if it satisfies the property \\[ \\forall a,b \\in X, (a,b)\\in R \\implies (b,a)\\in R. \\]\nA relation \\(R\\) on \\(X\\) is called transitive if it satisfies the property \\[\\forall a,b,c\\in X, ((a,b)\\in R \\land (b,c)\\in R) \\implies (a,c)\\in R.\\]\n\n\n\nTheorem 7.1 Let \\(R\\) and \\(S\\) be relations on \\(X\\) and let \\(A\\subseteq X.\\)\n\nA relation \\(R\\) is reflexive if and only if \\(I \\subseteq R.\\)\nA relation \\(R\\) is symmetric if and only if \\(R^{-1}\\subseteq R.\\)\n\nA relation \\(R\\) is transitive if and only if \\(R\\circ R\\subseteq R.\\)\n\n\n\nProof. The proof of each part follows.\n\nIf \\(R\\) is reflexive, then \\(I\\subseteq R.\\) \\[\n(x,y)\\in I \\Leftrightarrow y=x \\implies (x,y)\\in R\n\\] Conversely, if \\(I\\subseteq R\\), then \\(R\\) is reflexive. \\[\nx\\in X \\implies (x,x)\\in I \\implies (x,x)\\in R\n\\]\nIf \\(R\\) is symmetric, then \\(R^{-1}\\subseteq R.\\) \\[\n(x,y)\\in R^{-1}\\Leftrightarrow (y,x)\\in R \\implies (x,y)\\in R\n\\] Conversely, if \\(R^{-1}\\subseteq R\\), then \\(R\\) is symmetric. \\[\n(x,y)\\in R \\implies (y,x)\\in R^{-1} \\implies (y,x)\\in R\n\\]\nIf \\(R\\) is transitive, then \\(R\\circ R\\subseteq R.\\) \\[\n(x,y)\\in R\\circ R \\Leftrightarrow \\exists x\\in X, (x,z)\\in R \\land (z,y)\\in R \\implies (x,y)\\in R\n\\] Conversely, if \\(R\\circ R\\subseteq R\\), then \\(R\\) is transitive. \\[\n(x,y)\\in R \\land (y,z)\\in R \\implies (x,z)\\in R\\circ R \\implies (x,z)\\in R.\n\\] The proof is now complete.\n\n\n\nTheorem 7.2 If \\(R\\) and \\(S\\) are reflexive, then \\(R|_A\\), \\(R^{-1}\\), \\(S\\circ R\\), \\(R\\cup S\\), and \\(R\\cap S\\) are also reflexive, while \\(R^c\\) is not reflexive.\n\n\nProof. We find that \\(R|_A\\), \\(R^{-1}\\), \\(S\\circ R\\), \\(R\\cup S\\), and \\(R\\cap S\\) are reflexive, whenever \\(R\\) and \\(S\\) are reflexive by the following arguments, respectively.\n\n\\((x,x)\\in R \\land A\\subseteq X \\implies (x,x)\\in R|_{A}\\)\n\\((x,x)\\in R \\implies (x,x)\\in R^{-1}\\)\n\\((x,x)\\in R \\land (x,x)\\in S \\implies (x,x)\\in S\\circ R\\)\n\\((x,x)\\in R \\land (x,x)\\in S \\implies (x,x)\\in R\\cup S\\)\n\\((x,x)\\in R \\land (x,x)\\in S \\implies (x,x)\\in R\\cap S\\)\n\nNotice that \\(R^c\\) is not reflexive because \\(I\\subseteq R\\implies I\\not\\subseteq R^c.\\)\n\n\nTheorem 7.3 If \\(R\\) and \\(S\\) are symmetric, then \\(R|_A\\), \\(R^c\\), \\(R^{-1}\\), \\(R^{-1}\\circ R\\), \\(R\\cup S\\), and \\(R\\cap S\\) are also symmetric.\n\n\nProof. If \\(R\\) is symmetric, then \\(R|_{A}\\) is symmetric. \\[\\begin{align*}\n\\qquad \\qquad& (x,y)\\in R|_A \\Longleftrightarrow (x,y) \\in (A\\times A) \\cap R  \\\\\n& \\qquad \\Longleftrightarrow (x,y)\\in A\\times A \\land (x,y)\\in R \\Longleftrightarrow (y,x)\\in A\\times A \\land (y,x)\\in R \\\\\n& \\qquad \\Longleftrightarrow (y,x) \\in (A\\times A) \\cap R  \\Longleftrightarrow (x,y)\\in R|_A\n\\end{align*}\\]\nIf \\(R\\) is symmetric, then \\(R^c\\) is symmetric. \\[\\begin{align*}\n& (x,y)\\in R^c \\Longleftrightarrow (x,y)\\notin R \\Longleftrightarrow \\neg ((x,y)\\in R)  \\\\\n& \\qquad \\Longleftrightarrow \\neg( (y,x)\\in R) \\Longleftrightarrow (y,x)\\notin R \\Longleftrightarrow (y,x)\\in R^c\n\\end{align*}\\]\nIf \\(R\\) is symmetric, then \\(R^{-1}\\) is symmetric. \\[\\begin{align*}\n\\qquad (x,y)\\in R^{-1} \\Longleftrightarrow (y,x)\\in R \\Longleftrightarrow (x,y)\\in R \\Longleftrightarrow (y,x)\\in R^{-1}\n\\end{align*}\\]\nIf \\(R\\) and \\(S\\) are symmetric, then \\(R\\cup S\\) is symmetric. \\[\\begin{align*}\n\\qquad & (x,y)\\in R\\cup S \\Longleftrightarrow (x,y)\\in R \\lor (x,y)\\in S \\\\\n& \\qquad \\Longleftrightarrow (y,x)\\in R \\lor (y,x)\\in S \\Longleftrightarrow (y,x)\\in R\\cup S\n\\end{align*}\\]\nIf \\(R\\) and \\(S\\) are symmetric then the relation \\(R\\cap S\\) is symmetric. \\[\\begin{align*}\n\\qquad & (x,y)\\in R\\cap S \\Longleftrightarrow (x,y)\\in R \\land (x,y)\\in S\\\\\n& \\qquad \\Longleftrightarrow (y,x)\\in R \\land (y,x)\\in S \\Longleftrightarrow (y,x)\\in R\\cap S\n\\end{align*}\\]\nIf \\(R\\) is symmetric, then \\(R^{-1}\\circ R\\) is symmetric. \\[\\begin{align*}\n\\qquad \\qquad & (x,y)\\in R^{-1}\\circ R \\Longleftrightarrow \\exists z\\in X, (x,z)\\in R \\land (z,y)\\in R^{-1} \\\\\n& \\qquad \\Longleftrightarrow \\exists z\\in X, (z,x)\\in R^{-1} \\land (y,z)\\in R \\\\\n& \\qquad \\Longleftrightarrow \\exists z\\in X,  (y,z)\\in R \\land (z,x)\\in R^{-1} \\Longleftrightarrow (y,x)\\in R^{-1}\\circ R\n\\end{align*}\\]\nThe proof is now complete.\n\n\nTheorem 7.4 Let \\(R\\) and \\(S\\) be relations on \\(X\\) and let \\(A\\subseteq X.\\) If \\(R\\) and \\(S\\) are transitive, then \\(R|_A\\), \\(R^{-1}\\), \\(R^2\\), and \\(R\\cap S\\) are also transitive, while \\(R^c\\) and \\(R\\cup S\\) are not transitive.\n\n\nProof. If \\(R\\) is transitive, then \\(R|_{A}\\) is transitive. \\[\\begin{align*}\n\\qquad \\qquad & (x,y)\\in  R|_A \\land (y,z)\\in R|_A \\\\\n& \\qquad \\Longleftrightarrow [(x,y)\\in A\\times A \\land (x,y)\\in R] \\land [(y,z)\\in A\\times A \\land (y,z)\\in R]\\\\\n& \\qquad \\Longleftrightarrow (x,z)\\in A\\times A \\land (x,z)\\in R \\\\\n& \\qquad \\Longleftrightarrow (x,z)\\in (A\\times A) \\cap R \\Longleftrightarrow (x,z)\\in R|_A\n\\end{align*}\\]\nIf \\(R\\) is transitive, then \\(R^{-1}\\) is transitive. \\[\\begin{align*}\n\\qquad \\qquad & (x,y)\\in R^{-1} \\land (y,z)\\in R^{-1} \\Longleftrightarrow (y,x)\\in R \\land (z,y)\\in R \\\\\n& \\qquad \\Longleftrightarrow (z,y)\\in R \\land (y,x) \\in R  \\Longleftrightarrow (z,x)\\in R \\Longleftrightarrow (x,z)\\in R^{-1}\n\\end{align*}\\]\nIf \\(R\\) is transitive, then \\(R^2\\) is transitive. \\[\\begin{align*}\n\\quad \\qquad \\qquad & (x,y)\\in R^2 \\land (y,z)\\in R^2 \\\\\n& \\Longleftrightarrow [\\exists s\\in X, (x,s)\\in R \\land (s,y)\\in R] \\land [\\exists t\\in X, (y,t)\\in R \\land (t,z)\\in R] \\\\\n& \\Longleftrightarrow \\exists s,t\\in X, (x,s)\\in R \\land (s,y)\\in R \\land (y,t)\\in R \\land (t,z)\\in R\\\\\n& \\Longleftrightarrow \\exists s,t\\in X, (x,s)\\in R\\land (s,t)\\in R \\land (t,z)\\in R \\\\\n& \\Longleftrightarrow (x,t) \\in R \\land (t,z)\\in R \\Longleftrightarrow (x,z)\\in R^2\n\\end{align*}\\]\nIf \\(R\\) and \\(S\\) are transitive then the relation \\(R\\cap S\\) is transitive. \\[\\begin{align*}\n& (x,y)\\in R\\cap S \\land (y,z)\\in R\\cap S\\\\\n& \\qquad \\Longleftrightarrow (x,y)\\in R \\land (x,y)\\in S \\land (y,z)\\in R \\land (y,z)\\in S \\\\\n& \\qquad \\Longleftrightarrow (x,z)\\in R \\land (x,z)\\in S \\Longleftrightarrow (x,z)\\in R\\cap S\n\\end{align*}\\]\nIf \\(R\\) and \\(S\\) are transitive then the relation \\(R\\cup S\\) is not necessarily transitive. To see this let \\(X=\\{a,b,c\\}\\), \\(R=\\{(a,b),(b,c),(a,c)\\}\\) and \\(S=\\{(b,c),(c,d),(b,d)\\}.\\) Then \\(R\\) and \\(S\\) are transitive, however, \\(R\\cup S\\) is not transitive since \\((a,b), (b,d)\\in R\\cup S\\) yet \\((a,d)\\notin R\\cup S.\\) If \\(R\\) is transitive then \\(R^c\\) is not necessarily transitive. To see this let \\(X=\\{a,b\\}\\) and \\(R=I.\\) The \\(R\\) is transitive and \\(R^c=\\{(a,b),(b,a)\\}\\) which is not transitive.\n\n\nDefinition 7.2 If a relation is reflexive, symmetric, and transitive, then it is called an equivalence relation.\n\n\nTheorem 7.5 Let \\(R\\) and \\(S\\) be equivalence relations on \\(X\\) and let \\(A\\subseteq X.\\) Then \\(R|_A\\), \\(R^{-1}\\), \\(R^2\\), and \\(R\\cap S\\) are also equivalence relations.\n\n\nProof. The proof is left as Exercise 7.1.\n\n\nTheorem 7.6 Let \\(R\\) and \\(S\\) be relations on \\(X\\) and let \\(A\\subseteq X.\\)\n\nIf \\(R\\) and \\(S\\) are symmetric, then \\(S\\circ R\\) is symmetric if and only if \\(R\\circ S\\subseteq S\\circ R.\\)\nIf \\(R\\) and \\(S\\) are transitive and \\(R\\circ S\\subseteq S\\circ R\\), then \\(S\\circ R\\) is transitive, but not conversely.\nIf \\(R\\) and \\(S\\) are equivalence relations, then \\(S\\circ R\\) is an equivalence relation if and only if \\(R\\circ S\\subseteq S\\circ R.\\)\n\n\n\nProof. The proof of each part follows.\n\nIf \\(R\\) and \\(S\\) are symmetric and \\(R\\circ S\\subseteq S\\circ R\\), then \\(S\\circ R\\) is symmetric. \\[\\begin{align*}\n\\qquad  & (x,y)\\in S\\circ R \\Longleftrightarrow \\exists z\\in X, (x,z)\\in R \\land (z,y)\\in S \\\\\n& \\qquad \\Longleftrightarrow \\exists z\\in X, (z,x)\\in R \\land (y,z)\\in S \\\\\n& \\qquad \\Longleftrightarrow \\exists z\\in X, (y,z)\\in S \\land (z,x)\\in R \\Longleftrightarrow (y,x)\\in R\\circ S\\\\\n& \\qquad \\Longleftrightarrow (y,x)\\in S\\circ R\n\\end{align*}\\]\n\nConversely, assume \\(R\\), \\(S\\), and \\(S\\circ R\\) are symmetric, then \\(S\\circ R=R\\circ S.\\) \\[\\begin{align*}\n\\qquad  & (x,y)\\in S\\circ R \\Longleftrightarrow (y,x)\\in S\\circ R \\\\\n& \\qquad \\Longleftrightarrow \\exists z\\in X, (y,z)\\in R \\land (z,x)\\in S \\\\\n& \\qquad \\Longleftrightarrow \\exists z\\in X, (z,y)\\in R \\land (x,z)\\in S \\\\\n& \\qquad \\Longleftrightarrow \\exists z\\in X, (x,z)\\in S \\land (z,y)\\in R \\Longleftrightarrow (x,y)\\in R\\circ S\n\\end{align*}\\]\n\nIf \\(R\\) and \\(S\\) are transitive and \\(R\\circ S\\subseteq S\\circ R\\), then \\(S\\circ R\\) is transitive. \\[\\begin{align*}\n& (x,y)\\in S\\circ R \\land (y,z)\\in S\\circ R \\\\ & \\Longleftrightarrow [\\exists s\\in X, (x,s)\\in R\\land (s,y)\\in S] \\land [\\exists t\\in X, (y,t)\\in R \\land (t,z)\\in S] \\\\\n& \\Longleftrightarrow \\exists s,t\\in X, (x,s)\\in R \\land (s,y)\\in S \\land (y,t)\\in R \\land (t,z)\\in S \\\\\n& \\Longleftrightarrow \\exists s,t,\\in X, (x,s)\\in R \\land (s,t)\\in R\\circ S \\land (t,z)\\in S  \\\\\n&  \\Longleftrightarrow \\exists s,t\\in X, (x,s)\\in R \\land (s,t)\\in S\\circ R \\land (t,z)\\in S  \\\\\n&  \\Longleftrightarrow \\exists s,t,w\\in X, (x,s)\\in R \\land (s,w)\\in R \\land (w,t)\\in S \\land (t,z)\\in S  \\\\\n& \\Longleftrightarrow \\exists w\\in X, (x,w)\\in R \\land (w,z)\\in S \\Longleftrightarrow (x,z)\\in S\\circ R\n\\end{align*}\\]\n\nLet \\(X=\\{a,b,c\\}\\), \\(R=\\{(a,a), (a,b)\\}\\), and \\(S=\\{(b,b),(b,c)\\}.\\) Then \\(R\\) and \\(S\\) are transitive and so is \\(S\\circ R=\\{(a,b),(a,c)\\}.\\) However, \\(R\\circ S=\\emptyset.\\)\n\nIf \\(R\\), \\(S\\), and \\(S\\circ R\\) are equivalence relations on \\(X\\), then \\(R\\circ S \\subseteq S\\circ R.\\) \\[\\begin{align*}\n\\qquad S\\circ R & \\textrm{ is an equivalence relation} \\\\\n& \\Longleftrightarrow S\\circ R \\textrm{ is reflexive, symmetric, and transitive} \\\\\n& \\Longrightarrow S\\circ R \\textrm{ is symmetric } \\Longleftrightarrow R\\circ S \\subseteq S\\circ R\n\\end{align*}\\]\n\nConversely, if \\(R\\) and \\(S\\) are equivalence relations and \\(R\\circ S\\subseteq S\\circ R\\), then \\(S\\circ R\\) is an equivalence relation. \\[\\begin{align*}\n\\qquad & R\\circ S \\subseteq S\\circ R \\land S, R \\textrm{ are equivalence relations} \\\\\n& \\qquad \\Longrightarrow S\\circ R \\textrm{ is reflexive, symmetric, and transitive } \\\\\n& \\qquad \\Longleftrightarrow S\\circ R \\textrm{ is an equivalence relation }\n\\end{align*}\\] which completes the proof.\n\nA beautiful concise characterization of equivalence relation is here in the next theorem.\n::: {#thm-understanding-of-equivalence relation } Let \\(R\\) be a relation on \\(X.\\) Then \\(R\\) is an equivalence relation if and only if \\[\nR=I\\cup R^{-1} \\cup R^2.\n\\] :::\n\nProof. Let \\(R\\) be a relation on \\(X.\\) If \\(R\\) is reflexive, symmetric, and transitive it follows \\(I\\subseteq R\\), \\(R^{-1} =R\\), and \\(R^2=R\\); and thus \\(I\\cup R^{-1}\\cup R^2=R.\\) Conversely, assume \\(R\\) be a relation on \\(X.\\) If \\(I\\cup R^{-1}\\cup R^2=R\\), then \\(I\\subseteq R\\), \\(R^{-1} \\subseteq R\\), and \\(R^2\\subseteq R\\); and therefore \\(R\\) is an equivalence relation.\n\nAnother characterization of equivalence relation is here in the next theorem.\n\nTheorem 7.7 Let \\(\\sim\\) be a relation on \\(X.\\) Then \\(\\sim\\) is an equivalence relation if and only if the following property holds: \\[\\begin{equation}\n\\forall \\, a,b\\in X, a\\sim b  \\Leftrightarrow \\forall \\, c\\in X, a\\sim c \\Leftrightarrow b\\sim c.\n\\end{equation}\\]\n\n\nProof. Assume \\(\\sim\\) is an equivalence relation on \\(X.\\) Assume \\(a\\sim b\\) for arbitrary \\(a,b\\in X.\\) Let \\(c\\in X.\\) By symmetry and transitivity it follows that \\[\na\\sim c \\implies c\\sim a \\implies c\\sim b \\implies b\\sim c\n\\] and conversely, \\(b\\sim c \\implies a\\sim c\\) follows by transitivity. Therefore, by symmetry and transitivity we have \\[\n\\forall a,b \\in X, a\\sim b \\implies \\forall c\\in X, a\\sim c \\Leftrightarrow b\\sim c.\n\\] Assume for all \\(c\\in X\\) that \\(a\\sim c \\Leftrightarrow b\\sim c.\\) Let \\(c=a.\\) Then we have \\(a\\sim a \\Leftrightarrow b\\sim a.\\) Since \\(\\sim\\) is reflexive, \\(a\\sim b\\) must hold. Whence, \\[\n\\forall c\\in X, (a\\sim c \\Leftrightarrow b\\sim c) \\implies a\\sim b\n\\] as desired.\nConversely, assume the given property holds. To show reflexivity, let \\(a\\in X.\\) Since, \\(a\\sim a\\) if and only if \\(a\\sim a\\), obviously holds, it follows \\(a\\sim a\\) is valid. To prove the symmetric property holds, assume \\(a\\sim b.\\) Therefore the following holds, \\(\\forall c\\in X, a\\sim c \\Leftrightarrow b\\sim c.\\) Equivalently, the following holds \\(\\forall c\\in X, b\\sim c \\Leftrightarrow a\\sim c.\\) Thus is it obvious that, \\(a\\sim b \\implies b\\sim a\\) holds; and therefore \\(\\sim\\) is also symmetric. To show transitivity, let \\(a,b,c\\in X\\) and assume \\(a\\sim b\\) and \\(b\\sim c.\\) Therefore the following holds, \\[\n[\\forall c\\in X, a\\sim c \\Leftrightarrow b \\sim c]\n\\land\n[\\forall d\\in X, b\\sim d \\Leftrightarrow c \\sim d].\n\\] Let \\(e\\in X.\\) Then the following holds, \\[\na\\sim e \\Leftrightarrow b\\sim e \\Leftrightarrow c\\sim e.\n\\] Therefore, \\(a\\sim c\\) and so \\(\\sim\\) is also transitive. In conclusion, \\(\\sim\\) is an equivalence relation.\n\n\nDefinition 7.3 If \\(\\sim\\) is an equivalence relation on \\(X\\), then the set \\[[a]=\\{b\\in X : b\\sim a\\}\\] is called the equivalence class of \\(a\\) with respect to \\(\\sim.\\)\n\n\nDefinition 7.4 A partition of \\(X\\) is a collection of pairwise disjoint nonempty sets whose union is \\(X.\\)\n\n\nTheorem 7.8 Let \\(\\sim\\) be a relation on \\(X.\\) Then \\(\\sim\\) is an equivalence relation on \\(X\\) if and only if the set \\[\nP=\\{\\{b\\in X: a\\sim b \\}: a\\in X\\}\n\\] is a partition of \\(X\\) with the property \\(\\forall a,b\\in X, a\\sim b \\Leftrightarrow \\exists A\\in P\\) such that \\(a,b\\in A.\\)\n\n\nProof. Assume \\(\\sim\\) is an equivalence relation on \\(X.\\) We will prove that \\(P\\) is a partition of \\(X\\) with the desired property by proving the following four statements hold.\nClaim 1: \\(X\\) is the union of all equivalence classes of \\(\\sim.\\)\nProof: Since \\(\\sim\\) is reflexive it follows that \\[\nx\\in \\bigcup_{a\\in X}[a] \\Leftrightarrow \\exists a\\in X, x\\in [a] \\Leftrightarrow x\\in X.\n\\]\nClaim 2: For all \\(a,b\\in X\\), \\([a]\\cap [b]\\neq \\emptyset \\Leftrightarrow [a]=[b].\\)\nProof: Assume \\([a]\\cap [b] \\neq \\emptyset.\\) Since \\(\\sim\\) is symmetric and transitive, it follows \\[\\begin{align*}\nx\\in [a]  & \\Leftrightarrow x\\sim a \\Leftrightarrow x\\sim a \\land \\, \\exists y\\in [a] \\cap [b]\n\\\\ &  \\Leftrightarrow \\exists y\\in X, x\\sim a \\land y\\sim a \\land y\\sim b\n\\\\ &  \\Leftrightarrow \\exists y\\in X, x\\sim a \\land a\\sim y \\land y\\sim b\n\\\\ &  \\Leftrightarrow \\exists y\\in X, x\\sim y \\land y\\sim b  \\Leftrightarrow x\\sim b \\Leftrightarrow x\\in [b]\n\\end{align*}\\] Assume \\([a]=[b].\\) Since \\(\\sim\\) is reflexive \\[\na\\in [a]\n\\implies  a\\in [a] \\land a\\in [b] \\\\\n\\implies a\\in [a] \\cap [b] \\\\\n\\implies [a]\\cap [b] \\neq \\emptyset\n\\]\nClaim 3: Every equivalence class of \\(\\sim\\) is nonempty.\nProof: Since \\(\\sim\\) is reflexive, it follows that \\[\na\\in X \\implies a\\sim a \\implies a\\in [a] \\implies [a]\\neq \\emptyset.\n\\]\nClaim 4: For all \\(a,b\\in X\\), \\(a\\sim b \\Leftrightarrow [a]=[b].\\)\nProof: Let \\(a,b\\in X\\) and assume \\(a\\sim b.\\) Then it follows that \\[\nx\\in [a] \\Leftrightarrow x\\sim a \\Leftrightarrow x\\sim b \\Leftrightarrow x\\in [b].\n\\] Thus we have that \\([a]=[b].\\) Conversely, assume \\([a]=[b]\\) for all \\(a,b\\) in \\(X.\\) Then it follows that \\[\na\\in [a] \\implies a\\in [b] \\implies a\\sim b.\n\\] and so \\(a\\sim b\\) holds. Therefore we have shown that \\(P\\), the collection of equivalence class of \\(\\sim\\), is a partition on \\(X\\) with the desired property.\nConversely, assume \\(\\sim\\) is a relation on \\(X\\) and \\(P\\) is a partition of \\(X\\) with the stated property. First we notice \\(\\sim\\) is reflexive since \\[\na\\in X \\implies a\\in\\bigcup_{A\\in P} A \\implies \\exists A\\in P, a\\in A \\implies a\\sim a.\n\\] The symmetric property of \\(\\sim\\) follows by \\[\na\\sim b \\implies \\exists A\\in P, a\\in A \\land b\\in A \\implies b\\sim a.\n\\] We also notice \\(\\sim\\) is transitive by the following \\[\na\\sim b \\land b\\sim c\n\\Leftrightarrow \\exists a, b\\in P, a,b\\in A\\land b,c\\in B\n\\Longrightarrow A=B\n\\Leftrightarrow a\\sim c.\n\\] In conclusion \\(\\sim\\) is an equivalence relation where \\(a\\sim b\\) is equivalent to the existence of a set \\(A\\in P\\) with \\(a,b\\in A\\), namely the equivalence class \\(A=[a].\\)"
  },
  {
    "objectID": "connect-everything.html#exercise",
    "href": "connect-everything.html#exercise",
    "title": "7  Connect Everything",
    "section": "7.3 Exercise",
    "text": "7.3 Exercise\n\nExercise 7.1 Prove Theorem 7.5."
  },
  {
    "objectID": "connect-everything.html#reflexive-closure",
    "href": "connect-everything.html#reflexive-closure",
    "title": "7  Connect Everything",
    "section": "7.4 Reflexive Closure",
    "text": "7.4 Reflexive Closure\n\nTheorem 7.9 Let \\(R\\) be relation on \\(X\\) and \\(A\\subseteq X.\\) The reflexive closure of \\(R\\) is the relation \\[\nr(R)=R \\cup I.\n\\]\n\n\nProof. Let \\(R\\) b a relation, then \\(r(R)=R\\cup I.\\) Notice \\(R\\cup I\\) is reflexive since \\[\nx\\in X \\implies (x,x)\\in I\\implies (x,x)\\in R\\cup I.\n\\] Let \\(T\\) be a reflexive relation containing \\(R.\\) Then \\(R\\cup I\\subseteq T\\) since \\[\\begin{align*}\n& (x,y)\\in R\\cup I\n\\implies (x,y)\\in R \\lor (x,y)\\in I  \n\\\\&\\qquad\n\\implies (x,y)\\in T \\lor (x,y)\\in I\n\\implies (x,y)\\in T \\cup I =T\n\\end{align*}\\] Since \\(R\\subseteq R\\cup I \\subseteq T\\) where \\(T\\) is an arbitrary reflexive relation containing \\(R\\), it follows \\(r(R)=R\\cup I.\\)"
  },
  {
    "objectID": "connect-everything.html#symmetric-closure",
    "href": "connect-everything.html#symmetric-closure",
    "title": "7  Connect Everything",
    "section": "7.5 Symmetric Closure",
    "text": "7.5 Symmetric Closure\n\nTheorem 7.10 Let \\(R\\) be relation on \\(X\\) and \\(A\\subseteq X.\\) The symmetric closure of \\(R\\) is the relation \\[\ns(R)=R \\cup R^{-1}.\n\\]\n\n\nProof. Let \\(R\\) b a relation, then \\(s(R)=R\\cup R^{-1}.\\) Notice \\(R\\cup R^{-1}\\) is symmetric since \\[\\begin{align*}\n\\qquad \\qquad & (x,y) \\in R\\cup R^{-1}\n\\implies  (x,y)\\in R \\lor (x,y)\\in R^{-1}\n\\\\ & \\qquad\n\\implies  (y,x)\\in R^{-1} \\lor (y,x)\\in R\n\\implies  (y,x)\\in R^{-1} \\cup R=R\\cup R^{-1}\n\\end{align*}\\] Let \\(T\\) be a symmetric relation containing \\(R.\\) Then \\(R\\cup R^{-1}\\subseteq T\\) since \\[\\begin{align*}\n\\qquad \\qquad & (x,y) \\in R\\cup R^{-1}\n\\implies (x,y)\\in R \\lor (x,y)\\in R^{-1}\n\\\\ & \\qquad\n\\implies (x,y)\\in T \\lor (x,y)\\in R^{-1}\n\\implies (x,y)\\in T \\lor (y,x)\\in T\n\\\\ & \\qquad\n\\implies (x,y)\\in T \\lor (x,y)\\in T\n\\implies (x,y)\\in T\n\\end{align*}\\] Since \\(R\\subseteq R\\cup R^{-1} \\subseteq T\\) where \\(T\\) is an arbitrary symmetric relation containing \\(R\\), it follows \\(s(R)=R\\cup R^{-1}.\\)"
  },
  {
    "objectID": "connect-everything.html#reflexive-transitive",
    "href": "connect-everything.html#reflexive-transitive",
    "title": "7  Connect Everything",
    "section": "7.6 Reflexive Transitive",
    "text": "7.6 Reflexive Transitive\n\nTheorem 7.11 Let \\(R\\) be relation on \\(X\\) and \\(A\\subseteq X.\\) The transitive closure of \\(R\\) and the reflexive transitive closure of \\(R\\) are \\[\nt(R)=\\bigcup_{n\\geq 1} R^n.\n\\qquad \\qquad\nrt(R)=\\bigcup_{n\\geq 0} R^n.\n\\] respectively.\n\n\nProof. For \\(i>0\\) define \\[\nR^i=R^{i-1}\\cup \\{(a,b) : \\exists c\\in X, (a,c)\\in R^{i-1} \\land (c,b)\\in R^{i-1}\\}\n\\] The transitive closure of \\(R\\), denoted by \\(t(R)\\), is the relation \\(t(R)=\\cup_{n\\geq 1} R^n.\\) First notice \\(t(R)\\) contains all powers of \\(R\\) and so in particular \\(t(R)\\) contains \\(R.\\) Next notice that \\(t(R)\\) is transitive since \\[\\begin{align*}\n\\qquad \\qquad & (a,b)\\in t(R) \\land (b,c)\\in t(R)\n\\implies \\exists R^n, R^m, (a,b)\\in R^n \\land (b,c)\\in R^m\n\\\\ & \\qquad \\implies (a,c) \\in R^m\\circ R^n\\subseteq t(R)\n\\end{align*}\\] Let \\(T\\) be a transitive relation containing \\(R.\\) By induction it follows \\(R^k\\subseteq T\\) for all \\(k.\\) This is true for \\(k=1\\) since \\(T\\) contains \\(R.\\) Then \\[\nR^k\\subseteq T\n\\implies R^{k+1}\n=R^{k}\\circ R\n\\subseteq T\\circ R\n\\subseteq T \\circ T\n=T\n\\] demonstrates the claim. Whence, \\(t(R)=\\bigcup_{n\\geq 1}R^n\\subseteq T\\) as desired.\nDefine \\(R^0=I\\), then \\[\nrt(R)=r\\left(\\bigcup_{n\\geq1}R^n\\right)\n= \\bigcup_{n\\geq1}R^n\\cup I\n= \\bigcup_{n\\geq1}R^n \\cup R^0\n= \\bigcup_{n\\geq0}R^n.\n\\] which completes the proof."
  },
  {
    "objectID": "connect-everything.html#transitive-closure",
    "href": "connect-everything.html#transitive-closure",
    "title": "7  Connect Everything",
    "section": "7.7 Transitive Closure",
    "text": "7.7 Transitive Closure\n\nTheorem 7.12 Let \\(R\\) be a relation on \\(X.\\) Then \\(R\\) is transitive if and only if \\(R^n\\subseteq R\\), for \\(n\\geq 1.\\)\n\n\nProof. Assume \\(R\\) is transitive. We will prove \\(R^n \\subseteq R\\) for \\(n\\geq 1\\) by induction. The basis step is obvious. The induction step is: \\[\nR^n\\subseteq R \\implies R^{n+1}\\subseteq R\n\\] Assume \\(R^n\\subseteq R\\) for some \\(n\\geq 1.\\) Then \\[\\begin{align*}\n(x,y)\\in R^{n+1}\n& \\Leftrightarrow \\exists z\\in X, (x,z)\\in R \\land (z,y)\\in R^n\n\\\\ & \\Leftrightarrow \\exists z\\in X, (x,z)\\in R \\land (z,y)\\in R\n\\implies (x,z)\\in R\n\\end{align*}\\] Therefore, by induction \\(R^n\\subseteq R\\), for all \\(\\geq 1.\\) Conversely, assume \\(R^n\\subseteq R\\), for all \\(n\\geq 1.\\) Then \\((x,y)\\in R\\land (y,z)\\in R \\implies (x,z)\\in R^2 \\implies (x,y)\\in R.\\) Thus, \\(R\\) is transitive.\n\n\nTheorem 7.13 Let \\(R\\) be a relation on \\(X.\\) If \\(R\\) is reflexive, then \\(s(R)\\) and \\(t(R)\\) are reflexive.\n\n\nProof. If \\(R\\) is reflexive, then \\(s(R)\\) and \\(t(R)\\) are reflexive, then \\[\nI\\subseteq R\\subseteq s(R)\n\\text{ and }\nI\\subseteq R \\subseteq t(R)\n\\] as desired.\n\n\nTheorem 7.14 Let \\(R\\) be a relation on \\(X.\\) If \\(R\\) is symmetric, then \\(r(R)\\) and \\(t(R)\\) are symmetric.\n\n\nProof. If \\(R\\) is symmetric, then \\(r(R)\\) and \\(t(R)\\) are symmetric. \\[\\begin{align*}\n& (x,y)\\in r(R)=R\\cup I \\implies (x,y)\\in R \\lor (x,y)\\in I \\\\\n& \\qquad \\implies (y,x)\\in R \\lor (y,x)\\in I \\implies (y,x)\\in R \\cup I =r(R)\\\\\n& (x,y)\\in t(R)= \\bigcup_{n\\geq 1}R^n \\implies \\exists R^n, (x,y)\\in R^n \\\\\n& \\qquad \\implies \\exists R^n, (y,x)\\in R^n \\implies (y,x)\\in \\bigcup_{n\\geq 1}R^n=t(R)\n\\end{align*}\\] which completes the proof.\n\n\nTheorem 7.15 Let \\(R\\) be a relation on \\(X.\\) If \\(R\\) is transitive, then \\(r(R)\\) is transitive; however, \\(s(R)\\) may not be transitive.\n\n\nProof. If \\(R\\) is transitive, then \\(r(R)\\) is transitive. \\[\\begin{align*}\n& (x,y)\\in r(R) \\land (y,z)\\in r(R)\n\\implies (x,y)\\in R\\cup I \\land (y,z)\\in R\\cup I\n\\\\ & \\qquad\n\\implies ((x,y)\\in R \\lor (x,y)\\in I)\\land ((y,z)\\in R \\lor (y,z)\\in I)\n\\\\ & \\qquad\n\\implies (x,z)\\in R \\lor (x,z)\\in I\n\\implies (x,z)\\in R \\cup I =r(R)\n\\end{align*}\\] Let \\(X=\\{a,b\\}\\) and \\(R=\\{(a,b)\\}.\\) Then \\(R\\) is transitive and \\(s(R)=\\{(a,b),(b,a)\\}\\) is not transitive. Therefore, the symmetric closure of a transitive relation may not be transitive.\n\n\nTheorem 7.16 Let \\(R\\) be a relation on \\(X.\\) The following hold: \\(rt(R)=tr(R)\\), \\(rs(R)=sr(R)\\), \\(st(R)\\subseteq ts(R)\\), and \\(st(R)\\subsetneq ts(R)\\) can hold.\n\n\nProof. The proof of each part follows.\n\n\\(rt(R)=tr(R)\\): \\[\ntr(R)\n=t(R\\cup I)=\\bigcup_{n\\geq 1} (R\\cup I)^n\n=\\left(\\bigcup_{n\\geq 1}R^n \\right) \\cup I\n=\\bigcup_{n\\geq 0} R^n =rt(R)\n\\]\n\\(rs(R)=sr(R)\\): \\[\\begin{align*}\n& rs(R) = r(R\\cup R^{-1}) = I\\cup R\\cup R^{-1} \\\\\n& =r(R)\\cup R^{-1} =r(R)\\cup (R^{-1}\\cup I) =r(R)\\cup r(R)^{-1} = sr(R)\n\\end{align*}\\]\n\\(st(R)\\subseteq ts(R)\\):\n\nLet \\(A=\\{a,b,c\\}.\\) Then \\(st(R)=\\{(a,b),(b,a),(b,c),(c,b),(a,c),(c,a)\\}\\) and \\(ts(R)=A\\times A\\) which completes the proof."
  },
  {
    "objectID": "connect-everything.html#equivalence-relation-characterization",
    "href": "connect-everything.html#equivalence-relation-characterization",
    "title": "7  Connect Everything",
    "section": "7.8 Equivalence Relation Characterization",
    "text": "7.8 Equivalence Relation Characterization\n\nTheorem 7.17 Let \\(R\\) be a relation on a set \\(X.\\) Then \\(R\\) is an equivalence relation if and only if \\(R=rts(R).\\)\n\n\nProof. Assume \\(R\\) is an equivalence relation on \\(X.\\) Notice \\(R\\subseteq rts(R)\\), where \\(r\\), \\(s\\), and \\(t\\) denote the reflexive, symmetric and transitive closure operators, respectively. Let \\(T\\) be an arbitrary equivalence relation on \\(X\\) containing \\(R\\). Since \\(R\\subseteq T\\) and \\(T\\) is symmetric, if follows that \\(s(R)\\subseteq T\\). Then \\(ts(R)\\subseteq t(T)=T\\) and so \\(rts(R)\\subseteq r(T)=T\\). Thus it follows \\(rts(R)\\) is contained in \\(T\\). Since \\(R\\) is an equivalence relation on \\(X\\) containing \\(R\\), it follows that \\(rts(R)\\subseteq R.\\) Whence, \\(R=rts(R).\\)\nConversely, assume \\(R\\) is a relation on \\(X\\) such that \\(R=rts(R).\\) It is easy to check that \\(ts(R)\\) is symmetric and that \\(rts(R)\\) is symmetric and transitive. It follows that \\(rts(R)\\) is an equivalence relation. Thus \\(R\\) is an equivalence relation.\n\n\nTheorem 7.18 Let \\(\\longrightarrow\\) be a relation on \\(X\\) with transitive closure denoted by \\(\\stackrel{+}{\\longrightarrow}.\\) Then \\(a\\stackrel{+}{\\longrightarrow} b\\) if and only if there exists elements \\(a=x_1, x_2, x_3, ..., x_n=b\\) in \\(X\\) such that \\(x_1\\longrightarrow x_2 \\longrightarrow \\cdots \\longrightarrow x_n.\\)\n\n\nProof. The proof is left for the reader."
  },
  {
    "objectID": "connect-everything.html#the-kernel-and-image-of-a-function",
    "href": "connect-everything.html#the-kernel-and-image-of-a-function",
    "title": "7  Connect Everything",
    "section": "7.9 The Kernel and Image of a Function",
    "text": "7.9 The Kernel and Image of a Function\n\nTheorem 7.19 Let \\(f:X\\to X\\) be a function and let \\(\\sim\\) be the binary relation defined on \\(X\\) by \\(a\\sim b\\) if and only if \\(f(a)=f(b).\\) Then \\(\\sim\\) is an equivalence relation.\n\n\nProof. Since \\(f(a)=f(a)\\) holds for all \\(a\\in X\\), it follows \\(\\sim\\) is reflexive. Let \\(a,b\\in X\\) and assume \\(a\\sim b.\\) Then \\(f(b)=f(a)\\), and thus \\(f(b)=f(a)\\) also holds. Thus, \\(b\\sim a\\) and so \\(\\sim\\) is also symmetric. Let \\(a,b,c\\in X\\) and assume \\(a\\sim b\\) and \\(b\\sim c.\\) Then \\(f(a)=f(b)\\) and \\(f(b)=f(c).\\) Thus \\(f(a)=f(c)\\) and so \\(a\\sim c\\), which means \\(\\sim\\) is also transitive; and in conclusion an equivalence relation on \\(X.\\)\n\nRecall, if \\(R\\) is a binary relation on \\(X\\), then \\(R(x)=\\{y\\in X : (x,y)\\in R\\}\\), that is \\(R(x)\\) is the set of outputs of \\(R\\) for a given input \\(x.\\) Of course when \\(R\\) is a function \\(R(x)\\) is a singleton set for each \\(x\\in X.\\) In general \\(R(x)\\) can have many elements.\n\nTheorem 7.20 Let \\(R\\) be a binary relation on \\(X\\) and let \\(\\ker(R)\\) be the relation defined on \\(X\\) by \\((a,b)\\in \\ker(R)\\) if and only if \\(R(a)=R(b).\\) Then \\(\\ker(R)\\) is an equivalence relation.\n\n\nProof. Since \\(R(a)=R(a)\\) holds for all \\(a\\in X\\), it follows \\(\\ker(R)\\) is reflexive. Let \\(a,b\\in X\\) and assume \\((a,b)\\in \\ker(R).\\) Then \\(R(b)=R(a)\\), and thus \\(R(b)=R(a)\\) also holds. Thus, \\((b,a)\\in\\ker(R)\\) and so \\(\\ker(R)\\) is also symmetric. Let \\(a,b,c\\in X\\) and assume \\((a,b)\\) and \\((b,c)\\in\\ker(R).\\) Then \\(R(a)=R(b)\\) and \\(R(b)=R(c).\\) Thus \\(R(a)=R(c)\\) and so \\((a,c)\\in\\ker(R)\\), which means \\(\\ker(R)\\) is also transitive; and in conclusion an equivalence relation on \\(X.\\)\n\nRecall, if \\(R\\) is a binary relation on \\(X\\), then \\(R^{-1}(y)=\\{x\\in X : (x,y)\\in R\\}\\), that is \\(R^{-1}(y)\\) is the set of inputs of \\(R\\) for a given output \\(y.\\) In general \\(R(y)\\) can have many elements.\n\nTheorem 7.21 Let \\(R\\) be a binary relation on \\(X\\) and let \\(\\textnormal{im}(R)\\) be the relation defined on \\(X\\) by \\((a,b)\\in \\textnormal{im}(R)\\) if and only if \\(R^{-1}(a)=R^{-1}(b).\\) Then \\(\\textnormal{im}(R)\\) is an equivalence relation.\n\n\nProof. Since \\(R^{-1}(a)=R^{-1}(a)\\) holds for all \\(a\\in X\\), it follows \\(\\textnormal{im}(R)\\) is reflexive. Let \\(a,b\\in X\\) and assume \\((a,b)\\in\\textnormal{im}(R).\\) Then \\(R^{-1}(b)=R^{-1}(a)\\), and thus \\({R^{-1}(b)=R^{-1}(a)}\\) also holds. Thus, \\((b,a)\\in\\textnormal{im}(R)\\) and so \\(\\textnormal{im}(R)\\) is also symmetric. Let \\(a,b,c\\in X\\) and assume \\((a,b)\\in\\textnormal{im}(R)\\) and \\((b,c)\\in\\textnormal{im}(R).\\) Then \\(R^{-1}(a)=R^{-1}(b)\\) and \\(R^{-1}(b)=R^{-1}(c).\\) Thus \\(R^{-1}(a)=R^{-1}(c)\\) and so \\((a,c)\\in\\textnormal{im}(R)\\), which means \\(\\textnormal{im}(R)\\) is also transitive; and in conclusion an equivalence relation on \\(X.\\)\n\n\nTheorem 7.22 Let \\(R\\) be a binary relation on \\(X.\\) Then \\(R\\) is an equivalence relation if and only if \\(\\ker(R)=R\\) if and only if \\(\\textnormal{im}(R)=R\\) if and only if \\(R=R^*.\\)\n\n\nProof. The proof is left as an exercise."
  },
  {
    "objectID": "connect-everything.html#exercises",
    "href": "connect-everything.html#exercises",
    "title": "7  Connect Everything",
    "section": "7.10 Exercises",
    "text": "7.10 Exercises"
  },
  {
    "objectID": "connect-everything.html#up-sets-and-down-sets",
    "href": "connect-everything.html#up-sets-and-down-sets",
    "title": "7  Connect Everything",
    "section": "7.11 Up-sets and Down-sets",
    "text": "7.11 Up-sets and Down-sets\nThroughout we assume \\((X,\\geq)\\) is an ordered set. By this we mean that \\(X\\) is a set and that \\(\\geq\\) is binary relation on \\(X\\) that is reflexive, antisymmetric, and transitive.\n\nDefinition 7.5 A subset \\(U\\) of \\(X\\) is called an up-set if \\[(x\\in U, \\, y\\in X, \\text{ and } y\\geq x) \\implies y\\in U.\\] A subset \\(D\\) of \\(X\\) is called a down-set if \\[ (x\\in D, \\, y\\in X, \\text{ and } x\\geq y) \\implies y\\in D.\\]\n\n\nTheorem 7.23 Let \\((X,\\geq)\\) be an ordered set.\n\nThe union or intersection of any family of up-sets is an up-set.\nThe complement of an up-set is a down-set.\n\n\n\nProof. (1): Let \\(\\{U_i : i \\in I\\}\\) be a family of up-sets. Let \\[\nU=\\bigcup_{i\\in I} U_i\n\\quad \\text{and} \\quad\nF=\\bigcap_{i\\in I} U_i.\n\\] We will show that \\(U\\) is an up-set. Let \\(x\\in U\\), \\(y\\in X\\) and assume \\(y\\geq x.\\) Since \\(x\\in U\\), it follows \\(x\\in U_i\\) for some \\(i.\\) Since \\(U_i\\) is an up-set, it follows \\(y\\in U_i.\\) Hence \\(y\\in U.\\) Next we will show \\(F\\) is an up-set. Let \\(x\\in F\\) and \\(y\\in X\\) and assume \\(y\\geq x.\\) Since \\(x\\in F\\), it follows \\(x\\in U_i\\) for all \\(i\\in I.\\) Since \\(U_i\\) are all up-sets, it follows \\(y \\in U_i\\) for all \\(i\\in I.\\) Hence \\(y\\in F.\\)\n(2): Let \\(U\\) be an up-set and let \\(D\\) be the complement of \\(U.\\) Let \\(x\\in D\\), \\(y\\in X\\), and assume \\(x\\geq y.\\) Assume \\(y\\in U.\\) Since \\(U\\) is an up-set and \\(x\\geq y\\), if follows \\(x\\in U.\\) However, \\(x\\in U\\) and \\(x\\in D\\) is a contradiction. Thus, \\(y\\in D\\) as needed.\n\n\nTheorem 7.24 The union or intersection of any family of down-sets is a down-set. The complement of a down-set is an up-set.\n\n\nDefinition 7.6 If \\(A\\) is an arbitrary subset of \\(X\\) and \\(x\\in X\\), then we define \\[\n{\\uparrow}(A)=\\{y\\in X : \\exists\\, x\\in A,\\, y\\geq x\\}\\quad \\text{and} \\quad  {\\uparrow}(x)=\\{y\\in X :  y\\geq x\\}.\n\\] \\[\n{\\downarrow}(A)=\\{y\\in X : \\exists\\, x\\in A,\\, x\\geq y\\}\n\\quad \\text{and} \\quad\n{\\downarrow}(x)=\\{y\\in X : x\\geq y\\},\n\\] to be the up-closure of \\(A\\), up-closure of \\(x\\), down-closure of \\(A\\), and the down-closure of \\(x\\), respectively. Up-sets of the form \\({\\uparrow}(x)\\) are called principal up-sets and dually, down-sets of the form \\({\\downarrow}(x)\\) are called principal down-sets.\n\nImportant special cases are \\({\\uparrow}(X)=X\\), \\({\\downarrow}(X)=X\\), \\({\\downarrow}{\\emptyset}=\\emptyset\\) and \\({\\uparrow}{\\emptyset}=\\emptyset.\\) Clearly,\n\\[\\begin{equation}\n\\label{isoequiv1}\n\\forall \\ x,y\\in X, \\quad x\\geq y\n\\, \\Longleftrightarrow \\,\n{\\uparrow}(x)\\subseteq {\\uparrow}{y}\n\\, \\Longleftrightarrow \\,\n{\\downarrow}(x)\\supseteq {\\downarrow}{y}.\n\\end{equation}\\]\nTo see this, suppose \\(x\\geq y\\), and assume \\(z\\in {\\uparrow}(x)\\) and \\(w\\in {\\downarrow}{y}.\\) Then by transitivity of \\(\\geq\\) we have \\(z\\in {\\uparrow}{y}\\) and \\(w\\in {\\downarrow}(x).\\) Conversely, both \\({\\uparrow}(x)\\subseteq {\\uparrow}{y}\\) and \\({\\downarrow}(x)\\supseteq {\\downarrow}{y}\\) imply that \\(x\\geq y\\) which follows by the reflexive property.\n\nTheorem 7.25 Assume \\(A\\subseteq X\\) and \\(x\\in X.\\) Then\n\n\\({\\downarrow}(A)\\) is the smallest down-set containing \\(A\\),\n\\(A\\) is an down-set if and only if \\(A=\\, {\\downarrow}(A)\\), and\n\\({\\downarrow}(x)=\\, {\\downarrow}(x).\\)\n\n\n\nProof. (1): Let \\(x\\in {\\downarrow}(A)\\), \\(y\\in X.\\) Assume \\(x\\geq y.\\) Since \\(x\\in {\\downarrow}(A)\\), there exists \\(z\\in A\\) such that \\(z\\geq x.\\) By transitivity \\(z\\geq y.\\) Thus it follows \\(y\\in {\\downarrow}(A).\\) Therefore, \\({\\downarrow}(A)\\) is an down-set. Let \\(D\\) be an down-set that contains \\(A.\\) We will show \\({\\downarrow}(A)\\subseteq D.\\) Let \\(x\\in {\\downarrow}(A).\\) Then there exists \\(z\\in A\\) such that \\(z\\geq x.\\) Since \\(z\\in A\\), it follows \\(z\\in D.\\) Since \\(D\\) is an down-set, it follows that \\(x\\in D\\), as a needed.\n(2): Suppose \\(A={\\downarrow}(A)\\), then by part \\(\\eqref{basicpos1}\\), it follows \\(A\\) is an down-set. Conversely, assume \\(A\\) is an down-set. By \\(\\eqref{basicpos1}\\), \\({\\downarrow}(A)\\) is the smallest down-set that contains \\(A\\), so it follows \\({\\downarrow}(A)\\subseteq A\\) since \\(A\\) is an down-set and \\(A\\subseteq A.\\) Let \\(x\\in A.\\) By the reflexive property of \\(\\geq\\), it follows \\(x\\geq x\\), and thus \\(x\\in {\\downarrow}(A).\\) Hence \\({\\downarrow}(A)=A.\\)\n(3): Immediately, \\(y\\in {\\downarrow}(x) \\Longleftrightarrow x\\geq y \\Longleftrightarrow y\\in {\\downarrow}(x)\\).\n\n\nTheorem 7.26 Let \\((X,\\geq)\\) be an ordered set with \\(A\\subseteq X\\) and \\(x\\in X.\\)\n\n\\({\\uparrow}(A)\\) is the smallest up-set containing \\(A\\).\n\\(A\\) is an up-set if and only if \\(A=\\, {\\uparrow}(A).\\)\n\\({\\uparrow}(x)=\\, {\\uparrow}(x)\\).\n\n\n\nProof. (1): Let \\(x\\in {\\uparrow}(A)\\), \\(y\\in X.\\) Assume \\(y\\geq x.\\) Since \\(x\\in {\\uparrow}(A)\\), there exists \\(z\\in A\\) such that \\(x\\geq z.\\) By transitivity \\(y\\geq z.\\) Thus it follows \\(y\\in {\\uparrow}(A).\\) Therefore, \\({\\uparrow}(A)\\) is an up-set. Let \\(U\\) be an up-set that contains \\(A.\\) We will show \\({\\uparrow}(A)\\subseteq U.\\) Let \\(x\\in {\\uparrow}(A).\\) Then there exists \\(z\\in A\\) such that \\(x\\geq z.\\) Since \\(z\\in A\\), it follows \\(z\\in U.\\) Since \\(U\\) is an up-set, it follows that \\(x\\in U\\), as a needed.\n(2): Suppose \\(A={\\uparrow}(A)\\), then by part \\(\\eqref{basicpos2}\\), it follows \\(A\\) is an up-set. Conversely, assume \\(A\\) is an up-set. By \\(\\eqref{basicpos1}\\), \\({\\uparrow}(A)\\) is the smallest up-set that contains \\(A\\), so it follows \\({\\uparrow}(A)\\subseteq A\\) since \\(A\\) is an up-set and \\(A\\subseteq A.\\) Let \\(x\\in A.\\) By the reflexive property of \\(\\geq\\), it follows \\(x\\geq x\\), and thus \\(x\\in {\\uparrow}(A).\\) Hence \\({\\downarrow}(A)=A.\\)\n(3): Immediately, \\(y\\in {\\uparrow}(x) \\Longleftrightarrow y\\geq x \\Longleftrightarrow y\\in {\\uparrow}(x)\\).\n\n\nTheorem 7.27 For all \\(x,y\\in X\\), \\[\nx\\geq y \\, \\Longleftrightarrow \\, {\\downarrow}(x)\\supseteq {\\downarrow}{y} \\, \\Longleftrightarrow \\, {\\uparrow}(x)\\subseteq {\\uparrow}{y}.\n\\]\n\n\nProof. Suppose \\(x\\geq y.\\) Let \\(z\\in {\\downarrow}{y}\\) then \\(y\\geq z.\\) By transitivity of \\(\\geq\\) we have \\(x\\geq z\\) and thus \\(z\\in {\\downarrow}(x).\\) Therefore we have shown, if \\(x\\geq y\\) then \\({\\downarrow}(x)\\supseteq {\\downarrow}{y}.\\) Conversely, assume \\({\\downarrow}(x)\\supseteq {\\downarrow}{y}.\\) By reflexivity of \\(\\geq\\) we have \\(y\\in {\\uparrow}{y}\\) and so \\(y\\in {\\downarrow}(x)\\), and thus \\(x\\geq y.\\) Now suppose \\(x\\geq y.\\) Let \\(z\\in {\\uparrow}(x).\\) Then \\(z\\geq x\\) and so by transitivity of \\(\\geq\\) we have \\(z\\geq y\\), and therefore \\(z\\in {\\uparrow}{y}.\\) Conversely, assume \\({\\uparrow}(x)\\subseteq {\\uparrow}{y}.\\) Then \\(x\\in {\\uparrow}{y}\\) and thus \\(x\\geq y.\\)\n\n\nTheorem 7.28 Let \\((X,\\geq)\\) be an ordered set with \\(A,B\\subseteq X.\\)\n\n\\({\\uparrow}(A)={\\uparrow}({\\uparrow}(A))\\)\n\\({\\uparrow}(A\\cup B)={\\uparrow}(A)\\ \\cup {\\uparrow}(B)\\)\n\\({\\uparrow}(A\\cap B)\\subseteq {\\uparrow}(A)\\ \\cap {\\uparrow}(B)\\)\n\\({\\uparrow}(A)=\\bigcup_{x\\in A} {\\uparrow}(x)\\)\n\\(B\\supseteq A\\Rightarrow {\\uparrow}(B)\\supseteq {\\uparrow}(A)\\)\n\n\n\nProof. (1): Immediately we have \\({\\uparrow}(A)\\subseteq {\\uparrow}({\\uparrow}(A)).\\) Let \\(x\\in {\\downarrow}({\\downarrow}(A)).\\) Then there exists \\(y\\in{\\downarrow}(A)\\) such that \\(y\\geq x\\) and there exists \\(a\\in A\\) such that \\(a\\geq y\\geq x.\\) Hence \\(x\\in {\\downarrow}(A)\\).\n(2): Let \\(x\\in {\\uparrow}(A\\cup B).\\) Then there exists \\(y\\in A\\cup B\\) such that \\(x\\geq y.\\) If \\(y\\in A\\), then \\(x\\in {\\uparrow}(A).\\) If \\(y\\in B\\), then \\(x\\in {\\uparrow}(B).\\) Hence, \\(x\\in {\\uparrow}(A)\\ \\cup {\\uparrow}(B).\\) Conversely, assume \\(x\\in {\\uparrow}(A) \\ \\cup {\\uparrow}(B).\\) If \\(x\\in {\\uparrow}(A)\\), then there exists \\(a\\in A\\) such that \\(x \\geq a.\\) Hence \\(a\\in A\\cup B\\) with \\(x\\geq a\\) which yields \\(x\\in {\\uparrow}(A\\ \\cup B).\\) If \\(x\\in {\\uparrow}(B)\\), then there exists \\(b\\in B\\) such that \\(x \\geq b.\\) Hence \\(b\\in A\\cup B\\) with \\(x\\geq b\\) which yields \\(x\\in {\\uparrow}(A\\ \\cup B)\\).\n(3): Let \\(x\\in {\\uparrow}(A\\cap B).\\) Then there exists \\(y\\in A\\cap B\\) such that \\(x\\geq y.\\) Hence \\(y\\in A\\) with \\(x\\geq y\\) and \\(y\\in B\\) with \\(x\\geq y.\\) Thus \\(x\\in {\\uparrow}(A)\\) and \\(x\\in {\\uparrow}(B)\\), and so \\(x\\in {\\uparrow}(A)\\ \\cap {\\uparrow}(B).\\)\n(4): Let \\(z\\in {\\uparrow}(A).\\) Then there exists \\(a\\in A\\) such that \\(z\\geq a.\\) Hence it follows that \\(z\\in {\\uparrow}(a)\\subseteq \\bigcup_{x\\in A} {\\uparrow}(x)\\).Conversely, assume \\(z\\in \\bigcup_{x\\in A} {\\uparrow}(x).\\) Then there exists \\(x\\in A\\) such that \\(z\\in {\\uparrow}(x).\\) Hence we have \\(x\\in A\\) with \\(z\\geq x.\\) Thus it follows that \\(z\\in {\\uparrow}(A)\\) as needed.\n\n\nTheorem 7.29 Let \\((X,\\geq)\\) be an ordered set with \\(A,B\\subseteq X.\\)\n\n\\({\\downarrow}(A)={\\downarrow}({\\downarrow}(A))\\)\n\\({\\downarrow}(A\\cup B)={\\downarrow}(A)\\ \\cup {\\downarrow}(B)\\)\n\\({\\downarrow}(A\\cap B)\\subseteq {\\downarrow}(A)\\ \\cap {\\downarrow}(B)\\)\n\\({\\downarrow}(A)=\\bigcup_{x\\in A} {\\downarrow}(x)\\)\n\\(B\\supseteq A\\Rightarrow {\\downarrow}(B)\\supseteq {\\downarrow}(A)\\)"
  },
  {
    "objectID": "connect-everything.html#monotone-mappings",
    "href": "connect-everything.html#monotone-mappings",
    "title": "7  Connect Everything",
    "section": "7.12 Monotone Mappings",
    "text": "7.12 Monotone Mappings\n\nDefinition 7.7 Let \\((X,\\leq_1)\\) and \\((Y,\\leq_2)\\) be ordered sets. A mapping \\(f: X \\to Y\\) is said to be isotone ( order-preserving) whenever \\[\n(\\forall \\, x,y\\in X) \\quad x \\leq_1 y \\implies f(x) \\leq_2 f(y)\n\\] or is said to be antitone ( order-reversing) whenever \\[\n(\\forall \\, x,y\\in X) \\quad x \\leq_1 y \\implies f(x) \\geq_2 f(y).\n\\] Furthermore, \\(f\\) is called monotone if \\(f\\) is either isotone or antitone.\n\n\nTheorem 7.30 For every function \\(f\\) on an ordered set \\((X,\\geq)\\), we denote it to be \\(\\uparrow\\), \\(\\downarrow\\), or \\(\\updownarrow\\) according to whether it is isotone, antitone, or both. The following are some easy consequences:\n\n\\(\\uparrow \\circ \\downarrow = \\downarrow \\circ \\uparrow = \\downarrow\\) (meaning that the composition of an isotone and an antitone maps is antitone),\n\\(\\uparrow \\circ \\uparrow = \\downarrow \\circ \\downarrow = \\uparrow\\) (meaning that the composition of two isotone or two antitone maps is isotone),\n\\(f\\) is \\(\\updownarrow\\) if and only if it is a constant on any chain in \\(A\\), and if this is the case, for every \\(a\\in A\\), \\(f^{-1}(a)\\) is a maximal chain in \\(A\\).\n\n\n\nProof. An exercise for the reader as Exercise 7.2."
  },
  {
    "objectID": "connect-everything.html#exercises-1",
    "href": "connect-everything.html#exercises-1",
    "title": "7  Connect Everything",
    "section": "7.13 Exercises",
    "text": "7.13 Exercises\n\nExercise 7.2 Prove Theorem 7.30.\n\n\nTheorem 7.31 A mapping \\(f:X\\to Y\\) is isotone if and only if the inverse image of every principal down-set of \\(Y\\) is a down-set of \\(X\\).\n\n\nProof. The proof follows as in MR2126425. First notice that \\[\\begin{equation}\n\\label{eq-inverseprinds}\n\\forall y\\in Y, \\quad x\\in f^{-1}({\\downarrow}(y)) \\Longleftrightarrow y\\geq f(x).\n\\end{equation}\\]\nSuppose that \\(f\\) is isotone. Let \\({\\downarrow}(y)\\) be an arbitrary principal down-set of \\(Y\\) and let \\(A=f^{-1}({\\downarrow}(y))\\). Assume \\(x\\in A\\), \\(z\\in X\\), and \\(x\\geq z\\). Since \\(f\\) is isotone, we have \\(f(x)\\geq f(z)\\).\nSince \\(x\\in A\\) it follows by \\(\\eqref{eq-inverseprinds}\\) that \\(y\\geq f(x)\\); and so we have \\(y\\geq f(z)\\) by transitivity of \\(\\geq\\). Thus \\(z\\in A\\) as needed. For conversely, notice that by reflexivity of \\(\\geq\\) and \\(\\eqref{eq-inverseprinds}\\) it follows that for every \\(x\\in X\\) we have \\(x\\in f^{-1}({\\downarrow}(f(x)))\\). By hypothesis, \\(f^{-1}({\\downarrow}(f(x)))\\) is a down-set of \\(X\\); so if \\(y\\in X\\) is such that \\(x\\geq y\\) we have \\(y\\in f^{-1}({\\downarrow}(f(x)))\\). By \\(\\eqref{eq-inverseprinds}\\), it follows that \\(f(x)\\geq f(y)\\) and therefore \\(f\\) is isotone.\n\n\nTheorem 7.32 If \\(X, Y\\) are ordered sets and if \\(f:X\\to Y\\) is any mapping then the following statements are equivalent.\n\n\\(f\\) is isotone;\nthe inverse image of every principal down-set of \\(Y\\) is a down-set of \\(X\\);\nthe inverse image of every principal up-set of \\(Y\\) is an up-set of \\(X\\).\n\n\n\nProof. (1)\\(\\Leftrightarrow\\)(2): Suppose that \\(f\\) is isotone. Let \\(y\\in Y\\) and let \\(A=f^{\\leftarrow}(y^{\\downarrow})\\). If \\(A\\neq\\emptyset\\) assume \\(x\\in A\\). Then for every \\(z\\in X\\) with \\(z\\leq x\\) we have \\(f(z)\\leq f(x)\\leq y\\) whence \\(z\\in A\\). Thus \\(A\\) is a down-set of \\(X\\). Conversely, notice that for every \\(x\\in X\\) we have \\(x\\in f^{\\leftarrow}[f(x)^{\\downarrow}]\\). By (2) this is a down-set of \\(X\\); so if \\(y\\in X\\) is such that \\(y\\leq x\\) we have \\(y\\in f^{\\leftarrow}[f(x)^{\\downarrow}]\\). If follows that \\(f(y)\\leq f(x)\\) and therefore \\(f\\) is isotone.\n(1)\\(\\Leftrightarrow\\)(2): Assume \\(f\\) is order preserving. Let \\(y\\in Y\\) and let \\(A=f^{\\leftarrow}(y^{\\uparrow})\\) be the inverse image of a principal down-set of \\(Y\\). To show \\(A\\) is an up-set of \\(X\\), assume \\(x\\in A\\). If \\(z\\in X\\) with \\(z\\geq x\\) we have \\(f(z)\\geq f(x) \\geq y\\) whence \\(z\\in A\\) as needed. Conversely assume \\(x\\leq y\\) and that \\(\\eqref{ipu}\\) holds. Notice \\(x\\in f^{\\leftarrow}(f(x)^{\\uparrow})\\) holds for all \\(x\\in X\\). By assumption, \\(f^{\\leftarrow} (f(x)^{\\uparrow})\\) is an up-set of \\(X\\), and so it follows \\(y\\in f^{\\leftarrow}(f(x)^{\\uparrow})\\). Whence \\(f(y)\\geq f(x)\\) as needed.\n\n\nTheorem 7.33 A mapping \\(f: X \\to Y\\) is an order-isomorphism if and only if \\(f\\) is bijective and both \\(f\\) and \\(f^{-1}\\) are isotone.\n\n\nProof. The proof follows as in davey2002introduction. Assume \\(f:X\\to Y\\) is a order-isomorphism. By definition \\(f\\) is surjective. Using the reflexive and antisymmetric properties we have \\[\\begin{align*}\nf(x)=f(y) & \\Longleftrightarrow f(x)\\geq f(y)\\text{ and } f(y)\\geq f(x) \\\\\n& \\Longleftrightarrow x\\geq y \\text{ and } y\\geq x \\\\\n& \\Longleftrightarrow x=y\n\\end{align*}\\] Thus \\(f\\) is injective and so bijective. Since \\[\n\\forall x,y\\in X, \\quad x=f^{-1}(f(x))=f^{-1}(f(y))=y \\Longleftrightarrow f(x)\\geq_2 f(y)\n\\] it follows both \\(f\\) and \\(f^{-1}\\) are isotone. Conversely, assume \\(f\\) is bijective and both \\(f\\) and \\(f^{-1}\\) are isotone. Obviously, \\(f\\) is surjective. Let \\(x,y\\in X\\). Assume \\(x\\geq y\\). Then \\(f(x)\\geq f(y)\\) since \\(f\\) is isotone. Now assume \\(f(x)\\geq f(y)\\). Since \\(f^{-1}\\) is isotone and \\(f^{-1}\\) is the inverse of \\(f\\), we have \\(x=f^{-1}(f(x))\\geq y=f^{-1}(f(y))\\) as needed to establish \\(\\eqref{red-iso}\\).\n\n\nTheorem 7.34 The mapping \\(\\phi: X\\to \\mathcal{X}\\) defined by \\[\n\\phi(x)= {\\downarrow}(x).\n\\] is an order-isomorphism onto the set of all principal down-sets of \\(X\\).\n\n\nProof. First notice that \\(\\phi\\) is a bijection to the principal down-sets: \\[\n\\phi(x)=\\phi(y)\n\\Longleftrightarrow {\\downarrow}(x) = {\\downarrow}(y)\n\\Longleftrightarrow y\\geq x \\text{ and } x\\geq y\n\\Longleftrightarrow x=y.\n\\] To show that \\(\\phi\\) is a order-isomorphism, observe \\(\\eqref{isoequiv}\\) yields \\(x\\geq y\\) if and only if \\(\\phi(y) \\subseteq \\phi(x)\\), and the claim follows."
  },
  {
    "objectID": "connect-everything.html#residuated-mappings",
    "href": "connect-everything.html#residuated-mappings",
    "title": "7  Connect Everything",
    "section": "7.14 Residuated Mappings",
    "text": "7.14 Residuated Mappings\nLet \\((X,\\geq)\\) and \\((Y,\\succeq)\\) be ordered sets.\n\nDefinition 7.8 A mapping \\(f:X\\to Y\\) is called if the inverse image of every principal down-set of \\(Y\\) is a principal down-set of \\(X\\).\n\n\nTheorem 7.35 A mapping \\(f:X\\to Y\\) is residuated if and only if it is isotone and there exists a isotone mapping \\(g:Y\\to X\\) such that \\[\\begin{equation}\n\\label{adj}\n\\forall \\, x\\in X,   (g\\circ f)(x) \\geq  x\n\\quad \\text{ and } \\quad\n\\forall y \\, \\in Y,   y\\succeq (f\\circ g)(y).\n\\end{equation}\\]\n\n\nProof. The proof follows as in page 6 MR2126425. Assume \\(f\\) is residuated. It follows that \\(f\\) is isotone. Notice the definition of residuated means: for all \\(y\\in Y\\) there exists \\(x\\in X\\) such that \\(f^{-1}({ \\downarrow}(y)) = { \\downarrow}(x)\\). Now for every given \\(y\\in Y\\) this element \\(x\\) is clearly unique [if \\(f^{-1}({ \\downarrow}(y))={ \\downarrow}(x)\\) and \\(f^{-1}({ \\downarrow}(y))={ \\downarrow}(z)\\), then \\(z\\geq x\\) and \\(x\\geq z\\)], so we can define a mapping \\(g:Y\\to X\\) by setting \\(g(y)=x\\). It follows that \\(g\\) is isotone:\n\\[\\begin{align*}\ny_1\\succeq y_2 & \\implies {\\downarrow}(y_2) \\subseteq {\\downarrow}(y_1) \\implies f^{-1}({\\downarrow}(y_2)) \\subseteq f^{-1}({\\downarrow}(y_1)) \\\\\n& \\implies {\\downarrow}(x_2) \\subseteq {\\downarrow}(x_1) \\implies {\\downarrow}(g(y_2))\\subseteq {\\downarrow}(g(y_1)) \\implies g(y_1)\\geq g(y_2).\n\\end{align*}\\] Further it follows \\(g(y)\\in {\\downarrow}(g(y))= { \\downarrow}(x)=f^{-1}({ \\downarrow}(y))\\), and so \\(y\\succeq (f\\circ g)(y)\\), for all \\(y\\in Y\\); and \\(x\\in f^{-1}({\\downarrow}(f(x)))={\\downarrow}(g(f(x)))\\) so that \\((g\\circ f)(x)\\geq x\\), for all \\(x\\in X\\). Conversely, assume \\(f\\) and \\(g\\) are isotone mappings such that \\(\\eqref{adj}\\) holds. Then on the one hand we have \\[\ny\\succeq f(x) \\implies g(y)\\geq g(f(x)) \\geq x\n\\] and on the other hand we have \\[\ng(y) \\geq x \\implies y \\succeq f(g(y)) \\succeq f(x).\n\\] It follows from these observations that \\(y\\succeq f(x)\\) if and only if \\(g(y)\\geq x\\). Therefore we have \\(f^{-1}({ \\downarrow}(y))={\\downarrow}(g(y))\\). Whence \\(f\\) is residuated.\n\n\nTheorem 7.36 If \\(f:X\\to Y\\) is a residuated, then an isotone mapping that satisfies \\(\\eqref{adj}\\) is unique, and is called the of \\(f\\) and is denoted by \\(f^+\\).\n\n\nProof. Suppose that \\(g, h:Y\\to X\\) are each isotone mappings that satisfy \\(\\eqref{adj}\\). Then \\[\n\\forall y\\in Y, \\quad  h(y)\\geq h((f\\circ g)(y)) = (h\\circ f)(g(y))\\geq g(y)\n\\] Similarly it follows \\(g(y)\\geq h(y)\\) and therefore \\(g=h\\).\n\nFor every non-empty set \\(X\\) the residuated mappings on \\(\\mathcal{X}\\) are completely described in the following result.\n\nTheorem 7.37 Let \\(X\\) be a non-empty set and let \\(R\\) be a binary relation on \\(X\\). Then the mapping \\(\\zeta_R :\\mathcal{X}\\to\\mathcal{X}\\) defined by \\[\n\\zeta_R(A)=\\{y\\in X : (\\exists \\, x\\in A) \\, \\, (x,y)\\in R\\}\n\\] is residuated. Moreover, every residuated mapping \\(f:\\mathcal{X}\\to\\mathcal{X}\\) is of this form for some binary relation \\(R\\) on \\(X\\).\n\n\nProof. The proof follows as in p. 8 MR2126425.\nLet \\(\\iota : \\mathcal{X} \\to \\mathcal{X}\\) be the antitone mapping that sends each subset of \\(X\\) to its complement and let \\(\\zeta_{R^{-1}}:\\mathcal{X} \\to \\mathcal{X}\\) be defined by \\[\n\\zeta_{R^{-1}}(A)=\\{y\\in X : (\\exists \\, x\\in A) \\, \\, (x,y)\\in R^{-1}\\}.\n\\] The mapping \\(\\zeta_{R}^+:\\mathcal{X} \\to \\mathcal{X}\\) defined by \\(\\zeta_{R}^+=\\iota\\circ \\zeta_{R^{-1}}\\circ \\iota\\) is isotone. To see this, let \\(A,B\\in \\mathcal{X}\\). Then it follows that \\[\\begin{align*}\nA\\subseteq B & \\implies \\iota(A)\\supseteq \\iota(B) \\implies \\zeta_{R^{-1}}(\\iota(A))\\supseteq \\zeta_{R^{-1}}(\\iota(B)) \\\\\n& \\implies (\\iota\\circ \\zeta_{R^{-1}})(\\iota(A))\\subseteq (\\iota\\circ \\zeta_{R^{-1}})(\\iota(B)) \\implies \\zeta^+_R(A) \\subseteq \\zeta^+_R(B).\n\\end{align*}\\] We claim that \\((\\zeta_R^+\\circ \\zeta_R)(A)\\supseteq A\\), for all \\(A\\in \\mathcal{X}\\). It suffices to show \\((\\zeta_{R^{-1}}\\circ \\iota \\circ \\zeta_R)(A)\\subseteq \\iota(A)\\) because then we have \\((\\zeta^+_R\\circ \\zeta_R)(A)=(\\iota\\circ \\zeta_{R^{-1}})(A)\\supseteq A\\) as required. To this end notice that \\[\\begin{align*}\ny\\in (\\zeta_{R^{-1}}\\circ \\iota \\circ \\zeta_R)(A) \\implies \\exists z\\in (\\iota\\circ \\zeta_R)(A), (y,z)\\in R\n\\end{align*}\\] Assume \\(y\\in A\\). Then \\(y\\in A\\) and \\((y,z)\\in R\\) which yields \\(z\\in \\zeta_R(A)\\). However, \\(z\\notin \\zeta_R(A)\\). Hence \\(y\\notin A\\) and so \\(y\\in \\iota(A)\\) as desired.\nNext we claim that \\((\\zeta_R\\circ \\zeta_R^+)(A)\\subseteq A\\), for all \\(A\\in \\mathcal{X}\\). Equivalently we show that \\((\\zeta_R\\circ \\iota\\circ \\zeta_{R^{-1}})(A) \\subseteq \\iota(A)\\), for all \\(A\\in \\mathcal{X}\\). Assume \\(y\\in (\\zeta_R\\circ \\iota\\circ \\zeta_{R^{-1}})(A)\\) and \\(y\\in A\\). Then there exists \\(z\\in (\\iota\\circ \\zeta_{R^{-1}})(A)\\) such that \\((y,z)\\in R^{-1}\\). Thus, \\(z\\in (\\iota\\circ \\zeta_{R^{-1}})(A)\\) and \\(z\\in \\zeta_{R^{-1}}(A)\\). This contradiction shows that \\(y\\notin A\\) as desired.\nTo see that every residuated mapping \\(f : \\mathcal{X} \\to \\mathcal{X}\\) is of this form for some binary relation \\(R\\) on \\(X\\), consider the relation \\(R_f\\) defined on \\(X\\) by \\[\n(x,y)\\in R_f \\Longleftrightarrow y\\in f(\\{x\\}).\n\\] Observe that \\(\\zeta_{R_f}(\\{x\\})=\\{y\\in X : (x,y)\\in R_f\\}\\), so that \\(f\\) and \\(\\zeta_{R_f}\\) agree on singletons. Now if \\(k: \\mathcal{X}\\to \\mathcal{X}\\) is any residuated mapping then, since it is isotone, for every non-empty subset \\(A\\) of \\(X\\) we have \\[\\begin{equation}\n\\label{kab}\nk(A)=k\\left(\\, \\bigcup_{x\\in A}\\{x\\}\\right)=\\bigcup_{x\\in A} k(\\{x\\}).\n\\end{equation}\\] To see that \\(\\ref{kab}\\) holds, notice that if \\(B=\\bigcup_{x\\in A} k(\\{x\\})\\) then clearly \\(k(A)\\supseteq B\\). On the other hand, \\(k(\\{x\\})\\subseteq B\\) for every \\(x\\in A\\) and so \\(\\{x\\}\\subseteq k^+(B)\\) whence \\(A=\\bigcup_{x\\in A}\\{x\\}\\subseteq k^+(B)\\). and therefore \\(k(A)\\subseteq B\\). Now \\(\\ref{kab}\\) applied to both \\(f\\) and \\(\\zeta_{R_f}\\), together with the fact that \\(f\\) and \\(\\zeta_{R_f}\\) agree on singletons we now have \\[\nf(A)\n=\\bigcup_{x\\in A} f(\\{x\\})\n=\\bigcup_{x\\in A} \\zeta_{R_f} (\\{x\\})\n=\\zeta_{R_f} (A).\n\\] Whence we obtain \\(f=\\zeta_{R_f}\\).\n\n\nTheorem 7.38 The set \\(\\text{Res}(X)\\) of residuated mappings \\(f : X \\to X\\) forms a semigroup, as does the set \\(\\text{Res}^+(X)\\) of residual mappings \\(f^+:X\\to X\\).\n\n\nProof. The proof follows as in p. 9 MR2126425. Clearly, \\(g\\circ f\\) and \\(f\\circ g\\) are isotone. Moreover, \\[\\begin{align*}\n& (f^+\\circ g^+)\\circ (g\\circ f)\\geq f^+\\circ \\text{id}_Y \\circ f=f^+\\circ f \\geq \\text{id}_X \\\\\n& (g\\circ f)\\circ (f^+\\circ g^+)\\leq g\\circ \\text{id}_Y \\circ g^+=g\\circ g^+ \\leq \\text{id}_Y\n\\end{align*}\\] Thus by the uniqueness of residuals, \\((g\\circ f)^+\\) exists and is \\(f^+\\circ g^+\\). Therefore if \\(f:X\\to Y\\) and \\(g:Y\\to X\\) are residuated, then \\(g\\circ f\\) is also residuated and \\((g\\circ f)^+=f^+\\circ g^+\\)."
  },
  {
    "objectID": "connect-everything.html#closure-operators",
    "href": "connect-everything.html#closure-operators",
    "title": "7  Connect Everything",
    "section": "7.15 Closure Operators",
    "text": "7.15 Closure Operators\nLet \\((X,\\geq)\\) be an ordered set.\n\nDefinition 7.9 An isotone mapping \\(f : X \\to X\\) is a on \\(X\\) if it is such that \\[\n\\forall \\, x\\in X,   f(x)=(f\\circ f)(x) \\geq x\n\\] and is called a on \\(X\\) if it is such that \\[\n\\forall \\, x\\in X,   x\\geq f(x)=(f\\circ f)(x)\n\\]\n\n\nTheorem 7.39 If \\(X\\) is an ordered set then \\(f : X \\to X\\) is a closure if and only if there is an ordered set \\(Y\\) and a residuated mapping \\(g : X \\to Y\\) such that \\(f = g^+ \\circ g\\).\n\n\nProof. The proof follows as in .\n\\(\\Rightarrow\\): Suppose that \\(f:X\\to X\\) is a closure. Let \\(R\\) be the kernel of \\(f\\), i.e. the equivalence relation on \\(X\\) defined by \\[\n(x,y)\\in R \\Longleftrightarrow f(x)=f(y).\n\\] Define the relation \\(\\sqsubseteq\\) on the quotient set \\(E/R\\) by \\[\n[x]_R \\sqsubseteq [y]_R \\Longleftrightarrow f(x)\\leq f(y).\n\\] It is readily seen that \\(\\sqsubseteq\\) is an order on \\(E/R\\) and, since \\(f\\) is isotone, the natural mapping \\(\\tau_R :X\\to X/R\\) is intone. Now since \\(f\\) is a closure every \\(R\\)-class has a top element, that in \\([x]_R\\) being \\(f(x)\\). We can therefore define a mapping \\(g:E/R\\to E\\) by setting \\(g([x]_R)=f(x)\\). We then have \\[\n\\begin{cases}\n(g\\circ \\tau_R)(x)=g([x]_R)=f(x)\\geq x; \\\\\n(\\tau\\circ g)([x]_R)=\\tau_R(f(x))=[f(x)]_R=[x]_R.\n\\end{cases}\n\\] It follows that \\(\\tau\\) is residuated with \\(\\tau_R^+=g\\) and that \\(f=\\tau_R^+\\circ \\tau_R\\).\n\\(\\Leftarrow\\): Suppose conversely that there is an ordered set \\(Y\\) and a residuated mapping \\(g : X \\to Y\\) such that \\(f = g^+ \\circ g\\). Then on the one hand \\(g^+ \\circ g \\geq \\text{id}_X\\); and on the other, by \\(\\ref{resprop}\\), \\(g = g \\circ g^+ \\circ g\\), so that \\(g^+ \\circ g = (g^+ \\circ g)^2\\). Since \\(g^+\\circ g\\) is isotone it follows that \\(f=g^+\\circ g\\) is a closure on \\(X\\).\n\n\nTheorem 7.40 Dually, \\(f : X \\to X\\) is a dual closure if and only if there is an ordered set \\(Y\\) and a residuated mapping \\(g : X \\to Y\\) such that \\(f = g \\circ g^+\\).\n\nIf \\(f : X \\to X\\) is a closure or a dual closure and if \\(x \\in \\text{Im} f\\) then \\(x = f(y)\\) for some \\(y \\in E\\), whence we obtain \\(f(x) = f^2(y) = f(y) = x\\). Consequently, we see that \\[\n\\text{Im}f = \\{x \\in E : f(x) = x\\},\n\\] the set of of \\(f\\). In short, the image of a closure is its set of fixed points.\n\nDefinition 7.10 A subset \\(A\\) of an ordered set \\(X\\) is called a (dual) closure subset if there is a (dual) closure \\(f : X \\to X\\) such that \\(A = \\text{Im} f\\).\n\n\nTheorem 7.41 A subset \\(A\\) of an ordered set \\(X\\) is a closure subset of \\(X\\) if and only if for every \\(x\\in X\\) the set \\(x^{\\uparrow} \\cap A\\) has a bottom element.\n\n\nProof. The proof follows as in . Suppose that \\(A\\) is a closure subset of \\(X\\) and let \\(f : X \\to X\\) be a closure such that \\(A = \\text{Im} f\\). Then for every \\(x \\in X\\) the set \\(x^{\\uparrow} \\cap A\\) is not empty since clearly it contains the element \\(f(x)\\). Moreover, if \\(z \\in x^{\\uparrow} \\cap A\\) then \\(x\\leq z\\) and \\(f(x)\\leq f(z)=z\\). Consequently \\(x^{\\uparrow} \\cap A\\) has a bottom element, namely \\(f(x)\\). Conversely, suppose that for every \\(x \\in X\\) the set \\(x^{\\uparrow} \\cap A\\) has a bottom element, \\(x_*\\) say, and consider the mapping \\(f : X \\to X\\) given by \\(f(x) = x_*\\). If \\(x\\leq y\\) then \\(x^{\\uparrow} \\supseteq y^{\\uparrow}\\) gives \\(x^{\\uparrow} \\cap A \\supseteq y^{\\uparrow} \\cap A\\) whence it follows that \\(x_* \\leq y_*\\) and so \\(f\\) is isotone. Moreover, since \\(f(x) = x_* \\geq x\\) for every \\(x \\in X\\) we also have \\(f\\geq \\text{id}_X\\). Now for any \\(y\\in A\\) we clearly have \\(y=y_*=f(y)\\in\\text{Im} f\\). Applying this to \\(f(x)=x_* \\in A\\) we obtain \\(f^2(x)=f(x)\\). Hence \\(f^2 =f\\) and so \\(f\\) is a closure with \\(\\text{Im} f = A\\).\n\nis Connections\nGalois connections are mathematical structures that allow us to model the relationships between objects in a given category. In this comprehensive guide, you’ll learn everything you need to know about these fascinating structures, including their properties and applications. With plenty of examples and exercises to help you along the way, this book is perfect for anyone looking to gain a deeper understanding of Galois connections.\nIn mathematics, a Galois connection is a structure that allows us to model the relationships between objects. In this comprehensive guide, you’ll learn everything you need to know about these fascinating structures, including their properties and applications. With plenty of examples and exercises to help you along the way, this book is perfect for anyone looking to gain a deeper understanding of Galois connections.\nGalois connections are a type of relationship between two sets that allows for mappings between the two sets. These mappings preserve (or reverse) certain properties, such as order or containment.\nGalois connections were first studied by French mathematician Evariste Galois, who developed the theory of algebraic equations. Galois connections have since been applied to fields such as computer science and linguistics. In computer science, they are used to define data structures and algorithms. In linguistics, they are used to describe the relationship between meaning and sound in language.\nGalois connections are a powerful tool for understanding relationships between sets.\nGalois connections have a number of interesting properties that make them useful for modeling relationships between objects.\nFirst, every Galois connection has an associated closure operator. This operator takes a set and returns a new set that is “closed” under the given Galois connection. That is, if you have a set A and a Galois connection between A and B, then the closure of A will be a subset of B that contains all the elements of A, plus any additional elements that can be reached from A via the given Galois connection.\nSecond, every Galois connection has an associated interior operator. This operator takes a set and returns a new set that is “open” under the given Galois connection. That is, if you have a set A and a Galois connection between A and B, then the interior of A will be a subset of B that contains all the elements of A, minus any elements that can’t be reached from A via the given Galois connection.\nThird, every Galois connection defines a partial order on its associated sets. That is, if you have a set A and a Galois connection between A and B, then the elements of A will be partially ordered by the given Galois connection.\nFourth, every Galois connection has an associated notion of distance. This distance is used to define a metric on the sets that are connected by the Galois connection. This metric allows us to measure how “far” one element is from another.\nFinally, every Galois connection has an associated notion of connectedness. This allows us to determine whether two elements are “connected” by the given Galois connection.\nGalois connections can be used to model a wide variety of relationships between objects. In computer science, they are used to define data structures and algorithms. In linguistics, they are used to describe the relationship between meaning and sound in language.\nGalois connections are also used in category theory, a branch of mathematics that deals with the structure of objects and their relationships. In particular, Galois connections are used to define adjunctions between categories.\nFinally, Galois connections can be used to study problems in physics and engineering. For example, they can be used to model the propagation of waves through a medium.\nGalois connections are a powerful tool for understanding relationships between sets. This book is a complete guide to the theory of Galois connections, with plenty of examples and exercises to help you along the way.\nThere are two ways to construct a Galois connection. The first is to start with a closure operator and an interior operator, and then to define the associated mapping between the sets. The second is to start with a partial order and a metric, and then to define the associated closure and interior operators.\nLet \\((X,\\preceq)\\) and \\((Y,\\leqslant)\\) be ordered sets.\n\nDefinition 7.11 If \\(f_*:X\\to Y\\) and \\(f^*:Y\\to X\\) are functions such that \\[\\begin{equation}\n\\label{gc}\nf_*(x)\\leqslant y  \\Longleftrightarrow x\\preceq f^*(y)\n\\end{equation}\\] for all \\(x\\in X\\) and all \\(y\\in Y\\), then \\((f_*, f^*)\\) is called a Galois connection between \\((X,\\preceq)\\) and \\((Y,\\leqslant)\\).\n\nThere are several definitions of Galois connections in the literature; however they are all order-isomorphic to the definition above.\n\nTheorem 7.42 Let \\(f_*:X\\to Y\\) and \\(f^*:Y\\to X\\) be functions. Then \\((f_*, f^*)\\) is a Galois connection if and only if\n\nboth \\(f_*\\) and \\(f^*\\) are monotone,\n\\(x\\preceq (f^*\\circ f_*)(x)\\) for all \\(x\\in X\\), and\n\\((f_* \\circ f^*)(y)\\leqslant y\\) for all \\(y\\in Y\\).\n\n\n\nProof. Suppose \\((f_*, f^*)\\) is a Galois connection. By \\(\\eqref{gc}\\) it follows \\[\nf_*(x)\\leqslant f_*(x)  \\Longleftrightarrow x\\preceq (f^*\\circ f_*)(x).\n\\] Since \\(\\leqslant\\) is reflexive, \\(x\\preceq (f^*\\circ f_*)(x)\\) follows immediately. Similarly, by \\(\\eqref{gc}\\) it follows \\[\n(f_*\\circ f^*)(y)\\leqslant y \\Longleftrightarrow f^*(y)\\preceq f^*(y)\n\\] proving that \\(\\eqref{gc3}\\) also holds. Assume \\(x_1\\preceq x_2\\). By \\(\\eqref{gc2}\\) we have \\(x_2\\preceq (f^*\\circ f_*)(x_2)\\). By \\(\\eqref{gc}\\) it follows \\(f_*(x_1)\\leqslant f_*(x_2)\\) and so \\(f_*\\) is monotone. Assume \\(y_1\\leqslant y_2\\). By \\(\\eqref{gc3}\\) we have \\((f_*\\circ f^*)(y_1)\\leqslant y_1\\). By \\(\\eqref{gc}\\) it follows \\(f^*(y_1)\\preceq f^*(y_2)\\) and so \\(f^*\\) is also monotone.\nConversely, assume \\(\\eqref{gc1}\\), \\(\\eqref{gc2}\\), and \\(\\eqref{gc3}\\) all hold. Assume \\(f_*(x)\\leqslant y\\). By \\(\\eqref{gc1}\\) and \\(\\eqref{gc2}\\), it follows \\((f^*\\circ f_*)(x)\\preceq f^*(y)\\) and \\(x\\preceq (f^*\\circ f_*)(x)\\), respectively. By transitivity of \\(\\preceq\\), we have \\(x\\preceq f^*(y)\\) as needed. Assume \\(x\\preceq f^*(y)\\). By \\(\\eqref{gc1}\\) and \\(\\eqref{gc3}\\), it follows \\(f_*(x)\\leqslant (f_*\\circ f^*)(y)\\) and \\((f_*\\circ f^*)(y)\\leqslant y\\). By transitivity of \\(\\leqslant\\), we have \\(f_*(x)\\leqslant y\\) as needed. Therefore, \\(\\eqref{gc}\\) holds and so \\((f_*, f^*)\\) is a Galois connection.\n\n\nTheorem 7.43 Let \\(f_*:X\\to Y\\) and \\(f^*:Y\\to X\\) be mappings. Then \\((f_*, f^*)\\) is a Galois connection if and only if \\[\nf^*(y) \\succeq x \\Longleftrightarrow y \\succeq f_*(x)\n\\]\n\n\nProof. Suppose \\(\\eqref{gc}\\) holds. Then \\[\nf_*(x) \\succeq f_*(x)  \\Longleftrightarrow (f^*\\circ f_*)(x) \\succeq x.\n\\] Since \\(\\succeq\\) is reflexive, \\((f^*\\circ f_*)(x)\\succeq x\\) follows immediately. Similarly, by \\(\\eqref{gc}\\) it follows \\[\ny \\succeq (f_*\\circ f^*)(y)  \\Longleftrightarrow f^*(y)\\succeq f^*(y)\n\\] proving that \\(\\eqref{galcon}\\) holds.\nAssume \\(x_2\\succeq x_1\\). By \\(\\eqref{galcon}\\) we have \\((f^*\\circ f_*)(x_2)\\succeq x_2\\succeq x_1\\). By \\(\\eqref{gc}\\) it follows \\(f_*(x_2)\\succeq f_*(x_1)\\) and so \\(f_*\\) is isotone. Assume \\(y_1\\succeq y_2\\). By \\(\\eqref{galcon}\\) we have \\(y_1\\succeq y_2 \\succeq (f_*\\circ f^*)(y_2)\\). By \\(\\eqref{gc}\\) it follows \\(f^*(y_1)\\succeq f^*(y_2)\\) and so \\(f^*\\) is also isotone.\nConversely, assume \\(\\eqref{galcon}\\) holds. Assume \\(y\\succeq f_*(x)\\). It follows \\(f^*(y)\\succeq (f^*\\circ f_*)(x)\\) and \\((f^*\\circ f_*)(x)\\succeq x\\) and so by transitivity of \\(\\succeq\\) we have \\(f^*(y)\\succeq x\\) as needed. Assume \\(f^*(y)\\succeq x\\). It follows \\((f_*\\circ f^*)(y)\\succeq f_*(x)\\) and \\(y\\succeq (f_*\\circ f^*)(y)\\) and so by transitivity of \\(\\succeq\\) we have \\(y\\succeq f_*(x)\\) as needed. Therefore \\(\\eqref{gc}\\) holds and so \\((f_*, f^*)\\) is a Galois connection.\n\n\nTheorem 7.44 If \\((f_*, f^*)\\) is a Galois connection between \\((X,\\preceq)\\) and \\((Y,\\leqslant)\\), then\n\n\\(f^*(y)=\\max\\{x\\in X : y\\succeq f_*(x)\\}\\),\n\\(f_*\\circ f^* \\circ f_*=f_*\\),\n\\(x\\in f^*(Y)\\) if and only if \\(x\\) is a fixed point of \\(f^*\\circ f_*\\),\n\\(f^*(Y)=(f^*\\circ f_*)(X)\\), and\n\n\n\nProof. \\(\\eqref{gcmax}\\): Let \\(M=\\{x\\in X: y\\succeq f_*(x)\\}\\). By \\(\\eqref{galcon}\\) we have \\(f^*(y)\\in M\\). Let \\(x\\in M\\). Then \\(y\\succeq f_*(x)\\) and since \\(f^*\\) is isotone, it follows \\(f^*(y)\\succeq (f^*\\circ f_*)(x)\\). By \\(\\eqref{galcon}\\), we have \\((f^*\\circ f_*)(x)\\succeq x\\). By transitivity of \\(\\succeq\\), we have \\(f^*(y)\\succeq x\\) and thus \\(f^*(y)\\) is the maximum of \\(M\\). \\(\\eqref{gcprop1}\\): By \\(\\eqref{galcon}\\) we have \\(f_*(x) \\succeq (f_*\\circ f^*\\circ f_*)(x)\\). By \\(\\eqref{gc}\\) with \\(x:=(f^*\\circ f_*)(x)\\) and \\(y:=f_*(x)\\) it follows \\((f_*\\circ f^* \\circ f_*)(x)\\succeq f_*(x)\\) using that \\(\\succeq\\) is reflexive.\nSince \\(\\succeq\\) is antisymmetric, it follows \\(f_*(x)=(f_*\\circ f^*\\circ f_*)(x)\\) for arbitrary \\(x\\). \\(\\eqref{gcprop3}\\): Clearly \\(x\\in f^*(Y)\\) is equivalent to \\(f^*(y)=x\\) for some \\(y\\in Y\\). Then \\[\n(f^*\\circ f_*)(x)=(f^*\\circ f_* \\circ f^*)(y)=f^*(y)=x\n\\] follows by the dual of \\(\\eqref{gcprop1}\\). \\(\\eqref{gcprop5}\\): It follows by \\(\\eqref{gcprop3}\\) that \\(f^*(Y)\\subseteq (f^*\\circ f_*)(X)\\). Conversely, let \\(x\\in (f^*\\circ f_*)(X)\\). Then \\(x=f^*(y)\\) for some \\(y\\in f_*(X)\\subseteq Y\\). By definition, \\(x\\in f^*(Y)\\) and so \\((f^*\\circ f_*)(X)\\subseteq f^*(Y)\\).\n\n::: {#thm-galois connection-injective } If \\((f_*, f^*)\\) is a Galois connection, then \\(f_*\\) is injective if and only if \\(f^*\\) is surjective if and only if \\(f_*\\circ f^*\\) is the identity. :::\n\nProof. By \\(\\ref{gcprop}\\), every element of \\(X\\) is a fixed element of \\(f^*\\circ f_*\\) if and only if \\(f^*(Y)=X\\). Thus \\(f^*\\) is surjective if and only if \\(f^*\\circ f_*\\) is the identity of \\(X\\). Assume \\(f^*\\circ f_*\\) is the identity of \\(X\\). Then \\[\nf_*(x)=f_(y)\\implies x=(f^*\\circ f_*)(x)=(f^*\\circ f_*)(y)=y\n\\] which shows \\(f_*\\) is injective. Conversely, if \\(f_*\\) is injective then, for arbitrary \\(x\\in X\\), \\((f_*\\circ f^*\\circ f_*)(x)=f_*(x)\\) implies \\((f^*\\circ f_*)(x)=x\\) and so \\(f^*\\circ f_*\\) is the identity of \\(X\\).\n\n\nTheorem 7.45 If \\((f_*,g)\\) and \\((f_*, h)\\) are Galois connections between \\((X,\\preceq)\\) and \\((Y,\\leqslant)\\), then \\(g=h\\). Likewise, if \\((g, f^*)\\) and \\((h,f^*)\\) are Galois connections between \\((X,\\preceq)\\) and \\((Y,\\leqslant)\\), then \\(g=h\\).\n\n\nProof. Let \\(f_*:X \\to Y\\) and \\(g:Y\\to X\\) be a Galois connection. Also let \\(f_*\\) and \\(h:Y\\to X\\) be a Galois connection. By \\(\\eqref{gc}\\) we have the following\n\\[\nf_*(x) \\leqslant y \\Longleftrightarrow x\\preceq g(y)\n\\] \\[\nf_*(x)\\leqslant y  \\Longleftrightarrow x\\preceq h(y)\n\\] By \\(\\eqref{ugc1}\\) we have \\((f_*\\circ h)(y)\\leqslant y \\Longleftrightarrow h(y)\\preceq g(y)\\).\nNotice \\((f_*\\circ h)(y)\\leqslant y\\) holds by \\(\\ref{gcch}\\).\\(\\eqref{gc3}\\); and thus \\(h(y)\\preceq g(y)\\).\nBy \\(\\eqref{ugc2}\\) we have \\((f_*\\circ g)(y)\\leqslant y \\Longleftrightarrow g(y)\\preceq h(y)\\).\nNotice \\((f_*\\circ g)(y)\\leqslant y\\) holds by \\(\\ref{gcch}\\).\\(\\eqref{gc3}\\); and thus \\(h(y)\\preceq g(y)\\).\nSince \\(\\preceq\\) is antisymmetric, it follows \\(g(y)=h(y)\\) for arbitrary \\(y\\). The second statement is the dual of the first and follows just as easily using \\(\\ref{gcch}\\).\\(\\eqref{gc2}\\).\n\n\nTheorem 7.46 If \\((f_*, f^*)\\) is a Galois connection between \\((X,\\preceq)\\) and \\((Y,\\leqslant)\\), then\n\n\\(f^*(y)=\\textrm{the maximum of } \\{x\\in X : f_*(x)\\leqslant y\\}\\) and\n\\(f_*(x)=\\textrm{the minimum of } \\{y\\in Y : x\\preceq f^*(y)\\}\\).\n\n\n\nProof. Let \\(M=\\{x\\in X: f_*(x)\\leqslant y\\}\\). By \\(\\ref{gcch}\\).\\(\\eqref{gc3}\\) we have \\(f^*(y)\\in M\\).\nLet \\(x\\in M\\).\nThen \\(f_*(x)\\leqslant y\\) and since \\(f^*\\) is monotone, it follows \\((f^*\\circ f_*)(x)\\preceq f^*(y)\\). By \\(\\ref{gcch}\\).\\(\\eqref{gc2}\\), we have \\(x\\preceq (f^*\\circ f_*)(x)\\). By transitivity of \\(\\preceq\\), we have \\(x\\preceq f^*(y)\\) and thus \\(f^*(y)\\) is the maximum of \\(M\\). For the second statement, let \\(N=\\{y\\in Y : x\\preceq f^*(y)\\}\\).\nBy \\(\\ref{gcch}\\).\\(\\eqref{gc2}\\) we have \\(f_*(x)\\in N\\).\nLet \\(y\\in N\\). Then \\(x\\preceq f^*(y)\\) and since \\(f_*\\) is monotone, it follows \\(f_*(x)\\leqslant (f_*\\circ f^*)(y)\\).\nBy \\(\\ref{gcch}\\).\\(\\eqref{gc3}\\), we have \\((f_*\\circ f^*)(y)\\leqslant y\\) and so by transitivity, it follows \\(f_*(x)\\leqslant y\\). Thus \\(f_*(x)\\) is the minimum of \\(N\\).\n\n\nTheorem 7.47 If \\((f_*, f^*)\\) is a Galois connection between \\((X,\\preceq)\\) and \\((Y,\\leqslant)\\), then\n\n\\(f_*\\circ f^* \\circ f_*=f_*\\), \\(f^*\\circ f_* \\circ f^*=f^*\\),\n\\(x\\in f^*(Y)\\) if and only if \\(x\\) is a fixed point of \\(f^*\\circ f_*\\),\n\\(y\\in f_*(X)\\) if and only if \\(y\\) is a fixed point of \\(f_*\\circ f^*\\),\n\\(f^*(Y)=(f^*\\circ f_*)(X)\\), and \\(f_*(X)=(f_*\\circ f^*)(Y)\\).\n\n\n\nProof. \\(\\eqref{gcprop1}\\): Using \\(\\ref{gcch}\\), we have \\(f_*(x)\\leqslant (f_*\\circ f^*\\circ f_*)(x)\\). By \\(\\eqref{gc}\\) with \\(x:=(f^*\\circ f_*)(x)\\) and \\(y:=f_*(x)\\) it follows \\((f_*\\circ f^* \\circ f_*)(x)\\leqslant f_*(x)\\) using that \\(\\preceq\\) is reflexive. Since \\(\\leqslant\\) is antisymmetric, it follows \\(f_*(x)=(f_*\\circ f^*\\circ f_*)(x)\\) for arbitrary \\(x\\), thus proving \\(\\eqref{gcprop1}\\) holds. \\(\\eqref{gcprop3}\\): By definition, \\(x\\in f^*(Y)\\) is equivalent to \\(f^*(y)=x\\) for some \\(y\\in Y\\). Then \\[\n(f^*\\circ f_*)(x)=(f^*\\circ f_* \\circ f^*)(y)=f^*(y)=x\n\\]\nfollows by \\(\\eqref{gcprop1}\\). \\(\\eqref{gcprop5}\\): It follows by \\(\\eqref{gcprop3}\\) that \\(f^*(Y)\\subseteq (f^*\\circ f_*)(X)\\). Conversely, let \\(x\\in (f^*\\circ f_*)(X)\\). Then \\(x=f^*(y)\\) for some \\(y\\in f_*(X)\\subseteq Y\\). By definition, \\(x\\in f^*(Y)\\) and so \\((f^*\\circ f_*)(X)\\subseteq f^*(Y)\\).\n\n\nTheorem 7.48 If \\((f_*, f^*)\\) is a Galois connection between \\((X,\\preceq)\\) and \\((Y,\\leqslant)\\), then\n\n\\(x \\preceq f^*(y) \\Longleftrightarrow f_*(x)\\leqslant (f_*\\circ f^*)(y) \\Longleftrightarrow f_*(x)\\leqslant y \\Longleftrightarrow (f^*\\circ f_*)(x)\\preceq f^*(y)\\),\n\\(f^*(x)\\preceq f^*(y) \\Longleftrightarrow (f_*\\circ f^*)(x)\\leqslant (f_*\\circ f^*)(y) \\Longleftrightarrow (f_*\\circ f^*)(x)\\leqslant y\\)\n\\(f_*(x)\\leqslant f_*(y) \\Longleftrightarrow (f^*\\circ f_*)(x)\\preceq (f^*\\circ f_*)(y) \\Longleftrightarrow x\\preceq (f^*\\circ f_*)(x)\\),\n\\(f^*(x)=f^*(y) \\Longleftrightarrow (f_*\\circ f^*)(x)=(f_*\\circ f^*)(y)\\), and\n\\(f_*(x)=f_*(y) \\Longleftrightarrow (f^*\\circ f_*)(x)=(f^*\\circ f_*)(y)\\).\n\n\n\nProof. For the first statement we have \\[\\begin{align*}\nx \\preceq f^*(y) & \\implies f_*(x)\\leqslant (f_*\\circ f^*)(y) \\implies f_*(x)\\leqslant y \\\\\n& \\implies (f^*\\circ f_*)(x) \\preceq f^*(y)  \\implies x\\preceq f^*(y)  \n\\end{align*}\\] For the third statement we have \\[\\begin{align*}\nf^*(x) \\preceq f^*(y) & \\implies (f_*\\circ f_*)(x)\\leqslant (f_*\\circ f^*)(y) \\implies (f_*\\circ f_*)(x)\\leqslant y\n\\end{align*}\\] For the fourth statement we have \\[\\begin{align*}\nf^*(x)=f^*(y) &  \\Longleftrightarrow f^*(x)\\preceq f^*(y) \\land f^*(y) \\preceq f^*(x) \\\\\n& \\Longleftrightarrow (f_*\\circ f^*)(x)\\leqslant (f_*\\circ f^*)(y) \\land  (f_*\\circ f^*)(y)\\leqslant (f_*\\circ f^*)(x) \\\\\n& \\Longleftrightarrow (f_*\\circ f^*)(x)=(f_*\\circ f^*)(y)\n\\end{align*}\\] The remaining statements are the dual and easily proved.\n\n\nDefinition 7.12 By an order isomorphism from an ordered set \\(X\\) to another ordered set \\(Y\\) we shall mean an isotone bijection \\(f:X\\to Y\\) whose inverse \\(f^{-1}: Y\\to X\\) is also an isotone.\n\n\nTheorem 7.49 Ordered sets \\((X,\\preceq)\\) and \\((Y,\\leqslant)\\) are isomorphic if and only if there is a surjective mapping \\(f:X\\to Y\\) such that \\[\nx\\preceq y  \\Longleftrightarrow f(x)\\leqslant f(y).\n\\]\n\n\nProof. The necessity is clear. Suppose conversely that such a surjective mapping \\(f\\) exists. Then \\(f\\) is also injective; for if \\(f(x)=f(y)\\) then from \\(f(x)\\leqslant f(y)\\) we obtain \\(x\\preceq y\\) and from \\(f(y)\\leqslant f(x)\\) we obtain \\(y\\preceq x\\), so that \\(x=y\\). Hence \\(f\\) is a bijection. Clearly, \\(f\\) is isotone; and so also is \\(f^{-1}\\), since \\(x\\preceq y\\) can be written \\(f(f^{-1}))(x)\\leqslant f(f^{-1})(y)\\) which gives \\(f^{-1}(x)\\preceq f^{-1}(y)\\).\n\n\nTheorem 7.50 If \\((f_*, f^*)\\) is a Galois connection between \\((X,\\preceq)\\) and \\((Y,\\leqslant)\\), then \\(f^*(Y)\\) and \\(f_*(X)\\) are order-isomorphic.\n\n\nProof. This follows immediately from \\(\\ref{gcch}\\) and \\(\\ref{posetiso}\\).\n\n\nTheorem 7.51 If \\((f_*, f^*)\\) is a Galois connection between \\((X,\\preceq)\\) and \\((Y,\\leqslant)\\), then \\(f^*\\circ f_*\\) is a closure function for \\(X\\) and \\(f_*\\circ f^*\\) is a co-closure function for \\(Y\\).\n\n\nProof. Let \\(x\\in X\\). Then \\(x\\preceq (f^*\\circ f_*)(x)\\) follows by \\(\\ref{gcch}\\).\\(\\eqref{gc2}\\). Since both \\(f^*\\) and \\(f_*\\) are monotone we have, \\(x_1\\preceq x_2 \\implies (f^*\\circ f_*)(x_1)\\preceq (f^*\\circ f_*)(x_2)\\). Thus \\(f^*\\circ f_*\\) is also monotone. By associativity of functions and \\(\\ref{gcprop}\\).\\(\\eqref{gcprop1}\\) we have \\[\n(f^*\\circ f_*)\\circ (f^*\\circ f_*)=f^*\\circ (f_*\\circ f^*\\circ f_*)=f^*\\circ f_*\n\\]\nas needed. The dual statement is proved just as easily.\n\nBy \\(\\ref{gcprop}\\), the closed elements of \\(f^*\\circ f_*\\) and \\(f_*\\circ f^*\\) are precisely the elements that are an image of some element under \\(f^*\\), respectively \\(f_*\\).\n\nTheorem 7.52 If \\(f\\) is a closure (respectively co-closure) function, then there is a Galois connection \\((f_*,f^*)\\) such that \\(f=f^*\\circ f_*\\) (respectively \\(f=f_*\\circ f^*\\)).\n\n\nProof. Let \\(f:X\\to X\\) be a closure over \\((X,\\preceq)\\). Let \\(\\overline{X}\\) be the set of closed elements of \\(f\\) that is \\(f(X)=\\overline{X}\\). We will construct a Galois connection between \\(\\overline{X}\\) and \\(X\\) using \\(\\ref{gcch}\\). Let \\(f_*=f\\), that is \\(f_*:X\\to \\overline{X}\\) defined by \\(f_*(x)=f(x)\\) for all \\(x\\in X\\). Let \\(f^*:\\overline{X}\\to X\\) be the inclusion mapping, that is \\(f^*(x)=x\\) for all \\(x\\in \\overline{X}\\). Notice \\(f_*\\circ f^*\\) is the identity on \\(\\overline{X}\\) and \\(f^*\\circ f_*=f\\).\n\nNotice \\(f_*\\) is monotone since \\(f\\) is monotone and that \\(f^*\\) is monotone since the identity is monotone.\nLet \\(x\\in X\\). Since \\(f\\) is extensive, we have \\(x\\preceq f(x)\\). Thus it follows, \\[\nx\\preceq f(x)=(f^*\\circ f)(x)=(f^*\\circ f_*)(x).\n\\]\nLet \\(y\\in \\overline{X}\\). There exists \\(x\\in X\\) such that \\(y=f(x)\\). Since \\(f\\) is idempotent we have \\[\nf(y)=(f\\circ f)(y)\\preceq y\n\\] for all \\(y\\in \\overline{X}\\) as needed.\n\nTherefore, \\((f_*,f^*)=(f,f^*)\\) where \\(f^*:\\overline{X}\\to X\\) is the inclusion mapping is a Galois connection between \\((X,\\prec0\\) and \\((\\overline{X},\\preceq)\\).\n\nRemark. A Galois connection is not uniquely determined by a closure.\n\nTheorem 7.53 Let \\(R\\) be a relation between \\(X\\) and \\(Y\\) and let \\[\\begin{align}\n& f_R(A)=\\{b\\in Y:\\forall a (a\\in A\\implies (a,b)\\in R) \\} \\\\\n& f^R(B)=\\{a\\in X:\\forall b (b\\in B\\implies (a,b)\\in R) \\}.\n\\end{align}\\] Then \\((f_R, f^R)\\) is a Galois connection between \\((P(X),\\subseteq)\\) and \\((P(Y),\\supseteq)\\)\n\n\nProof. Clearly, \\(f_R:P(X)\\to P(Y)\\) and \\(f^R:P(Y)\\to P(X)\\) are functions. By \\(\\eqref{gc}\\) we must show\n\\[\\begin{equation}\n\\label{gcrel}\nf_R(A)\\supseteq B  \\Longleftrightarrow A\\subseteq f^R(B)\n\\end{equation}\\]\nfor all \\(A\\in P(X)\\) and all \\(B\\in P(Y)\\). Assume \\(B\\subseteq f_R(A)\\). We will show \\(A\\subseteq f^R(B)\\). Let \\(x\\in A\\). If \\(y\\in B\\), then \\(y\\in f_R(A)\\). Then, by \\(\\eqref{gcrel1}\\), it follows \\((x,y)\\in R\\). So we have shown, \\(y\\in B\\implies (x,y)\\in R\\) as needed to show \\(x\\in f^R(B)\\) Conversely, assume \\(A\\subseteq f^R(B)\\). We will show \\(B\\subseteq f_R(A)\\). Let \\(y\\in B\\). If \\(x\\in A\\), then \\(x\\in f^R(B)\\).Then, by \\(\\eqref{gcrel2}\\), it follows \\((x,y)\\in R\\). So we have shown, \\(x\\in A\\implies (x,y)\\in R\\) as needed to show \\(y\\in f_R(A)\\). Therefore, \\(\\eqref{gcrel}\\) holds.\n\nA relation \\(R\\) is a subset of \\(X\\times Y\\) where \\(X\\) and \\(Y\\) are sets. If \\((a,b)\\in R\\), then we say \\(a\\) is related to \\(b\\) by \\(R\\) and we write \\(aRb\\). Whenever \\(X=Y\\) we say that \\(R\\) is a relation on \\(X\\).\n\nDefinition 7.13 A relation \\(R\\) on a set \\(X\\) is called\n\n reflexive if \\(aRa\\) for all \\(a\\in X\\),\n irreflexive if \\(\\neg(aRa)\\) for all \\(a\\in X\\),\n symmetric if \\(aRb\\) implies \\(bRa\\) for all \\(a,b\\in X\\),\n asymmetric if \\(aRb\\) implies \\(\\neg(bRa)\\) for all \\(a,b\\in X\\),\n antisymmetric if (\\(aRb \\text { and } bRa) \\Rightarrow a=b\\) for all \\(a,b\\in X\\),\n transitive if \\((aRb \\text{ and } bRc)\\Rightarrow aRc\\) for all \\(a,b,c\\in X\\),\n antitransitive if \\((aRb \\text{ and } bRc)\\Rightarrow \\neg(aRc)\\) for all \\(a,b,c\\in X\\),\na preorder if \\(aRb \\Leftrightarrow \\big(\\forall c\\in X \\ cRa \\Rightarrow cRb\\, \\big)\\) for all \\(a,b,c\\in X\\),\nan equivalence relation if \\(aRb \\Leftrightarrow \\big(\\forall c\\in X \\ cRa \\Leftrightarrow cRb\\, \\big)\\) for all \\(a,b,c\\in X\\).\n\n\nThe asymmetric part of a preorder \\(\\succeq\\) (denoted by \\(\\succ\\)) is called a , i.e. \\(\\succ\\) is a strict preorder means there holds\n\\[\\begin{equation}\n\\forall \\, a,b \\in X \\qquad\na\\succ b \\Leftrightarrow (a\\succeq b \\text{ and } b\\not\\succeq a).\n\\end{equation}\\]\nAssociated with any preorder are its and , namely (respectively) subsets of the form \\[\n{{\\downarrow}(a) = \\{x\\in X : a\\succeq x\\}}\n\\qquad \\text{and} \\qquad\n{{\\uparrow}(a) = \\{x\\in X : x\\succeq a\\}}.\n\\] If \\(A\\subseteq X\\), then \\(A\\) is called an whenever \\((x\\in A, \\, y\\in X, \\text{ and } y\\succeq x) \\Rightarrow y\\in A\\) and is called a whenever \\((x\\in A, \\, y\\in X, \\text{ and } x\\succeq y) \\Rightarrow y\\in A\\). A preorder relation \\(\\succeq\\) together with the underlying set is called a and is denoted by \\({(X,\\succeq)}\\). In particular, if \\(\\succeq\\) is also symmetric i.e. an equivalence relation (denoted by \\(\\sim\\)), then sets of the form\n\\[\n[a] = \\{x \\in X : a\\sim x\\} = {\\uparrow}(a) = {\\downarrow}(a).\n\\] are called equivalence classes (we denote the collection of all equivalence class by \\(\\overline{X}\\)). It is interesting that whenever we have a preorder \\(\\succeq\\) the relation \\(\\approx\\) prescribed on \\(X\\) by\n\\[\\begin{equation}\n\\forall \\, a,b \\in X \\qquad\na\\approx b \\Leftrightarrow (a\\succeq b \\text{ and } b\\succeq a)\n\\end{equation}\\]\nis an equivalence relation. Further, we say an element \\(a\\) of a subset \\(A\\) of \\(X\\) is a maximum (resp. ) minimum for \\(A\\) whenever \\(a\\succeq x\\) (\\(x \\succeq a\\)) for all \\(x\\in A\\). Let \\(M(A)\\) and \\(m(A)\\) denote the collection of maximums and minimums of a subset \\(A\\) of \\(X\\), respectively. In point, if either \\(a,b\\in M(A)\\) or \\(a,b\\in m(A)\\), then \\(a\\approx b\\).\n\nDefinition 7.14 A mapping \\(f: (X,\\succeq) \\to (Y,\\succeq)\\) between preordered sets is called\n\n isotone if \\(a \\succeq b \\Rightarrow f(a) \\succeq f(b)\\) for all \\(a,b\\in X\\),\n antitone if \\(a \\succeq b \\Rightarrow f(b) \\succeq f(b)\\) for all \\(a,b\\in X\\),\n monotone if it is either isotone or antitone.\n\nFurther, if \\(Y=X\\), then \\(f\\) is called 1. inflationary if \\(f(a)\\succeq a\\) for all \\(a\\in X\\), 2. deflationary if \\(a\\succeq f(a)\\) for all \\(a\\in X\\), 3. quasi-idempotent if \\(f(a)\\approx (f\\circ f)(a)\\) for all \\(a\\in X\\), 4. idempotent if \\(f(a)=(f\\circ f)(a)\\) for all \\(a\\in X\\), 5. a closure operator if \\(f(b)\\succeq a \\Leftrightarrow f(b)\\succeq f(a)\\) for all \\(a,b\\in X\\), 6. a kernel operator \\(a\\succeq f(b) \\Leftrightarrow f(a)\\succeq f(b)\\) for all \\(a,b\\in X\\).\n\nWe call a preorder relation \\(\\geq\\) on set \\(X\\) that is also antisymmetric a partial order and we say that \\((X,\\geq)\\) is an ordered set. A mapping \\(f:X\\to Y\\) between ordered sets \\({(X,\\geq)}\\) and \\({(Y,\\succeq)}\\) is called an isomorphism if it is surjective and \\({x \\geq y \\Leftrightarrow f(x) \\succeq f(y)}\\) for all \\(x,y\\in X\\); and is called a if it is surjective and \\(x \\geq y \\Leftrightarrow f(y) \\succeq f(x)\\) for all \\(x,y\\in X\\). A mapping \\(f: X \\to Y\\) is an isomorphism if and only if \\(f\\) is bijective and both \\(f\\) and \\(f^{-1}\\) are isotone. For any set \\(X\\), the mapping \\(\\phi: X\\to \\mathcal{X}\\) prescribed by \\({\\phi(x)= \\, {\\downarrow}{x}}\\) is an isomorphism onto the set of all principal down-sets of \\(X\\).\nIt is straightforward to show that a mapping \\(f\\) on a preordered (ordered) set is a closure if and only if it is isotone, inflationary, and quasi-idempotent (idempotent). For example, the reflexive (symmetric, transitive) closure of a relation \\(R\\) is the intersection of all reflexive (symmetric, transitive) relations that contain \\(R\\), respectively. We denote these closures by \\(r(R)\\), \\(s(R)\\), and \\(t(R)\\) respectively, and we find there holds\n\\[\\begin{equation}\n\\label{relclsoure}\nr(R)=R \\cup I_X, \\qquad\ns(R)=R \\cup R^{-1}, \\qquad\nt(R)=\\bigcup_{n\\geq 1} R^n.\n\\end{equation}\\]\nWe say that a relation \\(R\\) generates an equivalence relation \\(\\sim\\) whenever \\(\\sim = rts(R)\\).\n\nDefinition 7.15 Let \\(R\\) and \\(S\\) be relations on sets \\(X\\) and \\(Y\\), respectively, and let \\(f:X\\to Y\\) and \\(g:Y\\to X\\) be mappings. The pair \\((f,g)\\) is called\n\na covariant connection between \\((X,R)\\) and \\((Y,S)\\), denoted by \\({(f,g):(X,R) \\leftrightarrow (Y,S)}\\) whenever \\(g(b) \\,R\\, a \\Leftrightarrow b\\,S\\,f(a), \\forall \\, a\\in X, \\forall \\, b\\in Y.\\)\nan inverse covariant connection between \\((X,R)\\) and \\((Y,S)\\), denoted by \\({(f,g):(X,R) \\leftrightarrow (Y,S)}\\) whenever \\(a\\,R\\, g(b) \\Leftrightarrow f(a)\\,S\\,b, \\forall \\, a\\in X, \\forall \\, b\\in Y.\\)\na contravariant connection between \\((X,R)\\) and \\((Y,S)\\), denoted by \\({(f,g):(X,R) \\leftrightarrow (Y,S)}\\) whenever \\(g(b)\\,R\\,a \\Leftrightarrow f(a)\\,S\\,b, \\forall \\, a\\in X, \\forall \\, b\\in Y.\\)\nan inverse contravariant connection between \\((X,R)\\) and \\((Y,S)\\), denoted by \\({(f,g):(X,R) \\leftrightarrow (Y,S)}\\) whenever \\(a\\,R\\,g(b) \\Leftrightarrow b\\,S\\, f(a), \\forall \\, a\\in X, \\forall \\, b\\in Y.\\)\n\nGenerically, we say \\((f,g)\\) forms a connection between \\((X,R)\\) and \\((Y,S)\\), denoted by \\({(f,g):(X,R) \\leftrightarrow (Y,S)}\\) whenever \\(\\leftrightarrow\\,\\in\\{\\leftrightarrow, \\leftrightarrow,\\leftrightarrow,\\leftrightarrow\\}\\). \\footnote{The notation used here in defining a connection was found in (García-Pardo et al. 2013)).\n\n\nExample 7.1 If \\(f:X\\to Y\\) is a bijection then \\((f,f^{-1}):(X,=)\\leftrightarrow (Y,=)\\) is a connection of any type. More generally, if \\(f\\) is injective, then \\((f,f^{-1}):(X,=)\\leftrightarrow (\\text{Im} f,=)\\) is a connection of any type.\n\n\nExample 7.2 The collection of up-sets \\(\\tau^R\\) of a preorder relation \\(R\\) on a nonempty set \\(X\\) forms an Alexandroff topology on \\(X\\). Conversely, if \\(\\tau\\) is a topology on \\(X\\) and if \\(R^\\tau\\) denotes the relation on \\(X\\) prescribed by\n\\[\\begin{equation}\nb \\ R^\\tau a \\ \\Leftrightarrow \\ \\forall O\\in \\tau\\, ( b\\in O \\Rightarrow a\\in O ),\n\\end{equation}\\]\nfor all \\(a,b\\in X\\), then \\(R^\\tau\\) is a preorder relation on \\(X\\) (called the of \\(\\tau\\)). Also notice that we have mappings prescribed by\n\n\\(f:Q(X)\\to A(X), \\quad f(R)=\\tau^R\\)\n\n\\(g:A(X)\\to Q(X), \\quad g(\\tau)=R^\\tau\\)\n\nwhere \\(Q(X)\\) and \\(A(X)\\) denote the collection of all preorder relations and all Alexandroff topologies on a set \\(X\\), respectively. Then for any preorder relation \\(R\\) on \\(X\\), and any Alexandroff topology \\(\\tau\\) on \\(X\\), we have\n\\[\\begin{equation}\n(g\\circ f)(R)=R\n\\qquad \\text{ and } \\qquad\n(f\\circ g)(\\tau)=\\tau.\n\\end{equation}\\]\nIn other words, there is a natural bijection where \\(f\\) and \\(g\\) are inverses of each other. Hence \\((f,g)\\) forms a connection of any type and we see that preorder relations and Alexandroff topologies are essential the same. Of course the same can be said for the special case of equivalence relations and partitions.\n\nThe next four propositions are either elementary or can be found in .\n\nLemma 7.1 If \\((f,g)\\) and \\((f, h)\\) are contravariant connections between preordered sets \\((X,\\geq)\\) and \\((Y,\\succeq)\\), then \\(g\\approx h\\).\n\n\nProof. Suppose we have maps \\(f:X \\to Y\\), \\(g:Y\\to X\\), and \\(h:Y\\to X\\) such that\n\\[\\begin{align}\n\\label{ugc1}\ng(b)\\geq a \\Leftrightarrow  f(a)\\succeq b  \n\\qquad  (\\forall a\\in X, \\forall b\\in Y)  \\\\\n\\label{ugc2}\nh(b)\\geq a \\Leftrightarrow f(a)\\succeq b\n\\qquad  (\\forall a\\in X, \\forall b\\in Y)\n\\end{align}\\]\nWe have \\((f\\circ h)(b)\\succeq b\\) if and only if \\(g(b)\\geq h(b)\\). Notice \\((f\\circ h)(b)\\succeq b\\) holds; and thus \\(g(b)\\geq h(b)\\). We have \\((f\\circ g)(b)\\succeq b\\) if and only if \\(h(b)\\geq g(b)\\). Notice \\((f\\circ g)(b)\\succeq b\\) holds; and thus \\(h(b)\\geq g(b)\\). Hence \\(g(b)\\approx h(b)\\) for arbitrary \\(b\\).\n\n\nLemma 7.2 If \\(f:X\\to Y\\), \\(g:Y\\to X\\) are mappings between preordered sets \\((X,\\geq)\\) and \\((Y,\\succeq)\\), then the following are equivalent:\n\n\\((f,g):(X,\\geq) \\leftrightarrow (Y,\\succeq)\\) is a contravariant connection\n\\(f\\) and \\(g\\) are antitone maps, and \\(g\\circ f\\), \\(f\\circ g\\) are inflationary maps\n\\({\\downarrow} f(a)=g^{-1}({\\uparrow} a)\\), for all \\(a\\in X\\)\n\\({\\downarrow} g(b)=f^{-1}({\\uparrow} b)\\), for all \\(b\\in Y\\)\n\\(f\\) is antitone and \\(g(b)\\in M(f^{-1}({\\uparrow} b))\\) for all \\(b\\in Y\\).\n\\(g\\) is antitone and \\(f(a)\\in M(g^{-1}({\\uparrow} a))\\) for all \\(a\\in X\\).\n\n\n\nProof. (1)\\(\\Rightarrow\\)(2): Suppose \\({g(b)\\geq a \\Leftrightarrow f(a)\\succeq b}\\) for all \\(a\\in X\\) and \\(b\\in Y\\). It follows that \\((g\\circ f)(a)\\geq a\\) and \\((f\\circ g)(b)\\succeq b\\) since \\(\\succeq\\) is reflexive. Hence \\(g\\circ f\\), \\(f\\circ g\\) are inflationary maps. Assume \\(a_1\\geq a_2\\) for any \\(a_1, a_2\\in X\\). We have \\((g\\circ f)(a_1)\\geq a_1\\), and so by transitivity \\((g\\circ f)(a_1)\\geq a_2\\); hence \\(f(a_2)\\succeq f(a_1)\\). Assume \\(b_1\\succeq b_2\\) for any \\(b_1, b_2\\in X\\). We have \\((f \\circ g)(b_1)\\succeq b_1\\), and so by transitivity \\((f\\circ g)(b_1)\\succeq b_2\\); hence \\(g(b_2)\\geq g(b_1)\\).\n(2)\\(\\Rightarrow\\)(3):\nOn one hand we have \\(f(a)\\succeq b\\) implies \\({g(b) \\geq (g\\circ f)(a)\\geq a}\\) since \\(g\\) is antitone and \\(g\\circ f\\) is inflationary. Conversely we have \\(g(b)\\geq a\\) implies \\({f(a)\\succeq (f\\circ g)(b)\\succeq b}\\) since \\(f\\) is antitone and \\(f\\circ g\\) is inflationary. Hence \\({f(a)\\succeq b \\Leftrightarrow g(b)\\geq a}\\) as needed to prove that \\({\\downarrow} f(a)=g^{-1}({\\uparrow} a)\\).\n(3)\\(\\Rightarrow\\)(4):\nLet \\(a\\in X\\) and \\(b\\in Y\\) be arbitrary elements. We find \\[\\begin{align*}\ng(b)\\geq a \\Leftrightarrow g(b)\\in {\\uparrow} a \\Leftrightarrow b\\in g^{-1}({\\uparrow} a)={\\downarrow} f(a)\n\\Leftrightarrow f(a)\\succeq b \\Leftrightarrow a\\in f^{-1}({\\uparrow} b).\n\\end{align*}\\]\n(4)\\(\\Rightarrow\\)(5):\nAssume that \\(a_1\\geq a_2\\) for arbitrary elements \\(a_1, a_2\\in X\\). Since \\({f(a_1)\\geq f(a_1)}\\), clearly \\(a_1\\in f^{-1}({\\uparrow} f(a_1))\\).Further, since \\(f^{-1}({\\uparrow} f(a_1))={\\downarrow} g(f(a_1))\\) and \\(a_1\\geq a_2\\), it follows that \\(a_2\\in f^{-1}({\\uparrow} f(a_1))\\). Hence \\(f(a_2)\\succeq f(a_1)\\). For the second statement, let \\(a\\in f^{-1}({\\uparrow} b)\\). Then by hypothesis \\(g(b)\\geq a\\), as needed.\n(5)\\(\\Rightarrow\\)(6):\nAssume that \\(b_1\\succeq b_2\\) for arbitrary elements \\(b_1, b_2\\in Y\\). Since \\({g(b_1)\\in f^{-1}({\\uparrow} b_1)}\\) we have \\((f\\circ g)(b_1)\\succeq b_1 \\succeq b_2\\). Hence \\(g(b_1)\\in f^{-1}({\\uparrow} b_2)\\) and so \\(g(b_2)\\geq g(b_1)\\). Let \\(a\\in X\\) be arbitrary and assume that \\(b\\in g^{-1}({\\uparrow} a)\\). Then \\(g(b)\\geq a\\). Since \\(f\\) is antitone, we have \\(f(a)\\succeq (f\\circ g)(b)\\succeq b\\) since \\(g(b)\\in f^{-1}({\\uparrow} b)\\).\n(6)\\(\\Rightarrow\\)(1):\nAssume that \\(g(b)\\geq a\\). Then \\(b\\in g^{-1}({\\uparrow} a)\\) and so \\(f(a)\\succeq b\\) by hypothesis. Conversely, assume that \\(f(a)\\succeq b\\). Then \\(g(b)\\geq (g\\circ f)(a)\\geq a\\) as needed.\n\n\nLemma 7.3 If \\({(f,g):(X,\\geq) \\leftrightarrow (Y,\\succeq)}\\) is a connection between preordered sets then \\(f\\circ g\\) and \\(g\\circ f\\) are closures Moreover, there holds\n\nIf \\((f,g)\\) is a contravariant and inverse contravariant (covariant and inverse covariant) connection, then \\((g\\circ f)(a)\\approx a\\) for all \\(a\\in A\\) and \\((f\\circ g)(b)\\approx b\\) for all \\(b\\in B\\).\nIf \\((f,g)\\) is a (contravariant or inverse contravariant) connect and a (covariant or inverse covariant) connection, then \\(a_1\\geq a_2\\) implies \\(f(a_1)\\approx f(a_2)\\) for all \\(a_1,a_2\\in X\\) and \\(b_1\\succeq b_2\\) implies \\(g(b_1)\\approx g(b_2)\\) for all \\(b_1,b_2\\in Y\\).\n\n\n\nProof. We prove this for the case of contravariant connections and leave the other cases for the reader as an exercise. Assume \\({(f,g):(X,\\geq) \\leftrightarrow (Y,\\succeq)}\\) is a contravariant connection. By \\(\\ref{connprop}\\), \\(f\\) and \\(g\\) are antitone and so it follows that \\(f\\circ g\\) and \\(g\\circ f\\) are isotone. Since \\({f\\circ g}\\) is inflationary we have \\({(f\\circ g\\circ f)(a)\\succeq f(a)}\\). Since \\(g\\circ f\\) is inflationary we have \\({(g\\circ f)(a)\\geq a}\\) and so \\(f(a)\\succeq (f\\circ g\\circ f)(a)\\) since \\(f\\) is antitone. Hence\n\\[\\begin{equation}\n\\label{equivclosure}\n{(f\\circ g\\circ f)(a)\\approx f(a)}\n\\end{equation}\\]\nfor all \\(a\\in X\\). Further since \\(g\\) is antitone we have \\((g\\circ f\\circ g\\circ f)(a) \\succeq (g\\circ f)(a)\\) and \\({(g\\circ f)(a) \\succeq (g\\circ f\\circ g\\circ f)(a)}\\). Thus \\(g\\circ f\\) is quasi-idempotent. Since \\(g\\circ f\\) is inflationary we have \\({(g\\circ f\\circ g)(b)\\succeq g(b)}\\). Since \\(f\\circ g\\) is inflationary we have \\({(f\\circ g)(b)\\geq b}\\) and so \\({g(b)\\succeq (g\\circ f\\circ g)(b)}\\) since \\(g\\) is antitone. Hence \\({(g\\circ f\\circ g)(b)\\approx g(b)}\\) for all \\(b\\in Y\\). Further since \\(f\\) is antitone we have \\((f\\circ g\\circ f\\circ g)(b) \\geq (f\\circ g)(b)\\) and \\({(f\\circ g)(b) \\succeq (f\\circ g\\circ f\\circ g)(b)}\\). Thus \\(f\\circ g\\) is quasi-idempotent.\n\nSuppose that \\((f,g)\\) is both a contravariant and inverse contravariant connection. Since \\(g\\circ f\\) is both inflationary and deflationary, we have \\((g\\circ f)(a)\\geq a\\) and \\(a\\geq (g\\circ f)(a)\\) and so \\((g\\circ f)(a)\\approx a\\). Since \\(f\\circ g\\) is both inflationary and deflationary, we have \\((f\\circ g)(b)\\geq b\\) and \\(b\\geq (f\\circ g)(b)\\) and so \\((f\\circ g)(b)\\approx b\\).\nSuppose that \\((f,g)\\) is both a contravariant and a covariant connection and assume that \\(a_1\\geq a_2\\). Since \\(f\\) is isotone and antitone, we have \\(f(a_1)\\succeq f(a_2)\\) and \\(f(a_2)\\succeq f(a_1)\\) as needed. If \\(b_1\\succeq b_2\\), then since \\(g\\) is isotone and antitone, we have \\(g(b_1)\\geq g(b_2)\\) and \\(g(b_2)\\geq g(b_1)\\) as needed.\n\n\n\nLemma 7.4 If \\((X,\\geq)\\) and \\((Y,\\succeq)\\) are preordered sets, there holds\n\\[\\begin{equation}\n\\label{connandpre}\n{(f,g):(X,\\geq) \\leftrightarrow (Y,\\succeq)} \\Rightarrow\n{(f_\\approx,g_\\approx):(\\overline{X},\\geqq) \\leftrightarrow (\\overline{Y},\\succsim)}\n\\end{equation}\\]\nwhere \\(f_\\approx([a])=[f(a)]\\) for all \\(a\\in X\\), \\(g_\\approx([b])=[g(b)]\\) for all \\(b\\in B\\), and \\({\\leftrightarrow\\,\\in\\{\\leftrightarrow, \\leftrightarrow,\\leftrightarrow,\\leftrightarrow\\}}\\).\n\n\nProof. We prove this for the case of contravariant connections and leave the other cases for the reader as an exercise. Assume \\({(f,g):(X,\\geq) \\leftrightarrow (Y,\\succeq)}\\) is a contravariant connection. We are assuming that \\(g(b)\\,\\geq\\,a \\Leftrightarrow f(a)\\,\\succeq\\,b\\) for all \\({a\\in X, b\\in Y}\\). We must show that \\({g_\\approx([b])\\,\\geqq\\,[a] \\Leftrightarrow f_\\approx([a])\\,\\succsim\\,[b]}\\) for all \\({[a]\\in \\overline{X}, [b]\\in \\overline{Y}}\\).\nSuppose that \\({g_\\approx([b])\\,\\geqq\\,[a]}\\). Then \\([g(b)]\\,\\geqq\\,[a]\\) and so \\({g(b)\\geq a}\\), hence \\({f(a)\\succeq b}\\). Thus we have that \\({f_\\approx([a])=[f(a)]\\succsim [b]}\\) as needed. Now suppose that \\({f_\\approx([a])\\,\\succsim\\,[b]}\\). Then \\({[f(a)]\\,\\succsim\\,[b]}\\) and so \\({f(a)\\succeq b}\\), hence \\(g(b)\\geq a\\). Thus we have that \\({g_\\approx([b])=[g(b)]\\succsim [a]}\\) as needed.\n\n\n\n\n\nGarcía-Pardo, F., I. P. Cabrera, P. Cordero, and Manuel Ojeda-Aciego. 2013. “On Galois Connections and Soft Computing.” In Advances in Computational Intelligence, edited by Ignacio Rojas, Gonzalo Joya, and Joan Cabestany, 7903:224–35. Lecture Notes in Computer Science. Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-642-38682-4_26."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Cantor, Georg. 1883. “Ueber Unendliche, Lineare\nPunktmannichfaltigkeiten.” Math. Ann. 21\n(4): 545–91. https://doi.org/10.1007/BF01446819.\n\n\nGarcía-Pardo, F., I. P. Cabrera, P. Cordero, and Manuel Ojeda-Aciego.\n2013. “On Galois Connections and Soft Computing.” In\nAdvances in Computational Intelligence, edited by Ignacio\nRojas, Gonzalo Joya, and Joan Cabestany, 7903:224–35. Lecture Notes in\nComputer Science. Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-642-38682-4_26.\n\n\nHalmos, Paul R. 1974. Naive Set Theory. Springer-Verlag, New\nYork-Heidelberg.\n\n\nMoore, Gregory H. 2012. Zermelo’s Axiom of Choice: Its Origins,\nDevelopment, and Influence. Courier Corporation.\n\n\nSzpilrajn, Edward. 1930. “Sur l’extension de l’ordre\nPartiel.” Fundamenta Mathematicae 16 (1): 386–89.\n\n\nTourlakis, George. 2003. Lectures in Logic and Set Theory: Volume 2,\nSet Theory. Vol. 83. Cambridge University Press."
  }
]