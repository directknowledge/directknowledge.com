<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.280">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<meta name="description" content="Learning Linear Algebra">
<title>Eigenvalues and Eigenvectors - Learning Linear Algebra</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>
<meta name="quarto:offset" content="./">
<link href="./canonical-forms.html" rel="next">
<link href="./determinants.html" rel="prev">
<link href="./../assets/favicon.ico" rel="icon">
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>
<style>
@media screen and (max-width: 440px) {
    .navbar-brand-logo::after {
        content: 'DK'!important;
        margin-top: -4px!important;
    }
    .navbar-toggler-icon {
        width:26px!important;
        height:26px!important;
    }
    .navbar-toggler {
        border:0px!important;
    }
    .navbar-title {
        display:none!important;
    }
    .footer-items {
        display:block!important;
        margin:40px 0px;
    }    
}
.navbar-title:hover, .navbar a:hover {
    color:#000000!important;
}
.book-title {
    font-weight:800;
    text-transform: uppercase;
    font-size: 150%;
    margin:-20px -20px 20px -20px;
    line-height:120%;
    text-decoration: none!important;
    display:block;
}
@media screen and (max-width: 990px) {
    .book-title {
        padding-left: 20px!important;
    }    
}
</style>
  
<meta property="og:title" content="Eigenvalues and Eigenvectors - Learning Linear Algebra">
<meta property="og:description" content="Learning Linear Algebra">
<meta property="og:site-name" content="Learning Linear Algebra">
</head>
<body class="nav-sidebar floating nav-fixed">
<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a href="./index.html" class="navbar-brand navbar-brand-logo">
    <img src="./../assets/directknowledge-logo.svg" alt="Direct Knowledge Logo" width="28" height="24"  class="navbar-logo">
    </a>
    <a aria-label="Learning Linear Algebra" class="navbar-brand" href="https://directknowledge.com">
    <span class="navbar-title">Direct Knowledge</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-books" role="button" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Books</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-books">    
        <li>
    <a class="dropdown-item" href="https://directknowledge.com/basic-set-theory/"><i class="bi bi-book" role="img" aria-label="Basic Set Theory Book">
</i> 
 <span class="dropdown-text">Basic Set Theory</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://directknowledge.com/learning-number-theory/"><i class="bi bi-book" role="img" aria-label="Learning Linear Algebra Book">
</i> 
 <span class="dropdown-text">Learning Number Theory</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://directknowledge.com/learning-linear-algebra/"><i class="bi bi-book" role="img" aria-label="Learning Linear Algebra Book">
</i> 
 <span class="dropdown-text">Learning Linear Algebra</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://directknowledge.com/single-variable-calculus/"><i class="bi bi-book" role="img" aria-label="Single Variable Calculus Book">
</i> 
 <span class="dropdown-text">Single Variable Calculus</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://directknowledge.com/multivariable-calculus/"><i class="bi bi-book" role="img" aria-label="Multivariable Calculus Book">
</i> 
 <span class="dropdown-text">Multivariable Calculus</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="http://directknowledge.com/about.html">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.youtube.com/channel/UCi_E35l9kKfrxoQJRMbgMsg/"><i class="bi bi-youtube" role="img" aria-label="YouTube">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/directknowledge/directknowledge.com"><i class="bi bi-github" role="img" aria-label="Source Code">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Eigenvalues and Eigenvectors</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
      <div class="mt-2 flex-shrink-0 align-items-center">
        <a class="book-title" href="https://directknowledge.com/learning-linear-algebra/">Learning Linear Algebra</a><div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Preface</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./systems-of-linear-equations.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Systems of Linear Equations</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./vector-spaces.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Vector Spaces</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./linear-transformations.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Linear Transformations</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./inner-products-spaces.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Inner Products Spaces</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./determinants.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Determinants</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./eigenvalues-and-eigenvectors.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Eigenvalues and Eigenvectors</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./canonical-forms.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Canonical Forms</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">References</a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><a href="https://directknowledge.com/learning-linear-algebra/"><picture><source type="image/webp" srcset="../../assets/learning-linear-algebra-cover.webp"><source type="image/webp" srcset="../../assets/learning-linear-algebra-cover-thumbnail.png"><img class="shadow border" style="margin-bottom:12px;" width="192" height="288" src="../../assets/learning-linear-algebra-cover.png" alt="Learning Linear Algebra Book Cover"></picture></a>
    <h2 id="toc-title">Chapter Contents</h2>
   
  <ul>
  <li><a href="#diagonalization" id="toc-diagonalization" class="nav-link active" data-scroll-target="#diagonalization"><span class="toc-section-number">6.1</span>  Diagonalization</a></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/directknowledge/directknowledge.com/issues/new" class="toc-action">Report an issue</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">
<header id="title-block-header">
<h1 class="title d-none d-lg-block display-7"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Eigenvalues and Eigenvectors</span></h1>
</header>
<div class="d-none">
<p><span class="math inline">\(\newcommand{\vlist}[2]{#1_1,#1_2,\ldots,#1_#2}\)</span> <span class="math inline">\(\newcommand{\vectortwo}[2]{\begin{bmatrix} #1 \\ #2\end{bmatrix}}\)</span> <span class="math inline">\(\newcommand{\vectorthree}[3]{\begin{bmatrix} #1 \\ #2 \\ #3\end{bmatrix}}\)</span> <span class="math inline">\(\newcommand{\vectorfour}[4]{\begin{bmatrix} #1 \\ #2 \\ #3 \\ #4\end{bmatrix}}\)</span> <span class="math inline">\(\newcommand{\vectorfive}[5]{\begin{bmatrix} #1 \\ #2 \\ #3 \\ #4 \\ #5 \end{bmatrix}}\)</span> <span class="math inline">\(\newcommand{\lincomb}[3]{#1_1 \vec{#2}_1+#1_2 \vec{#2}_2+\cdots + #1_m \vec{#2}_#3}\)</span> <span class="math inline">\(\newcommand{\norm}[1]{\left|\left |#1\right|\right |}\)</span> <span class="math inline">\(\newcommand{\ip}[1]{\left \langle #1\right \rangle}\)</span> <span class="math inline">\(\newcommand{\plim}[2]{\lim_{\footnotesize\begin{array}{c} \\[-10pt] #1 \\[0pt] #2 \end{array}}}\)</span></p>
</div>
<p>Let <span class="math inline">\(\mathbb{F}\)</span> be either the real numbers or the complex numbers. A nonzero vector <span class="math inline">\(\vec v\)</span> in <span class="math inline">\(\mathbb{F}^n\)</span> is called an of an <span class="math inline">\(n\times n\)</span> matrix <span class="math inline">\(A\)</span> if <span class="math inline">\(A \vec v\)</span> is a scalar multiple of <span class="math inline">\(\vec v\)</span>, that is <span class="math inline">\(A \vec v= \lambda \vec v\)</span> for some scalar <span class="math inline">\(\lambda\)</span>. Note that this scalar <span class="math inline">\(\lambda\)</span> may be zero. The scalar <span class="math inline">\(\lambda\)</span> is called the <strong>eigenvalue</strong> associated with the eigenvector <span class="math inline">\(\vec v\)</span>. Even though, <span class="math inline">\(A\vec 0=\lambda \vec 0\)</span> we do not call <span class="math inline">\(\vec 0\)</span> an eigenvector. Of course a matrix need not have any eigenvalues or eigenvectors, but notice if <span class="math inline">\(\vec v\)</span> is an eigenvector of matrix <span class="math inline">\(A\)</span>, then <span class="math inline">\(\vec v\)</span> is an eigenvector of matrices <span class="math inline">\(A^2\)</span>, <span class="math inline">\(A^3\)</span>, as well, with <span class="math inline">\(A^t\vec v=\lambda^t \vec v,\)</span> for all positive integers <span class="math inline">\(t\)</span>. If <span class="math inline">\(\mathbb{F}=\mathbb{C}\)</span>, then counting multiplicities, every <span class="math inline">\(n\times n\)</span> matrix has exactly <span class="math inline">\(n\)</span> eigenvalues.</p>
<p>If <span class="math inline">\(\vec v\)</span> is an eigenvector of the <span class="math inline">\(n\times n\)</span> matrix <span class="math inline">\(A\)</span> with associated eigenvalue <span class="math inline">\(\lambda\)</span>, what can you say about <span class="math inline">\(\ker(A-\lambda I_n)\)</span>? Is the matrix <span class="math inline">\(A-\lambda I_n\)</span> invertible? We know <span class="math inline">\(A \vec v=\lambda \vec v\)</span> so <span class="math inline">\((A-\lambda I_n)\vec v=A \vec v-\lambda I_n\vec v=\lambda\vec v-\lambda \vec v=0\)</span>. Thus a nonzero vector <span class="math inline">\(\vec v\)</span> is in the kernel of <span class="math inline">\((A-\lambda I_n)\)</span>. Therefore, <span class="math inline">\(\ker(A-\lambda I_n)\neq \{\vec 0\}\)</span> and so <span class="math inline">\(A-\lambda I_n\)</span> is not invertible.</p>
<div id="lem-" class="theorem lemma">
<p><span class="theorem-title"><strong>Lemma 6.1 </strong></span> Let <span class="math inline">\(A\)</span> be an <span class="math inline">\(n\times n\)</span> matrix <span class="math inline">\(A\)</span> and <span class="math inline">\(\lambda\)</span> a scalar. Then <span class="math inline">\(\lambda\)</span> is an eigenvalue of <span class="math inline">\(A\)</span> if and only if <span class="math inline">\(\det(A-\lambda I_n)=0\)</span>.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>The proof follows from the chain of equivalent statements:</p>
<ul>
<li><span class="math inline">\(\lambda\)</span> is an eigenvalue of <span class="math inline">\(A\)</span>,</li>
<li>there exists a nonzero vector <span class="math inline">\(\vec v\)</span> such that <span class="math inline">\((A -\lambda I_n ) \vec v=0,\)</span></li>
<li><span class="math inline">\(\ker(A -\lambda I_n )\neq \{\vec 0\}\)</span>,</li>
<li>matrix <span class="math inline">\(A-\lambda I_n\)</span> fails to be invertible, and</li>
<li><span class="math inline">\(\det(A -\lambda I_n )=0\)</span>.</li>
</ul>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 6.1 </strong></span>Find all eigenvectors and eigenvalues of the identity matrix <span class="math inline">\(I_n\)</span>. Since <span class="math inline">\(I_n \vec v = \lambda \vec v= 1 \vec v\)</span> for all <span class="math inline">\(\vec v\in \mathbb{R}^n\)</span>, all nonzero vectors in <span class="math inline">\(\mathbb{R}^n\)</span> are eigenvectors of <span class="math inline">\(I_n\)</span>, with eigenvalues <span class="math inline">\(\lambda=1\)</span>.</p>
</div>
<div id="lem-" class="theorem lemma">
<p><span class="theorem-title"><strong>Lemma 6.2 </strong></span> The eigenvalues of a triangular matrix are its diagonal entries.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>Let <span class="math inline">\(A\)</span> be a triangular matrix. Then <span class="math inline">\(A-\lambda I_n\)</span> is also a triangular matrix, and so <span class="math inline">\(\det(A-\lambda I_n)\)</span> is the product of its diagonal entries. Let <span class="math inline">\(a_{ii}\)</span> be any diagonal entry of <span class="math inline">\(A\)</span>. Then <span class="math inline">\(a_{ii}-\lambda\)</span> is the corresponding diagonal entry of <span class="math inline">\(A-\lambda I_n\)</span>. Thus <span class="math inline">\(\lambda\)</span> is an eigenvalue of <span class="math inline">\(A\)</span> if and only if <span class="math inline">\(a_{ii}-\lambda=0\)</span> by <span class="math inline">\(\ref{eigenprop}\)</span>.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 6.2 </strong></span>Find a basis of the linear space <span class="math inline">\(V\)</span> of all <span class="math inline">\(2\times 2\)</span> matrices for which <span class="math inline">\(\vec e_1\)</span> is an eigenvector. For an arbitrary <span class="math inline">\(2\times 2\)</span> matrix we want <span class="math display">\[
\begin{bmatrix} a &amp; b \\c &amp; d\end{bmatrix} \vectortwo{1}{0}=\vectortwo{a}{c}=\vectortwo{\lambda}{0}=\lambda \vectortwo{1}{0}
\]</span> for any <span class="math inline">\(\lambda\)</span>. Hence <span class="math inline">\(a, b, d\)</span> are free and <span class="math inline">\(c=0\)</span>; thus a desired basis of <span class="math inline">\(V\)</span> is <span class="math display">\[
\left(
\begin{bmatrix} 1 &amp; 0 \\ 0 &amp; 0\end{bmatrix},
\begin{bmatrix} 0 &amp; 1 \\ 0 &amp; 0\end{bmatrix},
\begin{bmatrix} 0 &amp; 0 \\ 0 &amp; 1\end{bmatrix}
\right).
\]</span></p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 6.3 </strong></span>Find a basis of the linear space <span class="math inline">\(V\)</span> of all <span class="math inline">\(4\times 4\)</span> matrices for which <span class="math inline">\(\vec e_2\)</span> is an eigenvector. We want to find all <span class="math inline">\(4 \times 4\)</span> matrices <span class="math inline">\(A\)</span> such that <span class="math inline">\(A \vec e_2=\lambda e_2\)</span>. Thus the second column of an arbitrary <span class="math inline">\(4 \times 4\)</span> matrix <span class="math inline">\(A\)</span> must be of the form <span class="math inline">\(\vectorfour{0}{\lambda}{0}{0}^T\)</span>, so <span class="math display">\[
A=\begin{bmatrix} a &amp; 0 &amp; c &amp; d \\ e &amp; \lambda &amp; f &amp; g \\ h &amp; 0 &amp; i &amp; j \\ k &amp; 0 &amp; l &amp; m\end{bmatrix}.
\]</span> Let <span class="math inline">\(E_{ij}\)</span> denote the <span class="math inline">\(4\times 4\)</span> matrix with all entries zero except for a 1 in the <span class="math inline">\(i\)</span>-th row and <span class="math inline">\(j\)</span>-th column. Then a basis for <span class="math inline">\(V\)</span> is <span class="math display">\[
\left(
E_{11}, E_{21}, E_{31}, E_{41}, E_{22}, E_{13}, E_{23}, E_{33}, E_{34}, E_{41}, E_{42}, E_{43}, E_{44}
\right)
\]</span> and so the dimension of <span class="math inline">\(V\)</span> is 13.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 6.4 </strong></span>Find the eigenvalues and find a basis for each eigenspace given <span class="math inline">\(A=\begin{bmatrix}1 &amp; 0 &amp; 0 \\ -5 &amp; 0 &amp; 2 \\ 0 &amp; 0 &amp; 1 \end{bmatrix}\)</span>. Find an eigenbasis for <span class="math inline">\(A\)</span>. The eigenvalues are <span class="math inline">\(\lambda_1=0\)</span> and <span class="math inline">\(\lambda_2=\lambda_3=1\)</span>. A basis for <span class="math inline">\(E_{0}\)</span> is <span class="math inline">\(\left(\vectorthree{0}{1}{0}\right)\)</span>. A basis for <span class="math inline">\(E_{1}\)</span> is <span class="math inline">\(\left(\vectorthree{1}{-5}{0},\vectorthree{0}{2}{1}\right)\)</span>. An eigenbasis for <span class="math inline">\(A\)</span> is <span class="math inline">\(\left(\vectorthree{0}{1}{0},\vectorthree{1}{-5}{0},\vectorthree{0}{2}{1}\right)\)</span>.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 6.5 </strong></span>Find a basis of the linear space <span class="math inline">\(V\)</span> of all <span class="math inline">\(2\times 2\)</span> matrices <span class="math inline">\(A\)</span> for which <span class="math inline">\(\vectortwo{1}{-3}\)</span> is an eigenvector. For an arbitrary <span class="math inline">\(2\times 2\)</span> matrix we want <span class="math display">\[
\begin{bmatrix} a &amp; b \\c &amp; d \end{bmatrix} \vectortwo{1}{-3}=\lambda\vectortwo{1}{-3}=\vectortwo{\lambda}{-3\lambda}.
\]</span> Thus <span class="math inline">\(a-3b=\lambda\)</span>, <span class="math inline">\(c-3d=-3\lambda\)</span> and so <span class="math inline">\(c=-3a+9b+3d\)</span>. Thus <span class="math inline">\(A\)</span> must be of the form <span class="math display">\[
\begin{bmatrix} a &amp; b \\ -3a+9b+3d &amp; d\end{bmatrix}=a\begin{bmatrix} 1 &amp; 0 \\-3 &amp; 0 \end{bmatrix}+b \begin{bmatrix} 0 &amp; 1 \\ 9 &amp; 0 \end{bmatrix}+ d\begin{bmatrix} 0 &amp; 0 \\ 3 &amp; 1\end{bmatrix}.
\]</span> Thus a basis of <span class="math inline">\(V\)</span> is <span class="math display">\[
\left( \begin{bmatrix} 1 &amp; 0 \\ -3 &amp; 0 \end{bmatrix}, \begin{bmatrix} 0 &amp; 1 \\ 9 &amp; 0 \end{bmatrix}, \begin{bmatrix} 0 &amp; 0 \\ 3 &amp; 1\end{bmatrix} \right)
\]</span> and so the dimension of <span class="math inline">\(V\)</span> is <span class="math inline">\(3\)</span>.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 6.6 </strong></span>Find a basis of the linear space <span class="math inline">\(V\)</span> of all <span class="math inline">\(3\times 3\)</span> matrices <span class="math inline">\(A\)</span> for which both <span class="math inline">\(\vectorthree{1}{0}{0}^T\)</span> and <span class="math inline">\(\vectorthree{0}{0}{1}^T\)</span> are eigenvectors. Since <span class="math inline">\(A \vectorthree{1}{0}{0}^T\)</span> is simply the first column of <span class="math inline">\(A\)</span>, the first column must be a multiple of <span class="math inline">\(\vec e_1\)</span>. Similarly, the third column must be a multiple of <span class="math inline">\(\vec e_3\)</span>. There are no other restrictions on the form of <span class="math inline">\(A\)</span>, meaning it can be any matrix of the form <span class="math display">\[
\begin{bmatrix} a &amp; b &amp; 0 \\ 0 &amp; c &amp; 0 \\ 0 &amp; d &amp; e \end{bmatrix}
\]</span> Thus a basis of <span class="math inline">\(V\)</span> is <span class="math display">\[
\left(
\begin{bmatrix} 1 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 \end{bmatrix},
\begin{bmatrix} 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 \end{bmatrix},
\begin{bmatrix} 0 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 0 \end{bmatrix},
\begin{bmatrix} 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 0 \end{bmatrix},
\begin{bmatrix} 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 1 \end{bmatrix}
\right)
\]</span> and so the dimension of <span class="math inline">\(V\)</span> is 5.</p>
</div>
<div id="thm-" class="theorem">
<p><span class="theorem-title"><strong>Theorem 6.1 </strong></span> If <span class="math inline">\(A\)</span> is an <span class="math inline">\(n\times n\)</span> matrix, then <span class="math inline">\(\det(A-\lambda I_n)\)</span> is a polynomial of degree <span class="math inline">\(n\)</span>, of the form <span class="math display">\[\begin{equation} \label{chpo}
f_A(\lambda)=(-\lambda)^n+\text{trace} (A) (-\lambda)^{n-1}+\cdots +\det(A).
\end{equation}\]</span></p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>This proof is left for the reader.</p>
</div>
<p>The equation <span class="math inline">\(\det(A-\lambda I_n)=0\)</span> is called the <strong>characteristic equation</strong> of <span class="math inline">\(A\)</span>. The polynomial in <span class="math inline">\(\ref{chpo}\)</span> is called the <strong>characteristic polynomial</strong> and is denoted by <span class="math inline">\(f_A(\lambda)\)</span>. We say that an eigenvalue <span class="math inline">\(\lambda_0\)</span> of a square matrix <span class="math inline">\(A\)</span> has <strong>algebraic multiplicity</strong> <span class="math inline">\(k\)</span> if <span class="math inline">\(\lambda_0\)</span> is a root of multiplicity <span class="math inline">\(k\)</span> of the characteristic polynomial <span class="math inline">\(f_A(\lambda)\)</span> meaning that we can write <span class="math display">\[
f_A(\lambda)=(\lambda_0-\lambda)^k g(\lambda)
\]</span> for some polynomial <span class="math inline">\(g(\lambda)\)</span> with <span class="math inline">\(g(\lambda_0)\neq 0\)</span>.</p>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 6.7 </strong></span>Find the characteristic equation for a $2 $ matrix <span class="math inline">\(A\)</span>. The characteristic equation of <span class="math inline">\(A=\begin{bmatrix} a&amp; b \\c &amp; d\end{bmatrix}\)</span> is <span class="math display">\[
f_A(\lambda)
=\det \begin{bmatrix} a-\lambda&amp; b \\c &amp; d-\lambda \end{bmatrix}
%=(a-\lambda)(d-\lambda)-bc
=\lambda^2-(a+d)\lambda +(ad-bc)=0.
\]</span></p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 6.8 </strong></span>Use the characteristic polynomial <span class="math inline">\(f_A(\lambda)\)</span> to determine the eigenvalues and their multiplicities of <span class="math display">\[
A=\begin{bmatrix} -1 &amp; -1 &amp; -1 \\ -1 &amp; -1 &amp; -1 \\ -1 &amp; -1 &amp; -1 \end{bmatrix}.
\]</span> The characteristic equation is <span class="math inline">\(f_A(\lambda)=-\lambda^2(\lambda+3)\)</span>. So <span class="math inline">\(\lambda_1=0\)</span> with algebraic multiplicity of 2 and <span class="math inline">\(\lambda_2=-3\)</span> with algebraic multiplicity of 1 are the eigenvalues of <span class="math inline">\(A\)</span>.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 6.9 </strong></span>Consider the matrix <span class="math inline">\(A=\begin{bmatrix} a &amp; b \\ b &amp; c \end{bmatrix}\)</span>, where <span class="math inline">\(a, b, c\)</span> are nonzero constants. For which values of $a, b, c $ does <span class="math inline">\(A\)</span> have two distinct eigenvalues? The characteristic equation is <span class="math inline">\(f_A(\lambda)=\lambda^2-(a+c)\lambda+(a c-b^2)\)</span>. The discriminant of this quadratic equation is <span class="math display">\[
(a+c)^2-4(ac-b^2)=a^2+2ac+c^2-4ac+4b^2=(a-c)^2+4b^2.
\]</span> The discriminant is always positive since <span class="math inline">\(b\neq 0\)</span>. Thus, the matrix <span class="math inline">\(A\)</span> there will always have two distinct real eigenvalues.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 6.10 </strong></span>In terms of eigenvalues of <span class="math inline">\(A\)</span>, which <span class="math inline">\(2\times 2\)</span> matrices <span class="math inline">\(A\)</span> does there exist an invertible matrix <span class="math inline">\(S\)</span> such that <span class="math inline">\(AS=SD\)</span>, where <span class="math inline">\(D=\begin{bmatrix} 2 &amp; 0 \\ 0 &amp; 3 \end{bmatrix}\)</span>? If we let <span class="math inline">\(S=\begin{bmatrix} \vec v_1 &amp; \vec v_2\end{bmatrix}\)</span>, then <span class="math inline">\(AS=\begin{bmatrix} A \vec v_1 &amp; A \vec v_2\end{bmatrix}\)</span> and <span class="math inline">\(SD=\begin{bmatrix} 2 \vec v_1 &amp; 3\vec v_2\end{bmatrix}\)</span>. So that <span class="math inline">\(\vec v_1\)</span> must be an eigenvector of <span class="math inline">\(A\)</span> with eigenvalue 2, and <span class="math inline">\(\vec v_2\)</span> must be an eigenvector of <span class="math inline">\(A\)</span> with eigenvalue 3. Thus, the matrix <span class="math inline">\(S\)</span> will exist and will have first column has an eigenvector of <span class="math inline">\(A\)</span> with eigenvalue 2, and have second column is an eigenvector of <span class="math inline">\(A\)</span> with eigenvalue of 3. Therefore, <span class="math inline">\(A\)</span> can be any matrix satisfying these requirements.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 6.11 </strong></span>Let <span class="math inline">\(A\)</span> be a matrix with eigenvalues <span class="math inline">\(\lambda_1, \ldots, \lambda_k\)</span>.</p>
<ul>
<li>Show the eigenvalues of <span class="math inline">\(A^T\)</span> are <span class="math inline">\(\lambda_1, \ldots, \lambda_k\)</span>.</li>
<li>Show the eigenvalues of <span class="math inline">\(\alpha A\)</span> are <span class="math inline">\(\alpha\lambda_1, \ldots, \alpha \lambda_k\)</span>.</li>
</ul>
<p>Show <span class="math inline">\(A^{-1}\)</span> exists if and only if <span class="math inline">\(\lambda_1 \cdots \lambda_k\neq 0\)</span>. - Also, show that if <span class="math inline">\(A^{-1}\)</span> exists then its eigenvalues are <span class="math inline">\(1/\lambda_1,\ldots,1/\lambda_k\)</span>.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 6.12 </strong></span>Let <span class="math inline">\(A\)</span> be a matrix with eigenvalues <span class="math inline">\(\lambda_1, \ldots, \lambda_k\)</span> and let <span class="math inline">\(m\)</span> be a positive integer. Show that the eigenvalues of <span class="math inline">\(A^m\)</span> are <span class="math inline">\(\lambda^m_1, \ldots, \lambda^m_k\)</span>.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 6.13 </strong></span>By using the matrix <span class="math display">\[
\begin{bmatrix}
0 &amp; 1 &amp; 0 &amp; \cdots &amp; 0\\
0 &amp; 0 &amp; 1 &amp; \cdots &amp; 0\\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; 0 &amp; \cdots &amp; 1 \\
\frac{-a_n}{a_0} &amp; \frac{-a_{n-1}}{a_0}&amp; \frac{-a_{n-2}}{a_0} &amp; \cdots &amp; \frac{-a_1}{a_0}
\end{bmatrix}
\]</span> Show that any given polynomial <span class="math inline">\(a_o \lambda^n+a_1\lambda^{n-1}+\cdots +a_{n-1}\lambda +a_n\)</span> where <span class="math inline">\(a_0\neq 0\)</span>, of degree <span class="math inline">\(n\)</span> may be regarded as the characteristic polynomial of a matrix of order <span class="math inline">\(n\)</span>. This matrix is called the <strong>companion matrix</strong> of the given polynomial.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 6.14 </strong></span>Let <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> be <span class="math inline">\(n\times n\)</span> matrices. Show that <span class="math inline">\(AB\)</span> and <span class="math inline">\(BA\)</span> have the same eigenvalues.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 6.15 </strong></span>Let <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> be real <span class="math inline">\(n\times n\)</span> matrices with distinct eigenvalues. Prove that <span class="math inline">\(AB=BA\)</span> if and only if <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> have the same eigenvectors.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 6.16 </strong></span>Prove that the characteristic polynomial of the block-triangular matrix <span class="math inline">\(A=\begin{bmatrix} B &amp; C\\ 0 &amp; D\end{bmatrix}\)</span> is the product of the characteristic polynomials of <span class="math inline">\(B\)</span> and <span class="math inline">\(D\)</span>.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 6.17 </strong></span>Suppose that <span class="math inline">\(A\)</span> is an invertible <span class="math inline">\(n\times n\)</span> matrix. Prove that <span class="math display">\[\begin{equation}
f_{A^{-1}}(x)=(-x)^n\det(A^{-1})f_A\left(\frac{1}{x}\right).
\end{equation}\]</span></p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 6.18 </strong></span>Let <span class="math inline">\(A\)</span> be an <span class="math inline">\(n\times n\)</span> matrix. Prove that <span class="math inline">\(A\)</span> and <span class="math inline">\(A^T\)</span> have the same characteristic polynomial and hence the same eigenvalues.</p>
</div>
<p>If<span class="math inline">\(\lambda\)</span> is an eigenvalue of an <span class="math inline">\(n\times n\)</span> matrix <span class="math inline">\(A\)</span>, then the kernel of the matrix <span class="math inline">\(A-\lambda I_n\)</span> is called the <strong>eigenspace</strong> associated with <span class="math inline">\(\lambda\)</span> and is denoted by <span class="math inline">\(E_\lambda\)</span>. The dimension of the eigenspace is called the <strong>geometric multiplicity</strong> of eigenvalue <span class="math inline">\(\lambda\)</span>. In other words, the geometric multiplicity is the nullity of the matrix <span class="math inline">\(A-\lambda I_n\)</span>.</p>
<div id="thm-" class="theorem">
<p><span class="theorem-title"><strong>Theorem 6.2 </strong></span> Let <span class="math inline">\(A\)</span> be an <span class="math inline">\(n\times n\)</span> matrix. If <span class="math inline">\(\lambda_1, \ldots, \lambda_k\)</span> are distinct eigenvalues of <span class="math inline">\(A\)</span>, and <span class="math inline">\(\vec v_1, \ldots, \vec v_k\)</span> are any nonzero eigenvectors associated with these eigenvalues respectively, then <span class="math inline">\(\vec v_1, \ldots, \vec v_k\)</span> are linearly independent.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>Suppose there exists constants <span class="math inline">\(c_1, \ldots, c_k\)</span> such that <span class="math display">\[\begin{equation}
\label{eigenveclin}
c_1 \vec v_1+\cdots +c_k \vec v_k=0
\end{equation}\]</span> Using the fact that <span class="math inline">\(A \vec v_i=\lambda_i \vec v_i\)</span> we multiply <span class="math inline">\(\ref{eigenveclin}\)</span> by <span class="math inline">\(A\)</span> to obtain <span class="math display">\[\begin{equation}
\label{eigenveclin2}
c_1 \lambda_1\vec v_1+\cdots c_k \lambda_k \vec v_k=0.
\end{equation}\]</span> Repeating this again we obtain <span class="math display">\[\begin{equation}
\label{eigenveclin3}
c_1 \lambda^2_1\vec v_1+\cdots +c_k \lambda^2_k \vec v_k=0.
\end{equation}\]</span> Repeating, we are lead to the system in the vector unknowns <span class="math inline">\(\vec v_1, \ldots, \vec v_k\)</span> <span class="math display">\[\begin{equation}
\begin{bmatrix}
c_1 \vec v_1 &amp; \cdots &amp; c_k \vec v_k
\end{bmatrix}_{n\times k}
\begin{bmatrix}
1 &amp; \lambda_1 &amp; \lambda_1^2 &amp; \cdots \lambda_1^{k-1} \\
1 &amp; \lambda_2 &amp; \lambda_2^2 &amp; \cdots \lambda_2^{k-1} \\
1 &amp; \lambda_3 &amp; \lambda_3^2 &amp; \cdots \lambda_3^{k-1} \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots \vdots \\
1 &amp; \lambda_k &amp; \lambda_k^2 &amp; \cdots \lambda_k^{k-1} \\
\end{bmatrix}_{k\times k}
=0_{n\times k}.
\end{equation}\]</span> Since the eigenvalues are distinct, the coefficient matrix is an invertible Vandermonde matrix. Multiplying on the right by its inverse shows that <span class="math display">\[
\begin{bmatrix}
c_1 \vec v_1 &amp; \cdots &amp; c_k \vec v_k
\end{bmatrix}
=0_{n\times k}.
\]</span> It follows that every <span class="math inline">\(c_i\)</span> must be zero. Hence <span class="math inline">\(\vec v_1, \ldots, \vec v_k\)</span> are linearly independent.</p>
</div>
<p>A basis of <span class="math inline">\(\mathbb{F}^n\)</span> consisting of eigenvectors of <span class="math inline">\(A\)</span> is called an <strong>eigenbasis</strong> for <span class="math inline">\(A\)</span>.<br>
In particular, if an <span class="math inline">\(n\times n\)</span> matrix <span class="math inline">\(A\)</span> has <span class="math inline">\(n\)</span> distinct eigenvalues, then there exists an eigenbasis for <span class="math inline">\(A\)</span>, namely, construct an eigenbasis by finding an eigenvector for each eigenvalue.</p>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 6.19 </strong></span>Find the characteristic equation, the eigenvalues, and a basis for the eigenspace. <span class="math display">\[A=\begin{bmatrix}
3 &amp; 2 &amp; 4 \\
2 &amp; 0 &amp; 2\\
4 &amp; 2 &amp; 3
\end{bmatrix}
\]</span> The eigenvalues are <span class="math inline">\(\lambda_1=8\)</span> (with algebraic multiplicity 1) and <span class="math inline">\(\lambda_2=-1\)</span> (with algebraic multiplicity 2) since <span class="math display">\[
\det(A-\lambda I)
=\begin{vmatrix}
3-\lambda &amp; 2 &amp; 4 \\
2 &amp; -\lambda &amp; 2\\
4 &amp; 2 &amp; 3-\lambda
\end{vmatrix}
=-\lambda^3+6\lambda^2+15\lambda+8=0.
\]</span> For <span class="math inline">\(\lambda_1=8\)</span> we obtain <span class="math display">\[
\begin{bmatrix}
-5 &amp; 2 &amp; 4 \\
2 &amp; -8 &amp; 2\\
4 &amp; 2 &amp; -5
\end{bmatrix}
\vectorthree{x_1}{x_2}{x_3}=\vectorthree{0}{0}{0}
\]</span> and we obtain the eigenvector <span class="math inline">\(\vec v_1=\vectorthree{2}{1}{2}^T\)</span> with <span class="math inline">\(E_8=\text{span}(\vec v_1)\)</span>. Therefore the geometric multiplicity of <span class="math inline">\(\lambda_1=8\)</span> is 1. For <span class="math inline">\(\lambda_1=-1\)</span> we obtain <span class="math display">\[
\begin{bmatrix}
4 &amp; 2 &amp; 4 \\
2 &amp; 1 &amp; 2\\
4 &amp; 2 &amp; 4
\end{bmatrix}
\vectorthree{x_1}{x_2}{x_3}=\vectorthree{0}{0}{0}
\]</span> and we obtain the eigenvectors <span class="math inline">\(\vec v_2=\vectorthree{1}{-2}{0}^T\)</span> and <span class="math inline">\(\vec v_3=\vectorthree{0}{-2}{1}^T\)</span> with <span class="math inline">\(E_{-1}=\text{span}(\vec v_2, \vec v_3)\)</span>. Therefore the geometric multiplicity of <span class="math inline">\(\lambda_2=-1\)</span> is 2.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 6.20 </strong></span>Show that for each of the following matrices, <span class="math inline">\(\lambda=3\)</span> is an eigenvalue of algebraic multiplicity 4. In each case, compute the geometric multiplicity of <span class="math inline">\(\lambda\)</span>. <span class="math display">\[
\begin{bmatrix}
3 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 3 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 3 &amp; 0\\
0 &amp; 0 &amp; 0 &amp; 3
\end{bmatrix}
\qquad
\begin{bmatrix}
3 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; 3 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 3 &amp; 0\\
0 &amp; 0 &amp; 0 &amp; 3
\end{bmatrix}
\qquad
\begin{bmatrix}
3 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; 3 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 3 &amp; 0\\
0 &amp; 0 &amp; 0 &amp; 3
\end{bmatrix}
\qquad
\begin{bmatrix}
3 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; 3 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 3 &amp; 1\\
0 &amp; 0 &amp; 0 &amp; 3
\end{bmatrix}
\]</span></p>
</div>
<div id="thm-" class="theorem">
<p><span class="theorem-title"><strong>Theorem 6.3 </strong></span> Similar matrices <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> have the same determinant, trace, characteristic polynomial, rank, nullity, and the same eigenvalues with the same algebraic multiplicities.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>The case for the determinant and trace are proven in <span class="math inline">\(\ref{propdettrace}\)</span>. Since <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are similar, there exists an invertible matrix <span class="math inline">\(P\)</span> such that <span class="math inline">\(B=P^{-1}AP\)</span>. Using <span class="math inline">\(\ref{propdettrace}\)</span> we find <span class="math display">\[\begin{align*}
\det(B-\lambda I)
&amp;=\det(P^{-1}AP-\lambda I)
=\det(P^{-1}AP-P^{-1}\lambda I P)
=\det(P^{-1}(A-\lambda I) P) \\
&amp; =\det(P^{-1})\det(A-\lambda I) \det(P)
=\det(P^{-1})\det(P) \det(A-\lambda I) \\
&amp; =\det(P^{-1}P)\det(A-\lambda I)
=\det(A-\lambda I)
\end{align*}\]</span> Thus <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> have the same characteristic equation. Therefore also the same eigenvalues with the same algebraic multiplicities according to <span class="math inline">\(\ref{eigenprop}\)</span> and <span class="math inline">\(\ref{charform}\)</span>.</p>
</div>
<p>In light of <span class="math inline">\(\ref{invsimmatrix}\)</span>, if <span class="math inline">\(T\)</span> is a linear transformation from <span class="math inline">\(V\)</span> to <span class="math inline">\(V\)</span> then a scalar <span class="math inline">\(\lambda\)</span> is called an <strong>eigenvalue</strong> of <span class="math inline">\(T\)</span> if there exists a nonzero element <span class="math inline">\(\vec v\)</span> in <span class="math inline">\(V\)</span> such that <span class="math inline">\(T(\vec v)=\lambda \vec v\)</span>. Assuming <span class="math inline">\(V\)</span> is finite-dimensional then a basis <span class="math inline">\(\mathcal{D}\)</span> of <span class="math inline">\(V\)</span> consisting of eigenvectors of <span class="math inline">\(T\)</span> is called an <strong>eigenbasis</strong> for <span class="math inline">\(T\)</span>.</p>
<div id="thm-" class="theorem">
<p><span class="theorem-title"><strong>Theorem 6.4 </strong></span>Let <span class="math inline">\(T\)</span> be a linear transformation on a finite-dimensional vector space <span class="math inline">\(V\)</span>, and let <span class="math inline">\(\lambda\)</span> be an eigenvalue of <span class="math inline">\(T\)</span>. The geometric multiplicity of <span class="math inline">\(\lambda\)</span> is less than or equal to the algebraic multiplicity of <span class="math inline">\(\lambda\)</span>.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>Let <span class="math inline">\(k\)</span> represent the geometric multiplicity of <span class="math inline">\(\lambda\)</span> and assume <span class="math inline">\(\dim V=n\)</span>. First notice, by definition, the eigenspace <span class="math inline">\(E_{\lambda}\)</span> must contain at least one nonzero vector, and thus <span class="math inline">\(k=\dim E_{\lambda} \geq 1\)</span>. Choose a basis <span class="math inline">\(\vec v_1, \ldots,\vec v_k\)</span> for <span class="math inline">\(E_{\lambda}\)</span> and, by <span class="math inline">\(\ref{basisspacethm}\)</span>, extend it to a basis <span class="math inline">\(\mathcal{B}=(\vec v_1, \ldots, \vec v_k, \vec v_{k+1},\ldots,\vec v_n)\)</span> of <span class="math inline">\(V\)</span>. For <span class="math inline">\(1\leq i \leq k\)</span>, notice <span class="math display">\[
[T(\vec v_i)]_{\mathcal{B}}
=[\lambda \vec v_i]_{\mathcal{B}}
=\lambda[\vec v_i]_{\mathcal{B}}
=\lambda \vec e_i.
\]</span> Thus the matrix representation for <span class="math inline">\(T\)</span> with respect to <span class="math inline">\(\mathcal{B}\)</span> has the form <span class="math display">\[\begin{equation}
B=
\begin{bmatrix}
\lambda I_k &amp; C\\ 0 &amp; D
\end{bmatrix}
\end{equation}\]</span> where <span class="math inline">\(C\)</span> is a <span class="math inline">\(k\times (n-k)\)</span> submatrix, <span class="math inline">\(O\)</span> is an <span class="math inline">\((n-k)\times k\)</span> zero submatrix, and <span class="math inline">\(D\)</span> is an <span class="math inline">\((n-k)\times (n-k)\)</span> submatrix.<br>
Using <span class="math inline">\(\ref{blockdetprod}\)</span> we determine the characteristic polynomial of <span class="math inline">\(T\)</span> <span class="math display">\[
f_T(x)
%=f_B(x)
=|x I_n-B|
=\left|xI_n-
\begin{bmatrix}
\lambda I_k &amp; C\\ 0 &amp; D
\end{bmatrix}
\right|
=
\begin{vmatrix}
(x-\lambda)I_k &amp; C\\ 0 &amp; xI_{n-k}-D
\end{vmatrix}
=(x-\lambda)^k f_D(x).
\]</span> It follows that <span class="math inline">\(f_T(x)=(x-\lambda)^{k+m} g(x)\)</span> where <span class="math inline">\(g(\lambda)\neq 0\)</span> and <span class="math inline">\(m\)</span> is the number of factors of <span class="math inline">\(x-\lambda\)</span> in <span class="math inline">\(f_D(x)\)</span>. Hence <span class="math inline">\(k\leq k+m\)</span> leading to the desired conclusion.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 6.21 </strong></span>Let <span class="math inline">\(T(M)=M-M^T\)</span> be a linear transformation from <span class="math inline">\(\mathbb{R}^{2\times2}\)</span> to <span class="math inline">\(\mathbb{R}^{2\times2}\)</span>. For each eigenvalue find a basis for the eigenspace and state the geometric multiplicity. Since <span class="math inline">\(A=A^T\)</span> for every symmetric matrix, we notice <span class="math inline">\(T(M)=M-M^T=M-M=0\)</span> whenever <span class="math inline">\(M\)</span> is a symmetric matrix. Thus the nonzero symmetric matrices are eigenmatrices with eigenvalue <span class="math inline">\(0\)</span>.<br>
Also notice the nonzero skew-symmetric matrices have eigenvalue <span class="math inline">\(2\)</span> since <span class="math inline">\(L(M)=M-M^T=M+M=2M\)</span>. For eigenvlaue <span class="math inline">\(\lambda=0\)</span> we have eigenspace <span class="math inline">\(E_0\)</span> with basis <span class="math display">\[
\left(
\begin{bmatrix}
1 &amp; 0 \\ 0 &amp; 0
\end{bmatrix},
\begin{bmatrix}
0 &amp; 1 \\ 1 &amp; 0
\end{bmatrix},
\begin{bmatrix}
0 &amp; 0 \\  0 &amp; 1
\end{bmatrix}
\right).
\]</span> This follow from the condition <span class="math inline">\(A=A^T\)</span> in <span class="math inline">\(\mathbb{R}^{2\times2}\)</span>. Therefore the geometric multiplicity of <span class="math inline">\(\lambda=0\)</span> is 3. For eigenvalue <span class="math inline">\(\lambda=2\)</span> we have eigenspace <span class="math inline">\(E_2\)</span> with basis <span class="math display">\[
\left(
\begin{bmatrix}
0 &amp; 1 \\ -1 &amp; 0
\end{bmatrix}
\right).
\]</span> which follows from the condition <span class="math inline">\(A=-A^T\)</span> in <span class="math inline">\(\mathbb{R}^{2\times2}\)</span>. Therefore the geometric multiplicity of <span class="math inline">\(\lambda=2\)</span> is 1. By <span class="math inline">\(\ref{eigenveceigenvallemma}\)</span> we have an eigenbasis <span class="math display">\[
\left(
\begin{bmatrix}
1 &amp; 0 \\ 0 &amp; 0
\end{bmatrix},
\begin{bmatrix}
0 &amp; 1 \\ 1 &amp; 0
\end{bmatrix},
\begin{bmatrix}
0 &amp; 0 \\  0 &amp; 1
\end{bmatrix},
\begin{bmatrix}
0 &amp; 1 \\ -1 &amp; 0
\end{bmatrix}
\right).
\]</span> for <span class="math inline">\(T\)</span>.</p>
</div>
<section id="diagonalization" class="level2" data-number="6.1">
<h2 data-number="6.1" class="anchored" data-anchor-id="diagonalization"><span class="header-section-number">6.1</span> Diagonalization</h2>
<p>An <span class="math inline">\(n\times n\)</span> matrix <span class="math inline">\(A\)</span> is called <strong>diagonalizable</strong> if <span class="math inline">\(A\)</span> is similar to some diagonal matrix <span class="math inline">\(D\)</span>. If the matrix of a linear transformation <span class="math inline">\(T\)</span> with respect to some basis is diagonal then we call <span class="math inline">\(T\)</span> <strong>diagonalizable</strong> .</p>
<div id="thm-" class="theorem">
<p><span class="theorem-title"><strong>Theorem 6.5 </strong></span> An <span class="math inline">\(n\times n\)</span> matrix <span class="math inline">\(A\)</span> is diagonalizable if and only if it has <span class="math inline">\(n\)</span> linearly independent eigenvectors. In that case, the diagonal matrix <span class="math inline">\(D\)</span> is similar to <span class="math inline">\(A\)</span> and is given by <span class="math display">\[\begin{equation}
\label{diagmat}
D=
\begin{bmatrix}
\lambda_1 &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; \lambda_2 &amp; \cdots &amp; 0 \\
\vdots &amp; \vdots &amp; \ddots&amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; \lambda_n
\end{bmatrix}
\end{equation}\]</span> where <span class="math inline">\(\lambda_1, ..., \lambda_n\)</span> are the eigenvalues of <span class="math inline">\(A\)</span>. If <span class="math inline">\(C\)</span> is a matrix whose columns are linearly independent eigenvectors of <span class="math inline">\(A\)</span>, then <span class="math inline">\(D=C^{-1}A C\)</span>.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>The proof is left for the reader.</p>
</div>
<div id="cor-" class="theorem corollary">
<p><span class="theorem-title"><strong>Corollary 6.1 </strong></span> Let <span class="math inline">\(T\)</span> be a linear transformation given by <span class="math inline">\(T(\vec x)=A\vec x\)</span> where <span class="math inline">\(A\)</span> is a square matrix. If <span class="math inline">\(\mathcal{D}=(\vec v_1, ....,\vec v_n)\)</span> is an eigenbasis for <span class="math inline">\(T\)</span>, with <span class="math inline">\(A\vec v_i=\lambda_i \vec v_i\)</span>, then the <span class="math inline">\(\mathcal{D}\)</span>-matrix <span class="math inline">\(D\)</span> of <span class="math inline">\(T\)</span> given in <span class="math inline">\(\ref{diagmat}\)</span> is <span class="math inline">\(D=[\vec v_1, ...., \vec v_n]^{-1}A [\vec v_1, ...., \vec v_n]\)</span>.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>The proof follows from <span class="math inline">\(\ref{dialineigvec}\)</span> and <span class="math inline">\(\ref{eigenveceigenvallemma}\)</span>.</p>
</div>
<div id="cor-" class="theorem corollary">
<p><span class="theorem-title"><strong>Corollary 6.2 </strong></span> A matrix <span class="math inline">\(A\)</span> is diagonalizable if andy only if there exists an eigenbasis for <span class="math inline">\(A\)</span>. In particular, if an <span class="math inline">\(n\times n\)</span> matrix <span class="math inline">\(A\)</span> has <span class="math inline">\(n\)</span> distinct eigenvalues, then <span class="math inline">\(A\)</span> is diagonalizable.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>The proof follows from <span class="math inline">\(\ref{dialineigvec}\)</span> and <span class="math inline">\(\ref{eigenveceigenvallemma}\)</span>.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 6.22 </strong></span>Let <span class="math inline">\(T: \mathcal{P}_2\to \mathcal{P}_2\)</span> be the linear transformation defined by<br>
<span class="math display">\[
T(a_0+a_1 x+a_2x^2)=(a_0+a_1+a_2)+(a_1+a_2)x+a_2x^2.
\]</span> Show that <span class="math inline">\(T\)</span> is not diagonalizable. The matrix of <span class="math inline">\(T\)</span> with respect to the usual basis <span class="math inline">\((, x, x^2)\)</span> for <span class="math inline">\(\mathcal{P}_2\)</span> is easily seen to be <span class="math display">\[
A=
\begin{bmatrix}
1 &amp; 1 &amp; 1 \\
0 &amp; 1 &amp; 1 \\
0 &amp; 0 &amp; 1
\end{bmatrix}.
\]</span> The characteristic polynomial is <span class="math inline">\(f_A(x)=-(x-1)^3\)</span> since <span class="math inline">\(A\)</span> is upper triangular. So <span class="math inline">\(T\)</span> has only one (repeated) eigenvalue <span class="math inline">\(\lambda=1\)</span>. A nonzero polynomial <span class="math inline">\(g\)</span> with <span class="math inline">\(g(x)=a_0+a_1 x+a_2 x^2\)</span> is an eigenvector if and only if <span class="math display">\[
\label{notdiageq}
\begin{bmatrix}
0 &amp; 1 &amp; 1 \\
0 &amp; 0 &amp; 1 \\
0 &amp; 0 &amp; 0
\end{bmatrix}
\vectorthree{a_0}{a_1}{a_2}=\vectorthree{0}{0}{0}.
\]</span> Thus <span class="math inline">\(a_1=0\)</span> and <span class="math inline">\(a_2=0\)</span>, so there is only one linearly independent eigenvector for <span class="math inline">\(\lambda=1\)</span>. Thus <span class="math inline">\(T\)</span> is not diagonalizable by <span class="math inline">\(\ref{diagonalizablechar}\)</span>.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 6.23 </strong></span>Let <span class="math inline">\(T:\mathcal{P}_2\to \mathcal{P}_2\)</span> be the linear transformation defined by<br>
<span class="math display">\[\begin{equation}
T(f(x))=x^2f''(x)+(3x-2)f'(x)+5 f(x).
\end{equation}\]</span> Find a basis for <span class="math inline">\(\mathcal{P}_2\)</span> such that the matrix representation of <span class="math inline">\(T\)</span> with respect to <span class="math inline">\(\mathcal{B}\)</span> is diagonal. Since <span class="math inline">\(T(x^2)=13x^2-4x\)</span>, <span class="math inline">\(T(x)=8x-2\)</span>, and <span class="math inline">\(T(1)=5\)</span> the matrix representation of <span class="math inline">\(T\)</span> with respect to the basis <span class="math inline">\(\mathcal{B}=(x^2,x,1)\)</span> is <span class="math display">\[
A=\begin{bmatrix}13 &amp; 0 &amp; 0 \\ -4 &amp; 8 &amp; 0 \\ 0 &amp; -2 &amp; 5 \end{bmatrix}.
\]</span> Hence <span class="math display">\[\begin{equation}
f_T(x)=f_A(x)=\begin{vmatrix} x-13  &amp; 0 &amp; 0 \\ 4 &amp; x-8 &amp; 0 \\ 0 &amp; 2 &amp; x-5 \end{vmatrix}=(x-13)(x-8)(x-5).
\end{equation}\]</span> The eigenvalues of <span class="math inline">\(T\)</span> are <span class="math inline">\(\lambda_1=13\)</span>, <span class="math inline">\(\lambda_2=8\)</span> and <span class="math inline">\(\lambda_3=5\)</span>. Solving each of the homogenous systems <span class="math inline">\((A-13I_3)\vec x=\vec 0\)</span>, <span class="math inline">\((A-8I_3)\vec x=\vec 0\)</span>, and <span class="math inline">\((A-5I_3)\vec x=\vec 0\)</span> yields the eigenvectors <span class="math inline">\(\vec v_1=5x^2-4x+1\)</span>, <span class="math inline">\(\vec v_2=3x-2\)</span>, and <span class="math inline">\(\vec v_3=1\)</span>, respectively. Notice <span class="math inline">\(\vec v_1, \vec v_2, \vec v_3\)</span> are 3 linearly independent vectors, so by <span class="math inline">\(\ref{dialineigvec}\)</span>, <span class="math inline">\(T\)</span> is diagonalizable. We let <span class="math inline">\(\mathcal{D}=(\vec v_1, \vec v_2, \vec v_3)\)</span> and since <span class="math inline">\(T(\vec v_1)=13\vec v_1\)</span>,<span class="math inline">\(T(\vec v_2)=8\vec v_2\)</span>, and <span class="math inline">\(T(\vec v_3)=5\vec v_3\)</span>, the matrix representation of <span class="math inline">\(T\)</span> with respect to <span class="math inline">\(\mathcal{D}\)</span> is the diagonal matrix <span class="math display">\[
\begin{bmatrix}13 &amp; 0 &amp; 0 \\ 0 &amp; 8 &amp; 0 \\ 0 &amp; 0 &amp; 5 \end{bmatrix}
\]</span> according to <span class="math inline">\(\ref{dialineigvec}\)</span>.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 6.24 </strong></span>Let <span class="math inline">\(T:\mathcal{P}_3\to \mathcal{P}_3\)</span> be the linear transformation defined by<br>
<span class="math display">\[\begin{equation}
T(f(x))=xf'(x)+f(x+1).
\end{equation}\]</span> Find a basis for <span class="math inline">\(\mathcal{P}_3\)</span> such that the matrix representation of <span class="math inline">\(T\)</span> with respect to <span class="math inline">\(\mathcal{B}\)</span> is diagonal. Since <span class="math inline">\(T(x^3)=4x^3+3x^2+3x+1\)</span>, <span class="math inline">\(T(x^2)=3x^2+2x+1\)</span>, <span class="math inline">\(T(x)=2x+1\)</span>, and <span class="math inline">\(T(1)=1\)</span> the matrix representation of <span class="math inline">\(T\)</span> with respect to the basis <span class="math inline">\(\mathcal{B}=(x^3,x^2,x,1)\)</span> is <span class="math display">\[
A=\begin{bmatrix} 4 &amp; 0 &amp; 0 &amp; 0 \\ 3 &amp; 3 &amp; 0 &amp; 0 \\ 3 &amp; 2 &amp; 2 &amp; 0 \\ 1 &amp; 1 &amp; 1 &amp; 1  \end{bmatrix}.
\]</span> Since <span class="math inline">\(A\)</span> is lower triangular, <span class="math inline">\(f_T(x)=f_A(x)=(x-4)(x-3)(x-2)(x-1)\)</span>; and so the eigenvalues are <span class="math inline">\(\lambda_1=4\)</span>, <span class="math inline">\(\lambda_2=3\)</span>, <span class="math inline">\(\lambda_3=2\)</span>, and <span class="math inline">\(\lambda_4=1\)</span>. Solving for a basis for each eigenspace of <span class="math inline">\(A\)</span> yields <span class="math display">\[
E_{\lambda_1}=\left(\vectorfour{6}{18}{27}{17}\right), \quad
E_{\lambda_2}=\left(\vectorfour{0}{2}{4}{3}\right), \quad
E_{\lambda_3}=\left(\vectorfour{0}{0}{1}{1}\right),\quad
E_{\lambda_4}=\left(\vectorfour{0}{0}{0}{1}\right).
\]</span> By taking the polynomial corresponding to the basis vectors, we let <span class="math inline">\(\mathcal{D}=(\vec v_1, \vec v_2, \vec v_3, \vec v_4)\)</span> where <span class="math inline">\(\vec v_1=6x^3+18x^2+27x+17\)</span>, <span class="math inline">\(\vec v_2=2x^2+4x+3\)</span>, <span class="math inline">\(\vec v_3=x+1\)</span>, and <span class="math inline">\(\vec v_4=1\)</span>. The diagonal matrix <span class="math display">\[
\begin{bmatrix}
4 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 3 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 2 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1
\end{bmatrix}
\]</span> is the matrix representation of <span class="math inline">\(T\)</span> in <span class="math inline">\(\mathcal{D}\)</span>-coordinates and has the eigenvalues of <span class="math inline">\(T\)</span> on its main diagonal. The transition matrix <span class="math inline">\(P\)</span> from <span class="math inline">\(\mathcal{B}\)</span>-coordinates to <span class="math inline">\(\mathcal{D}\)</span>-coordinates is <span class="math display">\[
P=\begin{bmatrix}
6 &amp; 0 &amp; 0 &amp; 0 \\
18 &amp; 2 &amp; 0 &amp; 0 \\
27 &amp; 4 &amp; 1 &amp; 0 \\
17 &amp; 3 &amp; 1 &amp; 1
\end{bmatrix}
\]</span><br>
and satisfies the required relation <span class="math inline">\(D=P^{-1}AP\)</span> as can be verified.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 6.25 </strong></span>If <span class="math inline">\(A\)</span> is similar to <span class="math inline">\(B\)</span>, show that <span class="math inline">\(A^n\)</span> is similar to <span class="math inline">\(B^n\)</span>, for any positive integer <span class="math inline">\(n\)</span>.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 6.26 </strong></span>Suppose that <span class="math inline">\(C^{-1}AC=D\)</span>. Show that for any integer <span class="math inline">\(n\)</span>, <span class="math inline">\(A^n=CD^nC^{-1}\)</span>.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 6.27 </strong></span>Let <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> be real numbers. By diagonalizing <span class="math display">\[
M=
\begin{bmatrix}
a &amp; b-a \\
0 &amp; b
\end{bmatrix},
\]</span> prove that <span class="math display">\[
M^n=
\begin{bmatrix}
a^n &amp; b^n-a^n \\
0 &amp; b^n
\end{bmatrix}
\]</span> for all positive integers <span class="math inline">\(n\)</span>. We need a basis of <span class="math inline">\(\mathbb{R}^2\)</span> consisting of eigenvectors of <span class="math inline">\(M\)</span>. One such basis is <span class="math inline">\(\vec v_1=\vec e_1\)</span> and <span class="math inline">\(\vec v_2=\vec e_1+\vec e_2\)</span> where <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> are eigenvalues for corresponding to these eigenvectors, respectively. Let <span class="math inline">\(P=\begin{bmatrix}\vec v_1 &amp; \vec v_2\end{bmatrix},\)</span> then by <span class="math inline">\(\ref{eigendmatrix}\)</span>, the diagonalization is <span class="math display">\[\begin{equation*}
D=\begin{bmatrix}\vec v_1 &amp; \vec v_2\end{bmatrix}^{-1}M\begin{bmatrix}\vec v_1 &amp; \vec v_2\end{bmatrix}=\begin{bmatrix}a &amp; 0 \\ 0 &amp; b \end{bmatrix}.
\end{equation*}\]</span> Therefore <span class="math display">\[\begin{equation*}
M^n=(PDP^{-1})^n=\underbrace{(PDP^{-1})\cdots (PDP^{-1})}_{n\text{-times}}=PD^n P^{-1}
=\begin{bmatrix}
a^n &amp; b^n-a^n \\
0 &amp; b^n
\end{bmatrix}.
\end{equation*}\]</span></p>
</div>
</section>
</main> <!-- /main -->
<script type="application/ld+json">
    {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "Direct Knowledge",
    "url": "https://diretcknowledge.com",
    "logo": "http://directknowledge.com/assets/directknowledge-logo.svg",
    "foundingDate": "2017",
    "founders": [
    {
    "@type": "Person",
    "name": "David Andrew Smith"
    },
    {
    "@type": "Person",
    "name": "David A. Smith"
    } ],
    "address": {
    "@type": "PostalAddress",
    "addressLocality": "Fort Worth",
    "addressRegion": "Texas",
    "addressCountry": "United States"
    },
    "contactPoint": {
    "@type": "ContactPoint",
    "contactType": "customer support",
    "email": "contact@directknowledge.com"
    },
    "sameAs": [
    "https://youtube.com/@directknowledge",
    "https://github.com/directknowledge/"
    ]
    }
</script>
<script type="application/ld+json">
    {
    "@context": "http://schema.org",
    "@type": "WebSite",
          "name": "Direct Knowledge",
        "url": "https://directknowledge.com"
    }
</script>
<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']],
    processRefs: true,
    processEnvironments: true,
    tags: 'ams',
    packages: {'[+]': ['newcommand']},
    processEnvironments: true,
      macros: {
        N: "{\\mathbb{N}}",
        Z: "{\\mathbb{Z}}",
        qed: "{\\square}"
      }
  },
  svg: {
    fontCache: 'global'
  }
};
console.log("MaxJax Initalizing");
</script>
  
<script>
var xtimes = 1;
console.log(xtimes);
ActiveMaxJax = function() {
  if( xtimes == 1 ) {
    var script = document.createElement('script');
    script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
    script.async = true;
    document.head.appendChild(script);
    xtimes = 0;
    console.log(xtimes);
  } 
};
window.addEventListener("scroll", function() { ActiveMaxJax(); });
window.addEventListener("click", function() { ActiveMaxJax(); });
window.addEventListener("mousemove", function() { ActiveMaxJax(); });
window.addEventListener("keydown", function() { ActiveMaxJax(); });
window.addEventListener("touchstart", function() { ActiveMaxJax(); });
window.addEventListener("keydown", function() { ActiveMaxJax(); });
console.log("MaxJax Initialization Complete");
</script>
<script>
// Load the script after the user scrolls, moves the mouse, or touches the screen
document.addEventListener('scroll', initGTMOnEvent);
document.addEventListener('mousemove', initGTMOnEvent);
document.addEventListener('touchstart', initGTMOnEvent);
// Or, load the script after 2 seconds
document.addEventListener('DOMContentLoaded', () => { setTimeout(initGTM, 2000); });
// Initializes Google Tag Manager in response to an event
function initGTMOnEvent (event) {
	initGTM();
	event.currentTarget.removeEventListener(event.type, initGTMOnEvent);
}
// Initializes Google Tag Manager
function initGTM () {
	if (window.gtmDidInit) {
	  // Don't load again
	  return false;
	}
	window.gtmDidInit = true;
	
	// Create the script
	const script = document.createElement('script');
	script.type = 'text/javascript';
	script.onload = () => { 
	  window.dataLayer = window.dataLayer || [];
	  function gtag(){ dataLayer.push(arguments); }
	  gtag('js', new Date());
	  gtag('config', 'G-899QW82HQV');
	}
	script.src = 'https://www.googletagmanager.com/gtag/js?id=G-899QW82HQV';
	
	// We are still deferring the script
	script.defer = true;
	
	// Append the script to the body of the document
	document.getElementsByTagName('body')[0].appendChild(script);
}
</script>
<style>
    .theorem {
        background: linear-gradient(90deg,rgba(200, 217, 234, .5), rgba(200, 217, 234, .8));
        padding:6px 6px 2px 6px;
        border-left:1px solid rgba(0, 0, 255, 0.22);
        margin:12px 0px;
    }
    .theorem-title strong::after {
        content:'. ';
        margin-left:-4px;
        padding-right:5px;
    }
    .lemma {
        background: linear-gradient(90deg,rgba(188, 201, 168, 0.5), rgba(188, 201, 168, .8));
    }
    .corollary {
        background: linear-gradient(90deg,rgba(248, 197, 240, 0.5), rgba(248, 197, 240, .8));
    }
    .proposition {
        background: linear-gradient(90deg,rgba(248, 210, 219, 0.5), rgba(248, 210, 219, .8));
    }
    .definition {
        background: linear-gradient(90deg,rgba(210, 180, 140, .5), rgba(210, 180, 140, .8));
    }
    .example {
        background: linear-gradient(90deg,rgba(255, 255, 204, .5), rgba(255, 255, 204, .8));
    }
    .exercise {
        background: linear-gradient(90deg,rgba(250, 235, 199, 0.5), rgba(250, 235, 199, .8));
    }
    .proof-title {
        font-weight:600;
    }
    ol li::marker {
        content: "(" counter(list-item, lower-arabic) ") ";
     }
     .solution:after, .proof:after {
        margin-top:-44px;
        margin-bottom:64px;
        float:right;
        content: '\25A0';
     }
     .blockquote {
        font-weight: 500!important;
        color:#000000!important;
     }
</style>
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var filterRegex = new RegExp(/https:\/\/directknowledge\.com\/learning-linear-algebra\//);
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
    var links = window.document.querySelectorAll('a:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // target, if specified
          link.setAttribute("target", "_blank");
      }
    }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./determinants.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Determinants</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./canonical-forms.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Canonical Forms</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
      <div class="nav-footer-center">
        <ul class="footer-items list-unstyled">
    <li class="nav-item">
    <a class="nav-link" href="https://directknowledge.com">© Copyright 2023, All Rights Reserved. DirectKnowledge.com</a>
  </li>  
</ul>
      </div>
  </div>
</footer>
<script src="site_libs/quarto-html/zenscroll-min.js"></script>
<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
</body></html>