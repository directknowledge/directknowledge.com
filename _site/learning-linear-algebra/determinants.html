<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.280">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<meta name="description" content="Learning Linear Algebra">
<title>Determinants - Learning Linear Algebra</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>
<meta name="quarto:offset" content="./">
<link href="./eigenvalues-and-eigenvectors.html" rel="next">
<link href="./inner-products-spaces.html" rel="prev">
<link href="./../assets/favicon.ico" rel="icon">
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>
<style>
@media screen and (max-width: 440px) {
    .navbar-brand-logo::after {
        content: 'DK'!important;
        margin-top: -4px!important;
    }
    .navbar-toggler-icon {
        width:26px!important;
        height:26px!important;
    }
    .navbar-toggler {
        border:0px!important;
    }
    .navbar-title {
        display:none!important;
    }
    .footer-items {
        display:block!important;
        margin:40px 0px;
    }    
}
.navbar-title:hover, .navbar a:hover {
    color:#000000!important;
}
.book-title {
    font-weight:800;
    text-transform: uppercase;
    font-size: 150%;
    margin:-20px -20px 20px -20px;
    line-height:120%;
    text-decoration: none!important;
    display:block;
}
@media screen and (max-width: 990px) {
    .book-title {
        padding-left: 20px!important;
    }    
}
</style>
  
<meta property="og:title" content="Determinants - Learning Linear Algebra">
<meta property="og:description" content="Learning Linear Algebra">
<meta property="og:site-name" content="Learning Linear Algebra">
</head>
<body class="nav-sidebar floating nav-fixed">
<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a href="./index.html" class="navbar-brand navbar-brand-logo">
    <img src="./../assets/directknowledge-logo.svg" alt="Direct Knowledge Logo" width="28" height="24"  class="navbar-logo">
    </a>
    <a aria-label="Learning Linear Algebra" class="navbar-brand" href="https://directknowledge.com">
    <span class="navbar-title">Direct Knowledge</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-books" role="button" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Books</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-books">    
        <li>
    <a class="dropdown-item" href="https://directknowledge.com/basic-set-theory/"><i class="bi bi-book" role="img" aria-label="Basic Set Theory Book">
</i> 
 <span class="dropdown-text">Basic Set Theory</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://directknowledge.com/learning-number-theory/"><i class="bi bi-book" role="img" aria-label="Learning Linear Algebra Book">
</i> 
 <span class="dropdown-text">Learning Number Theory</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://directknowledge.com/learning-linear-algebra/"><i class="bi bi-book" role="img" aria-label="Learning Linear Algebra Book">
</i> 
 <span class="dropdown-text">Learning Linear Algebra</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://directknowledge.com/single-variable-calculus/"><i class="bi bi-book" role="img" aria-label="Single Variable Calculus Book">
</i> 
 <span class="dropdown-text">Single Variable Calculus</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://directknowledge.com/multivariable-calculus/"><i class="bi bi-book" role="img" aria-label="Multivariable Calculus Book">
</i> 
 <span class="dropdown-text">Multivariable Calculus</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="http://directknowledge.com/about.html">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.youtube.com/channel/UCi_E35l9kKfrxoQJRMbgMsg/"><i class="bi bi-youtube" role="img" aria-label="YouTube">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/directknowledge"><i class="bi bi-github" role="img" aria-label="GitHub">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/directknowledge"><i class="bi bi-github" role="img" aria-label="Source Code">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Determinants</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
      <div class="mt-2 flex-shrink-0 align-items-center">
        <a class="book-title" href="https://directknowledge.com/learning-linear-algebra/">Learning Linear Algebra</a><div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Preface</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./systems-of-linear-equations.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Systems of Linear Equations</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./vector-spaces.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Vector Spaces</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./linear-transformations.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Linear Transformations</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./inner-products-spaces.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Inner Products Spaces</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./determinants.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Determinants</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./eigenvalues-and-eigenvectors.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Eigenvalues and Eigenvectors</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./canonical-forms.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Canonical Forms</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">References</a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><a href="https://directknowledge.com/learning-linear-algebra/"><picture><source type="image/webp" srcset="../../assets/learning-linear-algebra-cover.webp"><source type="image/webp" srcset="../../assets/learning-linear-algebra-cover-thumbnail.png"><img class="shadow border" style="margin-bottom:12px;" width="192" height="288" src="../../assets/learning-linear-algebra-cover.png" alt="Learning Linear Algebra Book Cover"></picture></a>
    <h2 id="toc-title">Chapter Contents</h2>
   
  <ul>
  <li><a href="#what-are-determinants-and-what-do-they-do" id="toc-what-are-determinants-and-what-do-they-do" class="nav-link active" data-scroll-target="#what-are-determinants-and-what-do-they-do"><span class="toc-section-number">5.1</span>  What are determinants and what do they do</a></li>
  <li><a href="#how-to-find-the-determinant-of-a-matrix" id="toc-how-to-find-the-determinant-of-a-matrix" class="nav-link" data-scroll-target="#how-to-find-the-determinant-of-a-matrix"><span class="toc-section-number">5.2</span>  How to find the determinant of a matrix</a></li>
  <li><a href="#determinant-properties" id="toc-determinant-properties" class="nav-link" data-scroll-target="#determinant-properties"><span class="toc-section-number">5.3</span>  Determinant Properties</a></li>
  <li><a href="#expansion-by-cofactors" id="toc-expansion-by-cofactors" class="nav-link" data-scroll-target="#expansion-by-cofactors"><span class="toc-section-number">5.4</span>  Expansion by Cofactors</a></li>
  <li><a href="#cramers-rule" id="toc-cramers-rule" class="nav-link" data-scroll-target="#cramers-rule"><span class="toc-section-number">5.5</span>  Cramer’s Rule</a></li>
  <li><a href="#how-i-teach-in-this-book" id="toc-how-i-teach-in-this-book" class="nav-link" data-scroll-target="#how-i-teach-in-this-book"><span class="toc-section-number">5.6</span>  How I teach in this book</a></li>
  <li><a href="#cramer" id="toc-cramer" class="nav-link" data-scroll-target="#cramer"><span class="toc-section-number">5.7</span>  Cramer</a></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/directknowledge/issues/new" class="toc-action">Report an issue</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">
<header id="title-block-header">
<h1 class="title d-none d-lg-block display-7"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Determinants</span></h1>
</header>
<div class="d-none">
<p><span class="math inline">\(\newcommand{\vlist}[2]{#1_1,#1_2,\ldots,#1_#2}\)</span> <span class="math inline">\(\newcommand{\vectortwo}[2]{\begin{bmatrix} #1 \\ #2\end{bmatrix}}\)</span> <span class="math inline">\(\newcommand{\vectorthree}[3]{\begin{bmatrix} #1 \\ #2 \\ #3\end{bmatrix}}\)</span> <span class="math inline">\(\newcommand{\vectorfour}[4]{\begin{bmatrix} #1 \\ #2 \\ #3 \\ #4\end{bmatrix}}\)</span> <span class="math inline">\(\newcommand{\vectorfive}[5]{\begin{bmatrix} #1 \\ #2 \\ #3 \\ #4 \\ #5 \end{bmatrix}}\)</span> <span class="math inline">\(\newcommand{\lincomb}[3]{#1_1 \vec{#2}_1+#1_2 \vec{#2}_2+\cdots + #1_m \vec{#2}_#3}\)</span> <span class="math inline">\(\newcommand{\norm}[1]{\left|\left |#1\right|\right |}\)</span> <span class="math inline">\(\newcommand{\ip}[1]{\left \langle #1\right \rangle}\)</span> <span class="math inline">\(\newcommand{\plim}[2]{\lim_{\footnotesize\begin{array}{c} \\[-10pt] #1 \\[0pt] #2 \end{array}}}\)</span></p>
</div>
<section id="what-are-determinants-and-what-do-they-do" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="what-are-determinants-and-what-do-they-do"><span class="header-section-number">5.1</span> What are determinants and what do they do</h2>
<p>Determinants are mathematical objects that affect the size, shape, or position of something else. In other words, they determine how something looks or behaves. The most common type of determinant is a matrix, which is used to determine the size, shape, and position of a two-dimensional object.</p>
<p>For example, a matrix can be used to determine the position of a point on a graph or the angle of a line. Determinants can also be used to solve problems in physics and engineering.</p>
<p>For example, they can be used to calculate the forces acting on an object in order to determine its motion. Determinants are also used in economics to predict changes in prices and wages. In short, determinants are powerful tools that can be used to solve a wide variety of problems.</p>
<p>A determinant is a value that can be computed from the elements of a square matrix. The determinant of a matrix A is denoted by det(A), det A, or <span class="math inline">\(\vert A\vert\)</span>.</p>
<p>Geometrically, it can be viewed as the volume of the n-dimensional parallelepiped that has the column vectors of A as its edges. If A is an invertible matrix, then the determinant is nonzero and A can be undone by multiplying it on either side by its inverse matrix. In particular, for a 2×2 matrix, the determinant is simply the product of the diagonal entries (top left times bottom right, minus top right times bottom left).</p>
</section>
<section id="how-to-find-the-determinant-of-a-matrix" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="how-to-find-the-determinant-of-a-matrix"><span class="header-section-number">5.2</span> How to find the determinant of a matrix</h2>
<p>A determinant is a scalar value that can be computed from the elements of a square matrix. It is a useful tool in linear algebra for solving systems of linear equations and for computing the inverse of a matrix.</p>
<p>The determinant of a 2×2 matrix is: <span class="math inline">\(|A|=ad-bc\)</span> where <span class="math inline">\(ad-bc\)</span> is the signed determinant (the “discriminant”) because its value changes sign when two rows or columns are interchanged.&nbsp;</p>
<p>For matrices of larger size, the determinant can be computed using any of several methods, such as cofactor expansion or Laplace expansion. When computing the determinant, it is often convenient to change the order of the rows or columns in order to simplify the calculation.&nbsp;</p>
<p>Another method is to use Gauss-Jordan elimination. This method involves using row operations to transform the matrix into an upper triangular matrix. The determinant of the matrix can then be found by taking the product of the diagonal elements.</p>
</section>
<section id="determinant-properties" class="level2" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="determinant-properties"><span class="header-section-number">5.3</span> Determinant Properties</h2>
<p>The determinant has several important properties:&nbsp;</p>
<ol type="1">
<li><p>If two rows (or columns) of a matrix are identical, then the determinant is zero.&nbsp;</p></li>
<li><p>If two rows (or columns) are interchanged, then the sign of the determinant changes.&nbsp;</p></li>
<li><p>If each element of a row (or column) is multiplied by a nonzero constant, then the determinant is multiplied by that constant.&nbsp;</p></li>
</ol>
</section>
<section id="expansion-by-cofactors" class="level2" data-number="5.4">
<h2 data-number="5.4" class="anchored" data-anchor-id="expansion-by-cofactors"><span class="header-section-number">5.4</span> Expansion by Cofactors</h2>
<p>The determinant of a matrix A is equal to the sum of the products of the elements in any one row or column, with each element being multiplied by a corresponding cofactor. Cofactors are special numbers that can be calculated from the minors of the matrix, which are the determinants of the matrices that result from removing one row and one column from A.</p>
<p>The sign of each cofactor is determined by its position in the matrix: odd-numbered rows and columns have positive signs, while even-numbered rows and columns have negative signs. The determinant of a matrix can be used to solve systems of linear equations, and it also provides information about the nature of the matrix itself.</p>
<p>For example, a matrix with a zero determinant is known as singular, meaning that it cannot be inverted. This makes it an important tool for solving mathematical problems. Determinants can be calculated by hand for small matrices, but larger matrices require the use of specialized software or an electronic calculator.</p>
</section>
<section id="cramers-rule" class="level2" data-number="5.5">
<h2 data-number="5.5" class="anchored" data-anchor-id="cramers-rule"><span class="header-section-number">5.5</span> Cramer’s Rule</h2>
<p>Cramer’s Rule is a method for solving systems of linear equations. In order to use Cramer’s Rule, the system must be expressed in matrix form. The determinant of the matrix is then calculated. This determinant is used to calculate the value of each variable in the system. Cramer’s Rule can be used to solve systems with any number of variables, but the matrices involved become increasingly complex as the number of variables increases.</p>
<p>Despite this complexity, Cramer’s Rule provides a convenient way to solve systems of linear equations.</p>
</section>
<section id="how-i-teach-in-this-book" class="level2" data-number="5.6">
<h2 data-number="5.6" class="anchored" data-anchor-id="how-i-teach-in-this-book"><span class="header-section-number">5.6</span> How I teach in this book</h2>
<p>How I teach in this book, is by showing examples that students can learn from and understand. I also offer an in-depth look into linear algebra. My approach in this book is to first provide a gentle introduction to the topic at hand. Next, I guide the reader through the necessary calculations required to fully grasp the concepts being presented. Finally, I show how these ideas can be applied in practical scenarios.</p>
<p>Throughout the book, I include worked examples and exercises for readers to test their understanding as they progress. With this book as your companion, you will soon be confident in manipulating determinants and matrices.</p>
<p>Determinants are a key concept in Linear Algebra, and understanding them is crucial for being able to do many matrix operations. This book will take you from the very basics of what determinants are, all the way up to using them in advanced topics like Cramer’s Rule. By the end, you will be a pro at using determinants in all sorts of situations.</p>
<p>The book will focus on the fundamentals of eigenvalues and eigenvectors, and how they can be applied in various settings. It is perfect for readers who want to learn more about these topics, or for those who need to brush up on their skills.</p>
<p>The book begins with a review of linear algebra, before moving on to discuss eigenvalues and eigenvectors. This is followed by a discussion of applications of these concepts, including in physics and engineering. The book concludes with a set of exercises for readers to test their understanding.</p>
<p>Eigenvalues and eigenvectors are fundamental concepts in linear algebra, with many applications in physics and engineering. In this section, we will discuss how to find eigenvalues and eigenvectors for a given matrix.</p>
<p>Suppose we have a square matrix <span class="math inline">\(A\)</span>. To find the eigenvalues of <span class="math inline">\(A\)</span>, we need to solve the equation <span class="math inline">\(Ax = \lambda x\)</span> for <span class="math inline">\(\lambda\)</span> and <span class="math inline">\(x\)</span>. Here, <span class="math inline">\(\lambda\)</span> is the eigenvalue and <span class="math inline">\(x\)</span> is the corresponding eigenvector.</p>
<p>To solve this equation, we can use the characteristic polynomial of <span class="math inline">\(A\)</span>. This is a polynomial equation whose roots are the eigenvalues of <span class="math inline">\(A\)</span>. To find the characteristic polynomial, we need to take the determinant of <span class="math inline">\(A - \lambda I\)</span>, where the matrix <span class="math inline">\(I\)</span> is the identity matrix.</p>
<p>In other words, an eigenvector is a vector that does not change direction when multiplied by a matrix. Eigenvectors are often used to diagonalize matrices, which means that they can be used to simplify matrices that do not have a simple structure.</p>
<p>To find the eigenvalues and eigenvectors of a matrix, one can use the characteristic polynomial of the matrix. The characteristic polynomial is a polynomial equation whose roots are the eigenvalues of the matrix. To find the eigenvectors of the matrix, one can use the inverse of the matrix.</p>
<p>The inverse of the matrix is a matrix that satisfies the equation: <span class="math inline">\(A*A-1 = I\)</span>. The inverse of a matrix exists if and only if the determinant of the matrix is not equal to zero. If the determinant of the matrix is equal to zero, then the matrix is singular and does not have an inverse. Once you have found the inverse of the matrix, you can multiply it by the original matrix to find the eigenvectors of the original matrix.</p>
<p>Linear algebra is the study of mathematical objects that can be described by linear equations. These objects include vectors, matrices, and linear transformations. Linear algebra is a powerful tool that can be used to solve many problems in physics and engineering.</p>
<p>One of the most important techniques in linear algebra is diagonalization. This technique can be used to simplify complicated systems of linear equations. It is also a powerful tool for solving eigenvalue problems. In general, diagonalization is an essential tool for anyone who needs to work with linear equations.</p>
<p>Eigenvectors and eigenvalues are often introduced in the context of the diagonalization of matrices. In this context, an <span class="math inline">\(n\)</span>-by-<span class="math inline">\(n\)</span> matrix <span class="math inline">\(A\)</span> is diagonalizable if and only if there exists <span class="math inline">\(n\)</span> linearly independent eigenvectors <span class="math inline">\(v_i\)</span> of <span class="math inline">\(A\)</span>, <span class="math inline">\(i=1,...,n\)</span> such that <span class="math inline">\(Av_i= \lambda_i v_i\)</span> for some scalars <span class="math inline">\(\lambda_i\)</span> which are called eigenvalues. If these conditions hold, then we say that <span class="math inline">\(A\)</span> has <span class="math inline">\(n\)</span> distinct eigenvectors and <span class="math inline">\(n\)</span> distinct eigenvalues.</p>
<p>Diagonalization is the process of diagonalizing a matrix, which means finding a matrix that is equivalent to the original matrix but with the eigenvalues on the diagonal. This can be done by solving for the eigenvectors and then putting them into a matrix.</p>
<p>The eigenvectors are the vectors that stay the same when multiplied by the matrix. They are also called the characteristic vectors or natural modes. The eigenvalues are the scalars that you get when you multiply the eigenvector by the matrix. They tell you how much the vector changes.</p>
<p>In order to find them, you need to set up an equation and solve for them. Once you have them, you can put them into a diagonal matrix and then diagonalize it. This is a very important tool in mathematics and physics.</p>
<p>Diagonalization is not always possible. For example, if the null space of a matrix is not spanned by eigenvectors, then the matrix cannot be diagonalized. However, when diagonalization is possible, it is often very useful. Diagonalization can be used to find solutions to systems of linear equations, simplify calculations, and understand the structure of matrices.</p>
<p>Eigenvalues and eigenvectors are important concepts in linear algebra. They can be used to diagonalize matrices, which is a powerful tool for solving problems. Eigenvalues and eigenvectors can also be used to understand the structure of matrices. In general, they are useful tools for anyone who needs to work with linear equations.</p>
<p>This book includes eigenvectors and eigenvalues and diagonalization of matrices. The teaching in this book is clear and concise, with plenty of opportunity for practice. The finding eigenvectors and eigenvalues chapter is particularly well explained, and the examples are helpful.</p>
<p>The diagonalization of matrices is also explained well, with plenty of opportunity for practice. The new exercises have been added to help reinforce the concepts learned in the book. Overall, this is an excellent resource for those who want to learn more about linear algebra.</p>
<p>Write a content brief for a book review on canonical forms from linear algebra. In mathematical terms, canonical forms are a way of representing a matrix in a simplified way. This book provides an in-depth introduction to the topic, starting with the basics and progressing to more complex concepts.</p>
<p>It is aimed at readers who have a basic understanding of linear algebra, and it covers topics such as invariant subspaces, the Jordan form, and the singular value decomposition. The book also includes worked examples and exercises to help readers develop their understanding of the material.</p>
<p>Invariant subspaces are key to understanding canonical forms. In short, they are mathematical objects that do not change under certain transformations. This book starts with an introduction to invariant subspaces. It explains what they are and how they can be used to simplify calculations. Invariant subspaces are a powerful tool for understanding and manipulating linear transformations. With this book, you will learn how to use them to your advantage.</p>
<p>In mathematics, an invariant subspace of a linear mapping <span class="math inline">\(T: V \to V\)</span>, i.e.&nbsp;from some vector space <span class="math inline">\(V\)</span> to itself, is a subspace <span class="math inline">\(W\)</span> of <span class="math inline">\(V\)</span> that is preserved by <span class="math inline">\(T\)</span>; that is, <span class="math inline">\(T(W) \subseteq W\)</span>. In other words, an invariant subspace is a subspace that is in some sense ``left unchanged” by the transformation. Intuitively, this means that if we take any vector in the subspace and apply the transformation to it, the result will still be in the subspace.</p>
<p>Invariant subspaces arise naturally in many areas of mathematics, and they can be used to great effect in studying linear transformations. For instance, the study of invariant subspaces can help us to understand the structure of a linear transformation and to decompose it into simpler parts.</p>
<p>In addition, the existence of an invariant subspace can often be used to simplify computations involving the transformation. Consequently, the study of invariant subspaces is a fundamental tool in many areas of mathematics.</p>
<p>The dimension of an invariant subspace is called the multiplicity of the eigenvalue associated with that subspace. If the multiplicity of an eigenvalue is equal to its algebraic multiplicity (i.e.&nbsp;if it has the same number of eigenvectors associated with it as there are linearly independent solutions to the equation), then the eigenvalue is said to be geometrically simple.</p>
<p>In contrast, if the multiplicity of an eigenvalue is less than its algebraic multiplicity, then the eigenvalue is said to be geometrically multiple. Geometrically multiple eigenvalues may or may not have distinct eigenspaces; if they do, then each such eigenspace is called an invariant subspace of T.</p>
<p>Geometrically simple eigenvalues always have distinct eigenspaces; in this case, each such eigenspace is also an invariant subspace of T. The study of invariant subspaces plays an important role in many areas of mathematics, including functional analysis, differential equations, and numerical linear algebra.</p>
<p>Jordan normal form is a specific type of upper triangular matrix that is used to represent linear operators on a finite-dimensional vector space. This matrix is made up of Jordan blocks, which are submatrices with identical eigenvalues that have each non-zero off-diagonal entry equal to 1.</p>
<p>Jordan normal form is useful because it allows for the efficient computation of matrix powers and roots. In addition, this form can be used to transform one matrix into another that is similar, meaning that they have the same eigenvalues. Jordan normal form is an important tool in linear algebra and has many applications in physics and engineering.</p>
<p>Jordan Canonical Form, also called Jordan normal form, is a block diagonal matrix consisting of Jordan blocks. This is not entirely unique as the order of the Jordan blocks are not fixed. The Jordan blocks are grouped together by their eigenvalues, but there is no ordering imposed among the eigenvalues or Jordan blocks. Jordan normal form can be applied to any square matrix as long as the field of coefficients contains all the eigenvalues of the matrix. This normal form is named after mathematician Camille Jordan.</p>
<p>Today, Jordan blocks are used in many different areas of mathematics and physics.</p>
<p>In this book, I provide a comprehensive introduction to invariant subspaces and Jordan canonical forms. This will include a review of the necessary linear algebra, as well as numerous examples and applications. In addition, I will discuss how these concepts can be used to simplify computations involving linear transformations.</p>
<p>My approach is to first introduce the necessary theory, followed by worked examples that illustrate how the theory can be applied in practice. I believe that this approach will provide readers with a strong understanding of the material covered in this book.</p>
<p>My approach is based on two fundamental principles: first, that students should be given a firm foundation in the core material; and second, that they should be given ample opportunity to work with the material in order to develop their understanding.</p>
<p>The study of invariant subspaces and Jordan canonical forms is a fundamental tool in many areas of mathematics. These concepts are important in understanding the structure of linear transformations and in simplifying computations. In addition, the existence of an invariant subspace can often be used to simplify computations involving the transformation. Consequently, the study of invariant subspaces and Jordan canonical forms is a fundamental tool in many areas of mathematics.</p>
<p>The determinant function can be defined by essentially two different methods. The advantage of the first definition, one which uses permutations, is that it provides an actual formula for <span class="math inline">\(\det(A)\)</span>, a fact of theoretical importance. The disadvantage is that, quite frankly, computing a determinant by this method can be cumbersome.</p>
<ul>
<li>A <strong>pattern</strong> in an <span class="math inline">\(n\times n\)</span> matrix is a way to choose <span class="math inline">\(n\)</span> entries of the matrix so that there is one chosen entry in each row and in each column of <span class="math inline">\(A\)</span>.</li>
<li>With a pattern <span class="math inline">\(P\)</span> we associate the <strong>product</strong> of all its entries, denoted by prod <span class="math inline">\(P\)</span>.</li>
<li>Two entries in a pattern are said to be <strong>inverted</strong> if one of them is located to the right and above the other in the matrix.</li>
<li>The <strong>signature</strong> of a pattern <span class="math inline">\(P\)</span> is defined as <span class="math inline">\(\text{sgn} P=(-1)^{(\text{number of inversions in } P)}.\)</span></li>
</ul>
<div id="def-" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 5.1 </strong></span>The <strong>determinant</strong> of an <span class="math inline">\(n\times n\)</span> matrix <span class="math inline">\(A\)</span> is defined as <span class="math display">\[
\det (A)=\sum (\text{sgn } P) (\text{prod } P)
\]</span> where the sum is taken over all <span class="math inline">\(n!\)</span> patterns <span class="math inline">\(P\)</span>.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 5.1 </strong></span>Use the definition of an <span class="math inline">\(n\times n\)</span> determinant to prove the formulas for determinants for <span class="math inline">\(2\times 2\)</span> matrices and <span class="math inline">\(3\times 3\)</span> matrices. We find <span class="math display">\[
\begin{vmatrix}
a_{11} &amp; a_{12} \\
a_{21} &amp; a_{22}
\end{vmatrix}
=a_{11}a_{22}-a_{12}a_{21}
\]</span> <span class="math display">\[
\begin{vmatrix}
a_{11} &amp; a_{12} &amp; a_{13} \\
a_{21} &amp; a_{22} &amp; a_{23} \\
a_{31} &amp; a_{32} &amp; a_{33}
\end{vmatrix}
=a_{11} a_{22} a_{33} + a_{12} a_{23} a_{31}
+ a_{13} a_{21} a_{32} - a_{11} a_{23} a_{32}
- a_{12} a_{21} a_{33} -a_{13} a_{22} a_{31}
\]</span></p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 5.2 </strong></span>Find the determinant of the following matrix using the definition of determinant <span class="math display">\[
M=\begin{bmatrix}  
0 &amp; 0 &amp; 1 &amp; 0 &amp; 2 \\
5 &amp; 4 &amp; 3 &amp; 2 &amp; 1 \\
1 &amp; 3 &amp; 5 &amp; 0 &amp; 7 \\
2 &amp; 0 &amp; 4 &amp; 0 &amp; 6 \\
0 &amp; 0 &amp; 3 &amp; 0 &amp; 4
\end{bmatrix} .
\]</span> There are only two patterns with a nonzero product. Therefore <span class="math display">\[
\det M= (-1)^8(2\cdot 3\cdot 3\cdot2\cdot2)+(-1)^{5}(2\cdot 3\cdot 1\cdot 2 \cdot 4)=24.
\]</span></p>
</div>
<div id="lem-" class="theorem lemma">
<p><span class="theorem-title"><strong>Lemma 5.1 </strong></span>The determinant of an (upper or lower) triangular matrix <span class="math inline">\(A\)</span> is the product of the diagonal entries of the matrix.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>Suppose <span class="math display">\[
A=
\begin{bmatrix}
a_{11} &amp; a_{12} &amp; \cdots &amp; a_{1n} \\
0 &amp; a_{22} &amp; \ddots &amp; \vdots \\
\vdots &amp; \ddots &amp; \ddots &amp; a_{n-1,n} \\
0 &amp; \cdots &amp; 0 &amp; a_{nn} &amp;
\end{bmatrix}
\qquad \text{or} \qquad
A=
\begin{bmatrix}
a_{11} &amp; 0 &amp; \cdots &amp; 0 \\
a_{21} &amp; a_{22} &amp; \ddots &amp; \vdots \\
\vdots &amp; \ddots &amp; \ddots &amp; 0 \\
a_{n,1} &amp; \cdots &amp; a_{n,n-1} &amp; a_{nn} &amp;
\end{bmatrix}.
\]</span> To have a nonzero product a pattern must contain the first component of the first column, then the second component of the second column, and so on. Thus, only the diagonal pattern <span class="math inline">\(P\)</span> makes a nonzero contribution. We conclude that <span class="math display">\[
\det A = (\text{sgn } P)(\text{prod }P)=(-1)^0 a_{11} \cdots a_{nn}= a_{11} \cdots a_{nn}.
\]</span></p>
</div>
<div id="thm-" class="theorem">
<p><span class="theorem-title"><strong>Theorem 5.1 </strong></span> Prove that if <span class="math inline">\(A\)</span> and <span class="math inline">\(C\)</span> are square matrices (not necessarily of the same size), then <span class="math display">\[
\det \begin{bmatrix}  A &amp; B \\ 0 &amp; C \end{bmatrix}
= \det \begin{bmatrix}  A &amp; 0 \\ B &amp; C \end{bmatrix}
= (\det A)(\det C).
\]</span></p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>The proof is left for the reader.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 5.3 </strong></span>Find the determinant of the matrix <span class="math display">\[
M=
\begin{bmatrix}
a_{11} &amp; a_{12} &amp; b_{11} &amp; b_{12} \\
a_{21} &amp; a_{22} &amp; b_{21} &amp; b_{22} \\
0 &amp; 0 &amp; c_{11} &amp; c_{12} \\
0 &amp; 0 &amp; c_{21} &amp; c_{22}
\end{bmatrix}.
\]</span> Let <span class="math display">\[
A=
\begin{bmatrix}
a_{11} &amp; a_{12} \\
a_{21} &amp; a_{22}
\end{bmatrix}
\]</span> and <span class="math display">\[
C=
\begin{bmatrix}
c_{11} &amp; c_{12} \\
c_{21} &amp; c_{22}
\end{bmatrix},
\]</span> then <span class="math display">\[
\det M=(\det A)(\det B)=(a_{11}a_{22}-a_{21}a_{12})(c_{11}c_{22}-c_{21}c_{12}).
\]</span></p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 5.4 </strong></span>Find <span class="math inline">\(2\times 2\)</span> matrices <span class="math inline">\(A, B, C, D\)</span> such that <span class="math display">\[
\det \begin{bmatrix} A &amp; B \\ C &amp; D \end{bmatrix} \neq (\det A)(\det D)-(\det B)(\det C).
\]</span> The standard basis for <span class="math inline">\(\mathbb{R}^{2 \times 2}\)</span> works.</p>
</div>
<p>The <strong>trace</strong> of an <span class="math inline">\(n\times n\)</span> matrix <span class="math inline">\(A\)</span> is defined as the sum of the diagonal entries of <span class="math inline">\(A\)</span> and is denoted by <span class="math inline">\(\text{trace}(A)\)</span>.</p>
<div id="thm-" class="theorem">
<p><span class="theorem-title"><strong>Theorem 5.2 </strong></span>If <span class="math inline">\(A\)</span> is a square matrix then <span class="math inline">\(\det (A^T)=\det (A)\)</span> and <span class="math inline">\(\text{trace}(A^T)=\text{trace}(A)\)</span>.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>For each pattern <span class="math inline">\(P\)</span> in <span class="math inline">\(A\)</span> we can consider the corresponding (transposed) pattern <span class="math inline">\(P^T\)</span> in <span class="math inline">\(A^T\)</span>. The two patterns <span class="math inline">\(P\)</span> and <span class="math inline">\(P^T\)</span> involve the same numbers, and they contain the same number of inversions, but the role of the two numbers in each inversion is reversed. Therefore, the two patterns make the same contribution to the respective determinant and so, <span class="math inline">\((\text{sgn} P)(\text{prod} P)=(\text{sgn} P^T)(\text{prod} P^T)\)</span>. Therefore, we conclude that <span class="math inline">\(\det(A)=\det(A^T)\)</span>.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 5.5 </strong></span>Find the determinant of the matrices <span class="math inline">\(M\)</span>, <span class="math inline">\(N\)</span>, <span class="math inline">\(M^T\)</span>, and <span class="math inline">\(N^T\)</span> where <span class="math display">\[
M=\begin{bmatrix} 4 &amp; 3 &amp; 2 &amp; 1 \\ 0 &amp; 5 &amp; 6 &amp; 7 \\ 0 &amp; 0 &amp; 3 &amp; 2 \\ 0 &amp; 0 &amp; 0 &amp; 4 \end{bmatrix}
\qquad \text{and} \qquad
N=\begin{bmatrix}  0 &amp; 0 &amp; 0 &amp; 8 \\ 0 &amp; 0 &amp; 2 &amp; 3 \\ 0 &amp; 7 &amp; 6 &amp; 5 \\ 1 &amp; 2 &amp; 3 &amp; 4  \end{bmatrix} .
\]</span> Since <span class="math inline">\(M\)</span> and <span class="math inline">\(N\)</span> are upper triangular and lower triangular, respectively, <span class="math display">\[
\det M= 4\cdot 5\cdot 3\cdot 4=240
\qquad \text{and} \qquad
\det N= 1\cdot 7\cdot 2\cdot 8=112.
\]</span> Since <span class="math display">\[
M^T=\begin{bmatrix}  4 &amp; 0 &amp; 0 &amp; 0 \\3 &amp; 5 &amp; 0 &amp; 0 \\ 2 &amp; 6 &amp; 3 &amp; 0 \\1 &amp; 7 &amp; 2 &amp; 4\end{bmatrix}
\qquad \text{and} \qquad
N^T=\begin{bmatrix}   0 &amp; 0 &amp; 0 &amp; 1 \\ 0 &amp; 0 &amp; 7 &amp; 2 \\ 0 &amp; 2 &amp; 6 &amp; 3\\ 8 &amp; 3 &amp; 5 &amp; 4 \end{bmatrix}\]</span> and these matrices are lower triangular and upper triangular, respectively, <span class="math display">\[
\det M=\det M^T
\qquad \text{and} \qquad
\det N= \det N^T.
\]</span></p>
</div>
<div id="lem-" class="theorem lemma">
<p><span class="theorem-title"><strong>Lemma 5.2 </strong></span> Suppose <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are <span class="math inline">\(n\times n\)</span> matrices.</p>
<ul>
<li> If <span class="math inline">\(B\)</span> is obtained from <span class="math inline">\(A\)</span> by dividing a row of <span class="math inline">\(A\)</span> by a scalar <span class="math inline">\(k\)</span>, then <span class="math inline">\(\det B=(1/k)\det (A)\)</span>.</li>
<li> If <span class="math inline">\(B\)</span> is obtained from <span class="math inline">\(A\)</span> by a row swap, then <span class="math inline">\(\det(B)=-\det(A)\)</span>.</li>
<li> If <span class="math inline">\(B\)</span> is obtained from <span class="math inline">\(A\)</span> by adding a multiple of a row of <span class="math inline">\(A\)</span> to another row, then <span class="math inline">\(\det(B)=\det(A)\)</span>.</li>
<li> Suppose you swap rows <span class="math inline">\(s\)</span> times as you transform <span class="math inline">\(A\)</span> into <span class="math inline">\(B\)</span>, and you divide various rows by the scalars <span class="math inline">\(k_1,\ldots ,k_r\)</span>, then <span class="math display">\[
\det(A)=(-1)^sk_1\cdots k_r\det(B).
\]</span></li>
<li> If <span class="math inline">\(s\)</span> is the number of row swaps and <span class="math inline">\(k_1,\ldots ,k_r\)</span> are the scalars used to divide rows to obtain pivots in producing <span class="math inline">\(\text{rref}(A)\)</span> when performing Gauss-Jordan elimination, then <span class="math display">\[\begin{equation}
\label{detgjr}
\det(A)=(-1)^sk_1\cdots k_r\det(\text{rref} (A)).
\end{equation}\]</span></li>
</ul>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>The proof is left for the reader.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 5.6 </strong></span>Use Gauss-Jordan elimination to find the determinant of the matrix <span class="math display">\[
M=
\begin{bmatrix}
1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \\
1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 \\
1 &amp; 3 &amp; 6 &amp; 10 &amp; 15 \\
1 &amp; 4 &amp; 10 &amp; 20 &amp; 35  \\
1 &amp; 5 &amp; 15 &amp; 35 &amp; 70
\end{bmatrix} .
\]</span> Using elementary row operations <span class="math inline">\(R_2\to R_2-R_1\)</span>, <span class="math inline">\(R_3\to R_3-R_1\)</span>, <span class="math inline">\(R_4\to R_4-R_1\)</span>, and <span class="math inline">\(R_5\to R_5-R_1\)</span>, <span class="math display">\[
M \rightarrow
M_1=
\begin{bmatrix}
1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \\
0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 \\
0 &amp; 2 &amp; 5 &amp; 9 &amp; 14 \\
0 &amp; 3 &amp; 9 &amp; 19 &amp; 34  \\
0 &amp; 4 &amp; 14 &amp; 34 &amp; 69
\end{bmatrix}
\qquad \text{with} \qquad
\det(M)=\det(M_1).
\]</span> Using elementary row operations <span class="math inline">\(R_3\to -2R2+R_3\)</span>, <span class="math inline">\(R_4\to -3R2+R_4\)</span>, and <span class="math inline">\(R_5\to -4R2+R_5\)</span>, <span class="math display">\[
M_1 \rightarrow
M_2=
\begin{bmatrix}
1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \\
0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 \\
0 &amp; 0 &amp; 1 &amp; 3 &amp; 6 \\
0 &amp; 0 &amp; 3 &amp; 10 &amp; 22  \\
0 &amp; 0 &amp; 6 &amp; 22 &amp; 53
\end{bmatrix}
\qquad \text{with} \qquad
\det(M_1)=\det(M_2).
\]</span> Using elementary row operations <span class="math inline">\(R_4\to -3R3+R_4\)</span>, <span class="math inline">\(R_5\to -6R3+R_5\)</span>, <span class="math display">\[
M_2 \rightarrow
M_3=
\begin{bmatrix}
1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \\
0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 \\
0 &amp; 0 &amp; 1 &amp; 3 &amp; 6 \\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 4  \\
0 &amp; 0 &amp; 0 &amp; 4 &amp; 17
\end{bmatrix}
\qquad \text{with} \qquad
\det(M_2)=\det(M_3).
\]</span> Using the elementary row operation <span class="math inline">\(R_5\to -4R4+R_5\)</span>, <span class="math display">\[
M_3 \rightarrow
M_4=
\begin{bmatrix}
1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \\
0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 \\
0 &amp; 0 &amp; 1 &amp; 3 &amp; 6 \\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 4  \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 1
\end{bmatrix}
\qquad \text{with} \qquad
\det(M_3)=\det(M_4).
\]</span> Therefore <span class="math inline">\(\det(M)=\det(M_4)=1\)</span>.</p>
</div>
<div id="thm-" class="theorem">
<p><span class="theorem-title"><strong>Theorem 5.3 </strong></span>A square matrix <span class="math inline">\(A\)</span> is invertible if and only if <span class="math inline">\(\det A\neq 0\)</span>.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>If <span class="math inline">\(A\)</span> is invertible, then <span class="math inline">\(\text{rref}(A)=I_n\)</span>, so that by <span class="math inline">\(\ref{detgjr}\)</span> <span class="math inline">\(\det(A)\neq 0\)</span>. Conversely, by contrapositive, if <span class="math inline">\(A\)</span> is noninvertible, then the last row of <span class="math inline">\(\text{rref}(A)\)</span> contains all zeros, so that <span class="math inline">\(\det(\text{rref}(A))=0\)</span>. Therefore, <span class="math inline">\(\ref{detgjr}\)</span> shows <span class="math inline">\(\det(A)=0\)</span>.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 5.7 </strong></span>Consider a <span class="math inline">\(4\times 4\)</span> matrix <span class="math inline">\(A\)</span> with rows <span class="math inline">\(\vec v_1, \vec v_2, \vec v_3, \vec v_4\)</span>. If <span class="math inline">\(\det (A)=8\)</span> find the determinant of the matrix <span class="math display">\[
\vectorfour{\vec v_4}{\vec v_2+9\vec v_4}{-\vec v_3}{\vec v_1}.
\]</span> Switching rows 1 and 4, then multiplying row 3 by <span class="math inline">\(-1\)</span>, then adding <span class="math inline">\(-9 R_4\)</span> to <span class="math inline">\(R_2\)</span> yields, <span class="math display">\[
\det \vectorfour{\vec v_4}{\vec v_2+9\vec v_4}{-\vec v_3}{\vec v_1}
=- \det \vectorfour{\vec v_1}{\vec v_2+9\vec v_4}{-\vec v_3}{\vec v_4}
= \det \vectorfour{\vec v_1}{\vec v_2+9\vec v_4}{\vec v_3}{\vec v_4}
= \det \vectorfour{\vec v_1}{\vec v_2}{\vec v_3}{\vec v_4}
=8.
\]</span></p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 5.8 </strong></span>Determine whether the linear transformation given by the following linear equations is an isomorphism. If so, find the inverse transformation. <span class="math display">\[
\left\{ \begin{array}{rl}
y_1&amp;=x_1+2x_2+3x_3 \\
y_2&amp; =3x_2+4x_3 \\
y_3 &amp;= x_1+6x_2 +5x_3.
\end{array}
\right.
\]</span> The coefficient matrix is <span class="math display">\[
A=\begin{bmatrix}  
1 &amp; 2 &amp; 3 \\
0 &amp; 3 &amp; 4 \\
1 &amp; 6 &amp; 5
\end{bmatrix} .
\]</span> We will form the matrix <span class="math inline">\(\left[ A | I_3 \right]\)</span> and apply row operations, thus completing two tasks at once. This process will convert the matrix <span class="math inline">\(A\)</span> into an upper-triangular matrix and thus be able to determine the determinant of <span class="math inline">\(A\)</span> (of thus of the linear transformation) before we actually find the inverse matrix. If at any time we see the determinant will be 0 we will stop and decide that the linear transformation is not an isomorphism. Otherwise we continue applying row operations until we determine <span class="math inline">\(A^{-1}\)</span>. After completing these steps we find <span class="math display">\[
A^{-1}=
\begin{bmatrix}  
9/10 &amp; -4/5 &amp; 1/10 \\
-2/5 &amp; -1/5 &amp; 2/5 \\
3/10 &amp; 2/5 &amp; -3/10
\end{bmatrix} .
\]</span> Therefore the linear transformation is an isomorphism and the inverse transformation is <span class="math display">\[
\left\{ \begin{array}{rl}
x_1&amp;= \frac{9}{10}y_1 -\frac{4}{5}y_2+\frac{1}{10}y_3 \\
x_2&amp; = -\frac{2}{5}y_1 -\frac{1}{5}y_2+\frac{2}{5}y_3 \\
x_3 &amp;=  \frac{3}{10} y_1+ \frac{2}{5}y_2 -\frac{3}{10}y_3.
\end{array}
\right.
\]</span></p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 5.9 </strong></span> The matrix defined by <span class="math display">\[\begin{equation}
\label{vandermondematrix}
V_n=
\begin{bmatrix}
1 &amp; x_1 &amp; x_1^2 &amp; \cdots &amp; x_1^{n-1} \\
1 &amp; x_2 &amp; x_2^2 &amp; \cdots &amp; x_2^{n-1} \\
1 &amp; x_3 &amp; x_3^2 &amp; \cdots &amp; x_3^{n-1} \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
1 &amp; x_n &amp; x_n^2 &amp; \cdots &amp; x_n^{n-1} \\
\end{bmatrix}
\end{equation}\]</span> is called the <span class="math inline">\(n\)</span>-th <strong>Vandermonde matrix</strong> . Prove <span class="math display">\[\begin{equation}
\label{vandermondedet}
det(V_n)=\prod_{1\leq i&lt;j\leq n} (x_j-x_i).
\end{equation}\]</span> By <span class="math inline">\(\ref{detgjrlemma}\)</span>-<span class="math inline">\(\eqref{detgjrlemmathree}\)</span>, we can perform the row operations <span class="math inline">\(R_i\rightarrow R_i-R_1\)</span> for <span class="math inline">\(2\leq i \leq n\)</span> leaving the value of the determinant unchanged, so <span class="math display">\[\begin{equation}
\det(V_n)
=
\begin{vmatrix}
1 &amp; x_1 &amp; x_1^2 &amp; \cdots &amp; x_1^{n-1} \\
1 &amp; x_2 &amp; x_2^2 &amp; \cdots &amp; x_2^{n-1} \\
1 &amp; x_3 &amp; x_3^2 &amp; \cdots &amp; x_3^{n-1} \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
1 &amp; x_n &amp; x_n^2 &amp; \cdots &amp; x_n^{n-1} \\
\end{vmatrix}
=
\begin{vmatrix}
1 &amp; x_1 &amp; x_1^2 &amp; \cdots &amp; x_1^{n-1} \\
0 &amp; x_2-x_1 &amp; x_2^2-x_1^2 &amp; \cdots &amp; x_2^{n-1}-x_1^{n-1} \\
0 &amp; x_3-x_1 &amp; x_3^2-x_1^2 &amp; \cdots &amp; x_3^{n-1}-x_1^{n-1} \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
0 &amp; x_n-x_1 &amp; x_n^2-x_1^2 &amp; \cdots &amp; x_n^{n-1}-x_1^{n-1} \\
\end{vmatrix}
\end{equation}\]</span> By <span class="math inline">\(\ref{detgjrlemma}\)</span>-<span class="math inline">\(\eqref{detgjrlemmathree}\)</span> and <span class="math inline">\(\ref{propdettrace}\)</span>-<span class="math inline">\(\eqref{propdettraceone}\)</span>, we can perform the column operations <span class="math inline">\(C_i\rightarrow C_{i}-x_1C_{i-1}\)</span> for <span class="math inline">\(2&lt; i \leq n\)</span> leaving the value of the determinant unchanged, so <span class="math display">\[\begin{equation}
=
\begin{vmatrix}
1 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; x_2-x_1 &amp; (x_2-x_1)x_2 &amp; \cdots &amp; (x_2-x_1)x_2^{n-2} \\
0 &amp; x_3-x_1 &amp; (x_3-x_1)x_3 &amp; \cdots &amp; (x_3-x_1)x_3^{n-2} \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
0 &amp; x_n-x_1 &amp; (x_n-x_1)x_n &amp; \cdots &amp; (x_n-x_1)x_n^{n-2} \\
\end{vmatrix}
=
\prod_{k=2}^n (x_k-x_1) \det(V_{n-1}).
\end{equation}\]</span> This process ends with <span class="math inline">\(\det(V_2)=x_n-x_{n-1}\)</span> and so <span class="math inline">\(\ref{vandermondedet}\)</span> follows.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 5.10 </strong></span>Show the transformation <span class="math display">\[
T(\vec x )=\det \begin{bmatrix}  \vec v_1 &amp; \cdots &amp; \vec v_{i-1} &amp; \vec x &amp; \vec v_{i+1} &amp; \cdots &amp; \vec v_n \end{bmatrix}
\]</span> from <span class="math inline">\(\mathbb{R}^{n\times 1}\)</span> to <span class="math inline">\(\mathbb{R}\)</span> is a linear transformation. Similarly, show the transformation <span class="math display">\[
T(\vec x )=\det \begin{bmatrix}  \vec v_1 &amp; \cdots &amp; \vec v_{i-1} &amp; \vec x &amp; \vec v_{i+1} &amp; \cdots &amp; \vec v_n \end{bmatrix} ^T
\]</span> from <span class="math inline">\(\mathbb{R}^{1\times n}\)</span> to <span class="math inline">\(\mathbb{R}\)</span> is a linear transformation.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 5.11 </strong></span>Find the image and kernel of the linear transformation <span class="math display">\[
T(\vec x)=\det \begin{bmatrix} \vec x &amp; \vec u &amp; \vec v \end{bmatrix}
\]</span> from <span class="math inline">\(\mathbb{R}^3\)</span> to <span class="math inline">\(\mathbb{R}\)</span>, where <span class="math inline">\(\vec u =\vectorthree{2}{0}{0}^T\)</span> and <span class="math inline">\(\vec v=\vectorthree{0}{1}{3}^T\)</span>. Notice that <span class="math display">\[\begin{align*}
T(\vec e_1) &amp;=\det \begin{bmatrix} 1 &amp; 2 &amp; 0 \\ 0 &amp; 0 &amp; 1 \\ 0 &amp; 0 &amp; 3 \end{bmatrix} = 0, \\
T(\vec e_2) &amp;=\det \begin{bmatrix} 0 &amp; 2 &amp; 0 \\ 1 &amp; 0 &amp; 1 \\ 0 &amp; 0 &amp; 3 \end{bmatrix}
=- \det \begin{bmatrix} 1 &amp; 0 &amp; 1 \\ 0 &amp; 2 &amp; 0 \\ 0 &amp; 0 &amp; 3 \end{bmatrix}
=-6, \quad \text{and} \\
T(\vec e_3) &amp;=\det \begin{bmatrix} 0 &amp; 2 &amp; 0 \\ 0 &amp; 0 &amp; 1 \\ 1 &amp; 0 &amp; 3 \end{bmatrix}
= \det \begin{bmatrix} 1 &amp; 0 &amp; 3 \\ 0 &amp; 2 &amp; 0 \\ 0 &amp; 0 &amp; 1 \end{bmatrix}
=2.
\end{align*}\]</span> Therefore, the matrix of <span class="math inline">\(T\)</span> with respect to the standard basis <span class="math inline">\(\vec e_1, \vec e_2, \vec e_3\)</span> is <span class="math inline">\(B=\begin{bmatrix} 0 &amp; -6 &amp; 2 \end{bmatrix}\)</span>, and so <span class="math inline">\(T(\vec x)=B \vec x\)</span>. To find the kernel we solve the system <span class="math display">\[
\begin{bmatrix} 0 &amp; -6 &amp; 2 \end{bmatrix} \vectorthree{x_1}{x_2}{x_3}^T=0.
\]</span> Thus the kernel has basis <span class="math display">\[
\left ( \vectorthree{1}{0}{0}^T, \vectorthree{0}{1}{1}^T\right )
\]</span> which means the dimension of the kernel of <span class="math inline">\(T\)</span> is 2, and so by the rank nullity theorem the dimension of the image of <span class="math inline">\(T\)</span> is 1.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 5.12 </strong></span>Consider the linear transformation <span class="math display">\[
T(\vec x)=\det \begin{bmatrix} \vec x &amp; \vec v_2 &amp; \vec v_3 &amp; \cdots &amp; v_n \end{bmatrix}
\]</span> from <span class="math inline">\(\mathbb{R}^n\)</span> to <span class="math inline">\(\mathbb{R}\)</span>, where <span class="math inline">\(\vec v_2, \vec v_3,\ldots ,\vec v_n\)</span> are linearly independent vectors in <span class="math inline">\(\mathbb{R}^n\)</span>. Describe the image and kernel of this transformation, and determine their dimensions. Since <span class="math inline">\(\vec v_1,\ldots ,\vec v_n\)</span> are linearly independent, <span class="math inline">\(T(\vec x)=0\)</span> only if <span class="math inline">\(\vec x\)</span> is a linear combination of the <span class="math inline">\(\vec v_i\)</span>’s, (otherwise the matrix <span class="math inline">\(\begin{bmatrix} \vec x &amp; \vec v_1 &amp; \cdots &amp; \vec v_n\end{bmatrix}\)</span> is invertible, and <span class="math inline">\(T(\vec x)\neq 0\)</span>). Hence, the kernel of <span class="math inline">\(T\)</span> is the span of <span class="math inline">\(\vec v_2,\ldots , \vec v_n\)</span>, an <span class="math inline">\((n-1)\)</span>-dimensional subspace of <span class="math inline">\(\mathbb{R}^n\)</span>. The image of <span class="math inline">\(T\)</span> is the real line <span class="math inline">\(\mathbb{R}\)</span> (since it must be 1-dimensional).</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 5.13 </strong></span>For a fixed positive integer <span class="math inline">\(n\)</span>, let <span class="math inline">\(D\)</span> be a function which assigns to any <span class="math inline">\(n\times n\)</span> matrix <span class="math inline">\(A\)</span> a number <span class="math inline">\(D(A)\)</span> such that</p>
<ul>
<li><span class="math inline">\(D\)</span> is linear in the rows,</li>
<li><span class="math inline">\(D(B)=-D(A)\)</span> if <span class="math inline">\(B\)</span> is obtained from <span class="math inline">\(A\)</span> by a row swap, and</li>
<li><span class="math inline">\(D(I_n)=1\)</span>.</li>
</ul>
<p>Show that <span class="math inline">\(D(A)=\det(A)\)</span> for all <span class="math inline">\(n\times n\)</span> matrices <span class="math inline">\(A\)</span>. First we comment that if a square matrix <span class="math inline">\(A\)</span> has two equal rows, then <span class="math inline">\(D(A)=0\)</span>. Indeed, if we swap two equal rows and call the resulting matrix <span class="math inline">\(B\)</span>, then <span class="math inline">\(B=A\)</span>, so that <span class="math inline">\(D(A)=D(B)=-D(A)\)</span>, by property (ii), and <span class="math inline">\(D(A)=0\)</span> as claimed.</p>
<p>Next we need to understand how the elementary row operations affect <span class="math inline">\(D\)</span>. Properties (i) and (ii) tell us about row multiplication and row swaps, but we still need to think about row additions. We will show that if <span class="math inline">\(B\)</span> is obtained from <span class="math inline">\(A\)</span> by adding <span class="math inline">\(k\)</span> times the <span class="math inline">\(i\)</span>th row to the <span class="math inline">\(j\)</span>th, then <span class="math inline">\(D(B)=D(A)\)</span>, Let’s label the row vectors of <span class="math inline">\(A\)</span> by <span class="math inline">\(\vec v_1,.,,,\vec v_n\)</span>. By linearity of <span class="math inline">\(D\)</span> in the <span class="math inline">\(j\)</span>th row (i) we have <span class="math display">\[
D(B)=D\left(\begin{bmatrix} \vdots \\ \vec v_i \\ \vdots \\ \vec v_j+k \vec v_i \\ \vdots  \end{bmatrix} \right)
=D(A)+kD\left(\begin{bmatrix} \vdots \\ \vec v_i \\ \vdots \\ \vec v_i \\ \vdots \end{bmatrix} \right)
=D(A).
\]</span> Note that in the last step we have used the remark made at the beginning. Now we can write <span class="math display">\[
D(A)=(-1)^sk_1\cdots k_r D(\text{rref}(A))
\]</span> where <span class="math inline">\(s\)</span> is the number of row swaps and <span class="math inline">\(k_1,\ldots ,k_r\)</span> are scalars used to obtain the pivots in the Gaussian reduction.</p>
<p>Next we observe that if <span class="math inline">\(D(\text{rref}(A))=\det(\text{rref}(A))\)</span> for all square matrices <span class="math inline">\(A\)</span>. Indeed, if <span class="math inline">\(A\)</span> is invertible, then <span class="math inline">\(\text{rref}(A)=I_n\)</span>, and <span class="math inline">\(D(I_n)=1=\det(I_n)\)</span> by property (iii). If <span class="math inline">\(A\)</span> fails to be invertible then <span class="math display">\[
D(\text{rref}(A))=0=\det(\text{rref}(A)
\]</span> by linearity in the last row.</p>
<p>It follows that <span class="math display">\[
D(A)=(-1)^sk_1\cdots k_r D(\text{rref}(A))=(-1)^sk_1\cdots k_r \det(\text{rref}(A))=\det(A)
\]</span> as desired.</p>
</div>
<p>::: {#thm- } [Properties of Determinant and Trace] </p>
<ul>
<li>If <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are square matrices, then <span class="math inline">\(\det (AB)=(\det A)(\det B)\)</span>.</li>
<li>If <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are square matrices of the same size, then <span class="math inline">\(\text{trace}(AB)=\text{trace}(BA)\)</span> and <span class="math inline">\(\text{trace}(A+B)=\text{trace}(A)+\text{trace}(B)\)</span>.</li>
<li>If <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are similar matrices, then <span class="math inline">\(\det(A)=\det(B)\)</span> and <span class="math inline">\(\text{trace}(A)=\text{trace}(B)\)</span>.</li>
<li>If <span class="math inline">\(A\)</span> is an invertible matrix, then <span class="math inline">\(\det (A^{-1})=(\det A)^{-1}\)</span>. :::</li>
</ul>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>The proof of each part follows.</p>
<ul>
<li>Suppose <span class="math inline">\(A=\begin{bmatrix} a_{i j} \end{bmatrix}\)</span> and <span class="math inline">\(B=\begin{bmatrix} b_{i j} \end{bmatrix}.\)</span> The <span class="math inline">\(i^\text{th}\)</span> term on the diagonal of <span class="math inline">\(A+B\)</span> is <span class="math inline">\(a_{i,i}+b_{i,i}\)</span>, thus <span class="math display">\[
\text{trace}(A+B)=\sum_{i=1}^n  (a_{i,i}+b_{i,i})=\sum_{i=1}^n  a_{i,i}+\sum_{i=1}^nb_{i,i}=\text{trace}(A)+\text{trace}(B).
\]</span> The <span class="math inline">\(i^\text{th}\)</span> term on the diagonal of <span class="math inline">\(AB\)</span> is <span class="math inline">\(\sum_{j=1}^na_{i,j}b_{j,i}\)</span> and the <span class="math inline">\(i^\text{th}\)</span> term on the diagonal of <span class="math inline">\(BA\)</span> is <span class="math inline">\(\sum_{i=1}^n b_{j,i}a_{i,j}.\)</span> Therefore, <span class="math display">\[
\text{trace}(AB)
=\sum_{i=1}^n \sum_{j=1}^n a_{i,j}b_{j,i}
=\sum_{i=1}^n \sum_{j=1}^n b_{j,i}a_{i,j}
=\text{trace}(BA)
\]</span> as desired.</li>
<li>If matrices <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are similar there exists an invertible matrix <span class="math inline">\(P\)</span> such that <span class="math inline">\(B=P^{-1}AB\)</span>. Then, <span class="math display">\[
\text{trace}(P^{-1}AP)
=\text{trace}(P^{-1}(AP))
=\text{trace}((AP)P^{-1})
=\text{trace}(A).
\]</span></li>
</ul>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 5.14 </strong></span>Consider an <span class="math inline">\(n\times n\)</span> matrix <span class="math inline">\(A\)</span> such that both <span class="math inline">\(A\)</span> and <span class="math inline">\(A^{-1}\)</span> have integer entries. What are the possible values of <span class="math inline">\(\det(A)\)</span>? Applying the determinant to the equation <span class="math inline">\(A A^{-1}=I_n\)</span>, it follows <span class="math inline">\(\det(A) \det (A^{-1})=1\)</span>. The only way the product of the two integers <span class="math inline">\(\det(A)\)</span> and <span class="math inline">\(\det(A^{-1})\)</span> can be 1 is when they are both 1 or both <span class="math inline">\(-1\)</span>. Therefore, <span class="math inline">\(\det(A)=\pm 1\)</span>.</p>
</div>
<p>Consider the <span class="math inline">\((n-1)\times (n-1)\)</span> matrix <span class="math inline">\(M_{i,j}\)</span> obtained from an <span class="math inline">\(n\times n\)</span> matrix <span class="math inline">\(A\)</span> by deleting the <span class="math inline">\(i\)</span>-th row and <span class="math inline">\(j\)</span>-th column. Then the determinant of <span class="math inline">\(M_{i,j}\)</span> is called the <span class="math inline">\((i,j)\)</span>-th <strong>minor</strong> of <span class="math inline">\(A\)</span>.</p>
<div id="thm-laplace-expansion" class="theorem">
<p><span class="theorem-title"><strong>Theorem 5.4 (Laplace Expansion) </strong></span>The determinant of an <span class="math inline">\(n\times n\)</span> matrix <span class="math inline">\(A=[a_{i,j}]\)</span> can be evaluated by using either one of the following equations: <span class="math display">\[\begin{equation}\label{row expansion}
\det(A)=(-1)^{i+1}a_{i,1}\det(M_{i,1})+\cdots + (-1)^{i+n} a_{i,n}\det(M_{i,n})
\end{equation}\]</span> where <span class="math inline">\(i\)</span> is any integer such that <span class="math inline">\(1\leq i \leq n\)</span>, or <span class="math display">\[\begin{equation}\label{column expansion}
\det(A)=(-1)^{1+j}a_{1,j}\det(M_{1,j})+\cdots + (-1)^{n+j} a_{n,j}\det(M_{n,j})
\end{equation}\]</span> where <span class="math inline">\(j\)</span> is any integer such that <span class="math inline">\(1\leq j \leq n\)</span>.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>The proof is left for the reader.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 5.15 </strong></span>Evaluate the determinant of the matrix <span class="math display">\[
A=
\begin{bmatrix}
3 &amp; 2 &amp; 6 &amp; 4 \\
1 &amp; -2 &amp; -3 &amp; 1 \\
0 &amp; 2 &amp; 3 &amp; 8 \\
4 &amp; -1 &amp; 7 &amp; 2
\end{bmatrix}
\]</span> by using expansion of minors along the second row. Expanding along the second row, by using <span class="math inline">\(\ref{row expansion}\)</span> with <span class="math inline">\(i=2\)</span> and <span class="math inline">\(n=4\)</span> <span class="math display">\[\begin{align*}
\det(A)
&amp;= - \det(M_{2,1})  -2\det(M_{2,2}) +3\det(M_{2,3})  + \det(M_{2,4}) \\
&amp; =-(-104)-2(-6)+3(68)+27=347.
\tag*{ }
\end{align*}\]</span></p>
</div>
<p>The trace and determinant share come common properties, for example, they both are invariants of a linear transformation. To be more explicit, let <span class="math inline">\(T\)</span> be a linear transformation from a linear space <span class="math inline">\(V\)</span> to <span class="math inline">\(V\)</span>, where <span class="math inline">\(V\)</span> is a finite-dimensional linear space. If <span class="math inline">\(\mathcal{B}\)</span> is a basis of <span class="math inline">\(V\)</span> and <span class="math inline">\(B\)</span> is the <span class="math inline">\(\mathcal{B}\)</span>-matrix of <span class="math inline">\(T\)</span>, then we define the <strong>determinant</strong> and <strong>trace</strong> of the linear transformation <span class="math inline">\(T\)</span> as <span class="math inline">\(\det(T)=\det(B)\)</span> and <span class="math inline">\(\text{trace}(T)=\text{trace}(B)\)</span>, respectively.</p>
<div id="thm-" class="theorem">
<p><span class="theorem-title"><strong>Theorem 5.5 </strong></span>The determinant and trace of a linear transformation are independent of the basis chosen.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 5.16 </strong></span>Compute the determinant of the linear transformation <span class="math inline">\(T(f(t))=f(3t-2)\)</span> from <span class="math inline">\(\mathcal{P}_2\)</span> to <span class="math inline">\(\mathcal{P}_2\)</span> and use it to determine whether the linear transformation is an isomorphism. We choose to use the standard basis of <span class="math inline">\(\mathcal{P}_2\)</span>, namely <span class="math inline">\((1, t, t^2)\)</span>. With respect to this basis the matrix of <span class="math inline">\(T\)</span> is <span class="math inline">\(A=\begin{bmatrix} 1 &amp; -2 &amp; 4 \\ 0 &amp; 3 &amp; -12 \\ 0 &amp; 0 &amp; 9 \end{bmatrix},\)</span> so that <span class="math inline">\(\det(T)=\det(A)=27\)</span>. Therefore, the given transformation is an isomorphism.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 5.17 </strong></span>Find the determinant of the linear transformation <span class="math display">\[
T(M)=\begin{bmatrix} 1 &amp; 2 \\ 2 &amp; 3\end{bmatrix} M+M\begin{bmatrix} 1 &amp; 2 \\ 2 &amp; 3\end{bmatrix}
\]</span> from the space <span class="math inline">\(V\)</span> of symmetric <span class="math inline">\(2\times 2\)</span> matrices to <span class="math inline">\(V\)</span> and use it to determine whether the linear transformation is an isomorphism. A basis for the space of symmetric <span class="math inline">\(2\times 2\)</span> matrices is <span class="math display">\[
\left(
\begin{bmatrix}  1 &amp; 0 \\ 0 &amp; 0 \end{bmatrix},
\begin{bmatrix}  0 &amp; 1 \\ 1 &amp; 0 \end{bmatrix},
\begin{bmatrix}  0 &amp; 0 \\ 0 &amp; 1 \end{bmatrix}
\right).
\]</span> The matrix of <span class="math inline">\(T\)</span> with respect to this basis is <span class="math display">\[
A=\begin{bmatrix} 2 &amp; 4 &amp; 0 \\ 2 &amp; 4 &amp; 2 \\ 0 &amp; 4 &amp; 6 \end{bmatrix}
\]</span> so that <span class="math inline">\(\det(T)=\det(A)=-16\)</span>. Therefore, the given transformation is an isomorphism.</p>
</div>
<p>::: {#thm- } <a href="#cramer">Cramer</a></p>
<p>Cramer’s rule can be used to prove the Cayley Hamilton theorem of linear algebra, as well as Nakayama’s lemma, which is fundamental in commutative ring theory.</p>
</section>
<section id="cramer" class="level2" data-number="5.7">
<h2 data-number="5.7" class="anchored" data-anchor-id="cramer"><span class="header-section-number">5.7</span> Cramer</h2>
<p>Consider the system of equations <span class="math inline">\(A \vec x=\vec b\)</span> where <span class="math inline">\(A\)</span> is an <span class="math inline">\(n\times n\)</span> invertible matrix. Then the unique solution to the system is given by <span class="math display">\[
x_1=\frac{\det(A_1)}{\det(A)},\qquad x_2=\frac{\det(A_2)}{\det(A)},\cdots, \qquad x_n=\frac{\det(A_n)}{\det(A)}
\]</span> where the matrix <span class="math inline">\(A_i\)</span> is the matrix <span class="math inline">\(A\)</span> with the <span class="math inline">\(i\)</span>-th column replaced by <span class="math inline">\(\vec b\)</span>. :::</p>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>The proof is left for the reader.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 5.18 </strong></span>Solve the system using Cramer’s Rule. <span class="math display">\[
\left\{
\begin{matrix}
2x_1 +3x_2-x_3 &amp; =1 \\
4x_1+x_2+2x_3 &amp; = 5 \\
x_1-x_2+x_3 &amp; =2
\end{matrix}
\right.
\]</span> First we compute the determinant of the coefficient matrix <span class="math inline">\(A\)</span>, and find <span class="math inline">\(\det (A)=5\)</span> Since <span class="math inline">\(\det(A)\neq 0\)</span>, we can apply Cramer’s rule, so we compute the required determinants and obtain, according to Cramer’s rule, the solution to the system is <span class="math display">\[
x_1=\frac{\det(A_1)}{\det(A)}=\frac{7}{5},\quad x_2=\frac{\det(A_2)}{\det(A)}=-\frac{3}{5}, \quad x_3=\frac{\det(A_n)}{\det(A)}=0.
\]</span></p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 5.19 </strong></span>Use paper, pencil, and Cramer’s rule to solve the system <span class="math inline">\(A\vec x=\vec b\)</span> where <span class="math inline">\(A\)</span> and <span class="math inline">\(\vec b\)</span> are the following matrices <span class="math display">\[
A=
\begin{bmatrix}
1 &amp; 2 &amp; 3 &amp; 4 \\
-5 &amp; -6 &amp; -7 &amp; -8 \\
9 &amp; -10 &amp; 11 &amp; -12 \\
-13 &amp; 14 &amp; -15 &amp; 16
\end{bmatrix}
\qquad \text{and} \qquad
\vec b=
\begin{bmatrix}
1 \\ 2 \\ 3 \\ 4
\end{bmatrix} .
\]</span> First we find <span class="math inline">\(\det(A)=-256\)</span> and then we find the solution vector <span class="math display">\[
\vec x= \vectorfour{-51/8}{5}{41/8}{-9/2}.
\]</span></p>
</div>
</section>
</main> <!-- /main -->
<script type="application/ld+json">
    {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "Direct Knowledge",
    "url": "https://diretcknowledge.com",
    "logo": "http://directknowledge.com/assets/directknowledge-logo.svg",
    "foundingDate": "2017",
    "founders": [
    {
    "@type": "Person",
    "name": "David Andrew Smith"
    },
    {
    "@type": "Person",
    "name": "David A. Smith"
    } ],
    "address": {
    "@type": "PostalAddress",
    "addressLocality": "Fort Worth",
    "addressRegion": "Texas",
    "addressCountry": "United States"
    },
    "contactPoint": {
    "@type": "ContactPoint",
    "contactType": "customer support",
    "email": "contact@directknowledge.com"
    },
    "sameAs": [
    "https://youtube.com/@directknowledge",
    "https://github.com/directknowledge/"
    ]
    }
</script>
<script type="application/ld+json">
    {
    "@context": "http://schema.org",
    "@type": "WebSite",
          "name": "Direct Knowledge",
        "url": "https://directknowledge.com"
    }
</script>
<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']],
    processRefs: true,
    processEnvironments: true,
    tags: 'ams',
    packages: {'[+]': ['newcommand']},
    processEnvironments: true,
      macros: {
        N: "{\\mathbb{N}}",
        Z: "{\\mathbb{Z}}",
        qed: "{\\square}"
      }
  },
  svg: {
    fontCache: 'global'
  }
};
console.log("MaxJax Initalizing");
</script>
  
<script>
var xtimes = 1;
console.log(xtimes);
ActiveMaxJax = function() {
  if( xtimes == 1 ) {
    var script = document.createElement('script');
    script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
    script.async = true;
    document.head.appendChild(script);
    xtimes = 0;
    console.log(xtimes);
  } 
};
window.addEventListener("scroll", function() { ActiveMaxJax(); });
window.addEventListener("click", function() { ActiveMaxJax(); });
window.addEventListener("mousemove", function() { ActiveMaxJax(); });
window.addEventListener("keydown", function() { ActiveMaxJax(); });
window.addEventListener("touchstart", function() { ActiveMaxJax(); });
window.addEventListener("keydown", function() { ActiveMaxJax(); });
console.log("MaxJax Initialization Complete");
</script>
<script>
// Load the script after the user scrolls, moves the mouse, or touches the screen
document.addEventListener('scroll', initGTMOnEvent);
document.addEventListener('mousemove', initGTMOnEvent);
document.addEventListener('touchstart', initGTMOnEvent);
// Or, load the script after 2 seconds
document.addEventListener('DOMContentLoaded', () => { setTimeout(initGTM, 2000); });
// Initializes Google Tag Manager in response to an event
function initGTMOnEvent (event) {
	initGTM();
	event.currentTarget.removeEventListener(event.type, initGTMOnEvent);
}
// Initializes Google Tag Manager
function initGTM () {
	if (window.gtmDidInit) {
	  // Don't load again
	  return false;
	}
	window.gtmDidInit = true;
	
	// Create the script
	const script = document.createElement('script');
	script.type = 'text/javascript';
	script.onload = () => { 
	  window.dataLayer = window.dataLayer || [];
	  function gtag(){ dataLayer.push(arguments); }
	  gtag('js', new Date());
	  gtag('config', 'G-899QW82HQV');
	}
	script.src = 'https://www.googletagmanager.com/gtag/js?id=G-899QW82HQV';
	
	// We are still deferring the script
	script.defer = true;
	
	// Append the script to the body of the document
	document.getElementsByTagName('body')[0].appendChild(script);
}
</script>
<style>
    .theorem {
        background: linear-gradient(90deg,rgba(200, 217, 234, .5), rgba(200, 217, 234, .8));
        padding:6px 6px 2px 6px;
        border-left:1px solid rgba(0, 0, 255, 0.22);
        margin:12px 0px;
    }
    .theorem-title strong::after {
        content:'. ';
        margin-left:-4px;
        padding-right:5px;
    }
    .lemma {
        background: linear-gradient(90deg,rgba(188, 201, 168, 0.5), rgba(188, 201, 168, .8));
    }
    .corollary {
        background: linear-gradient(90deg,rgba(248, 197, 240, 0.5), rgba(248, 197, 240, .8));
    }
    .proposition {
        background: linear-gradient(90deg,rgba(248, 210, 219, 0.5), rgba(248, 210, 219, .8));
    }
    .definition {
        background: linear-gradient(90deg,rgba(210, 180, 140, .5), rgba(210, 180, 140, .8));
    }
    .example {
        background: linear-gradient(90deg,rgba(255, 255, 204, .5), rgba(255, 255, 204, .8));
    }
    .exercise {
        background: linear-gradient(90deg,rgba(250, 235, 199, 0.5), rgba(250, 235, 199, .8));
    }
    .proof-title {
        font-weight:600;
    }
    ol li::marker {
        content: "(" counter(list-item, lower-arabic) ") ";
     }
     .solution:after, .proof:after {
        margin-top:-44px;
        margin-bottom:64px;
        float:right;
        content: '\25A0';
     }
     .blockquote {
        font-weight: 500!important;
        color:#000000!important;
     }
</style>
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var filterRegex = new RegExp(/https:\/\/directknowledge\.com\/learning-linear-algebra\//);
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
    var links = window.document.querySelectorAll('a:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // target, if specified
          link.setAttribute("target", "_blank");
      }
    }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./inner-products-spaces.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Inner Products Spaces</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./eigenvalues-and-eigenvectors.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Eigenvalues and Eigenvectors</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
      <div class="nav-footer-center">
        <ul class="footer-items list-unstyled">
    <li class="nav-item">
    <a class="nav-link" href="https://directknowledge.com">© Copyright 2023, All Rights Reserved. DirectKnowledge.com</a>
  </li>  
</ul>
      </div>
  </div>
</footer>
<script src="site_libs/quarto-html/zenscroll-min.js"></script>
<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
</body></html>