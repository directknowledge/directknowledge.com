<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.280">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<meta name="description" content="Learning Linear Algebra">
<title>Linear Transformations - Learning Linear Algebra</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>
<meta name="quarto:offset" content="./">
<link href="./inner-products-spaces.html" rel="next">
<link href="./vector-spaces.html" rel="prev">
<link href="./../assets/favicon.ico" rel="icon">
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>
<style>
@media screen and (max-width: 440px) {
    .navbar-brand-logo::after {
        content: 'DK'!important;
        margin-top: -4px!important;
    }
    .navbar-toggler-icon {
        width:26px!important;
        height:26px!important;
    }
    .navbar-toggler {
        border:0px!important;
    }
    .navbar-title {
        display:none!important;
    }
    .footer-items {
        display:block!important;
        margin:40px 0px;
    }    
}
.navbar-title:hover, .navbar a:hover {
    color:#000000!important;
}
.book-title {
    font-weight:800;
    text-transform: uppercase;
    font-size: 150%;
    margin:-20px -20px 20px -20px;
    line-height:120%;
    text-decoration: none!important;
    display:block;
}
@media screen and (max-width: 990px) {
    .book-title {
        padding-left: 20px!important;
    }    
}
</style>
  
<meta property="og:title" content="Linear Transformations - Learning Linear Algebra">
<meta property="og:description" content="Learning Linear Algebra">
<meta property="og:site-name" content="Learning Linear Algebra">
</head>
<body class="nav-sidebar floating nav-fixed">
<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a href="./index.html" class="navbar-brand navbar-brand-logo">
    <img src="./../assets/directknowledge-logo.svg" alt="Direct Knowledge Logo" width="28" height="24"  class="navbar-logo">
    </a>
    <a aria-label="Learning Linear Algebra" class="navbar-brand" href="https://directknowledge.com">
    <span class="navbar-title">Direct Knowledge</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-books" role="button" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Books</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-books">    
        <li>
    <a class="dropdown-item" href="https://directknowledge.com/basic-set-theory/"><i class="bi bi-book" role="img" aria-label="Basic Set Theory Book">
</i> 
 <span class="dropdown-text">Basic Set Theory</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://directknowledge.com/learning-number-theory/"><i class="bi bi-book" role="img" aria-label="Learning Linear Algebra Book">
</i> 
 <span class="dropdown-text">Learning Number Theory</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://directknowledge.com/learning-linear-algebra/"><i class="bi bi-book" role="img" aria-label="Learning Linear Algebra Book">
</i> 
 <span class="dropdown-text">Learning Linear Algebra</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://directknowledge.com/single-variable-calculus/"><i class="bi bi-book" role="img" aria-label="Single Variable Calculus Book">
</i> 
 <span class="dropdown-text">Single Variable Calculus</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://directknowledge.com/multivariable-calculus/"><i class="bi bi-book" role="img" aria-label="Multivariable Calculus Book">
</i> 
 <span class="dropdown-text">Multivariable Calculus</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="http://directknowledge.com/about.html">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.youtube.com/channel/UCi_E35l9kKfrxoQJRMbgMsg/"><i class="bi bi-youtube" role="img" aria-label="YouTube">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/directknowledge"><i class="bi bi-github" role="img" aria-label="GitHub">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/directknowledge"><i class="bi bi-github" role="img" aria-label="Source Code">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Linear Transformations</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
      <div class="mt-2 flex-shrink-0 align-items-center">
        <a class="book-title" href="https://directknowledge.com/learning-linear-algebra/">Learning Linear Algebra</a><div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Preface</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./systems-of-linear-equations.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Systems of Linear Equations</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./vector-spaces.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Vector Spaces</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./linear-transformations.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Linear Transformations</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./inner-products-spaces.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Inner Products Spaces</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./determinants.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Determinants</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./eigenvalues-and-eigenvectors.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Eigenvalues and Eigenvectors</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./canonical-forms.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Canonical Forms</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">References</a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><a href="https://directknowledge.com/learning-linear-algebra/"><picture><source type="image/webp" srcset="../../assets/learning-linear-algebra-cover.webp"><source type="image/webp" srcset="../../assets/learning-linear-algebra-cover-thumbnail.png"><img class="shadow border" style="margin-bottom:12px;" width="192" height="288" src="../../assets/learning-linear-algebra-cover.png" alt="Learning Linear Algebra Book Cover"></picture></a>
    <h2 id="toc-title">Chapter Contents</h2>
   
  <ul>
  <li><a href="#introduction-to-linear-transformations" id="toc-introduction-to-linear-transformations" class="nav-link active" data-scroll-target="#introduction-to-linear-transformations"><span class="toc-section-number">3.1</span>  Introduction to Linear Transformations</a></li>
  <li><a href="#linear-transformations-in-geometry" id="toc-linear-transformations-in-geometry" class="nav-link" data-scroll-target="#linear-transformations-in-geometry"><span class="toc-section-number">3.2</span>  Linear Transformations in Geometry</a></li>
  <li><a href="#introduction-to-linear-maps" id="toc-introduction-to-linear-maps" class="nav-link" data-scroll-target="#introduction-to-linear-maps"><span class="toc-section-number">3.3</span>  Introduction to Linear Maps</a></li>
  <li><a href="#kernel-and-image-of-a-linear-transformation" id="toc-kernel-and-image-of-a-linear-transformation" class="nav-link" data-scroll-target="#kernel-and-image-of-a-linear-transformation"><span class="toc-section-number">3.4</span>  Kernel and Image of a Linear Transformation</a></li>
  <li><a href="#invertible-linear-transformations" id="toc-invertible-linear-transformations" class="nav-link" data-scroll-target="#invertible-linear-transformations"><span class="toc-section-number">3.5</span>  Invertible Linear Transformations</a></li>
  <li><a href="#coordinates" id="toc-coordinates" class="nav-link" data-scroll-target="#coordinates"><span class="toc-section-number">3.6</span>  Coordinates</a></li>
  <li><a href="#coordinates-and-the-matrix-of-a-linear-map" id="toc-coordinates-and-the-matrix-of-a-linear-map" class="nav-link" data-scroll-target="#coordinates-and-the-matrix-of-a-linear-map"><span class="toc-section-number">3.7</span>  Coordinates and the Matrix of a Linear Map</a></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/directknowledge/issues/new" class="toc-action">Report an issue</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">
<header id="title-block-header">
<h1 class="title d-none d-lg-block display-7"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Linear Transformations</span></h1>
</header>
<div class="d-none">
<p><span class="math inline">\(\newcommand{\vlist}[2]{#1_1,#1_2,\ldots,#1_#2}\)</span> <span class="math inline">\(\newcommand{\vectortwo}[2]{\begin{bmatrix} #1 \\ #2\end{bmatrix}}\)</span> <span class="math inline">\(\newcommand{\vectorthree}[3]{\begin{bmatrix} #1 \\ #2 \\ #3\end{bmatrix}}\)</span> <span class="math inline">\(\newcommand{\vectorfour}[4]{\begin{bmatrix} #1 \\ #2 \\ #3 \\ #4\end{bmatrix}}\)</span> <span class="math inline">\(\newcommand{\vectorfive}[5]{\begin{bmatrix} #1 \\ #2 \\ #3 \\ #4 \\ #5 \end{bmatrix}}\)</span> <span class="math inline">\(\newcommand{\lincomb}[3]{#1_1 \vec{#2}_1+#1_2 \vec{#2}_2+\cdots + #1_m \vec{#2}_#3}\)</span> <span class="math inline">\(\newcommand{\norm}[1]{\left|\left |#1\right|\right |}\)</span> <span class="math inline">\(\newcommand{\ip}[1]{\left \langle #1\right \rangle}\)</span> <span class="math inline">\(\newcommand{\plim}[2]{\lim_{\footnotesize\begin{array}{c} \\[-10pt] #1 \\[0pt] #2 \end{array}}}\)</span></p>
</div>
<p>This book is designed to help students from beginners to pro as they learn and grow in their understanding of linear transformations. Linear transformations are a powerful tool that can be used in a variety of settings, from solving equations to graphing functions.</p>
<p>In this book, students will learn the basics of linear transformations and how to apply them in various situations. By the end of this book, students will be well-prepared to tackle any problem that involves linear transformations.</p>
<p>Linear transformations are a critical tool in mathematics, allowing us to understand how certain objects change under certain conditions. In particular, they help us to understand how vector spaces change when we apply a linear transformation to them.</p>
<p>A vector space is a set of vectors that can be added together and scaled by real numbers. Linear transformations preserve the structure of vector spaces, meaning that they preserve the concept of addition and scalar multiplication.</p>
<p>In other words, if we have a vector space <span class="math inline">\(V\)</span> and a linear transformation <span class="math inline">\(T\)</span>, then the transformed vector space <span class="math inline">\(T(V)\)</span> will also be a vector space. This property is what makes linear transformations so powerful: they allow us to study how objects change without losing any important information about them.</p>
<p>The range of the transformation may be the same as the domain, and when that happens, the transformation is known as an endomorphism or, if invertible, an automorphism.</p>
<p>Vector spaces and linear transformations are important in physics because they provide a way to describe how physical quantities change under the influence of external forces.</p>
<p>For example, the motion of a particle in a straight line can be described as a vector in a vector space, and the force that causes the particle to accelerate can be described as a linear transformation of that vector. Similarly, the electric field in an insulating material can be described as a vector, and the charge that produces that field can be described as a linear transformation of that vector.</p>
<p>Linear transformations are one of the most important tools in mathematical geometry, and they can be used to describe a wide variety of geometric operations. The best-known linear transformation is the translation, which simply moves a figure from one point to another. But there are many other possibilities, including scaling (which changes the size of a figure), rotation (which turns a figure around a fixed point), and reflection (which flips a figure over a line or plane).</p>
<p>Linear transformations can be represented by matrices, which makes them easy to work with in computer programs. And because they preserve straight lines and angles, they are often very useful for solving problems in physics and engineering. In short, linear transformations are a powerful tool for understanding and manipulating the shapes of objects in our world.</p>
<p>Invertible linear transformations are a special type of linear transformation that has an inverse function. This means that it can be undone and that it is reversible. Invertible linear transformations are important in many fields, such as engineering and physics. They are used to model systems that can be reversed, such as springs and magnets. Invertible linear transformations are also used in computer graphics and image processing, where they are used to rotate and resize images.</p>
<p>Linear transformations are a critical tool in mathematics, used to abstract and study problems in a wide variety of fields. In this book, you’ll learn about the kernel and image of a linear transformation.</p>
<p>First, let’s recall the definition of a linear transformation. A linear transformation is a function that satisfies the following two properties:</p>
<ul>
<li>It is additive: for any two vectors x and y in its domain, the function produces a new vector that is the sum of x and y. That is, <span class="math inline">\(T(x+y) = T(x)+T(y)\)</span>.</li>
<li>It is homogeneous: for any vector x in its domain and scalar c, the function produces a new vector that is equal to cx. That is, <span class="math inline">\(T(cx) = cT(x)\)</span>.</li>
</ul>
<p>Now let’s turn our attention to the kernel of a linear transformation. The kernel of a linear transformation <span class="math inline">\(T\)</span> is the set of all vectors x in the domain of <span class="math inline">\(T\)</span> such that <span class="math inline">\(T(x)=0\)</span>. In other words, it is the set of all vectors that are mapped to <span class="math inline">\(0\)</span> by <span class="math inline">\(T\)</span>. It’s important to note that the kernel is always a subspace of the domain of <span class="math inline">\(T\)</span>. This means that it must be closed under addition and scalar multiplication.</p>
<p>The image of a linear transformation <span class="math inline">\(T\)</span> is the set of all vectors <span class="math inline">\(y\)</span> in the codomain of <span class="math inline">\(T\)</span> such that there exists some vector <span class="math inline">\(x\)</span> in the domain of <span class="math inline">\(T\)</span> such that <span class="math inline">\(T(x)=y\)</span>. In other words, it is the set of all vectors that can be reached from some vector in the domain by applying <span class="math inline">\(T\)</span>. Like the kernel, the image is always a subspace of the codomain of <span class="math inline">\(T\)</span>.</p>
<p>The kernel and image of a linear transformation encode important information about how that transformation behaves. By understanding these concepts, we can better analyze and work with linear transformations.</p>
<p>In mathematics, a coordinate matrix is a matrix whose elements are the coordinates of a given vector with respect to a given basis. In other words, if <span class="math inline">\(v\)</span> is a vector in <span class="math inline">\(\mathbb{R}^n\)</span> and <span class="math inline">\(B\)</span> is an <span class="math inline">\(n×n\)</span> matrix, then the product <span class="math inline">\(Bv\)</span> is another vector in <span class="math inline">\(\mathbb{R}^n\)</span> whose coordinates with respect to the standard basis are precisely the entries of the matrix <span class="math inline">\(B\)</span>.</p>
<p>Coordinate matrices are used to represent linear transformations. Given a linear transformation <span class="math inline">\(T:V\to W\)</span> between two finite-dimensional vector spaces <span class="math inline">\(V\)</span> and <span class="math inline">\(W\)</span>, there is a unique coordinate matrix <span class="math inline">\(A\)</span> such that for any vector <span class="math inline">\(v\in V\)</span>, we have <span class="math inline">\(T(v)=Av\)</span>.</p>
<p>In particular, this means that the columns of <span class="math inline">\(A\)</span> are precisely the images of the vectors in some basis for <span class="math inline">\(V\)</span>. Similarly, the rows of <span class="math inline">\(A\)</span> are the coordinates of the vectors in some basis for <span class="math inline">\(W\)</span> with respect to the standard basis. Thus, coordinate matrices can be used to change between different bases.</p>
<p>For instance, if <span class="math inline">\(B\)</span> is a basis for <span class="math inline">\(V\)</span> and <span class="math inline">\(C\)</span> is a basis for <span class="math inline">\(W\)</span>, then the matrix <span class="math inline">\(CB\)</span> is a coordinate matrix for <span class="math inline">\(T\)</span> with respect to the bases <span class="math inline">\(B\)</span> and <span class="math inline">\(C\)</span>. Conversely, every matrix can be viewed as a coordinate matrix; simply choose any bases for <span class="math inline">\(V\)</span> and <span class="math inline">\(W\)</span> and view the matrix as a transformation between these spaces.</p>
<p>In short, coordinate matrices are useful when working with linear transformations because they make it easy to change between different bases.</p>
<p>In this book, we’ve learned about linear transformations and their properties. We’ve seen how to represent them using matrices, and how to use these matrices to change between different bases. We’ve also learned about the kernel and image of a linear transformation, and how these concepts can be used to better understand the behavior of linear transformations. With this knowledge in hand, we’re now ready to tackle more advanced topics in linear algebra.</p>
<section id="introduction-to-linear-transformations" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="introduction-to-linear-transformations"><span class="header-section-number">3.1</span> Introduction to Linear Transformations</h2>
<p>A linear transformation is a function of the form <span class="math inline">\(\vec y =A \vec x\)</span> where <span class="math inline">\(A\)</span> is an <span class="math inline">\(n\times m\)</span> matrix. More specifically, a linear transformation is a function that assigns to each <span class="math inline">\(\vec x\in \mathbb{R}^m\)</span>, a unique <span class="math inline">\(\vec y\in \mathbb{R}^n\)</span> – and this assignment is defined by a matrix <span class="math inline">\(A\)</span>. When <span class="math inline">\(A\)</span> is the identity matrix and <span class="math inline">\(T(\vec x)=A \vec x\)</span> we call <span class="math inline">\(T\)</span> the <strong>identity transformation</strong> .</p>
<div id="def-" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3.1 </strong></span> A function <span class="math inline">\(T\)</span> from <span class="math inline">\(\mathbb{R}^m\)</span> to <span class="math inline">\(\mathbb{R}^n\)</span> is called a <strong>linear transformation</strong> if there exists an <span class="math inline">\(n\times m\)</span> matrix <span class="math inline">\(A\)</span> such that <span class="math inline">\(T(\vec x)=A \vec x\)</span>, for all <span class="math inline">\(\vec x\)</span> in the vector space <span class="math inline">\(\vec R^m\)</span>.</p>
</div>
<div id="lem-" class="theorem lemma">
<p><span class="theorem-title"><strong>Lemma 3.1 </strong></span>Let <span class="math inline">\(T\)</span> be a linear transformation from <span class="math inline">\(\mathbb{R}^m\)</span> to <span class="math inline">\(\mathbb{R}^n\)</span>, then the matrix of <span class="math inline">\(T\)</span> is <span class="math display">\[\begin{equation}
\label{trancol}
A=\begin{bmatrix} | &amp;  &amp; | \\ T(\vec e_1) &amp; \cdots &amp; T(\vec e_m) \\ | &amp;  &amp; | \end{bmatrix}
\end{equation}\]</span> where <span class="math inline">\(\vec e_i\)</span> (for <span class="math inline">\(0\leq i \leq m\)</span>) are the standard vectors.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>Suppose <span class="math inline">\(T\)</span> is a linear transformation from <span class="math inline">\(\mathbb{R}^m\)</span> to <span class="math inline">\(\mathbb{R}^n\)</span>, then there exists an <span class="math inline">\(n\times m\)</span> matrix <span class="math inline">\(A\)</span> such that <span class="math inline">\(T(\vec x)=A\vec x\)</span> for all <span class="math inline">\(\vec x\in \mathbb{R}^m\)</span>. Let <span class="math inline">\(\vec e_1, ..., \vec e_m\)</span> be the standard vectors of <span class="math inline">\(\mathbb{R}^m\)</span> and let <span class="math inline">\(A=[a_{ij}]\)</span>, then <span class="math display">\[
T(\vec e_1)=A \vec e_1=
\begin{bmatrix}
a_{11} &amp; \cdots &amp; a_{1m} \\
\vdots &amp; \cdots &amp; \vdots \\
a_{n1} &amp; \cdots &amp; a_{nm}
\end{bmatrix}
\vectorthree{1}{\vdots}{0}
=\vectorthree{a_{11}}{\vdots}{a_{n1}}
\]</span> <span class="math display">\[
\vdots
\]</span> <span class="math display">\[
T(\vec e_m)=A \vec e_m=
\begin{bmatrix}
a_{11} &amp; \cdots &amp; a_{1m} \\
\vdots &amp; \cdots &amp; \vdots \\
a_{n1} &amp; \cdots &amp; a_{nm}
\end{bmatrix}
\vectorthree{0}{\vdots}{1}
=\vectorthree{a_{1m}}{\vdots}{a_{nm}}
\]</span> which are the columns of the matrix <span class="math inline">\(A\)</span>.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.1 </strong></span>Determine the linear transformation <span class="math inline">\(T\)</span> given by the system of linear equations: <span class="math display">\[
\begin{array}{l}
y_1=  7x_1+3x_2-9x_3+8x_4 \\
y_2 =  6x_1+2x_2-8x_3+7x_4 \\
y_3 =  8x_1+4x_2+7x_4
\end{array}
\]</span> The matrix of the linear transformation is <span class="math inline">\(A=\begin{bmatrix} 7 &amp; 3 &amp; -9 &amp; 8 \\ 6 &amp; 2 &amp; -8 &amp; 7 \\ 8 &amp; 4 &amp; 0 &amp; 7 \end{bmatrix}\)</span> since <span class="math display">\[
T(\vec e_1)=\vectorthree{7}{6}{8},  
\qquad
T(\vec e_2)=\vectorthree{3}{2}{4},
\qquad
T(\vec e_3)=\vectorthree{-9}{-8}{0},
\qquad
T(\vec e_4)=\vectorthree{8}{7}{7}.
\]</span> Notice <span class="math inline">\(T\)</span> is a linear transformation from <span class="math inline">\(\mathbb{R}^4\)</span> to <span class="math inline">\(\mathbb{R}^3\)</span> and <span class="math inline">\(A\)</span> is a <span class="math inline">\(3\times 4\)</span> matrix.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.2 </strong></span>Is the transformation <span class="math inline">\(T(\vec{x})=\vec{v}\cdot \vec{x}\)</span> from <span class="math inline">\(\mathbb{R}^3\)</span> to <span class="math inline">\(\mathbb{R}\)</span> a linear transformation? If so, find the matrix of <span class="math inline">\(T\)</span>. Let <span class="math inline">\(\vec{v}=\vectorthree{v_1}{v_2}{v_3}\)</span>. Then <span class="math display">\[
T(\vec{x})=\vec{v}\cdot \vec{x}=\vectorthree{v_1}{v_2}{v_3}\cdot \vectorthree{x_1}{x_2}{x_3}=v_1 x_1+v_2 x_2+v_3 x_3 =
\begin{bmatrix}v_1 &amp; v_2 &amp; v_3 \end{bmatrix}\vec{x}.\]</span> Therefore, by <span class="math inline">\(\ref{lintrdef}\)</span>, <span class="math inline">\(T\)</span> is a linear transformation with matrix <span class="math display">\[
\begin{bmatrix}v_1 &amp; v_2 &amp; v_3 \end{bmatrix}.
\]</span></p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.3 </strong></span>Is the transformation <span class="math inline">\(T(\vec{x})=\vec{v}\times \vec{x}\)</span> from <span class="math inline">\(\mathbb{R}^3\)</span> to <span class="math inline">\(\mathbb{R}\)</span> a linear transformation? If so, find the matrix of <span class="math inline">\(T\)</span>. Let <span class="math inline">\(\vec{v}=\vectorthree{v_1}{v_2}{v_3}\)</span>. Then <span class="math display">\[
T(\vec{x})=\vec{v}\times \vec{x}=\vectorthree{v_1}{v_2}{v_3}\times \vectorthree{x_1}{x_2}{x_3}
=\begin{bmatrix}v_2x_3 -v_3x_2\\ v_3x_1-v_1x_3 \\ v_1 x_2-v_2x_1 \end{bmatrix}
=\begin{bmatrix}0 &amp; -v_3 &amp; v_2\\ v_3 &amp; 0 &amp; -v_1 \\ -v_2 &amp; v_1 &amp; 0 \end{bmatrix}\vec{x}
\]</span> Therefore, by <span class="math inline">\(\ref{lintrdef}\)</span>, <span class="math inline">\(T\)</span> is a linear transformation with matrix <span class="math display">\[
\begin{bmatrix}0 &amp; -v_3 &amp; v_2\\ v_3 &amp; 0 &amp; -v_1 \\ -v_2 &amp; v_1 &amp; 0 \end{bmatrix}.
\]</span></p>
</div>
<div id="thm-" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.1 </strong></span> A function <span class="math inline">\(T\)</span> from <span class="math inline">\(\mathbb{R}^m\)</span> to <span class="math inline">\(\mathbb{R}^n\)</span> is a linear transformation if and only if both of the following hold:</p>
<ul>
<li><span class="math inline">\(T(\vec v+ \vec w)=T(\vec v)+T(\vec w)\)</span> for all vectors <span class="math inline">\(\vec v\)</span> and <span class="math inline">\(\vec w\)</span> in <span class="math inline">\(\mathbb{R}^m\)</span>, and</li>
<li><span class="math inline">\(T(k \vec v)=k T(\vec v)\)</span> for all vectors <span class="math inline">\(\vec v\)</span> in <span class="math inline">\(\mathbb{R}^m\)</span> and all scalars <span class="math inline">\(k\)</span>.</li>
</ul>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>Suppose <span class="math inline">\(T\)</span> is a linear transformation from <span class="math inline">\(\mathbb{R}^m\)</span> to <span class="math inline">\(\mathbb{R}^n\)</span>, then there exists an <span class="math inline">\(n\times m\)</span> matrix <span class="math inline">\(A\)</span> such that <span class="math inline">\(T(\vec x)=A\vec x\)</span> for all <span class="math inline">\(\vec x\in \mathbb{R}^m\)</span>. The proof of each part follows.</p>
<ul>
<li>Let <span class="math inline">\(\vec u, \vec v\in \mathbb{R}^m\)</span>, then <span class="math inline">\(T(\vec v+\vec w)=A (\vec v+\vec w)=A \vec v+A \vec w=T(\vec v)+T(\vec w)\)</span>.</li>
<li>Let <span class="math inline">\(\vec v\in \mathbb{R}^m\)</span> and <span class="math inline">\(k\in \mathbb{R}\)</span>. Then <span class="math inline">\(T(k \vec v)=A(k \vec v)=(A k) \vec v=k(A \vec v)=k T(\vec v)\)</span>.</li>
</ul>
<p>Now suppose both (i) and (ii) hold. We need to find a matrix <span class="math inline">\(A\)</span> such that <span class="math inline">\(Tx =A \vec x\)</span> for all <span class="math inline">\(\vec x\in \mathbb{R}^m\)</span>. We can use the standard vectors in <span class="math inline">\(\mathbb{R}^m\)</span>. Then by <span class="math inline">\(\ref{trancol}\)</span>, <span class="math display">\[\begin{align*}
T(\vec x)  &amp; = T(x \vec e_1+\cdots + x_m \vec e_m)
=T(x_1\vec e_1)+\cdots +T(x_m\vec e_m) \\
&amp; = x_1 T(\vec e_1)+\cdots +x_m T(\vec e_m)
=
\begin{bmatrix} | &amp;  &amp; | \\
T(\vec e_1) &amp; \cdots &amp; T(\vec e_m) \\
| &amp;  &amp; | \end{bmatrix}
\vectorthree{x_1}{\vdots}{x_m}=A\vec x
\end{align*}\]</span> as desired.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.4 </strong></span>Write <span class="math inline">\(\vectorthree{-1}{1}{0}\)</span> as a linear combination of <span class="math inline">\(\vectorthree{3}{-1}{2}\)</span> and <span class="math inline">\(\vectorthree{1}{0}{1}\)</span>. Let <span class="math inline">\(T:\mathbb{R}^3\to\mathbb{R}\)</span> be a linear transformation with <span class="math inline">\(T\vectorthree{3}{-1}{2}=5\)</span> and <span class="math inline">\(T\vectorthree{1}{0}{1}=2\)</span>. Find <span class="math inline">\(T\vectorthree{-1}{1}{0}\)</span>. Notice <span class="math display">\[
\vectorthree{-1}{1}{0}=
(-1)\vectorthree{3}{-1}{2}+2\vectorthree{1}{0}{1}.
\]</span> Therefore, <span class="math display">\[
T\vectorthree{-1}{1}{0}
=T\left((-1)\vectorthree{3}{-1}{2}+2\vectorthree{1}{0}{1}\right)
=(-1)\, T\vectorthree{3}{-1}{2}+2 \, T\vectorthree{1}{0}{1}
=-1.
\]</span></p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.5 </strong></span>Let <span class="math inline">\(T:\mathbb{R}^2\to\mathbb{R}^2\)</span> be defined by <span class="math inline">\(T\vectortwo{x_1}{x_2}=\vectortwo{2x_1}{x_2^2}\)</span>. Is <span class="math inline">\(T\)</span> a linear transformation? Let <span class="math inline">\(\alpha=\vectortwo{x_1}{x_2}\)</span> and <span class="math inline">\(\beta=\vectortwo{y_1}{y_2}\)</span>. Then <span class="math display">\[\begin{align*}
T(\alpha+\beta) &amp;
=T\left(\vectortwo{x_1}{x_2}+\vectortwo{y_1}{y_2}\right)
=T\vectortwo{x_1+y_1}{x_2+y_2}
=\vectortwo{2(x_1+y_1)}{(x_2+y_2)^2}
\end{align*}\]</span> On the other hand <span class="math display">\[\begin{align*}
T(\alpha)+T(\beta) &amp;
=T\vectortwo{x_1}{x_2}+T\vectortwo{y_1}{y_2}
=\vectortwo{2x_1}{x_2^2} + \vectortwo{2y_1}{y_2^2}
= \vectortwo{2(x_1+y_1)}{x_2^2+y_2^2}
\end{align*}\]</span> Since <span class="math inline">\(T(\alpha+\beta)\neq T(\alpha)+T(\beta)\)</span>, we use <span class="math inline">\(\ref{thm:linthm}\)</span> to conclude that <span class="math inline">\(T\)</span> is not linear transformation.</p>
</div>
<div id="thm-" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.2 </strong></span>Let <span class="math inline">\(T\)</span> be a linear transformation from <span class="math inline">\(\mathbb{R}^m\)</span> to <span class="math inline">\(\mathbb{R}^n\)</span>.</p>
<ul>
<li>If <span class="math inline">\(\vec{0}_m\)</span> is the zero vector in <span class="math inline">\(\mathbb{R}^m\)</span>, then <span class="math inline">\(T(\vec{0}_m)\)</span> is the zero vector in <span class="math inline">\(\mathbb{R}^n\)</span>.</li>
<li>For all <span class="math inline">\(\vec{v}\)</span> in <span class="math inline">\(\mathbb{R}^m\)</span>, <span class="math inline">\(T(-\vec{v})=-T(\vec{v})\)</span>.</li>
<li>For all <span class="math inline">\(\vec{u}, \vec{v}\)</span> in <span class="math inline">\(\mathbb{R}^m\)</span>, <span class="math inline">\(T(\vec{u}-\vec{v})=T(\vec{u})-T(\vec{v})\)</span>.</li>
<li>For all <span class="math inline">\(a_1,...,a_n\in \mathbb{R}\)</span> and for all <span class="math inline">\(\vec{v}_1, ...., \vec{v}_n\in \mathbb{R}^m\)</span>, <span class="math display">\[
T(a_1\vec{v}_1+a_2\vec{v}_2+\cdots + a_n\vec{v}_n)
=a_1T(\vec{v}_1)+a_2T(\vec{v}_2)+\cdots+a_nT(\vec{v}_n).
\]</span></li>
</ul>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>There proof is for the reader.</p>
</div>
</section>
<section id="linear-transformations-in-geometry" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="linear-transformations-in-geometry"><span class="header-section-number">3.2</span> Linear Transformations in Geometry</h2>
<p>Next we give several examples of linear transformations from <span class="math inline">\(\mathbb{R}^2\)</span> to <span class="math inline">\(\mathbb{R}^2\)</span> that are commonly used in plane geometry.</p>
<div id="thm-" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.3 </strong></span>Let <span class="math inline">\(T\)</span> be a linear transformation from <span class="math inline">\(\mathbb{R}^2\)</span> to <span class="math inline">\(\mathbb{R}^2\)</span>. If the matrix of <span class="math inline">\(T\)</span> is of the form <span class="math display">\[
\begin{bmatrix} k &amp; 0 \\ 0 &amp; k  \end{bmatrix}
\]</span> then <span class="math inline">\(T\)</span> is a <strong>scaling</strong> transformation. If <span class="math inline">\(k&gt;1\)</span> then the scaling is called a <strong>dilation</strong>, and is called a <strong>contraction</strong> when <span class="math inline">\(k&lt;1\)</span>.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>The proof is left for the reader.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.6 </strong></span>Is the linear transformation given by the system of linear equations <span class="math display">\[
\left\{
\begin{array}{l}
y_1=  7x_1 \\
y_2 =  7x_2 \\
\end{array}
\right.
\]</span> from <span class="math inline">\(\mathbb{R}^2\)</span> to <span class="math inline">\(\mathbb{R}^2\)</span> a scaling? The answer is yes since the matrix of the linear transformation is <span class="math inline">\(\begin{bmatrix} 7 &amp; 0 \\ 0 &amp; 7 \end{bmatrix}\)</span>, which by definition is a scaling. For example, we can write <span class="math display">\[
T(\vec x)=\begin{bmatrix} 7 &amp; 0 \\ 0 &amp; 7 \end{bmatrix} \vec x.
\]</span> We can use <span class="math inline">\(T\)</span> to dilate the vector <span class="math inline">\(\vectortwo{1}{2}\)</span> by <span class="math inline">\(7\)</span> to obtain <span class="math display">\[
T\vectortwo{1}{2}
=\begin{bmatrix} 7 &amp; 0 \\ 0 &amp; 7 \end{bmatrix}\vectortwo{1}{2}
=\vectortwo{7}{14}.
\]</span></p>
</div>
<div id="thm-" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.4 </strong></span> Let <span class="math inline">\(T\)</span> be a linear transformation from <span class="math inline">\(\mathbb{R}^2\)</span> to <span class="math inline">\(\mathbb{R}^2\)</span>. If the matrix of <span class="math inline">\(T\)</span> is of the form <span class="math display">\[
\frac{1}{w_1^2+w_2^2} \begin{bmatrix} w_1^2 &amp; w_1 w_2 \\ w_1 w_2 &amp; w_2^2  \end{bmatrix}
\]</span> then <span class="math inline">\(T\)</span> is an <strong>orthogonal projection</strong> transformation onto the line <span class="math inline">\(L\)</span> spanned by any nonzero vector <span class="math inline">\(\vec w = \begin{bmatrix} w_1 \\ w_2 \end{bmatrix}\)</span> parallel to <span class="math inline">\(L\)</span>.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>Suppose line <span class="math inline">\(L\)</span> is spanned by <span class="math inline">\(\vec w\)</span>. We can decompose any vector <span class="math inline">\(\vec x\)</span> as <span class="math inline">\(\vec x^{||}+\vec x^\perp\)</span> as diagrammed: Notice <span class="math inline">\(\vec x^\perp\)</span> is the perpendicular component so <span class="math display">\[\begin{equation}\label{perpeq}
\vec w \cdot \vec x^\perp =0
\qquad \text{or equivalently} \qquad
\vec w \cdot (\vec x -\vec x^{||}) =0.
\end{equation}\]</span> To project <span class="math inline">\(\vec x\)</span> onto the line <span class="math inline">\(L\)</span> we notice <span class="math display">\[\begin{equation}\label{projfac}
\vec x^{||}=k \vec w
\end{equation}\]</span> for some scalar <span class="math inline">\(k\)</span>. By substitution, of <span class="math inline">\(\ref{projfac}\)</span> into <span class="math inline">\(\ref{perpeq}\)</span> and solving for <span class="math inline">\(k\)</span> we obtain <span class="math display">\[\begin{equation}\label{facdef}
k=\frac{\vec w \cdot \vec x}{\vec w \cdot \vec w}.
\end{equation}\]</span> Using <span class="math inline">\(\ref{projfac}\)</span> and <span class="math inline">\(\ref{facdef}\)</span> we define the orthogonal projection of a vector <span class="math inline">\(\vec x\)</span> onto a given line <span class="math inline">\(L\)</span> as <span class="math display">\[\begin{equation}\label{projdef}
\text{proj}_L(\vec x)
=\frac{\vec w \cdot \vec x}{\norm{\vec w}^2}\vec w.
\end{equation}\]</span> We would like to have <span class="math inline">\(\ref{projdef}\)</span> in the form of a matrix. To do so let <span class="math inline">\(\vec w=\vectortwo{w_1}{w_2}\)</span> and <span class="math inline">\(\vec x=\vectortwo{x_1}{x_2}\)</span>. Then from <span class="math inline">\(\ref{facdef}\)</span> and <span class="math inline">\(\ref{projdef}\)</span> we find <span class="math display">\[\begin{align*}
\text{proj}_L(\vec x)
&amp; = \frac{1}{\norm{\vec w}^2} \left((x_1 w_1+x_2 w_2)\vectortwo{w_1}{w_2} \right) \\
&amp; = \frac{1}{\norm{\vec w}^2} \left((x_1 w_1\vectortwo{w_1}{w_2}+x_2 w_2 \vectortwo{w_1}{w_2} \right) \\
&amp; = \frac{1}{\norm{\vec w}^2} \left(\vectortwo{x_1 w_1^2}{x_1w_1 w_2}+\vectortwo{x_2w_1w_2}{x_2w_2^2} \right) \\
&amp; = \frac{1}{\norm{\vec w}^2} \vectortwo{x_1 w_1^2+x_2w_1w_2}{x_1w_1 w_2+x_2w_2^2}
= \frac{1}{\norm{\vec w}^2}
\begin{bmatrix} w_1^2 &amp; w_1 w_2 \\ w_1 w_2 &amp; w_2^2  \end{bmatrix}
\vectortwo{x_1}{x_2}
.
\tag*{ }
\end{align*}\]</span></p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.7 </strong></span>Find the matrix <span class="math inline">\(A\)</span> of the orthogonal projection onto the line <span class="math inline">\(L\)</span> spanned by <span class="math inline">\(\vec w = \begin{bmatrix} 4 \\3 \end{bmatrix}\)</span> and project the vector <span class="math inline">\(\vec u=\vectortwo{1}{5}\)</span> onto the line <span class="math inline">\(L\)</span> spanned by <span class="math inline">\(\vec w\)</span>. By <span class="math inline">\(\ref{orthproj}\)</span>, the matrix is <span class="math display">\[
A=\frac{1}{w_1^2+w_2^2}
\begin{bmatrix}
w_1^2 &amp; w_1 w_2 \\
w_1 w_2 &amp; w_2^2
\end{bmatrix}
=\frac{1}{25}
\begin{bmatrix}
16 &amp; 12 \\
12 &amp; 9
\end{bmatrix}
=
\begin{bmatrix}
16/25 &amp; 12/25 \\
12/25 &amp; 9/25
\end{bmatrix}
.
\]</span> For example, we can project the vector <span class="math inline">\(\vec u\)</span> onto the line <span class="math inline">\(L\)</span> spanned by <span class="math inline">\(\vec w\)</span>. The matrix <span class="math inline">\(A\)</span> defines this linear transformation <span class="math inline">\(T\)</span> and so to project onto the line <span class="math inline">\(L\)</span> is just matrix multiplication: <span class="math display">\[
T\vectortwo{1}{5}=\frac{1}{25}
\begin{bmatrix}
16 &amp; 12 \\
12 &amp; 9
\end{bmatrix}
\vectortwo{1}{5}
=\vectortwo{76/25}{57/25}.
%\approx \vectortwo{3.04}{2.28}.
\tag*{ }
\]</span></p>
</div>
<div id="thm-" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.5 </strong></span> Let <span class="math inline">\(T\)</span> be a linear transformation from <span class="math inline">\(\mathbb{R}^2\)</span> to <span class="math inline">\(\mathbb{R}^2\)</span>. If the matrix of <span class="math inline">\(T\)</span> is of the form <span class="math display">\[
\begin{bmatrix} 2 u_1^2-1 &amp; 2 u_1 u_2 \\ 2 u_1 u_2 &amp; 2 u_2^2 -1   \end{bmatrix}
\]</span> then <span class="math inline">\(T\)</span> defines a <strong>reflection</strong> transformation about the line <span class="math inline">\(L\)</span>, where <span class="math inline">\(\vec u = \begin{bmatrix} u_1 \\ u_2 \end{bmatrix}\)</span> is any unit vector lying on <span class="math inline">\(L\)</span>.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>Suppose we want to reflect <span class="math inline">\(\vec x\)</span> through the line <span class="math inline">\(L\)</span> as diagrammed: Then <span class="math display">\[\begin{equation}\label{ref1}
\text{ref}_L(\vec x)=\vec x^{||}-\vec x^\perp  
\end{equation}\]</span> and <span class="math display">\[\begin{equation}\label{ref2}
\text{proj}_L(\vec x)=\vec x^{||}.
\end{equation}\]</span> By subtracting <span class="math inline">\(\ref{ref2}\)</span> from <span class="math inline">\(\ref{ref1}\)</span>, we obtain <span class="math display">\[\begin{equation}\label{ref3}
\text{ref}_L(\vec x)=2 \text{proj}_L(\vec x)-\vec x.
\end{equation}\]</span> For simplicity assume <span class="math inline">\(L\)</span> is a any line that passes through the origin and let <span class="math inline">\(\vec u\)</span> be a unit vector <span class="math inline">\(\vec u = \begin{bmatrix} u_1 \\ u_2 \end{bmatrix}\)</span> lying on <span class="math inline">\(L\)</span>. Notice <span class="math inline">\(\ref{projdef}\)</span> in the special case of a unit vector <span class="math inline">\(\vec u\)</span> becomes <span class="math inline">\(\text{proj}_L(\vec x)=(\vec u\cdot \vec x)\vec u.\)</span> Then <span class="math display">\[\begin{align*}
\text{ref}_L(\vec x)&amp; =2 \text{proj}_L(\vec x)-\vec x
=2(\vec u\cdot \vec x)\vec u-\vec x \\
&amp; = 2(u_1x_1+u_2x_2)\begin{bmatrix} u_1 \\ u_2  \end{bmatrix}-\begin{bmatrix} x_1 \\ x_2  \end{bmatrix}
=2u_1 x_1 \begin{bmatrix} u_1 \\ u_2  \end{bmatrix}+2u_2x_2 \begin{bmatrix} u_1 \\ u_2  \end{bmatrix}-\begin{bmatrix} x_1 \\ x_2  \end{bmatrix} \\
&amp; = \begin{bmatrix}  
2u_1^2x_1+2u_1 u_2x_2-x_1 \\ 2u_1u_2x_1+2u_2^2 u_2x_2-x_2
\end{bmatrix}
= \begin{bmatrix}  
2u_1^2-1 &amp; 2u_1 u_2\\
2u_1 u_2 &amp; 2u_2^2-1
\end{bmatrix}
\vectortwo{x_1}{x_2}.
\tag*{ }
\end{align*}\]</span></p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.8 </strong></span>Find the matrix <span class="math inline">\(A\)</span> of a reflection through the line through the origin spanned by <span class="math inline">\(\vec w = \begin{bmatrix} 4 \\3 \end{bmatrix}\)</span> and use it to reflect <span class="math inline">\(\begin{bmatrix} 1 \\5 \end{bmatrix}\)</span> about the line <span class="math inline">\(L\)</span>. Let <span class="math inline">\(\vec u=\vectortwo{4/5}{3/5}\)</span>. We notice <span class="math inline">\(\vec u\)</span> is a unit vector, since <span class="math inline">\(\norm{u}=1\)</span>. Then, by <span class="math inline">\(\ref{reflmatrix}\)</span>, the matrix we seek is <span class="math display">\[
A=\begin{bmatrix}
7/25 &amp; 24/25 \\ 24/25 &amp; -7/25
\end{bmatrix}.
\]</span> We can reflect the vector <span class="math inline">\(\begin{bmatrix} 1 \\5 \end{bmatrix}\)</span> about the line <span class="math inline">\(L\)</span> using matrix multiplication <span class="math display">\[
T \begin{bmatrix} 1 \\5  \end{bmatrix}
=
\frac{1}{25}
\begin{bmatrix}
7 &amp; 24 \\ 24 &amp; -7
\end{bmatrix}
\begin{bmatrix} 1 \\5  \end{bmatrix}
=\vectortwo{127/25}{-11/25}.
%\approx \vectortwo{5.08}{-0.44}.
\tag*{ }
\]</span></p>
</div>
<div id="thm-" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.6 </strong></span> Let <span class="math inline">\(T\)</span> be a linear transformation from <span class="math inline">\(\mathbb{R}^2\)</span> to <span class="math inline">\(\mathbb{R}^2\)</span>. If the matrix of <span class="math inline">\(T\)</span> is of the form <span class="math display">\[
\begin{bmatrix}
\cos \theta &amp; -\sin \theta  \\
\sin \theta &amp; \cos \theta  \end{bmatrix}
\]</span> then <span class="math inline">\(T\)</span> is a (counterclockwise) <strong>rotation</strong> transformation through an angle <span class="math inline">\(\theta\)</span>.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>If a vector <span class="math inline">\(\vec x=\vectortwo{x_1}{x_2}\)</span> is rotated through an angle of <span class="math inline">\(\pi/2\)</span>, then a vector <span class="math inline">\(\vec y=\vectortwo{-x_2}{x_1}\)</span> is obtained, via <span class="math inline">\(\vec x\cdot \vec y =\vec 0\)</span>. More generally, if we rotate (counterclockwise) a given <span class="math inline">\(\vec x\)</span> through an angle <span class="math inline">\(\theta\)</span> we determine <span class="math display">\[\begin{align*}
T(\vec x)&amp;=(\cos \theta) \vec x+(\sin\theta) \vec y
=(\cos \theta)\vectortwo{x_1}{x_2}+(\sin \theta)\vectortwo{-x_2}{x_1} \\
&amp;=\vectortwo{(\cos \theta)x_1-(\sin\theta))x_2}{(\sin \theta)x_1-(\cos\theta))x_2}
=\begin{bmatrix} \cos \theta &amp; -\sin \theta  \\ \sin \theta &amp; \cos \theta  \end{bmatrix} \vectortwo{x_1}{x_2}
=\begin{bmatrix} \cos \theta &amp; -\sin \theta  \\ \sin \theta &amp; \cos \theta  \end{bmatrix} \vec x
\end{align*}\]</span> as seen from the diagram.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.9 </strong></span>Find the matrix of the linear transformation that rotates the vector <span class="math inline">\(\begin{bmatrix} 4 \\ 2 \end{bmatrix}\)</span> by 30 degrees counterclockwise. By <span class="math inline">\(\ref{rotmatrix}\)</span>, the matrix of this transformation is <span class="math inline">\(A=\begin{bmatrix} \sqrt{3}/2 &amp; -1/2 \\ 1/2 &amp; \sqrt{3}/2 \end{bmatrix}.\)</span> We will use matrix multiplication to perform the transformation <span class="math display">\[
T\vectortwo{4}{2}
= \begin{bmatrix} \frac{\sqrt{3}}{2} &amp; \frac{-1}{2} \\
\frac{1}{2} &amp; \frac{\sqrt{3}}{2}
\end{bmatrix}
\vectortwo{4}{2}
=\cos 30^\circ \vectortwo{4}{2}+\sin 30^\circ \vectortwo{4}{2}
=\vectortwo{2\left(\sqrt{3}+1\right)}{\sqrt{3}+1}.
\approx \vectortwo{2.46}{3.73}
\]</span></p>
</div>
<div id="thm-" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.7 </strong></span> Let <span class="math inline">\(T\)</span> be a linear transformation from <span class="math inline">\(\mathbb{R}^2\)</span> to <span class="math inline">\(\mathbb{R}^2\)</span>. If the matrix of <span class="math inline">\(T\)</span> is of the form <span class="math display">\[
\begin{bmatrix} 1 &amp; 0  \\ k &amp; 1  \end{bmatrix}
\qquad \text{or} \qquad
\begin{bmatrix} 1 &amp; k  \\ 0 &amp; 1  \end{bmatrix},
\]</span> where <span class="math inline">\(k\)</span> is any constant, then <span class="math inline">\(T\)</span> defines a <strong>vertical shear</strong> or <strong>horizontal shear</strong> transformation, respectively.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>The proof is left for the reader.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.10 </strong></span>Given the vector <span class="math inline">\(\begin{bmatrix} 2 \\3 \end{bmatrix}\)</span> in <span class="math inline">\(\mathbb{R}^2\)</span> show geometrically a vertical shear of 2 and a horizontal shear of <span class="math inline">\(\frac{1}{2}\)</span>. By <span class="math inline">\(\ref{shearmatrix}\)</span>, we can apply these linear transformations using matrix multiplication by using the matrices <span class="math inline">\(\begin{bmatrix} 1 &amp; 0 \\ 2 &amp; 1 \end{bmatrix}\)</span> and <span class="math inline">\(\begin{bmatrix} 1 &amp; 1/2 \\ 0 &amp; 1 \end{bmatrix}\)</span>. <span class="math display">\[
\label{verticalshear}
\text{Vertical Shear: \quad }  T\begin{bmatrix} 2 \\3  \end{bmatrix}
= \begin{bmatrix} 1 &amp; 0  \\ 2 &amp; 1  \end{bmatrix} \begin{bmatrix} 2 \\3  \end{bmatrix} = \begin{bmatrix} 2 \\7  \end{bmatrix}
\]</span> <span class="math display">\[
\label{horizontalshear}
\text{Horizontal Shear: \quad } T\begin{bmatrix} 2 \\3  \end{bmatrix}
= \begin{bmatrix} 1 &amp; 1/2  \\ 0 &amp; 1  \end{bmatrix} \begin{bmatrix} 2 \\3  \end{bmatrix} =\begin{bmatrix} 7/2 \\3  \end{bmatrix}
\]</span></p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.11 </strong></span>Interpret the linear transformation <span class="math inline">\(T(\vec x)=\begin{bmatrix} 0 &amp; -1 \\ -1 &amp; 0 \end{bmatrix}\vec x\)</span> geometrically. The transformation has a matrix of the form <span class="math display">\[
\begin{bmatrix} 2u_1^2-1 &amp; 2 u_1 u_2 \\ 2u_1 u_2 &amp; 2u_2^2-1 \end{bmatrix}
\]</span> where <span class="math inline">\(u_1=\sqrt{2}/2\)</span> and <span class="math inline">\(u_2=-\sqrt{2}/2\)</span> since <span class="math inline">\(2u_1^2-1=0\)</span>, <span class="math inline">\(2u_2^2-1=0\)</span>, and <span class="math inline">\(2u_1 u_2=-1\)</span>. Since <span class="math inline">\(|| \vec u ||=1\)</span> and <span class="math inline">\(\vec u\)</span> lies on the line <span class="math inline">\(y=x\)</span>, then matrix <span class="math inline">\(\begin{bmatrix} 0 &amp; -1 \\ -1 &amp; 0 \end{bmatrix}\)</span> represents the linear transformation which is a reflection through the line <span class="math inline">\(y=x\)</span>.</p>
</div>
<p><span class="math display">\[\begin{align*}
\text{scaling} \quad &amp;
\begin{bmatrix} k &amp; 0 \\ 0 &amp; k  \end{bmatrix} &amp;
\text{shears} \quad &amp;  
\begin{bmatrix} 1 &amp; 0  \\ k &amp; 1  \end{bmatrix}
\text{ or }
\begin{bmatrix} 1 &amp; k  \\ 0 &amp; 1  \end{bmatrix} \\
\text{reflection} \quad &amp;
\begin{bmatrix} 2 u_1^2-1 &amp; 2 u_1 u_2 \\ 2 u_1 u_2 &amp; 2 u_2^2 -1   \end{bmatrix} &amp;
\text{rotation} \quad &amp;
\begin{bmatrix} \cos \theta &amp; -\sin \theta  \\ \sin \theta &amp; \cos \theta  \end{bmatrix} &amp;  \\
\text{orthogonal projection} \quad &amp;
\frac{1}{w_1^2+w_2^2} \begin{bmatrix} w_1^2 &amp; w_1 w_2 \\ w_1 w_2 &amp; w_2^2  \end{bmatrix} &amp;
\end{align*}\]</span></p>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.12 </strong></span>Interpret the linear transformation <span class="math inline">\(T(\vec x)=\begin{bmatrix} 1 &amp; 1 \\ -1 &amp; 1 \end{bmatrix} \vec x\)</span>, geometrically. Explain. This is a rotation combined with a scaling. The transformation rotates 45 degrees counterclockwise and has a scaling factor of <span class="math inline">\(\sqrt{2}\)</span>.</p>
</div>
</section>
<section id="introduction-to-linear-maps" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="introduction-to-linear-maps"><span class="header-section-number">3.3</span> Introduction to Linear Maps</h2>
<div id="def-" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3.2 </strong></span>Let <span class="math inline">\(V\)</span> and <span class="math inline">\(W\)</span> be linear spaces. A function <span class="math inline">\(T\)</span> from <span class="math inline">\(V\)</span> to <span class="math inline">\(W\)</span> is called a <strong>linear map</strong> if <span class="math display">\[
T(f+g)=T(f)+T(g)
\qquad \text{and}\qquad
T(k f)=k T(f)
\]</span> for all elements <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span> of <span class="math inline">\(V\)</span> and for all scalars <span class="math inline">\(k\)</span>.</p>
</div>
<p>The collection of all linear maps from <span class="math inline">\(V\)</span> to <span class="math inline">\(W\)</span> is denoted by <span class="math inline">\(\mathcal{L}(V,W)\)</span> and if <span class="math inline">\(T\)</span> is a linear map from <span class="math inline">\(V\)</span> to <span class="math inline">\(W\)</span> we denote this by <span class="math inline">\(T\in \mathcal{L}(V,W)\)</span>.</p>
<div id="def-" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3.3 </strong></span>Let <span class="math inline">\(T\in \mathcal{L}(V,W)\)</span>.</p>
<ul>
<li>Then the <strong>kernel</strong> of <span class="math inline">\(T\)</span> is the subset of <span class="math inline">\(V\)</span> consisting of the vectors that <span class="math inline">\(T\)</span> maps to 0; that is<br>
<span class="math inline">\(\ker(T)=\{v\in V \, | \, T v=0\}.\)</span></li>
<li>Then the <strong>image</strong> of <span class="math inline">\(T\)</span> is the subset of <span class="math inline">\(W\)</span> consisting of the vectors of the form <span class="math inline">\(Tv\)</span> for some <span class="math inline">\(v\in V\)</span>; that is <span class="math inline">\(\text{im}(T)=\{w\in W \, | \, \text{ there exists } v \in V \text{ such that } w=T v\}.\)</span></li>
</ul>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.13 </strong></span>The function from <span class="math inline">\(C^{\infty}\)</span> to <span class="math inline">\(C^{\infty}\)</span> defined by <span class="math inline">\(T(f)=f''\)</span> is a linear map. Find the kernel and image of <span class="math inline">\(T\)</span>.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.14 </strong></span>The function from <span class="math inline">\(C^{\infty}\)</span> to <span class="math inline">\(C^{\infty}\)</span> defined by $T(f)=_0^1 f(x) , dx $ is a linear map. Find the kernel and image of <span class="math inline">\(T\)</span>.</p>
</div>
<div id="thm-" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.8 </strong></span>If <span class="math inline">\(T \in \mathcal{L}(V,W),\)</span> then null <span class="math inline">\(T\)</span> is a subspace of <span class="math inline">\(V\)</span>.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>By definition, <span class="math inline">\(\text{ker} T=\{v\in V \mid T v=0\}\)</span> and so <span class="math inline">\(\text{ker} T \subseteq W\)</span>. Let <span class="math inline">\(u, v\in \text{ker} T\)</span>. Then, <span class="math inline">\(T(u+v)=T u+ Tv=0+0=0\)</span> which shows, <span class="math inline">\(u+v\in \text{ker} T\)</span>, for all <span class="math inline">\(u , v \in \text{ker} T\)</span>. Let <span class="math inline">\(k\)</span> be a scalar and <span class="math inline">\(u\in \text{ker} T\)</span>. Then <span class="math inline">\(T(k u)=k T u= k(0)=0\)</span>, which shows, <span class="math inline">\(k u\in \text{ker} T\)</span> for all scalars <span class="math inline">\(k\)</span> and all <span class="math inline">\(u\in \text{ker} T\)</span>. Since <span class="math inline">\(T(0)=T(0+0)=T(0)+T(0)\)</span>, <span class="math inline">\(T(0)=0\)</span> in <span class="math inline">\(W\)</span> which shows, <span class="math inline">\(0\in \text{ker} T\)</span>. Therefore, <span class="math inline">\(\text{ker} T\)</span> is a subspace of <span class="math inline">\(W\)</span>.</p>
</div>
<div id="def-" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3.4 </strong></span>A linear map <span class="math inline">\(T: V\rightarrow W\)</span> is called <strong>injective</strong> whenever <span class="math inline">\(u, v\in V\)</span> and <span class="math inline">\(T u=T v\)</span>, we have <span class="math inline">\(u=v\)</span>.</p>
</div>
<div id="thm-" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.9 </strong></span>Let <span class="math inline">\(T\in \mathcal{L}(V,W)\)</span>, then <span class="math inline">\(T\)</span> is injective if and only if null <span class="math inline">\(T=\{0\}\)</span>.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>Suppose <span class="math inline">\(T\)</span> is injective. Since <span class="math inline">\(T(0)=0\)</span>, <span class="math inline">\(0\in \text{ker} T\)</span> and so <span class="math inline">\(\{0\}\subseteq \text{ker} T\)</span>. Let <span class="math inline">\(v\in \text{ker} T\)</span>. Then <span class="math inline">\(T(0)=0=T(v)\)</span> yields <span class="math inline">\(v=0\)</span> because <span class="math inline">\(T\)</span> is injective. Thus, <span class="math inline">\(\text{ker} T\subseteq \{0\}\)</span>. Therefore, <span class="math inline">\(\text{ker} T=\{0\}\)</span>. Conversely, assume <span class="math inline">\(\text{ker} T=\{0\}\)</span>. Let <span class="math inline">\(u, v\in V\)</span>. If <span class="math inline">\(Tu=Tv\)</span>, then <span class="math inline">\(T(u-v)=Tu - T v=0\)</span> which shows <span class="math inline">\(u-v \in \text{ker} T\)</span>. Thus <span class="math inline">\(u=v\)</span> and therefore, <span class="math inline">\(T\)</span> is injective.</p>
</div>
<div id="def-" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3.5 </strong></span>For <span class="math inline">\(T\in \mathcal{L}(V,W)\)</span>, the <strong>image</strong> of <span class="math inline">\(T\)</span>, denoted by <span class="math inline">\(\text{im}(T)\)</span>, is the subset of <span class="math inline">\(W\)</span> consisting of those vectors that are of the form <span class="math inline">\(T v\)</span> for some <span class="math inline">\(v\in V\)</span>.</p>
</div>
<div id="def-" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3.6 </strong></span>A linear map <span class="math inline">\(T: V\rightarrow W\)</span> is called <strong>surjective</strong> if its range equals <span class="math inline">\(W\)</span>.</p>
</div>
<div id="thm-" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.10 </strong></span>If <span class="math inline">\(T\in \mathcal{L}(V,W)\)</span>, then <span class="math inline">\(\text{im} T\)</span> is a subspace of <span class="math inline">\(W\)</span>.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>By definition, <span class="math inline">\(\text{im} T=\{T v \mid v\in V\}\subseteq W\)</span>. Let <span class="math inline">\(w_1,w_2\in W \in \text{im} T\)</span>. Then there exists <span class="math inline">\(v_1,v_2\in V\)</span> such that <span class="math inline">\(w_1=Tv_1\)</span> and <span class="math inline">\(w_2=T v_2\)</span>. By linearity of <span class="math inline">\(T\)</span>, <span class="math inline">\(w_1+w_2=Tv_1+Tv_2=T(v_1+v_2)\)</span> which shows <span class="math inline">\(w_1+w_2\in \text{im} T\)</span> for all <span class="math inline">\(w_1,w_2 \in \text{im} T\)</span>. Let <span class="math inline">\(w\in \text{im} T\)</span> and let <span class="math inline">\(k\)</span> be a scalar. Then there exists <span class="math inline">\(v\in V\)</span> such that <span class="math inline">\(w=T v\)</span>. By linearity of <span class="math inline">\(T\)</span>, $ kw =k Tv =T(k v)$ which shows <span class="math inline">\(kw\in \text{im} T\)</span> for all <span class="math inline">\(w\in \text{im} T\)</span> and for all scalars <span class="math inline">\(k\)</span>. Therefore, <span class="math inline">\(\text{im} T\)</span> is a subspace of <span class="math inline">\(W\)</span>.</p>
</div>
<p>::: {#thm- } [Rank-Nullity Theorem] If <span class="math inline">\(V\)</span> is finite-dimensional and <span class="math inline">\(T\in \mathcal{L}(V,W)\)</span>, then range <span class="math inline">\(T\)</span> is finite-dimensional and <span class="math inline">\(\text{dim} V= \text{dim} (\text{im} T) + \text{dim} (\text{ker} T)\)</span>. :::</p>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>Since <span class="math inline">\(V\)</span> is a finite-dimensional and <span class="math inline">\(\text{ker} T\)</span> is a subspace of <span class="math inline">\(V\)</span>, <span class="math inline">\(\text{ker} T\)</span> is finite-dimensional and so let <span class="math inline">\((u_1,\ldots,u_n)\)</span> be a basis of <span class="math inline">\(\text{ker} T\)</span>. Since <span class="math inline">\((u_1,\ldots,u_n)\)</span> is linearly independent in <span class="math inline">\(V\)</span>, it can be extended to a basis of <span class="math inline">\(V\)</span>, say <span class="math inline">\(\mathcal{B}=(u_1,\ldots,u_n,v_1,\ldots,v_m)\)</span>. It suffices to show <span class="math inline">\((T v_1,\ldots, T v_m)\)</span> is a basis of <span class="math inline">\(\text{im} T\)</span>, for then <span class="math inline">\(\text{im} T\)</span> is finite-dimensional is proven and <span class="math inline">\(\text{dim} V=n+m=\text{dim} \text{ker} T+\text{dim} \text{im} T\)</span> holds as well.</p>
<p>Let <span class="math inline">\(w\in \text{im} T\)</span>. Then there exists <span class="math inline">\(v\in V\)</span> and scalars <span class="math inline">\(a_1,\ldots,a_n, b_1,\ldots,b_m\)</span> such that <span class="math display">\[w=Tv=T(a_1 u_1+\cdots + a_n u_n+b_1 v_1+\cdots + b_m v_m)=b_1 T v_1+\cdots + b_m T v_m.\]</span> Thus <span class="math inline">\((T v_1,\ldots,T v_m)\)</span> spans <span class="math inline">\(\text{im} T\)</span>. Suppose <span class="math inline">\(c_1,\ldots,c_m\)</span> are scalars such that <span class="math inline">\(c T v_1+\cdots + c_m T v_m=0\)</span>. Then there exist scalars <span class="math inline">\(d_1,\ldots,d_n\)</span> such that <span class="math display">\[c_1 v_1+\cdots + c_m v_m=d_1 u_1+\cdots +d_n u_n.\]</span> Since <span class="math inline">\(\mathcal{B}\)</span> is a basis of <span class="math inline">\(V\)</span> and <span class="math inline">\(c_1 v_1+\cdots c_m v_m+(-d_1) u_1 + \cdots +(-d_n)u_n=0\)</span> it follows <span class="math inline">\(c_1=\cdots = c_m = d_1 = \cdots = \cdots =d_n=0\)</span>. In particular, <span class="math inline">\(c_1=\cdots = c_m=0\)</span> shows <span class="math inline">\(T v_1,\ldots, T v_m\)</span> are linearly independent. Therefore, <span class="math inline">\((T v_1,\ldots, T v_m)\)</span> is a basis fo <span class="math inline">\(\text{im} T\)</span>.</p>
</div>
<div id="cor-" class="theorem corollary">
<p><span class="theorem-title"><strong>Corollary 3.1 </strong></span>If <span class="math inline">\(V\)</span> and <span class="math inline">\(W\)</span> are finite-dimensional vector spaces with <span class="math inline">\(T\in \mathcal{L}(V,W)\)</span>, then</p>
<ul>
<li><span class="math inline">\(\text{dim} V &gt; \text{dim} W \implies T\)</span> is not injective, and</li>
<li><span class="math inline">\(\text{dim} V &lt; \text{dim} W \implies T\)</span> is not surjective.</li>
</ul>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>The proof of each part follows.</p>
<ul>
<li>By the Rank-Nullity Theorem, <span class="math inline">\(\text{dim} V=\text{dim} \text{ker} T+ \text{dim} \text{im} T \leq \text{dim} \text{ker} T +\text{dim} W.\)</span> Since $ V &gt; W $, it follows <span class="math inline">\(0&lt;\text{dim} V-\text{dim} W\leq \text{dim} \text{ker} T.\)</span> Thus, <span class="math inline">\(\text{ker} T \neq \{0\}\)</span> and so <span class="math inline">\(T\)</span> is not injective.</li>
<li>Again by the Rank-Nullity Theorem, <span class="math inline">\(\text{dim} V=\text{dim} \text{ker} T+ \text{dim} \text{im} T\)</span> and so <span class="math inline">\(\text{dim} \text{im} T\leq \text{dim} V\)</span>. Since $ V &lt; W $, <span class="math inline">\(0&lt;\text{dim} W-\text{dim} V\leq \text{dim} W-\text{dim} \text{im} T\)</span> and so there exists a nonzero element <span class="math inline">\(w\in W\)</span> with <span class="math inline">\(w\in \text{im} T\)</span>. Therefore, <span class="math inline">\(T\)</span> is not surjective.</li>
</ul>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.15 </strong></span>Suppose that <span class="math inline">\(T\)</span> is a linear map from <span class="math inline">\(V\)</span> to <span class="math inline">\(\mathbb{F}\)</span>. Prove that if <span class="math inline">\(u \in V\)</span> is not in <span class="math inline">\(\text{ker} T\)</span>, then <span class="math inline">\(V=\text{ker} T \, \oplus \{a u:a\in F\}\)</span>. Let <span class="math inline">\(U=\{a u \mid a\in \mathbb{F}\}\)</span>. The following arguments show <span class="math inline">\(V=\text{ker} T +U\)</span> and <span class="math inline">\(\text{ker} T \cap U=\{0\}\)</span>, respectively.</p>
<ul>
<li>Let <span class="math inline">\(v\in V\)</span> with <span class="math inline">\(Tv=b\)</span>. Since <span class="math inline">\(Tu\neq 0\)</span> there is a <span class="math inline">\(u_1 \in U\)</span> such that <span class="math inline">\(T u_1=b\)</span>. Then we can write <span class="math inline">\(v=u_1+(v-u_1)\)</span>, and <span class="math inline">\(v-u_1\in \text{ker} T\)</span>. This gives <span class="math inline">\(V=\text{ker} T+ U\)</span>.</li>
<li>Let <span class="math inline">\(v\in \text{ker} T \cap U\)</span>, then there exists <span class="math inline">\(a \in \mathbb{F}\)</span> such that <span class="math inline">\(v=a u\)</span> and so <span class="math inline">\(T(v)=a T u=0\)</span> since <span class="math inline">\(T v\in \text{ker} T\)</span>. Thus <span class="math inline">\(a=0\)</span> and so <span class="math inline">\(v=0\)</span> meaning <span class="math inline">\(\text{ker} T \cap U\subseteq \{0\}\)</span>. Since <span class="math inline">\(0 \in \text{ker} T \cap U\)</span>, it follows <span class="math inline">\(\text{ker} T \cap U= \{0\}\)</span>.</li>
</ul>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.16 </strong></span>Suppose that <span class="math inline">\(T\in \mathcal{L}(U,W)\)</span> is injective and <span class="math inline">\((v_1,\ldots,v_n)\)</span> is linearly independent in <span class="math inline">\(V\)</span>. Prove that <span class="math inline">\((T v_1,\ldots,T v_n)\)</span> is linearly independent in <span class="math inline">\(W\)</span>. Suppose <span class="math inline">\(a_1 T v_1+ \cdots a_n T v_n=0\)</span> in <span class="math inline">\(W\)</span> where <span class="math inline">\(a_1,\ldots,a_n \in \mathbb{F}\)</span>. Then by linearity of <span class="math inline">\(T\)</span>, <span class="math inline">\(T(a_1 v_1 + \cdots + a_n v_n)=0\)</span>. Since <span class="math inline">\(T(0)\)</span> and <span class="math inline">\(T\)</span> is injective, <span class="math inline">\(a_1 v_1+\cdots + a_n v_n=0\)</span>. Since <span class="math inline">\((v_1,\ldots,v_n)\)</span> is linearly independent <span class="math inline">\(a_1=\cdots = a_n =0\)</span>. Therefore, <span class="math inline">\((T v_1,\ldots, T v_n)\)</span> is linearly independent.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.17 </strong></span>Show that every linear map from a one-dimensional vector space to itself is multiplication by some scalar. More precisely, prove that if <span class="math inline">\(\text{dim} V=1\)</span> and <span class="math inline">\(T\in \mathcal{L}(V,V)\)</span>, then there exists <span class="math inline">\(a\in \mathbb{F}\)</span> such that <span class="math inline">\(T v=a v\)</span> for all <span class="math inline">\(v\in V\)</span>. Let <span class="math inline">\(\{w\}\)</span> be a basis of <span class="math inline">\(V\)</span>, and let <span class="math inline">\(v\in V\)</span>. Then there exists <span class="math inline">\(c\in \mathbb{F}\)</span> such that <span class="math inline">\(v=c w\)</span>. Applying <span class="math inline">\(T\)</span> yields, <span class="math display">\[
T v=T(c w)=cTw=c(a w)=(ca)w=a(cw)=a v
\]</span> where <span class="math inline">\(Tw=aw\)</span> since <span class="math inline">\(Tw\in V\)</span> and <span class="math inline">\(\{w\}\)</span> is a basis of <span class="math inline">\(V\)</span>.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.18 </strong></span> <strong>linear extension</strong> Suppose that <span class="math inline">\(V\)</span> is finite-dimensional. Prove that any linear map on a subspace of <span class="math inline">\(V\)</span> can be extended to a linear map on <span class="math inline">\(V\)</span>. In other words, show that if <span class="math inline">\(U\)</span> is a subspace of <span class="math inline">\(V\)</span> and <span class="math inline">\(S\in \mathcal{L}(U,W)\)</span>, then there exists <span class="math inline">\(T\in \mathcal{L}(V,W)\)</span> such that <span class="math inline">\(Tu=Su\)</span> for all <span class="math inline">\(u\in U\)</span>. Let <span class="math inline">\((u_1,\ldots,u_n)\)</span> be a basis of <span class="math inline">\(U\)</span> and extend this basis of <span class="math inline">\(U\)</span> to a basis of <span class="math inline">\(V\)</span>, say <span class="math inline">\((u_1,\ldots,u_n, v_1,\ldots,v_m)\)</span>. Define <span class="math inline">\(T\)</span> as the linear extension of <span class="math inline">\(S\)</span>, as follows <span class="math display">\[
T(u_i)=S(u_i) \text{ for } 1\leq i \leq n \hspace{.5cm} \text{ and } \hspace{.5cm}  T(v_j)=v_j \text{ for } 1\leq j \leq m.
\]</span> Then for all <span class="math inline">\(u\in U\)</span>, <span class="math display">\[\begin{align*}
T(u) &amp; =T(a_1 u_1+\cdots + a_n u_n)
=a_1 T u_1+\cdots a_n T u_n \\
&amp; =a_1 S u_1+\cdots +a_n S u_n
=S(a_1u_1+\cdots a_n u_n)
=S(u)
\end{align*}\]</span> where <span class="math inline">\(a_1,\ldots,a_n\in \mathbb{F}\)</span>. By definition of <span class="math inline">\(T\)</span>, <span class="math inline">\(T\in \mathcal{L}(V,W)\)</span>.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.19 </strong></span>Prove that if <span class="math inline">\(S_1,\ldots,S_n\)</span> are injective linear maps such that <span class="math inline">\(S_1 \cdots S_n\)</span> makes sense, then <span class="math inline">\(S_1 \cdots S_n\)</span> is injective. Suppose <span class="math inline">\(v\)</span> and <span class="math inline">\(w\)</span> are any vectors and <span class="math inline">\((S_1\cdots S_n)v=(S_1\cdots S_n)w\)</span>. Then by definition of composition, <span class="math inline">\(S_1(S_2\cdots S_n)v=S_1(S_2\cdots S_n)w\)</span>, and since <span class="math inline">\(S_1\)</span> is injective <span class="math inline">\(S_2(S_3\cdots S_n)v=S_2(S_3\cdots S_n)w\)</span>. Since <span class="math inline">\(S_2,\ldots,S_n\)</span> are all injective <span class="math inline">\(v=w\)</span> as desired showing <span class="math inline">\(S_1\cdots S_n\)</span> is injective.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.20 </strong></span>Prove that if <span class="math inline">\((v_1,\ldots,v_n)\)</span> spans <span class="math inline">\(V\)</span> and <span class="math inline">\(T\in \mathcal{L}(V,W)\)</span> is surjective, then <span class="math inline">\((T v_1,\ldots,T v_n)\)</span> spans <span class="math inline">\(W\)</span>. Let <span class="math inline">\(w\in W\)</span>. Then, since <span class="math inline">\(T\)</span> is surjective, there exists <span class="math inline">\(v\in V\)</span> such that <span class="math inline">\(T(v)=w\)</span>. Since <span class="math inline">\((v_1,\ldots,v_n)\)</span> spans <span class="math inline">\(V\)</span> there exists scalars <span class="math inline">\(a_1,\ldots,a_n\)</span> such that <span class="math inline">\(v=a_1 v_1+ \dots a_n v_n\)</span> and by linearity of <span class="math inline">\(T\)</span>, <span class="math inline">\(T(v)=a_1 T v_1+ \cdots a_n T v_n=w.\)</span> Therefore, <span class="math inline">\((T v_1,\ldots,T v_n)\)</span> spans <span class="math inline">\(W\)</span> because every element <span class="math inline">\(w\)</span> in <span class="math inline">\(W\)</span> is a linear combination of the <span class="math inline">\(T v\)</span>’s.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.21 </strong></span>Suppose that <span class="math inline">\(V\)</span> is finite-dimensional and that <span class="math inline">\(T\in \mathcal{L}(V,W)\)</span>. Prove that there exists a subspace <span class="math inline">\(U\)</span> of <span class="math inline">\(V\)</span> such that <span class="math inline">\(U\cap \text{ker} T=\{0\}\)</span> and range <span class="math inline">\(T = \{T u : u\in U\}\)</span>. Since <span class="math inline">\(V\)</span> is finite-dimensional so is <span class="math inline">\(\text{ker} T\)</span>. Let <span class="math inline">\((v_1,\ldots,v_n)\)</span> be a basis of <span class="math inline">\(\text{ker} T\)</span> and extend this basis to a basis of <span class="math inline">\(V\)</span>, namely let <span class="math inline">\(\mathcal{B}=(v_1,\ldots,v_n,u_1,\ldots,u_m)\)</span> be a basis of <span class="math inline">\(V\)</span>. Let <span class="math inline">\(U=\text{span} (u_1,\ldots,u_m)\)</span>, we will show <span class="math inline">\(U\cap \text{ker} T=\{0\}\)</span> and range <span class="math inline">\(T = \{T u : u\in U\}\)</span>. Clearly, <span class="math inline">\(\{0\}\subseteq U\cap \text{ker} T\)</span> since both <span class="math inline">\(U\)</span> and <span class="math inline">\(\text{ker} T\)</span> are subspaces. Let <span class="math inline">\(v\in U\cap \text{ker} T\)</span>. Then <span class="math inline">\(v\in U\)</span> implies there exists <span class="math inline">\(a_1,\ldots,a_m\)</span> such that <span class="math inline">\(v=a_1 u_1+\cdots +a_m u_m\)</span>. Then <span class="math inline">\(v\in \text{ker} T\)</span> implies there exists <span class="math inline">\(b_1,\ldots,b_n\)</span> such that <span class="math inline">\(v=b_1 v_1+\cdots +b_n v_n\)</span>. Then <span class="math inline">\(a_1 u_1+\cdots +a_m u_m+(-b_1)v_1+\cdots +(-b_n)v_n=0\)</span> and since <span class="math inline">\(\mathcal{B}\)</span> is a basis of <span class="math inline">\(V\)</span> the <span class="math inline">\(u\)</span>’s and <span class="math inline">\(v\)</span>’s are linearly independent and so <span class="math inline">\(a_1=\cdots =a_m=b_1=\cdots =b_n=0\)</span> meaning <span class="math inline">\(v=0\)</span>; and so <span class="math inline">\(\text{ker} T = \{0\}\)</span>. Let <span class="math inline">\(v\in V\)</span>. Then <span class="math inline">\(T(v)=a_1T v_1+\cdots +a_n T v_n+b_1 T u_1+\cdots + b_m T u_m=b_1 Tu_1+\cdots +b_m T u_m\)</span> showing <span class="math inline">\(\{T v : v\in T\}\subseteq \{T v : v\in U\}\)</span> conversely is obvious, since <span class="math inline">\(U\subseteq V\)</span>.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.22 </strong></span>Prove that if there exists a linear map on <span class="math inline">\(V\)</span> whose null space and range are both finite-dimensional, then <span class="math inline">\(V\)</span> is finite-dimensional.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.23 </strong></span>Suppose that <span class="math inline">\(V\)</span> and <span class="math inline">\(W\)</span> are finite-dimensional and <span class="math inline">\(T\in \mathcal{L}(V,W)\)</span>. Prove that there exists a surjective linear map from <span class="math inline">\(V\)</span> onto <span class="math inline">\(W\)</span> if and only if <span class="math inline">\(\text{dim} W \leq \text{dim} V\)</span>. Suppose <span class="math inline">\(T\)</span> is a linear map of <span class="math inline">\(V\)</span> onto <span class="math inline">\(W\)</span>, then <span class="math inline">\(\text{dim} V=\text{dim} \text{ker} T+\text{dim} \text{im} T\)</span>. Since <span class="math inline">\(\text{dim} \text{ker} T \geq 0\)</span>, <span class="math inline">\(\text{dim} V\geq \text{dim} \text{im} T=\text{dim} W\)</span>, since <span class="math inline">\(T\)</span> is onto. Conversely, assume <span class="math inline">\(m=\text{dim} W\leq \text{dim} V=n\)</span> with bases of <span class="math inline">\(W\)</span> say <span class="math inline">\((w_1,\ldots,w_m)\)</span> and of <span class="math inline">\(V\)</span> say <span class="math inline">\((v_1,\ldots,v_n)\)</span>. Define <span class="math inline">\(T\)</span> to be the linear extension of: <span class="math display">\[
\begin{cases}
T(v_i)=w_i &amp; \text{ if } 1\leq i\leq m \\
T(v_i)=0 &amp; \text{ if } i&gt;m
\end{cases}
\]</span> Then <span class="math inline">\(T\)</span> is surjective since: if <span class="math inline">\(w\in W\)</span> then there exists <span class="math inline">\(a_i\in \mathbb{F}\)</span> such that <span class="math inline">\(w=a_1 w_1+\cdots + a_m w_m=a_1 T(v_1)+\cdots + a_m T(v_m)=T(a_1 v_1+\cdots + a_m v_m)\)</span> showing every element in <span class="math inline">\(W\)</span> is in <span class="math inline">\(\text{im} T\)</span>.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.24 </strong></span>Suppose that <span class="math inline">\(W\)</span> is finite-dimensional and <span class="math inline">\(T\in \mathcal{L}(V,W)\)</span>. Prove that <span class="math inline">\(T\)</span> is injective if and only if there exists <span class="math inline">\(S\in \mathcal{L}(W,V)\)</span> such that <span class="math inline">\(S T\)</span> is the identity map on <span class="math inline">\(V\)</span>. Suppose <span class="math inline">\(S\in\mathcal{L}(W,V)\)</span> and <span class="math inline">\(ST\)</span> is the identity on <span class="math inline">\(V\)</span>. Then <span class="math inline">\(\text{ker} T\subseteq \text{ker} ST=\{0\}\)</span> and so <span class="math inline">\(\text{ker} T=\{0\}\)</span>. Therefore, <span class="math inline">\(T\)</span> is injective. Conversely, suppose <span class="math inline">\(T\)</span> is injective. So we can define <span class="math inline">\(S_1\in\mathcal{L}(W,V)\)</span> by the following: <span class="math inline">\(S_1(w)=v\)</span> where <span class="math inline">\(v=T^{-1}(w)\)</span> (since <span class="math inline">\(T\)</span> is injective). So <span class="math inline">\(S_1:\text{im} T \rightarrow V\)</span> and since <span class="math inline">\(W\)</span> is finite-dimensional, by <span class="math inline">\(\ref{Linear Extension}\)</span>, <span class="math inline">\(S_1\)</span> can be extended to <span class="math inline">\(S: W\rightarrow V\)</span> and by definition of <span class="math inline">\(S_1\)</span>, if <span class="math inline">\(v\in V\)</span>, then <span class="math inline">\(ST(v)=S(Tv)=T^{-1}(Tv)=v\)</span>.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.25 </strong></span>Suppose that <span class="math inline">\(V\)</span> is finite-dimensional and <span class="math inline">\(T\in \mathcal{L}(V,W)\)</span>. Prove that <span class="math inline">\(T\)</span> is surjective if and only if there exists <span class="math inline">\(S\in \mathcal{L}(W,V)\)</span> such that <span class="math inline">\(T S\)</span> is the identity map on <span class="math inline">\(W\)</span>. We will present two proofs.</p>
<ul>
<li>Suppose <span class="math inline">\(S\in \mathcal{L}(W,V)\)</span> and <span class="math inline">\(TS=I_W\)</span>. Let <span class="math inline">\(w\in W\)</span>. Then <span class="math inline">\(v=S(w)\in V\)</span> is such that <span class="math inline">\(T(v)=TS(w)=w\)</span> and therefore <span class="math inline">\(T\)</span> is surjective. Conversely, suppose <span class="math inline">\(T\)</span> is surjective. Since <span class="math inline">\(V\)</span> is a finite-dimensional vector space and <span class="math inline">\(T\)</span> is a linear map, <span class="math inline">\(W\)</span> is finite-dimensional. Let <span class="math inline">\((v_1,\ldots,v_n)\)</span> be a basis for <span class="math inline">\(V\)</span>. Since <span class="math inline">\(T\)</span> is surjective, <span class="math inline">\((T v_1,\ldots,T v_n)\)</span> spans <span class="math inline">\(W\)</span>. Also since <span class="math inline">\(T\)</span> is surjective <span class="math inline">\(\text{dim} W\leq \text{dim} V=n\)</span> Any spanning set reduced to a basis say <span class="math inline">\((T v_1,\ldots,T v_m)\)</span> is a basis of <span class="math inline">\(W\)</span> where <span class="math inline">\(m\leq n\)</span>. Define <span class="math inline">\(S\)</span> as the linear extension of <span class="math inline">\(S(T v_i)=v_i\)</span> for each <span class="math inline">\(1\leq i \leq m\)</span>. Then, for all <span class="math inline">\(w\in W\)</span>, <span class="math inline">\(S(w)=S(a_1 T v_1+\cdots +a_m T v_m)=a_1 ST v_1+\cdots + a_m ST v_m=a_1 v_1+\cdots + a_m v_m=w\)</span> for scalars <span class="math inline">\(a_1,\ldots,a_m\in \mathbb{F}\)</span>, and so <span class="math inline">\(TS=I_W\)</span>.</li>
<li>Suppose <span class="math inline">\(T\)</span> is surjective. Using <span class="math inline">\(\ref{Null Space Decomposition}\)</span>, there exists a subspace <span class="math inline">\(U\)</span> of <span class="math inline">\(V\)</span> such that <span class="math inline">\(U\cap \text{ker} T=\{0\}\)</span> and <span class="math inline">\(\text{im} T=\{T u : u\in U\}\)</span>. Define <span class="math inline">\(T_1: U\rightarrow W\)</span> by <span class="math inline">\(T_1 u=T u\)</span> for <span class="math inline">\(u\in U\)</span>. Notice <span class="math inline">\(T_1\)</span> is injective and surjective and so <span class="math inline">\(T_1\)</span> has an inverse. Define <span class="math inline">\(S=T_1^{-1}\)</span> we have <span class="math inline">\(TS w= T_1 T_1^{-1}w=w\)</span> for all <span class="math inline">\(w\in W\)</span>.</li>
</ul>
</div>
<p>A linear map <span class="math inline">\(T\in \mathcal{L}(V,W)\)</span> is called <strong>invertible</strong> if there exists a linear map <span class="math inline">\(S\in \mathcal{L}(W,V)\)</span> such that <span class="math inline">\(S T\)</span> equals the identity map on <span class="math inline">\(V\)</span> and <span class="math inline">\(TS\)</span> equal the identity map on <span class="math inline">\(W\)</span>. Given <span class="math inline">\(T\in\mathcal{L}(V,W)\)</span>. A linear map <span class="math inline">\(S\in\mathcal{L}(W,V)\)</span> satisfying <span class="math inline">\(S T=I\)</span> and <span class="math inline">\(T S=I\)</span> is called an <strong>inverse</strong> of <span class="math inline">\(T\)</span>. Two vector spaces are called <strong>isomorphic</strong> if there is an invertible linear map from one vector space onto the other one.</p>
<div id="thm-" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.11 </strong></span>If <span class="math inline">\(\mathcal{B}=(f_1,\ldots,f_n)\)</span> is a basis of a linear space <span class="math inline">\(V\)</span>, then the coordinate transformation <span class="math display">\[
L_{\mathcal{B}}(f) = [f]_{\mathcal{B}}
\]</span> from <span class="math inline">\(V\)</span> to <span class="math inline">\(\mathbb{R}^n\)</span> is an isomorphism. Thus any linear space <span class="math inline">\(V\)</span> is isomorphic to <span class="math inline">\(\mathbb{R}^n\)</span>.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>The proof if left for the reader.</p>
</div>
<p>An invertible linear transformation <span class="math inline">\(T\)</span> is called an <strong>isomorphism</strong>. Recall the rank-nullity theorem states that if <span class="math inline">\(V\)</span> and <span class="math inline">\(W\)</span> are finite-dimensional vector spaces and <span class="math inline">\(T\)</span> is a linear transformation from <span class="math inline">\(V\)</span> to <span class="math inline">\(W\)</span> then <span class="math inline">\(\text{dim} V=\text{dim} \ker T+\text{dim} \text{im} T\)</span> where <span class="math inline">\(\text{dim} \ker T\)</span> is called the <strong>nullity</strong> and <span class="math inline">\(\text{dim} \text{im} T\)</span> is called the <strong>rank</strong>.</p>
<div id="thm-" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.12 </strong></span>If <span class="math inline">\(V\)</span> and <span class="math inline">\(W\)</span> are finite-dimensional linear spaces, then</p>
<ul>
<li><span class="math inline">\(T\)</span> is an isomorphism from <span class="math inline">\(V\)</span> to <span class="math inline">\(W\)</span> if and only if <span class="math inline">\(\ker(T)= \{0\}\)</span> and <span class="math inline">\(\text{im} (T)=W\)</span>,</li>
<li>if <span class="math inline">\(V\)</span> is isomorphic to <span class="math inline">\(W\)</span>, then <span class="math inline">\(\text{dim} (V)=\text{dim} (W)\)</span>,</li>
<li>if <span class="math inline">\(\text{dim} (V)=\text{dim} (W)\)</span> and <span class="math inline">\(\ker(T)=\{0\}\)</span>, then <span class="math inline">\(T\)</span> is an isomorphism, and</li>
<li>if <span class="math inline">\(\text{dim} (V)=\text{dim} (W)\)</span> and <span class="math inline">\(\text{im}(T)=W\)</span>, then <span class="math inline">\(T\)</span> is an isomorphism.</li>
</ul>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>The proof of each part follows.</p>
<ul>
<li>Suppose <span class="math inline">\(T\)</span> is an isomorphism from <span class="math inline">\(V\)</span> to <span class="math inline">\(W\)</span>. This means there exists an invertible linear transformation <span class="math inline">\(T^{-1}\)</span> from <span class="math inline">\(W\)</span> to <span class="math inline">\(V\)</span> such that <span class="math inline">\(T(T^{-1})=I_W\)</span> and <span class="math inline">\(T^{-1}(T)=I_V\)</span>, where <span class="math inline">\(I_W\)</span> and <span class="math inline">\(I_V\)</span> are the identity transformations on <span class="math inline">\(W\)</span> and <span class="math inline">\(V\)</span> respectively. We will use <span class="math inline">\(T^{-1}\)</span> to show <span class="math inline">\(\ker T=\{0\}\)</span> and <span class="math inline">\(\text{im} T= W\)</span>. Since <span class="math inline">\(\ker T\)</span> is a subspace, <span class="math inline">\(\{0\}\subset \ker T\)</span>. Conversely, suppose <span class="math inline">\(f\in \ker T\)</span>. Then <span class="math inline">\(T(f)=0\)</span> and so <span class="math inline">\(T^{-1}(T(f))=f=0\)</span> so that <span class="math inline">\(\ker T\subseteq \{0\}\)</span>. Thus <span class="math inline">\(\ker T = \{0\}\)</span>. Since <span class="math inline">\(\text{im} T\)</span> is a subspace of <span class="math inline">\(W\)</span>, <span class="math inline">\(\text{im} T\subseteq W\)</span>. To show conversely, let <span class="math inline">\(w\in W\)</span>. Then <span class="math inline">\(T^{-1}(w)\in V\)</span> and so <span class="math inline">\(T(T^{-1}w)=w\)</span> shows <span class="math inline">\(w\in \text{im} T\)</span>. Thus <span class="math inline">\(\text{im} T=W\)</span>.</li>
</ul>
<p>Conversely, suppose <span class="math inline">\(\ker T=\{0\}\)</span> and <span class="math inline">\(\text{im} T=W\)</span>. We will show <span class="math inline">\(T\)</span> is an isomorphism, which means we must show <span class="math inline">\(T(f)=g\)</span> has a unique solution <span class="math inline">\(f\)</span> for each <span class="math inline">\(g\in W\)</span>. Now since <span class="math inline">\(\text{im} T=W\)</span>, <span class="math inline">\(T(f)=g\)</span> has at least one solution, say <span class="math inline">\(f\)</span>. Suppose <span class="math inline">\(T(f)=g\)</span> has two solutions, say <span class="math inline">\(T(f_1)=g=T(f_2)\)</span>. Then <span class="math inline">\(0=T(f_1)-T(f_2)=T(f_1-f_2)\)</span> shows <span class="math inline">\(f_1-f_2\in \ker T\)</span>. Since <span class="math inline">\(\ker T=\{0\}\)</span>, <span class="math inline">\(f_1=f_2\)</span> must follow, which means <span class="math inline">\(T(f)=g\)</span> must have only one solution, so that <span class="math inline">\(T^{-1}\)</span> exists, and therefore, <span class="math inline">\(T\)</span> is an isomorphism.<br>
- If <span class="math inline">\(V\)</span> is isomorphic to <span class="math inline">\(W\)</span>, then there exists a linear transformation <span class="math inline">\(T\)</span> such that <span class="math inline">\(\ker T=\{0\}\)</span> and <span class="math inline">\(\text{im} T=W\)</span>. By the rank-nullity theorem, <span class="math inline">\(\text{dim} V=\text{dim} \ker T + \text{dim} \text{im} T=0+\text{dim} W\)</span>. - By the previous part, <span class="math inline">\(T\)</span> is an isomorphism when <span class="math inline">\(\ker =\{0\}\)</span> and <span class="math inline">\(\text{im} T=W\)</span>. We are assuming <span class="math inline">\(\ker T=\{0\}\)</span> so it remains to show <span class="math inline">\(\text{im} T=W\)</span>. By the rank-nullity theorem <span class="math inline">\(\text{dim} V=\text{dim} \ker T+\text{dim} \text{im} T=\text{dim} \ker T+\text{dim} W=\text{dim} W\)</span>. Thus, <span class="math inline">\(\ker T=0\)</span> and so <span class="math inline">\(\ker T=\{0\}\)</span>. Therefore, <span class="math inline">\(T\)</span> is an isomorphism. - By the previous part, <span class="math inline">\(T\)</span> is an isomorphism when <span class="math inline">\(\ker =\{0\}\)</span> and <span class="math inline">\(\text{im} T=W\)</span>. We are assuming <span class="math inline">\(\text{im} T=W\)</span> so it remains to show <span class="math inline">\(\ker T=\{o\}\)</span>. By the rank-nullity theorem <span class="math inline">\(\text{dim} V=\text{dim} \ker T+\text{dim} \text{im} T=\text{dim} \text{im} T=\text{dim} W\)</span>. Therefore, <span class="math inline">\(\text{im} T=W\)</span> and so <span class="math inline">\(T\)</span> is an isomorphism.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.26 </strong></span>Show that the transformation <span class="math inline">\(T(A)=S^{-1}AS\)</span>, from <span class="math inline">\(\mathbb{R}^{2\times 2}\)</span> to <span class="math inline">\(\mathbb{R}^{2\times 2}\)</span> where <span class="math inline">\(S=\begin{bmatrix} 1 &amp; 2 \\ 3 &amp; 4 \end{bmatrix}\)</span> is an isomorphism. Notice that <span class="math inline">\(\text{dim} \mathbb{R}^{2\times 2}=\text{dim} \mathbb{R}^{2\times 2}\)</span>. Can we determine an invertible linear transformation <span class="math inline">\(T^{-1}\)</span>? Checking the linearity conditions,<span class="math display">\[
T(A_1+A_2)=S^{-1}(A_1+A_2)S=S^{-1}A_1S+S^{-1}A_2S=T(A_1)+T(A_2)
\]</span> and<span class="math display">\[
T(k A)=S^{-1}(k A)S=kS^{-1}A S=k T(A).
\]</span> Now we know <span class="math inline">\(T\)</span> is a linear transformation. Is it invertible? We need to solve the equation, <span class="math inline">\(B=S^{-1} A S\)</span> for input <span class="math inline">\(A\)</span>. We can do this because <span class="math inline">\(S\)</span> is an invertible matrix, so <span class="math inline">\(S B=S(S^{-1}AS)=AS\)</span> and multiplying by <span class="math inline">\(S^{-1}\)</span> on the right <span class="math inline">\(S BS^{-1}=A\)</span> so that <span class="math inline">\(T\)</span> is invertible, and the linear transformation is <span class="math inline">\(T^{-1}(B)=S B S^{-1}\)</span>.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.27 </strong></span>Is the transformation <span class="math inline">\(L( f)=\vectorthree{f(1)}{f(2)}{f(3)}\)</span> from <span class="math inline">\(\mathcal{P}_3\)</span> to <span class="math inline">\(\mathbb{R}^3\)</span> an isomorphism? Since <span class="math inline">\(\text{dim} \mathcal{P}_3=4\)</span> and <span class="math inline">\(\text{dim} \mathbb{R}^3=3\)</span>, the spaces <span class="math inline">\(\mathcal{P}_3\)</span> and <span class="math inline">\(\mathbb{R}^3\)</span> fail to be isomorphic, so that <span class="math inline">\(L\)</span> is not an isomorphism.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.28 </strong></span>Is the transformation <span class="math inline">\(L( f)=\vectorthree{f(1)}{f(2)}{f(3)}\)</span> from <span class="math inline">\(\mathcal{P}_2\)</span> to <span class="math inline">\(\mathbb{R}^3\)</span> an isomorphism? Notice <span class="math inline">\(\text{dim} \mathcal{P}_2=3\)</span> and <span class="math inline">\(\text{dim} \mathbb{R}^3=3\)</span> so the dimensions of the domain and the target space have the same dimension. Checking the linearity conditions, <span class="math display">\[
L(f_1+f_2)
=\vectorthree{(f_1+f_2)(1)}{(f_1+f_2)(2)}{(f_1+f_2)(3)}
=\vectorthree{f_1(1)}{f_1(2)}{f_1(3)}+\vectorthree{f_2(1)}{f_2(2)}{(f_2(3)}=L(f_1)+L(f_2)
\]</span> and <span class="math display">\[
T(k f)=\vectorthree{(k f)(1)}{(k f)(2)}{(kf)(3)}
=k\vectorthree{f(1)}{f(2)}{f(3)}
=k T(f).
\]</span> The kernel of <span class="math inline">\(T\)</span> consists of all polynomials <span class="math inline">\(f(x)\)</span> in <span class="math inline">\(\mathcal{P}_2\)</span> such that <span class="math display">\[
T(f(x))=\vectorthree{f(1)}{f(2)}{f(3)}=\vectorthree{0}{0}{0}.
\]</span> Since a nonzero polynomial in <span class="math inline">\(\mathcal{P}_2\)</span> has at most two zeros, the zero polynomial is the only solution, so that <span class="math inline">\(\ker T=\{0\}\)</span>. Therefore, <span class="math inline">\(T\)</span> is an isomorphism.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.29 </strong></span>Determine whether the transformation <span class="math display">\[T(M)=M\begin{bmatrix} 2 &amp; 0 \\ 0 &amp; 3  \end{bmatrix}-\begin{bmatrix} 3 &amp; 0 \\ 0 &amp; 4  \end{bmatrix}M\]</span> from <span class="math inline">\(\mathbb{R}^{2\times 2}\)</span> to <span class="math inline">\(\mathbb{R}^{2\times 2}\)</span> is an isomorphism. Notice that <span class="math inline">\(\text{dim} \mathbb{R}^{2\times 2}=\text{dim} \mathbb{R}^{2\times 2}\)</span>. Can we determine an invertible linear transformation <span class="math inline">\(T^{-1}\)</span>? Checking the linearity conditions,<span class="math display">\[
\begin{array}{rl}
T(M+N)
&amp;=(M+N)\begin{bmatrix} 2 &amp; 0 \\ 0 &amp; 3  \end{bmatrix}-\begin{bmatrix} 3 &amp; 0 \\ 0 &amp; 4  \end{bmatrix}(M+N) \\
&amp;=M\begin{bmatrix} 2 &amp; 0 \\ 0 &amp; 3  \end{bmatrix}-\begin{bmatrix} 3 &amp; 0 \\ 0 &amp; 4  \end{bmatrix}M
+ N\begin{bmatrix} 2 &amp; 0 \\ 0 &amp; 3  \end{bmatrix}-\begin{bmatrix} 3 &amp; 0 \\ 0 &amp; 4  \end{bmatrix}N  =T(M)+T(N)
\end{array}
\]</span> and<span class="math display">\[
\begin{array}{rl}
T(k M)
&amp; =(kM)\begin{bmatrix} 2 &amp; 0 \\ 0 &amp; 3  \end{bmatrix}-\begin{bmatrix} 3 &amp; 0 \\ 0 &amp; 4  \end{bmatrix}(Mk) \\
&amp; =k \left ( M\begin{bmatrix} 2 &amp; 0 \\ 0 &amp; 3  \end{bmatrix}-\begin{bmatrix} 3 &amp; 0 \\ 0 &amp; 4  \end{bmatrix}M \right ) k
= k T(M)
\end{array}
\]</span> The kernel of <span class="math inline">\(T\)</span> consists of <span class="math inline">\(M=\begin{bmatrix} a &amp; b \\ c &amp; d \end{bmatrix}\)</span> such that<span class="math display">\[
\begin{bmatrix} a &amp; b \\ c &amp; d  \end{bmatrix}
\begin{bmatrix} 2 &amp; 0 \\ 0 &amp; 3  \end{bmatrix}-\begin{bmatrix} 3 &amp; 0 \\ 0 &amp; 4  \end{bmatrix}
\begin{bmatrix} a &amp; b \\ c &amp; d  \end{bmatrix}
=
\begin{bmatrix} -a &amp; 0 \\ -2c &amp; -d  \end{bmatrix}
\begin{bmatrix} 0 &amp; 0 \\ 0 &amp; 0  \end{bmatrix}.
\]</span> Thus <span class="math inline">\(a=c=d=0\)</span>. However, when <span class="math inline">\(M=\begin{bmatrix} 0 &amp; 1 \\ 0 &amp; 0 \end{bmatrix}\)</span> then <span class="math inline">\(T(M)=0\)</span> so that <span class="math inline">\(\ker T \neq \{0\}\)</span>, and so <span class="math inline">\(T\)</span> is not an isomorphism.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.30 </strong></span>Determine whether the transformation <span class="math inline">\(T(f(t))=\vectorthree{f(1)}{f'(2)}{f(3)}\)</span> from <span class="math inline">\(\mathcal{P}_2\)</span> to <span class="math inline">\(\mathbb{R}^3\)</span> is a linear transformation. Then determine whether <span class="math inline">\(T\)</span> is an isomorphism and if not then find its image and kernel. This transformation is linear since<span class="math display">\[
T(f(t)+g(t))=\vectorthree{f(1)+g(1)}{f'(2)+g'(2)}{f(3)+g(3)}=
\vectorthree{f(1)}{f'(2)}{f(3)}+ \vectorthree{g(1)}{g'(2)}{g(3)}=
T(f(t))+T(g(t))
\]</span> and <span class="math display">\[
T(k f(t))=\vectorthree{kf(1)}{k f'(2)}{k f(3)}=
k \vectorthree{f(1)}{f'(2)}{f(3)}=
k T(f(t)).
\]</span> Since <span class="math inline">\(T(t-1)(t-3))=T(t^2-4t+3)=\vec 0\)</span> shows <span class="math inline">\(\ker T \neq \{0\}\)</span>, T is not an isomorphism.</p>
</div>
<div id="thm-" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.13 </strong></span>A linear map is invertible if and only if it is injective and surjective.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>Suppose <span class="math inline">\(T\in \mathcal{L}(V,W)\)</span> is invertible with inverse <span class="math inline">\(T\)</span>. Let <span class="math inline">\(u,v\in V\)</span>. If <span class="math inline">\(Tu=Tv\)</span> then <span class="math display">\[u=(T^{-1})u)=T^{-1}(Tu)=T^{-1}(Tv)=(T^{-1}T)(v)=v\]</span> and so <span class="math inline">\(T\)</span> is injective. If <span class="math inline">\(w\in W\)</span>, then <span class="math inline">\(v=T^{-1} w\in V\)</span> with <span class="math inline">\(T v=T(T^{-1}w)=w\)</span> shows <span class="math inline">\(T\)</span> is surjective. Assume <span class="math inline">\(T\)</span> is injective and surjective. For each <span class="math inline">\(w\in W\)</span> assign <span class="math inline">\(T(v)=w\)</span>. Such <span class="math inline">\(S(w)=v\)</span> exists because <span class="math inline">\(T\)</span> is surjective and is unique since <span class="math inline">\(T\)</span> is injective. Then <span class="math inline">\(T(v)=w\)</span> shows <span class="math inline">\(ST(v)=S(w)=v\)</span> so that <span class="math inline">\(ST\)</span> is the identity on <span class="math inline">\(V\)</span>. Also, <span class="math inline">\(TS(w)=T(Sw)=Tv=w\)</span> shows <span class="math inline">\(TS\)</span> is the identity on <span class="math inline">\(W\)</span>. Thus <span class="math inline">\(S\)</span> and <span class="math inline">\(T\)</span> are inverses.</p>
<p>Now <span class="math inline">\(S\)</span> is linear since:</p>
<ul>
<li>if <span class="math inline">\(w_1,w_2\in W\)</span>, then there exists a unique <span class="math inline">\(v_1\)</span> and <span class="math inline">\(v_2\)</span> such that <span class="math inline">\(Tv_1=w_1\)</span> and <span class="math inline">\(Tv_2=w_2\)</span>, <span class="math inline">\(S(w_1)=v_1\)</span>, and <span class="math inline">\(S(w_2)=v_2\)</span>. By linearity of <span class="math inline">\(T\)</span>, <span class="math inline">\(S(w_1+w_2)=S(T v_1+Tv_2)=(ST)(v_1+v_2)=v_1+v_2=S(w_1)+S(w_2)\)</span>.</li>
<li>If <span class="math inline">\(w\in W\)</span> and <span class="math inline">\(k\in \mathbb{F}\)</span> then there exists a unique <span class="math inline">\(v\in V\)</span> such that <span class="math inline">\(Tv=w\)</span> and <span class="math inline">\(S(w)=v\)</span>. By linearity of <span class="math inline">\(T\)</span>, <span class="math inline">\(S(kw)=S(k Tv)=S(T k v)=k v=kS(w)\)</span>.</li>
</ul>
<p>Therefore <span class="math inline">\(S\)</span> is linear and is the inverse of <span class="math inline">\(T\)</span>.</p>
</div>
<p>Consider the transformation <span class="math display">\[
L \left( \, \begin{bmatrix} a &amp; b \\ c &amp; d  \end{bmatrix} \, \right)=\vectorfour{a}{b}{c}{d}
\]</span> from <span class="math inline">\(\mathbb{R}^{2\times 2}\)</span> to <span class="math inline">\(\mathbb{R}^4\)</span>. Note that <span class="math inline">\(L\)</span> is the coordinate transformation <span class="math inline">\(L_{\mathcal{B}}\)</span> with respect to the basis <span class="math display">\[
\mathcal{B}=
\left(
\begin{bmatrix} 1 &amp; 0 \\ 0 &amp; 0  \end{bmatrix},
\begin{bmatrix} 0 &amp; 1 \\ 0 &amp; 0  \end{bmatrix},
\begin{bmatrix} 0 &amp; 0 \\ 1 &amp; 0  \end{bmatrix},
\begin{bmatrix} 0 &amp; 0 \\ 0 &amp; 1  \end{bmatrix}
\right)
\]</span> Being a coordinate transformation, <span class="math inline">\(L\)</span> is both linear and invertible. Therefore <span class="math inline">\(L\)</span> is an isomorphism.</p>
<div id="thm-" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.14 </strong></span>Let <span class="math inline">\(T\)</span> be the linear transformation from <span class="math inline">\(V\)</span> to <span class="math inline">\(V\)</span> and let <span class="math inline">\(B\)</span> be the matrix of <span class="math inline">\(T\)</span> with respect to a basis <span class="math inline">\(\mathcal{B}=(f_1,\ldots,f_n)\)</span> of <span class="math inline">\(V\)</span>. Then <span class="math display">\[
B=
\begin{bmatrix}[T(f_1)]_{\mathcal{B}} &amp; \cdots &amp; [T(f_n)]_{\mathcal{B}}]
\end{bmatrix}
\]</span> In other words, the columns of <span class="math inline">\(B\)</span> are the <span class="math inline">\(\mathcal{B}\)</span>-coordinate vectors of the transformation of the basis elements <span class="math inline">\(f_1,\ldots,f_n\)</span> of <span class="math inline">\(V\)</span>.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>The proof if left for the reader.</p>
</div>
<div id="thm-" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.15 </strong></span>Two finite-dimensional vector spaces are isomorphic if and only if they have the same dimension.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>Suppose <span class="math inline">\(V\)</span> and <span class="math inline">\(W\)</span> are finite-dimensional vector spaces that are isomorphic. If <span class="math inline">\(\text{dim} V &gt; \text{dim} W\)</span>, then no linear map between <span class="math inline">\(T\)</span> and <span class="math inline">\(W\)</span> can be injective. Thus <span class="math inline">\(V\)</span> and <span class="math inline">\(W\)</span> are not isomorphic contrary to hypothesis. If <span class="math inline">\(\text{dim} V &lt; \text{dim} W\)</span>, then no linear map between <span class="math inline">\(V\)</span> and <span class="math inline">\(W\)</span> can be surjective. Thus <span class="math inline">\(V\)</span> and <span class="math inline">\(W\)</span> are not isomorphic contrary to hypothesis. Therefore, <span class="math inline">\(\text{dim} V =\text{dim} W\)</span>.</p>
<p>Suppose <span class="math inline">\(V\)</span> and <span class="math inline">\(W\)</span> are vector spaces with <span class="math inline">\(\text{dim} V=\text{dim} W=n\)</span>. Let <span class="math inline">\((v_1,\ldots,v_n)\)</span> ba a basis of <span class="math inline">\(V\)</span> and let <span class="math inline">\((w_1,\ldots,w_n)\)</span> be a basis of <span class="math inline">\(W\)</span>. Define a linear map <span class="math inline">\(T\)</span> by <span class="math inline">\(T(a_1 v_1+\cdots +a_n v_n)=a_1 w_1+\cdots +a_n w_n\)</span>. It’s an easy exercise to show <span class="math inline">\(T\)</span> is linear, injective, and surjective. Thus <span class="math inline">\(T\)</span> is an isomorphism as required.</p>
</div>
<div id="thm-" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.16 </strong></span> If <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are matrices of a linear transformation <span class="math inline">\(T\)</span> with respect to different bases, then <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are similar matrices.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>The proof is left for the reader.</p>
</div>
<div id="thm-" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.17 </strong></span>Suppose <span class="math inline">\(V\)</span> and <span class="math inline">\(W\)</span> are finite-dimensional vector spaces, then <span class="math inline">\(\mathcal{M}\)</span> is an invertible linear map between <span class="math inline">\(\mathcal{L}(V,W)\)</span> and <span class="math inline">\(Mat(m,n,\mathbb{F})\)</span></p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>Suppose <span class="math inline">\((v_1,\ldots,v_n)\)</span> and <span class="math inline">\(w_1,\ldots,w_m)\)</span> are bases of <span class="math inline">\(V\)</span> and <span class="math inline">\(W\)</span> respectively. For each <span class="math inline">\(T\in \mathcal{L}(V,W)\)</span> we assign,<span class="math display">\[
\mathcal{M}(T)=\begin{bmatrix}a_{11} &amp; &amp; a_{1n}  \\ \vdots &amp; \cdots &amp; \vdots \\ a_{m1} &amp; &amp; a_{mn} \end{bmatrix}.
\]</span> where <span class="math inline">\(T v_k=a_{1k} w_1+\cdots + a_{mk} w_m\)</span>. Since <span class="math inline">\((w_1,\ldots,w_m)\)</span> is a basis of <span class="math inline">\(W\)</span>, This assigment is well-defined. The following arguments show <span class="math inline">\(\mathcal{M}\)</span> is linear, injective, and surjective, respectively.</p>
<ul>
<li>If <span class="math inline">\(S,T\in \mathcal{L}(V,W)\)</span>, then <span class="math inline">\(\mathcal{M}(S+T)=\mathcal{M}(S)+\mathcal{M}(T)\)</span> follows by the definition of matrix addition. If <span class="math inline">\(S\in \mathcal{L}(V,W)\)</span> and <span class="math inline">\(k\mathbb{F}\)</span>, then <span class="math inline">\(\mathcal{M}(kS)=k\mathcal{M}(S)\)</span> follows by the definition of scalar multiplication of matrices.</li>
<li>If <span class="math inline">\(T\in \mathcal{L}(V,W)\)</span> with <span class="math inline">\(\mathcal{M}(T)=0\)</span>, then for entries in <span class="math inline">\([a_{ij}]\)</span> are zero showing <span class="math inline">\(T v_k=0\)</span> for each <span class="math inline">\(k\)</span>. Since <span class="math inline">\((v_1,\ldots,v_n)\)</span> is a basis of <span class="math inline">\(V\)</span>, <span class="math inline">\(T\)</span> must be the zero map, and so <span class="math inline">\(\text{ker} \mathcal{M}=\{0\}\)</span>. Therefore, <span class="math inline">\(\mathcal{M}\)</span> is injective.</li>
<li>If <span class="math inline">\(A \in Mat(m,n,\mathbb{F})\)</span> then <span class="math inline">\(A\)</span> is an <span class="math inline">\(m\times n\)</span> matrix with entries <span class="math inline">\([a_{ij}]\)</span>. We define <span class="math inline">\(Tv_k=a_{1k} w_1+\cdots a_{mk} w_m\)</span> for each <span class="math inline">\(k\)</span>. Then, by the definition of the matrix of a linear map, <span class="math inline">\(\mathcal{M}(T)=A\)</span> and so <span class="math inline">\(\mathcal{M}\)</span> is surjective.</li>
</ul>
</div>
<div id="thm-" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.18 </strong></span>If <span class="math inline">\(V\)</span> and <span class="math inline">\(W\)</span> are finite-dimensional, then <span class="math inline">\(\mathcal{L}(V,W)\)</span> is finite-dimensional and <span class="math inline">\(\text{dim} \mathcal{L}(V,W) =(\text{dim} V) (\text{dim} W)\)</span>.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>If <span class="math inline">\(V\)</span> and <span class="math inline">\(W\)</span> are finite-dimensional vector spaces then <span class="math inline">\(\mathcal{L}(V,W)\)</span> is isomorphic to <span class="math inline">\(Mat(m,n,\mathbb{F})\)</span> where <span class="math inline">\(n=\text{dim} V\)</span> and <span class="math inline">\(m=\text{dim} W\)</span>. If follows <span class="math display">\[
\text{dim}  \mathcal{L}(V,W) =\text{dim}  Mat(mn,\mathbb{F})= m n=(\text{dim}  W)(\text{dim}  V).
\]</span> since <span class="math inline">\(\text{dim} Mat(m,n,\mathbb{F})= m n\)</span>.</p>
</div>
<div id="thm-" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.19 </strong></span>If <span class="math inline">\(V\)</span> is finite-dimensional and <span class="math inline">\(T\in \mathcal{L}(V)\)</span>, the the following are equivalent:</p>
<ul>
<li><span class="math inline">\(T\)</span> is invertible,</li>
<li><span class="math inline">\(T\)</span> is injective, and</li>
<li><span class="math inline">\(T\)</span> is surjective.</li>
</ul>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>The proof of each part follows.</p>
<ul>
<li>Suppose <span class="math inline">\(T\)</span> is invertible, then by definition <span class="math inline">\(T\)</span> is injective.</li>
<li>Suppose <span class="math inline">\(T\)</span> is injective. Thus <span class="math inline">\(\text{ker} T=\{0\}\)</span>. Since <span class="math inline">\(V\)</span> is finite-dimensional, we can apply the Rank-Nullity Theorem so <span class="math inline">\(\text{dim} V=\text{dim} \text{im} T\)</span>. Since <span class="math inline">\(\text{im} T\)</span> is a subspace of <span class="math inline">\(V\)</span> with the same dimension as <span class="math inline">\(V\)</span>, <span class="math inline">\(\text{im} T=V\)</span>. Therefore, <span class="math inline">\(T\)</span> is surjective.</li>
<li>Suppose <span class="math inline">\(T\)</span> is surjective. Then <span class="math inline">\(T(V)=V\)</span> and so <span class="math inline">\(\text{dim} V=\text{dim} \text{im} T\)</span>. Since <span class="math inline">\(V\)</span> is finite-dimensional, <span class="math inline">\(\text{dim} V=\text{dim} \text{ker} T+\text{dim} \text{im}\)</span> T by the Rank-Nullity Theorem. Thus, <span class="math inline">\(\text{dim} \text{ker} T =0\)</span> and so <span class="math inline">\(\text{ker} T=\{0\}\)</span>. Therefore, <span class="math inline">\(T\)</span> is injective, and since <span class="math inline">\(T\)</span> is injective and surjective, <span class="math inline">\(T\)</span> is invertible.</li>
</ul>
</div>
</section>
<section id="kernel-and-image-of-a-linear-transformation" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="kernel-and-image-of-a-linear-transformation"><span class="header-section-number">3.4</span> Kernel and Image of a Linear Transformation</h2>
<p>In this section we introduce the kernel and image of a linear transformation. We show how they can be realized as geometric objects and demonstrate how to find spanning sets for them.</p>
<div id="def-" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3.7 </strong></span>Let <span class="math inline">\(T\)</span> be a linear transformation from <span class="math inline">\(\mathbb{R}^m\)</span> to <span class="math inline">\(\mathbb{R}^n\)</span> with <span class="math inline">\(n\times m\)</span> matrix <span class="math inline">\(A\)</span>.</p>
<ul>
<li>The <strong>kernel</strong> of <span class="math inline">\(T\)</span>, denoted by <span class="math inline">\(\ker(T)\)</span>, is the set of all vectors <span class="math inline">\(\vec x\)</span> in <span class="math inline">\(\mathbb{R}^n\)</span> such that <span class="math inline">\(T(\vec x)=A \vec x = \vec 0\)</span>.</li>
<li>The <strong>image</strong> of <span class="math inline">\(T\)</span>, denoted by <span class="math inline">\(\text{im}(T)\)</span>, is the set of all vectors in <span class="math inline">\(\mathbb{R}^n\)</span> of the form <span class="math inline">\(T (\vec x)=A\vec x\)</span>.</li>
</ul>
<p>The kernel and image of a matrix <span class="math inline">\(A\)</span> of <span class="math inline">\(T\)</span> is defined as the kernel and image of <span class="math inline">\(T\)</span>.</p>
</div>
<p>Now to adequately describe the kernel and image of a linear transformation we need the concept of the span of a collection of vectors. We will see that one of the best ways to describe the kernel and image of a linear transformation is to describe them in terms of collections of linear combinations of vectors.</p>
<p>The next three lemmas describe basic properties of kernel and image.</p>
<div id="lem-" class="theorem lemma">
<p><span class="theorem-title"><strong>Lemma 3.2 </strong></span>The kernel of any linear transformation <span class="math inline">\(T\)</span> has the following properties:</p>
<ul>
<li><span class="math inline">\(\vec 0 \in \ker(T)\)</span>,</li>
<li>if <span class="math inline">\(\vec v, \vec w\in \ker(T)\)</span>, then <span class="math inline">\(\vec v+\vec w\in \ker(T)\)</span>, and</li>
<li>if <span class="math inline">\(\vec v\in \ker(T)\)</span> and <span class="math inline">\(k\in \mathbb{R}\)</span>, then <span class="math inline">\(k\vec v\in \ker(T)\)</span>.</li>
</ul>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>Let <span class="math inline">\(A\)</span> be the matrix for <span class="math inline">\(T\)</span>. Then <span class="math inline">\(A\vec 0=\vec 0\)</span> which shows <span class="math inline">\(\vec 0 \in \ker(T)\)</span>. If <span class="math inline">\(\vec v, \vec w\in \ker(T)\)</span>, then <span class="math inline">\(A\vec v=\vec 0\)</span> and <span class="math inline">\(A\vec w=\vec 0\)</span>. Thus, <span class="math inline">\(A\vec v+A\vec w=A(\vec v+\vec w)=\vec 0\)</span> implying <span class="math inline">\(\vec v+\vec w\in \ker(T)\)</span>. If <span class="math inline">\(\vec v\in \ker(T)\)</span> and <span class="math inline">\(k\in \mathbb{R}\)</span>, then <span class="math inline">\(\vec 0=A\vec v\)</span> implying <span class="math inline">\(A(k \vec v)=\vec 0\)</span>. Thus, <span class="math inline">\(k\vec v\in \ker(T)\)</span>.</p>
</div>
<div id="lem-" class="theorem lemma">
<p><span class="theorem-title"><strong>Lemma 3.3 </strong></span>Let <span class="math inline">\(T\)</span> be a linear transformation with matrix <span class="math inline">\(A\)</span>.</p>
<ul>
<li><p>If <span class="math inline">\(A\)</span> is an <span class="math inline">\(n\times n\)</span> matrix, then <span class="math inline">\(\ker(A)=\{\vec 0\}\)</span> if and only if <span class="math inline">\(\text{rank} (A)=n\)</span>.</p></li>
<li><p>If <span class="math inline">\(A\)</span> is an <span class="math inline">\(n\times m\)</span> matrix, then</p></li>
<li><p><span class="math inline">\(\ker(A)=\{\vec 0\} \implies m\geq n\)</span></p></li>
<li><p><span class="math inline">\(m&gt;n \implies \ker(A)\)</span> contains non-zero vectors</p></li>
<li><p>If <span class="math inline">\(A\)</span> is a square matrix, then <span class="math inline">\(\ker(A)=\{\vec 0\}\)</span> if and only if <span class="math inline">\(A\)</span> is invertible.</p></li>
</ul>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>If <span class="math inline">\(T\)</span> is a linear transformation <span class="math inline">\(T(\vec x )=A\vec x\)</span> from <span class="math inline">\(\mathbb{R}^m\)</span> to <span class="math inline">\(\mathbb{R}^n\)</span> where <span class="math inline">\(m&gt;n\)</span>, then there will be free variables for the equation <span class="math inline">\(T(\vec x)=A\vec x=\vec 0\)</span>; that is the system will have infinitely many solutions. Therefore, the kernel of <span class="math inline">\(T\)</span> will consists of infinitely many vectors. If <span class="math inline">\(m=n\)</span> and for an invertible <span class="math inline">\(n\times n\)</span> matrix <span class="math inline">\(A\)</span>, how do we find <span class="math inline">\(\ker(A)\)</span>? Since <span class="math inline">\(A\)</span> is invertible, <span class="math inline">\(A\vec x=\vec 0\)</span> can be solved by <span class="math inline">\(A^{-1}(A \vec x)=A^{-1}\vec 0\)</span> showing <span class="math inline">\(\vec x=\vec 0\)</span>; that is the only solution to the system <span class="math inline">\(A \vec x=\vec 0\)</span> is <span class="math inline">\(\vec 0\)</span> so that <span class="math inline">\(\ker(A)=\{\vec 0\}\)</span> whenever <span class="math inline">\(A\)</span> is invertible.</p>
</div>
<div id="lem-" class="theorem lemma">
<p><span class="theorem-title"><strong>Lemma 3.4 </strong></span>The image of any linear transformation <span class="math inline">\(T\)</span> has the following properties:</p>
<ul>
<li><span class="math inline">\(\vec 0 \in \text{im}(T)\)</span>,</li>
<li>if <span class="math inline">\(\vec v, \vec w\in \text{im}(T)\)</span>, then <span class="math inline">\(\vec v+\vec w\in \text{im}(T)\)</span>, and</li>
<li>if <span class="math inline">\(\vec v\in \text{im}(T)\)</span> and <span class="math inline">\(k\in \mathbb{R}\)</span>, then <span class="math inline">\(k\vec v\in \text{im}(T)\)</span>.</li>
</ul>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>Let <span class="math inline">\(A\)</span> be the matrix for <span class="math inline">\(T\)</span>. Then <span class="math inline">\(A\vec 0=\vec 0\)</span> which shows <span class="math inline">\(\vec 0 \in \text{im}(T)\)</span>. If <span class="math inline">\(\vec v, \vec w\in \text{im}(T)\)</span>, then there exists <span class="math inline">\(\vec x\)</span> and <span class="math inline">\(\vec y\)</span> such that <span class="math inline">\(A\vec x=\vec v\)</span> and <span class="math inline">\(A\vec y=\vec w\)</span>. Thus, <span class="math inline">\(\vec v+\vec w=A\vec x+A\vec y=A(\vec x+\vec y)\)</span> implying <span class="math inline">\(\vec v+\vec w\in \text{im}(T)\)</span>. If <span class="math inline">\(\vec v\in \text{im}(T)\)</span> and <span class="math inline">\(k\in \mathbb{R}\)</span>, then there exists <span class="math inline">\(\vec u\)</span> such that <span class="math inline">\(\vec v=A\vec u\)</span> implying <span class="math inline">\(A(k \vec u)=k \vec v\)</span>. Thus, <span class="math inline">\(k\vec v\in \text{im}(T)\)</span>.</p>
</div>
<div id="thm-" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.20 </strong></span> Let <span class="math inline">\(T:\mathbb{R}^m\to \mathbb{R}^n\)</span> be a linear transformation with matrix <span class="math inline">\(A\)</span>. Then <span class="math inline">\(\text{im}(T)=\text{span}(\vec v_1, ....,\vec v_m)\)</span> where <span class="math inline">\(\vec v_1, ..., \vec v_m\)</span> are the column vectors of <span class="math inline">\(A\)</span>.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>Since <span class="math inline">\(\vec v_1,...,\vec v_m\)</span> are the column vectors of <span class="math inline">\(A\)</span> <span class="math display">\[\begin{equation}
\label{lineq}
T(\vec x)=
A \vec x =
\begin{bmatrix}
\vec v_1 &amp; \cdots &amp; \vec v_m
\end{bmatrix}
\vectorthree{x_1}{\vdots}{x_m}=x_1 v_1+\cdots + x_m v_m.
\end{equation}\]</span> If <span class="math inline">\(\vec u\in \text{span}(\vec v_1, ....,\vec v_m)\)</span> then there exists <span class="math inline">\(x_1, ..., x_m\)</span> such that <span class="math inline">\(u=x_1 v_1+\cdots +x_m v_m\)</span>. By <span class="math inline">\(\ref{lineq}\)</span>, <span class="math inline">\(u=T(\vec x)\)</span> for <span class="math inline">\(\vec x\in \mathbb{R}^m\)</span>. Thus, <span class="math inline">\(\vec u\in \text{im}(T)\)</span>. Conversely, assume <span class="math inline">\(\vec u\in\text{im}(T)\)</span>. Then there exists <span class="math inline">\(\vec x\)</span> such that <span class="math inline">\(\vec u=T(\vec x)\)</span>. By <span class="math inline">\(\ref{lineq}\)</span>, there exists <span class="math inline">\(x_1, ...,x_m\)</span> such that <span class="math inline">\(u=x_1 v_1+\cdots +x_m v_m\)</span>. Therefore, <span class="math inline">\(\vec u \in \text{span}(\vec v_1, ....,\vec v_m)\)</span> and so <span class="math inline">\(\text{im}(T)=\text{span}(\vec v_1, ....\vec v_m)\)</span> follows.:::</p>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.31 </strong></span>Find vectors that span <span class="math inline">\(\ker(A)\)</span> and <span class="math inline">\(\text{im}(A)\)</span> given <span class="math display">\[
A=
\begin{bmatrix}
2 &amp; 1 &amp; 3 \\
3 &amp; 4 &amp; 2 \\
6 &amp; 5 &amp; 7
\end{bmatrix}.
\]</span> Describe <span class="math inline">\(\text{im}(A)\)</span> geometrically. To first find a spanning set of <span class="math inline">\(\ker(A)\)</span> we solve the system <span class="math inline">\(A\vec x=\vec 0\)</span>. We use the augmented matrix and elementary row operations and find reduced row-echelon form <span class="math display">\[
\text{rref}(A)=
\begin{bmatrix}
1 &amp; 0 &amp; 2 &amp; 0 \\
0 &amp; 1 &amp; -1 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0
\end{bmatrix}.
\]</span> Thus the solution set is <span class="math display">\[
\vectorthree{x_1}{x_2}{x_2}=t\vectorthree{-2}{1}{1}:=t\vec{w}
\]</span> where <span class="math inline">\(t\in \mathbb{R}\)</span>. Therefore <span class="math inline">\(\ker(A)=\text{span}(\vec{w})\)</span>. Next we find <span class="math inline">\(\text{im}(A).\)</span> To do so let <span class="math inline">\(\vec v_1, \vec v_2, \vec v_3\)</span> be the column vectors of the matrix <span class="math inline">\(A\)</span>. Since <span class="math inline">\(\text{im}(A)\)</span> is spanned by the columns of <span class="math inline">\(A\)</span> and <span class="math inline">\(\vec v_3=2\vec v_1+(-1)\vec v_2\)</span>, we find <span class="math inline">\(\text{im}(A)=\text{span}\left(\vec v_1, \vec v_2\right)\)</span>. Therefore the image of <span class="math inline">\(A\)</span> is a plane in <span class="math inline">\(\mathbb{R}^3\)</span> that passes through the origin.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.32 </strong></span>Give an example of a matrix <span class="math inline">\(A\)</span> such that <span class="math inline">\(\text{im}(A)\)</span> is the plane with normal vector <span class="math inline">\(\vec w=\vectorthree{1}{3}{2}\)</span> in <span class="math inline">\(\mathbb{R}^3\)</span>. Since <span class="math inline">\(\vec w\)</span> is a normal vector we let <span class="math inline">\(A=\begin{bmatrix} 1&amp; 3 &amp; 2\end{bmatrix}\)</span>. First we find <span class="math inline">\(\ker(A)\)</span> because <span class="math display">\[
\begin{bmatrix} 1&amp; 3 &amp; 2\end{bmatrix} \vectorthree{x}{y}{z}=\vectorthree{0}{0}{0}
\]</span> is the plane <span class="math inline">\(x+3y+2z=0\)</span> where <span class="math inline">\(\vec w\)</span> is a normal vector. Let <span class="math inline">\(z=t\)</span> and <span class="math inline">\(y=s\)</span>, then <span class="math inline">\(x=-3s-2t\)</span> so the solutions to the system <span class="math inline">\(A\vec x=\vec 0\)</span> are <span class="math display">\[
\vectorthree{x}{y}{z}=\vectorthree{-3s-2t}{s}{t}=s\vectorthree{0}{1}{-3}+t\vectorthree{1}{0}{-2}
:=s\vec u+t \vec v
\]</span> where <span class="math inline">\(s\)</span> and <span class="math inline">\(t\)</span> are real numbers; and thus <span class="math inline">\(\ker(A)=\text{span}(\vec{u}, \vec{v})\)</span>. These vectors yield the image of <span class="math inline">\(A\)</span> since <span class="math inline">\(\text{im}(A)\)</span> is the plane with normal vector <span class="math inline">\(\vec w\)</span> so <span class="math inline">\(A\)</span> is one such matrix; and <span class="math inline">\(\text{im}(A)=\text{span}(\vec{u}, \vec{v})\)</span> is the plane in <span class="math inline">\(\mathbb{R}^3\)</span> with normal vector <span class="math inline">\(\vec{w}\)</span>.</p>
</div>
<p>The kernel, being the most important subspace, has a special name for its dimension; namely, the dimension of <span class="math inline">\(\ker A\)</span> is called the <strong>nullity</strong> of <span class="math inline">\(A\)</span>.</p>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.33 </strong></span>Find the reduced row-echelon form of the matrix <span class="math display">\[
A=
\begin{bmatrix}
1 &amp; 2 &amp; 3 &amp; 2 &amp; 1 \\
3 &amp;  6 &amp; 9 &amp; 6 &amp; 3 \\
1 &amp; 2 &amp; 4 &amp; 1 &amp; 2 \\
2 &amp; 4 &amp; 9 &amp; 1 &amp; 2
\end{bmatrix}.
\]</span> Find a basis and state the dimension for the image and kernel of <span class="math inline">\(A\)</span>.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.34 </strong></span>Find vectors that span <span class="math inline">\(\ker(A)\)</span> and <span class="math inline">\(\text{im}(A)\)</span> given <span class="math display">\[
A=
\begin{bmatrix}
1 &amp; -1 &amp; -1 &amp; 1 &amp; 1 \\
-1 &amp; 1 &amp; 0 &amp; -2 &amp; 2 \\
1 &amp; -1 &amp; -2 &amp; 0 &amp; 3 \\
2 &amp; -2 &amp; -1 &amp; 3 &amp; 4
\end{bmatrix}.
\]</span> We will solve the system <span class="math inline">\(A\vec x=\vec 0\)</span> to find <span class="math inline">\(\ker(A)\)</span>. Using the augmented matrix and elementary row operations, we find <span class="math display">\[
\text{rref}(A)=
\begin{bmatrix}
1 &amp; -1 &amp; 0 &amp; 2 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 1 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0
\end{bmatrix}.
\]</span> So the solutions to the system <span class="math inline">\(A\vec x=\vec 0\)</span> are <span class="math display">\[
\vectorfive{x_1}{x_2}{x_3}{x_4}{x_5}=\vectorfive{s-2t}{s}{-t}{t}{0}=s\vectorfive{1}{1}{0}{0}{0}+t\vectorfive{-2}{0}{-1}{1}{0}:=s\vec{u}+t\vec{v}
\]</span> where <span class="math inline">\(s,t\in \mathbb{R}\)</span>. Therefore <span class="math inline">\(\ker(A)=\text{span}(\vec{u},\vec{v}).\)</span> Since <span class="math inline">\(\text{im}(A)\)</span> is the span of the column vectors of <span class="math inline">\(A\)</span>, we let <span class="math inline">\(\vec{v}_1,\vec{v}_2,\vec{v}_3,\vec{v}_4,\vec{v}_5\)</span> be the column vectors of <span class="math inline">\(A\)</span>. By <span class="math inline">\(\ref{imspan}\)</span>, <span class="math inline">\(\text{im}(A)=\text{span}(\vec{v}_1,\vec{v}_2,\vec{v}_3,\vec{v}_4,\vec{v}_5).\)</span> Using <span class="math inline">\(\text{rref}(A)\)</span> as a guide, we notice <span class="math inline">\(\vec{v}_2=(-1)\vec{v}_1\)</span> so we eliminate <span class="math inline">\(\vec{v}_2\)</span>. Also, <span class="math inline">\(\vec{v}_4=(2)\vec{v}_1+\vec{v}_3\)</span> so we also eliminate <span class="math inline">\(\vec{v}_4\)</span>. Therefore, <span class="math inline">\(\text{im}(A)=\text{span}(\vec{v}_1,\vec{v}_2,\vec{v}_5)\)</span>.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.35 </strong></span>Give an example of a linear transformation whose kernel is the line spanned by <span class="math inline">\(\vec{w}=\begin{bmatrix}-1 \\ 1 \\2\end{bmatrix}\)</span>. Considering the intersection of the planes <span class="math inline">\(x+y=0\)</span> and <span class="math inline">\(2x+z=0\)</span>, we try to use the linear transformation, <span class="math display">\[
T(\vec{x})
=T\vectorthree{x}{y}{z}=\vectortwo{x+y}{2x+z}
=\begin{bmatrix}
1 &amp; 1 &amp; 0\\
2 &amp; 0 &amp; 1
\end{bmatrix}\vec{x}:=A\vec{x}. \]</span> To find the kernel of <span class="math inline">\(T\)</span> we solve <span class="math inline">\(A \vec x= \vec 0\)</span>. Since <span class="math inline">\(\text{rref}(A)=\begin{bmatrix}  1 &amp; 0 &amp; 1/2 \\  0 &amp; 1 &amp; -1/2 \end{bmatrix}\)</span> the solutions are of the form <span class="math inline">\(t \vec{w}\)</span> where <span class="math inline">\(t\)</span> is a real number. Therefore it suffices to let <span class="math inline">\(T\)</span> be the requested linear transformation.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.36 </strong></span>Express the line <span class="math inline">\(L\)</span> in <span class="math inline">\(\mathbb{R}^3\)</span> spanned by the vector <span class="math inline">\(\vec{w}=\begin{bmatrix} 1 \\1 \\1 \end{bmatrix}\)</span> as the image of a matrix <span class="math inline">\(A\)</span> and as the kernel of a matrix <span class="math inline">\(B\)</span>. Let <span class="math inline">\(A=\vec{w}\)</span>, then <span class="math inline">\(L=\text{im}(A)=\text{span}(\vec{w})\)</span>. Therefore it suffices to let <span class="math inline">\(A\)</span> be the requested matrix. Considering the intersection of the planes <span class="math inline">\(x=y\)</span> and <span class="math inline">\(y=z\)</span>, we try to find <span class="math inline">\(B\)</span> using the linear transformation <span class="math display">\[
T(\vec{x})
=T\vectorthree{x}{y}{z}=\vectortwo{x-y}{y-z}
=\begin{bmatrix}
1 &amp; -1 &amp; 0\\
0 &amp; 1 &amp; -1
\end{bmatrix}
:= B \vec{x}
\]</span> To find the kernel of <span class="math inline">\(T\)</span> we solve <span class="math inline">\(B \vec x= \vec 0\)</span>. Since <span class="math inline">\(\text{rref}(B)=\begin{bmatrix}  1 &amp; 0 &amp; -1 \\  0 &amp; 1 &amp; -1 \end{bmatrix}\)</span> the solutions are of the form <span class="math inline">\(t \vec{w}\)</span> where <span class="math inline">\(t\)</span> is a real number. Therefore it suffices to let <span class="math inline">\(B\)</span> be the other requested matrix.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.37 </strong></span>Find a basis for the kernel and the image of the linear transformations defined by <span class="math display">\[
T_1 = \left \{
\begin{array}{rl}
y_1 = &amp; x_1+x_2+3x_3 \\
y_2 = &amp; 2x_1+x_2+4x_3
\end{array}
\right .
\qquad \text{with} \qquad
\text{rref}(T_1)  = \begin{bmatrix}
1 &amp; 0 &amp;1 \\
0 &amp; 1 &amp; 2
\end{bmatrix}.
\]</span> All solutions to the system <span class="math inline">\(A\vec x=\vec 0\)</span> are <span class="math inline">\(\vectorthree{x_1}{x_2}{x_3}=t\vectorthree{-1}{-2}{1}\)</span> where <span class="math inline">\(t\in\mathbb{R}\)</span>. Since <span class="math inline">\(\vectorthree{-1}{-2}{1}\)</span> is linearly independent and spans the kernel, the vector <span class="math inline">\(\vectorthree{-1}{-2}{1}\)</span> forms a basis of <span class="math inline">\(\ker(A)\)</span>. Since the columns of <span class="math inline">\(A\)</span> spans the image of <span class="math inline">\(A\)</span> and <span class="math inline">\(\vectortwo{3}{4}=(1)\vectortwo{1}{2}+(2)\vectortwo{1}{1}\)</span> we find the vector <span class="math inline">\(\vectortwo{3}{4}\)</span> redundant. Since the remaining vectors are linearly independent and span <span class="math inline">\(\text{im}(A)\)</span>, they form a basis for <span class="math inline">\(\text{im}(A)\)</span>.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.38 </strong></span>Find a basis for the kernel and the image of the linear transformations defined by <span class="math display">\[
T_2 =
\left \{
\begin{array}{rlll}
y_1= &amp; x_1 +3x_2 +9x_3  \\
y_2= &amp; 4x_1+5 x_2 +8x_3  \\
y_3= &amp; 7x_1+6 x_2 +3x_3  \\
\end{array}
\right .
\qquad \text{with} \qquad
\text{rref}(T_2)  = \begin{bmatrix}
1 &amp; 0 &amp; -3 \\
0 &amp; 1 &amp; 4 \\
0 &amp; 0 &amp; 0
\end{bmatrix}
\]</span> To find a basis of the kernel we solve <span class="math inline">\(A\vec x = \vec 0\)</span> where <span class="math inline">\(A\)</span> is the matrix of the given transformation. Since <span class="math display">\[
\text{rref(A)}=
\begin{bmatrix} 1 &amp; 0 &amp;-3 \\ 0 &amp; 1 &amp; 4 \\ 0 &amp; 0 &amp; 0 \end{bmatrix}
\]</span> all solutions have the form <span class="math inline">\(\vectorthree{3t}{-4t}{t}\)</span>. Therefore a basis of the kernel of <span class="math inline">\(A\)</span> is <span class="math inline">\(\vectorthree{3}{-4}{1}\)</span>. In the original matrix <span class="math inline">\(A\)</span> the third column is redundant since <span class="math inline">\(\vectorthree{9}{8}{3}=(-3)\vectorthree{1}{4}{7}+(4)\vectorthree{3}{5}{6}\)</span>, and since the vectors <span class="math inline">\(\vectorthree{1}{4}{7}\)</span> and <span class="math inline">\(\vectorthree{3}{5}{6}\)</span> are linearly independent and span, they form a basis of <span class="math inline">\(\text{im}(A)\)</span>.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.39 </strong></span>Find a basis for the kernel and the image of the linear transformations defined by <span class="math display">\[
T_3 =
\left \{
\begin{array}{rlllll}
y_1= &amp; 4x_1+8 x_2 +x_3 +x_4+6x_5 \\
y_2= &amp; 3x_1+6 x_2 +x_3 +2x_4+5x_5 \\
y_3= &amp; 2x_1+4 x_2 +x_3 +9x_4+10x_5 \\
y_4= &amp; x_1+ 2x_2 + 3x_3 +2x_4 \\
\end{array}
\right .
\quad \text{with} \quad
\text{rref}(T_3)  = \begin{bmatrix}
1 &amp; 2 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp;1
\end{bmatrix}
\]</span> The solutions to the system <span class="math inline">\(A\vec x=\vec 0\)</span> are <span class="math display">\[
\vec x=\vectorfive{x_1}{x_2}{x_3}{x_4}{x_5}=t \vectorfive{-2}{1}{0}{0}{0}=t \vec v \qquad \text{where $t\in\mathbb{R}$.}
\]</span> The vector <span class="math inline">\(\vec v\)</span> is linearly independent and spans <span class="math inline">\(\ker(A)\)</span>; thus it forms a basis for <span class="math inline">\(\ker(A)\)</span>. Since <span class="math inline">\(\vectorfour{8}{6}{4}{2}=2\vectorfour{4}{3}{2}{1}\)</span> the vector <span class="math inline">\(\vectorfour{8}{6}{4}{2}\)</span> is redundant and since the column vectors of <span class="math inline">\(A\)</span> are linearly independent and span <span class="math inline">\(\text{im}(A)\)</span>, we have that the vectors <span class="math inline">\(\vectorfour{4}{3}{2}{1}\)</span>, <span class="math inline">\(\vectorfour{1}{1}{1}{3}\)</span>, <span class="math inline">\(\vectorfour{1}{2}{9}{2}\)</span>, and <span class="math inline">\(\vectorfour{6}{5}{10}{0}\)</span> form a basis of <span class="math inline">\(\text{im}(A)\)</span>.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.40 </strong></span>Show <span class="math inline">\(\ker(A)\neq \ker(B)\)</span> where <span class="math display">\[
A=
\begin{bmatrix}
1 &amp; 0 &amp; 2 &amp; 0 &amp; 4 &amp; 0 \\
0 &amp; 1 &amp; 3 &amp; 0 &amp; 5 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 6 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1
\end{bmatrix}
\qquad \text{and} \qquad
%$ and $
B=
\begin{bmatrix}
1 &amp; 0 &amp; 2 &amp; 0 &amp; 0 &amp; 4 \\
0 &amp; 1 &amp; 3 &amp; 0 &amp; 0 &amp; 5 \\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 6 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 7
\end{bmatrix}.
\]</span> We solve the system <span class="math inline">\(A\vec x=\vec 0\)</span>, written out we find: <span class="math display">\[
\begin{bmatrix}
x_1 \\ x_2 \\ x_3 \\ x_4 \\ x_5 \\ x_6
\end{bmatrix}
= s
\begin{bmatrix}
-4 \\ -5 \\ 0 \\ 6 \\ 1 \\ 0
\end{bmatrix}
+t
\begin{bmatrix}
-2 \\ -3 \\ 1\\ 0 \\ 0 0
\end{bmatrix}
=s\vec v_1+t\vec v_2
\quad \text{ where $s,t\in \mathbb{R}$}.
\]</span> Since <span class="math inline">\(v_1\)</span> and <span class="math inline">\(v_2\)</span> are linearly independent and span <span class="math inline">\(\ker(A)\)</span>, they form a basis of the kernel of <span class="math inline">\(A\)</span>. By noticing <span class="math inline">\(B \vec v_1\neq \vec 0\)</span> we conclude <span class="math inline">\(\ker(A)\neq \ker(B)\)</span>.</p>
</div>
<div id="thm-" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.21 </strong></span> For any matrix <span class="math inline">\(A\)</span>, <span class="math inline">\(\dim(\text{im} A )=\text{rank}(A)\)</span>.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span></p>
</div>
<p>::: {#thm- } [Rank-Nullity] Let <span class="math inline">\(T\)</span> be a linear transformation from <span class="math inline">\(\mathbb{R}^m\)</span> to <span class="math inline">\(\mathbb{R}^n\)</span> with <span class="math inline">\(n\times m\)</span> matrix <span class="math inline">\(A\)</span>. Then <span class="math display">\[
\text{rank}(A)+\text{nullity}(A)
=\dim(\text{im} A)+\dim(\ker A)=m.
\]</span></p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>Let <span class="math inline">\(\vec{y}=A\vec{x}\)</span> be the corresponding system of linear equations. Recall,<br>
<span class="math display">\[\begin{equation}
\label{varequ} \small
\begin{tabular}{ccccccc}
$\left(\parbox[c]{1.55cm}{\begin{center}
number of free variables
\end{center}}\right)$ &amp; $=$  &amp;
$\left(\parbox[c]{1.55cm}{\begin{center}
total number of variables
\end{center}}\right)$ &amp; $-$  &amp;
$\left(\parbox[c]{1.55cm}{\begin{center}
number of leading variables
\end{center}}\right)$ &amp; $=$  
&amp; $\parbox[c]{1.75cm}{\begin{center}
\normalsize
$m-\text{rank}(A)$
\end{center}}$
\end{tabular}
\end{equation}\]</span> Apparently, the number of free variables is the dimension of the kernel of <span class="math inline">\(A\)</span>. Thus <span class="math inline">\(\ref{varequ}\)</span> becomes <span class="math inline">\(\text{nullity}(A)=m-\text{rank}(A)\)</span>. By <span class="math inline">\(\ref{dimenimgrank}\)</span> we arrive at the conclusion <span class="math inline">\(\text{rank}(A)+\text{nullity}(A)=m\)</span>.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.41 </strong></span>If possible, find a <span class="math inline">\(3\times 3\)</span> matrix such that <span class="math inline">\(\text{im} A=\ker A\)</span>.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.42 </strong></span>If possible, find a <span class="math inline">\(4\times 4\)</span> matrix such that <span class="math inline">\(\text{im} A=\ker A\)</span>.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.43 </strong></span>Give an example of a <span class="math inline">\(4\times 5\)</span> matrix <span class="math inline">\(A\)</span> with <span class="math inline">\(\dim(\ker A)=3\)</span>.</p>
</div>
<div id="thm-" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.22 </strong></span>The vectors <span class="math inline">\(\vec{v}_1,\ldots,\vec{v}_n\)</span> in <span class="math inline">\(\mathbb{R}^n\)</span> form a basis of <span class="math inline">\(\mathbb{R}^n\)</span> if and only if the matrix whose columns consists of <span class="math inline">\(\vec{v}_1,...,\vec{v}_n\)</span> is invertible.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span></p>
</div>
<p>For example, consider the matrix <span class="math display">\[
A=
\begin{bmatrix}
1 &amp; 2 &amp; 1 &amp; 2 \\
1 &amp; 2 &amp; 2 &amp; 3 \\
1 &amp; 2 &amp; 3 &amp; 4
\end{bmatrix}
\]</span> What is the smallest number of vectors needed to span the image of <span class="math inline">\(A\)</span>? Of course we know, <span class="math display">\[
\text{im}(A)=\text{span}\left(\vectorthree{1}{1}{1},\vectorthree{2}{2}{2},\vectorthree{1}{2}{3},\vectorthree{2}{3}{4}\right).
\]</span> However, it is easy to show that <span class="math inline">\(\vectorthree{2}{3}{4}\)</span> and <span class="math inline">\(\vectorthree{2}{2}{2}\)</span> are redundant; and that the remaining vectors are linearly independent. Thus, <span class="math display">\[
\text{im}(A)=\text{span}\left(\vectorthree{1}{1}{1},\vectorthree{1}{2}{3}\right).
\]</span> Clearly, the image of the linear transformation defined by <span class="math inline">\(A\)</span> is more easily understood by having a spanning set of linearly independent vectors.</p>
</section>
<section id="invertible-linear-transformations" class="level2" data-number="3.5">
<h2 data-number="3.5" class="anchored" data-anchor-id="invertible-linear-transformations"><span class="header-section-number">3.5</span> Invertible Linear Transformations</h2>
<p>An <span class="math inline">\(n\times n\)</span> matrix <span class="math inline">\(A\)</span> is called <strong>invertible</strong> if and only if there exists a matrix <span class="math inline">\(B\)</span> such that <span class="math inline">\(A B=I_n\)</span> and <span class="math inline">\(BA=I_n\)</span>. Using the inverse of a matrix we also define the inverse of a linear transformation.<br>
Let <span class="math inline">\(T(\vec x)=A\vec x\)</span> be a linear transformation from <span class="math inline">\(\mathbb{R}^n\)</span> to <span class="math inline">\(\mathbb{R}^n\)</span>. If the matrix <span class="math inline">\(A\)</span> has inverse <span class="math inline">\(A^{-1}\)</span>, then the linear transformation defined by <span class="math inline">\(A^{-1} \vec x\)</span> is called the <strong>inverse transformation</strong> of <span class="math inline">\(T\)</span> and is denoted by <span class="math inline">\(T^{-1}(\vec x)=A^{-1}.\)</span></p>
<p>A function <span class="math inline">\(T\)</span> from <span class="math inline">\(X\)</span> to <span class="math inline">\(Y\)</span> is called <strong>invertible</strong> if the equation <span class="math inline">\(T(x)=y\)</span> has a unique solution <span class="math inline">\(x\in X\)</span> for each <span class="math inline">\(y\in Y\)</span>. A square matrix <span class="math inline">\(A\)</span> is called <strong>invertible</strong> if the linear transformation <span class="math inline">\(\vec y=T(\vec x)=A\vec x\)</span> is invertible. In this case, then matrix of <span class="math inline">\(T^{-1}\)</span> is denoted by <span class="math inline">\(A^{-1}\)</span>. If the linear transformation is invertible, then its inverse is <span class="math inline">\(\vec x = T^{-1} (\vec y)=A^{-1}.\)</span></p>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.44 </strong></span>Find the inverse transformation of the following linear transformation: <span class="math display">\[
\begin{array}{rl}
y_1 = &amp; x_1+3x_2+3x_3 \\
y_2 = &amp; x_1+4x_2+8x_3 \\
y_3 = &amp; 2x_1+7x_2+12x_3
\end{array}.
\]</span> To find the inverse transformation we solve for <span class="math inline">\(x_1, x_2, x_3\)</span> in terms of <span class="math inline">\(y_1,.y_2,y_3\)</span>. To do this we find the inverse matrix of <span class="math display">\[
A=
\begin{bmatrix}
1 &amp; 3 &amp; 3 \\
1 &amp; 4 &amp; 8 \\
2 &amp; 7 &amp; 12
\end{bmatrix}.
\]</span> Applying elementary-row operations, <span class="math display">\[
\begin{bmatrix}
1 &amp; 3 &amp; 3 &amp; 1 &amp; 0 &amp; 0 \\
1 &amp; 4 &amp; 8 &amp; 0 &amp; 1 &amp; 0 \\
2 &amp; 7 &amp; 12 &amp; 0 &amp; 0 &amp; 1
\end{bmatrix}\begin{array}{c}
\stackrel{\longrightarrow}{R_2-R_1} \\
\stackrel{\longrightarrow}{-2R_1+R_3}
\end{array}
\begin{bmatrix}1 &amp; 3 &amp; 3 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 5 &amp; 1 &amp; 1 &amp; 0 \\
0 &amp; 1 &amp; 6 &amp; -2 &amp; 0 &amp; 1
\end{bmatrix}
\]</span> <span class="math display">\[
\stackrel{\longrightarrow}{-R_2+R_3}
\begin{bmatrix}
1 &amp; 3 &amp; 3 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 5 &amp; -1 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 1 &amp; -1 &amp; -1 &amp; 1
\end{bmatrix}\stackrel{\longrightarrow}{-5R_3+R_2}
\begin{bmatrix}1 &amp; 3 &amp; 3 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 &amp; 4 &amp; 6 &amp; -5 \\
0 &amp; 0 &amp; 1 &amp; -1 &amp; -1 &amp; 1
\end{bmatrix}
\]</span> <span class="math display">\[
\stackrel{\longrightarrow}{-3R_3+R_1}
\begin{bmatrix}
1 &amp; 3 &amp; 0 &amp; 4 &amp; -3 &amp; 3 \\
0 &amp; 1 &amp; 0 &amp; 4 &amp; 6 &amp;-5 \\
0 &amp; 0 &amp; 1 &amp; -1 &amp; -1 &amp; 1
\end{bmatrix}\stackrel{\longrightarrow}{-3R_2+R_1}
\begin{bmatrix}
1 &amp; 0 &amp; 0 &amp; -8 &amp; -15 &amp; 12 \\
0 &amp; 1 &amp; 0 &amp; 4 &amp; 6 &amp; -5 \\
0 &amp; 0 &amp; 1 &amp; -1 &amp; -1 &amp; 1
\end{bmatrix}\]</span> we find <span class="math display">\[
A^{-1}=
\begin{bmatrix}
-8 &amp; -15 &amp; 12 \\
4 &amp; 6 &amp; -5 \\
1 &amp; -1 &amp; 1
\end{bmatrix}.
\]</span> Therefore the requested linear transformation is <span class="math display">\[
\begin{array}{rl}
x_1 = &amp; -8y_1-15y_2+12y_3 \\
x_2 = &amp; 4y_1+6y_2-5y_3 \\
x_3 = &amp; -y_1-y_2+y_3.
\end{array}
\]</span></p>
</div>
<p>Of course inverse transformations makes sense in terms of inverse functions; that is, if <span class="math inline">\(T^{-1}\)</span> is the inverse transformation of <span class="math inline">\(T\)</span> then <span class="math inline">\((T\circ T^{-1})(\vec x)=\vec x\)</span> and <span class="math inline">\((T^{-1 }\circ T)(\vec x)=\vec x\)</span>. For example, for <span class="math inline">\(T\)</span> given in <span class="math inline">\(\ref{invtranseq}\)</span> we illustrate <span class="math display">\[
(T^{-1}\circ T)\vectorthree{1}{2}{3}=T^{-1}\vectorthree{2}{4}{-5}=\vectorthree{1}{2}{3}
\]</span> as one can verify.</p>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.45 </strong></span>Find the inverse of the linear transformation <span class="math display">\[\begin{align*}
&amp; y_1 = 3x_1 +5x_2 \\
&amp; y_2 =3x_1+4x_2.
\end{align*}\]</span> Reducing the system <span class="math display">\[
\begin{bmatrix}
3x_1+5x_2&amp; =y_1 \\
3x_1+4x_2 &amp; =y_2
\end{bmatrix}
\]</span> we obtain <span class="math display">\[
\begin{bmatrix}
x_1 &amp; =-\frac{4}{3}y_1+\frac{5}{3}y_2 \\
x_2 &amp; = y_1-y_2
\end{bmatrix}.
\]</span></p>
</div>
<div id="thm-" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.23 </strong></span>Let <span class="math inline">\(A\)</span> be an <span class="math inline">\(n\times n\)</span> matrix. Then</p>
<ul>
<li><span class="math inline">\(A\)</span> is invertible if and only if rref(<span class="math inline">\(A\)</span>)<span class="math inline">\(=I_n\)</span>,</li>
<li><span class="math inline">\(A\)</span> is invertible if and only if <span class="math inline">\(\text{rank}(A)=n\)</span>, and</li>
<li><span class="math inline">\(A\)</span> is invertible if and only if <span class="math inline">\(A^{-1} A= I_n\)</span> and <span class="math inline">\(A A^{-1}=I_n\)</span>.</li>
</ul>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>The proof is left for the reader.</p>
</div>
<p>To find the inverse of an <span class="math inline">\(n \times n\)</span> matrix <span class="math inline">\(A\)</span>, form the augmented matrix <span class="math inline">\([ \, A \, | \, I_n \, ]\)</span> and compute $(, [ , A , | , I_n , ] , ) $. If $(, [ , A , | , I_n , ] , ) $ is of the form $(, [ , I_n , | , B , ] , ) $, then <span class="math inline">\(A\)</span> is invertible and <span class="math inline">\(A^{-1}=B\)</span>. Otherwise <span class="math inline">\(A\)</span> is not invertible. For example <span class="math display">\[\begin{equation}
\label{invtranseq}
=\text{rref}\left(
\begin{bmatrix}
1 &amp; -1 &amp; 1 &amp; 1 &amp; 0 &amp; 0 \\
1 &amp; 0 &amp; 1 &amp; 0 &amp; 1 &amp; 0 \\
-1 &amp; -2 &amp; 0 &amp; 0 &amp; 0 &amp; 1
\end{bmatrix}
\right)
=
\begin{bmatrix}
1 &amp; 0 &amp; 0 &amp; 2 &amp; -2 &amp; -1 \\
0 &amp; 1 &amp; 0 &amp; -1 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 1 &amp; -2 &amp; 3 &amp; 1
\end{bmatrix}
= [ \,  I_3 \,  |  \,  B \, ]
\end{equation}\]</span> shows <span class="math inline">\(B=A^{-1}\)</span> where <span class="math display">\[
B=
\begin{bmatrix}
2 &amp; -2 &amp; -1 \\
-1 &amp; 1 &amp; 0 \\
-2 &amp; 3 &amp; 1
\end{bmatrix}
\]</span> and <span class="math display">\[A=
\begin{bmatrix}
1 &amp; -1 &amp; 1  \\
1 &amp; 0 &amp; 1 \\
-1 &amp; -2 &amp; 0
\end{bmatrix}
\]</span> as one can verify, by showing <span class="math inline">\(AB=I_3\)</span> and <span class="math inline">\(BA=I_3\)</span>.</p>
<div id="thm-" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.24 </strong></span>Let <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> be <span class="math inline">\(n \times n\)</span> matrices. Then</p>
<ul>
<li>if <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are invertible, then <span class="math inline">\(B A\)</span> is invertible as well and <span class="math display">\[
(B A)^{-1}= A^{-1}B^{-1}
\]</span></li>
<li>if <span class="math inline">\(B A= I_n\)</span>, then <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are both invertible, <span class="math display">\[
A^{-1}=B, \qquad B^{-1}=A, \qquad \text{ and } \qquad AB = I_n.
\]</span></li>
</ul>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>The proof is left for the reader.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.46 </strong></span>Find the inverse matrices of <span class="math display">\[
A=
\begin{bmatrix} 2 &amp; 3 \\ 6 &amp; 9 \end{bmatrix}
\]</span> and <span class="math display">\[
B=
\begin{bmatrix} 1 &amp; 2 \\ 3 &amp; 9 \end{bmatrix}
\]</span> Since <span class="math inline">\(\text{rref}(A)=\begin{bmatrix} 1/2 &amp; 3/2 \\ 0 &amp; 0 \end{bmatrix}\neq I_2\)</span>, <span class="math inline">\(A^{-1}\)</span> does not exist. The inverse of <span class="math inline">\(B\)</span> does exist and <span class="math inline">\(B^{-1}=\begin{bmatrix} 3 &amp; -2/3 \\ -1 &amp; 1/3 \end{bmatrix}\)</span> since <span class="math inline">\(B^{-1}B=I_2\)</span> and <span class="math inline">\(B B^{-1}=I_2\)</span>.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.47 </strong></span> Show that <span class="math inline">\(A=\begin{bmatrix} a &amp; b \\ c&amp; d \end{bmatrix}\)</span> is invertible if and only if <span class="math inline">\(a d- b c \neq 0\)</span> and when possible <span class="math display">\[\begin{equation}
\label{twodet}
A^{-1}=\frac{1}{a d - b c}\begin{bmatrix} d &amp; -b \\ -c &amp; a \end{bmatrix}.
\end{equation}\]</span> We proceed to find the inverse: <span class="math display">\[
\begin{bmatrix}
a &amp; b  &amp; 1 &amp; 0 \\
c &amp; d &amp; 0 &amp; 1
\end{bmatrix}\begin{array}{c}
\stackrel{\longrightarrow}{\frac{1}{a} R_1}
\\
\stackrel{\longrightarrow}{\frac{1}{c} R_2}
\end{array}
\begin{bmatrix}
1 &amp; \frac{b}{a} &amp; \frac{1}{a} &amp; 0 \\
1 &amp; \frac{d}{c} &amp; 0 &amp; \frac{1}{c}
\end{bmatrix}\begin{array}{c}
\stackrel{\longrightarrow}{-R_1+R_2}
\end{array}
\begin{bmatrix}
1 &amp; \frac{b}{a} &amp; \frac{1}{a} &amp; 0 \\
0 &amp; \frac{ad-bc}{ac} &amp; \frac{-1}{a} &amp; \frac{1}{c}
\end{bmatrix}
\]</span> <span class="math display">\[
\begin{array}{c}
\stackrel{\longrightarrow}{\frac{ac}{ad-bc} R_2}
\end{array}
\begin{bmatrix}
1 &amp; \frac{b}{a} &amp; \frac{1}{a} &amp; 0 \\
0 &amp; 1 &amp; \frac{-c}{ad-bc} &amp; \frac{a}{ad-bc}
\end{bmatrix}\begin{array}{c}
\stackrel{\longrightarrow}{\frac{-b}{a}R_2+R_1}
\end{array}
\begin{bmatrix}
1 &amp; 0 &amp; \frac{d}{ad-bc} &amp; \frac{-b}{ad-bc} \\
0 &amp; 1 &amp; \frac{-c}{ad-bc} &amp; \frac{a}{ad-bc}
\end{bmatrix}
\]</span> Therefore, <span class="math inline">\(A\)</span> is invertible if and only if <span class="math inline">\(a d- b c \neq 0\)</span> and <span class="math inline">\(\ref{twodet}\)</span> holds.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.48 </strong></span>For which values of constants <span class="math inline">\(a, b, c,\)</span> is the matrix <span class="math display">\[
A=
\begin{bmatrix}
0 &amp; a &amp; b \\
-a &amp; 0 &amp; c \\
-b &amp; -c &amp; 0
\end{bmatrix}
\]</span> invertible? Suppose <span class="math inline">\(a\neq 0\)</span>. Applying row-operations <span class="math display">\[
\begin{bmatrix}
0 &amp; a &amp; b &amp; 1 &amp; 0 &amp; 0\\
-a &amp; 0 &amp; c &amp; 0 &amp; 1 &amp; 0 \\
-b &amp; -c &amp; 0 &amp; 0 &amp; 0 &amp; 1
\end{bmatrix}\begin{array}{c}
\stackrel{\longrightarrow}{R_2\leftrightarrow R_1}
\end{array}
\begin{bmatrix}
-a &amp; 0 &amp; c &amp; 0 &amp; 1 &amp; 0 \\
0 &amp; a &amp; b &amp; 1 &amp; 0 &amp; 0\\
-b &amp; -c &amp; 0 &amp; 0 &amp; 0 &amp; 1
\end{bmatrix}
\]</span> <span class="math display">\[
\stackrel{\longrightarrow}{-\frac{1}{a}R_1}
\begin{bmatrix}
1 &amp; 0 &amp; -\frac{c}{a} &amp; 0 &amp; -\frac{1}{a} &amp; 0 \\
0 &amp; a &amp; b &amp; 1 &amp; 0 &amp; 0\\
-b &amp; -c &amp; 0 &amp; 0 &amp; 0 &amp; 1
\end{bmatrix}\stackrel{\longrightarrow}{bR_1+R_3}
\begin{bmatrix}
1 &amp; 0 &amp; -\frac{c}{a} &amp; 0 &amp; -\frac{1}{a} &amp; 0 \\
0 &amp; a &amp; b &amp; 1 &amp; 0 &amp; 0\\
0 &amp; -c &amp; \frac{-bc}{a} &amp; 0 &amp; \frac{-b}{a} &amp; 1
\end{bmatrix}
\]</span> <span class="math display">\[
\stackrel{\longrightarrow}{\frac{1}{a}R_2}
\begin{bmatrix}
1 &amp; 0 &amp; -\frac{c}{a} &amp; 0 &amp; -\frac{1}{a} &amp; 0 \\
0 &amp; 1 &amp; \frac{b}{a} &amp; \frac{1}{a} &amp; 0 &amp; 0\\
0 &amp; -c &amp; \frac{-bc}{a} &amp; 0 &amp; \frac{-b}{a} &amp; 1
\end{bmatrix}\stackrel{\longrightarrow}{cR_2+R_3}
\begin{bmatrix}
1 &amp; 0 &amp; -\frac{c}{a} &amp; 0 &amp; -\frac{1}{a} &amp; 0 \\
0 &amp; 1 &amp; \frac{b}{a} &amp; \frac{1}{a} &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 0 &amp; \frac{c}{a} &amp; \frac{-b}{a} &amp; 1
\end{bmatrix}
\]</span> Thus, if <span class="math inline">\(a\neq 0\)</span> then <span class="math inline">\(A\)</span> is not invertible, since <span class="math inline">\(\text{rref}{(A)}\neq I_3\)</span>. If <span class="math inline">\(a=0\)</span>, then clearly, <span class="math inline">\(\text{rref}{(A)}\neq I_3\)</span>, and so <span class="math inline">\(A\)</span> is not invertible in either case. Therefore, there are no constants <span class="math inline">\(a, b, c\)</span> for which <span class="math inline">\(A\)</span> is invertible.</p>
</div>
<div id="cor-" class="theorem corollary">
<p><span class="theorem-title"><strong>Corollary 3.2 </strong></span>Let <span class="math inline">\(A\)</span> be an <span class="math inline">\(n \times n\)</span> matrix.</p>
<ul>
<li>Consider a vector <span class="math inline">\(\vec b\)</span> in <span class="math inline">\(\mathbb{R}^n\)</span>. If <span class="math inline">\(A\)</span> is invertible, then the system <span class="math inline">\(A \vec x = \vec b\)</span> has the unique solution <span class="math inline">\(\vec x = A^{-1} b\)</span>. If <span class="math inline">\(A\)</span> is non-invertible, then the system <span class="math inline">\(A \vec x = \vec b\)</span> has infinitely many solutions or none.</li>
<li>The system <span class="math inline">\(A \vec x = \vec 0\)</span> has <span class="math inline">\(\vec x = \vec 0\)</span> as a solution. If <span class="math inline">\(A\)</span> is invertible, then this is the only solution. If <span class="math inline">\(A\)</span> is non-invertible, then the system <span class="math inline">\(A \vec x= \vec 0\)</span> has infinitely many solutions.</li>
</ul>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>The proof is left for the reader.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.49 </strong></span>Find all invertible matrices <span class="math inline">\(A\)</span> such that <span class="math inline">\(A^2=A\)</span>. Since <span class="math inline">\(A\)</span> is invertible we multiply by <span class="math inline">\(A^{-1}\)</span> to obtain: <span class="math display">\[
A=IA=(A^{-1}A)A=A^{-1}(A^2)=A^{-1}A=I_n
\]</span> and therefore <span class="math inline">\(A\)</span> must be the identity matrix.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.50 </strong></span>For which values of constants <span class="math inline">\(b\)</span> and <span class="math inline">\(c\)</span> is the matrix <span class="math display">\[
B=
\begin{bmatrix}0 &amp; 1 &amp; b \\
-1 &amp; 0 &amp; c \\
-b &amp; -c &amp; 0
\end{bmatrix}
\]</span> invertible? The matrix <span class="math inline">\(B\)</span> is not invertible for any <span class="math inline">\(b\)</span> and <span class="math inline">\(c\)</span> since<span class="math display">\[
\text{rref}(B)=
\begin{bmatrix}1 &amp; 0 &amp; -c \\
0 &amp; 1 &amp; b \\
0 &amp; 0 &amp; 0
\end{bmatrix}\neq I_3
\]</span> for all <span class="math inline">\(b\)</span> and <span class="math inline">\(c\)</span>.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.51 </strong></span>Find the matrix <span class="math inline">\(A\)</span> satisfying the equation <span class="math display">\[
\begin{bmatrix} 1 &amp; 0 \\ 0 &amp; -1 \end{bmatrix}
A
\begin{bmatrix} 2 &amp; 0 \\ 0 &amp; -2 \end{bmatrix}
=
\begin{bmatrix} 1 &amp; 1 \\ 1 &amp; 1 \end{bmatrix}
.\]</span> Let <span class="math inline">\(B=\begin{bmatrix} 1 &amp; 0 \\ 0 &amp; -1 \end{bmatrix}\)</span> and <span class="math inline">\(C=\begin{bmatrix} 2 &amp; 0 \\ 0 &amp; -2 \end{bmatrix}\)</span>. Then <span class="math display">\[
B^{-1}=\begin{bmatrix} 1&amp; 0 \\ 0 &amp;-1\end{bmatrix}
\qquad \text{and}\qquad
C^{-1}=\begin{bmatrix} 1/2 &amp; 0 \\ 0 &amp; -1/2 \end{bmatrix}.
\]</span> Multiplying on the right by <span class="math inline">\(B^{-1}\)</span> and on the left by <span class="math inline">\(C^{-1}\)</span> we find <span class="math display">\[
A=B^{-1}\begin{bmatrix} 1 &amp; 1 \\ 1 &amp; 1 \end{bmatrix}C^{-1}
=\begin{bmatrix} 1/2 &amp; -1/2 \\ -1/2 &amp; 1/2\end{bmatrix}.
\]</span></p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.52 </strong></span>Suppose that <span class="math inline">\(A\)</span>, <span class="math inline">\(B\)</span>, and <span class="math inline">\(C\)</span> are <span class="math inline">\(n\times n\)</span> matrices and that both <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> commute with <span class="math inline">\(C\)</span>. Show that <span class="math inline">\(AB\)</span> commutes with <span class="math inline">\(C\)</span>.<br>
To show that <span class="math inline">\(AB\)</span> commutes with <span class="math inline">\(C\)</span> we need to show <span class="math inline">\((AB)C=C(AB)\)</span>. This is easy since <span class="math display">\[
(AB)C=A(BC)=A(CB)=(AC)B=(CA)B=C(AB).
\]</span> Can you justify each step?</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.53 </strong></span>Show that <span class="math inline">\(AB=BA\)</span> if and only if <span class="math inline">\((A-B)(A+B)=A^2-B^2\)</span>. Suppose <span class="math inline">\(AB=BA\)</span> we will show <span class="math inline">\((A-B)(A+B)=A^2-B^2\)</span>. Starting with the left-hand side we obtain <span class="math display">\[\begin{align*}
(A-B)(A+B)
&amp; =(A-B)A+(A-B)B
=A^2-BA+AB-B^2 \\
&amp; =A^2-BA+BA-B^2
=A^2-B^2
\end{align*}\]</span> Now suppose <span class="math inline">\((A-B)(A+B)=A^2-B^2\)</span>, we will show <span class="math inline">\(AB=BA\)</span>. This is easy since <span class="math display">\[
(A-B)(A+B)
%=(A-B)A+(A-B)B
=A^2-BA+AB-B^2
=A^2-B^2
\]</span> implies <span class="math inline">\(-BA+AB=0\)</span> as desired.</p>
</div>
</section>
<section id="coordinates" class="level2" data-number="3.6">
<h2 data-number="3.6" class="anchored" data-anchor-id="coordinates"><span class="header-section-number">3.6</span> Coordinates</h2>
<div id="def-" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3.8 </strong></span>Let <span class="math inline">\(\mathcal{B}=(v_1,...,v_n)\)</span> be a basis of a subspace <span class="math inline">\(V\)</span> of <span class="math inline">\(\mathbb{R}^n\)</span>. For any <span class="math inline">\(\vec x \in V\)</span> we can write <span class="math inline">\(\vec v= c_1 \vec v_1 + \cdots +c_m \vec v_m\)</span>. The scalars <span class="math inline">\(c_1,...,c_m\)</span> are called the <strong><span class="math inline">\(\mathcal{B}\)</span>-coordinates</strong> of <span class="math inline">\(\vec x\)</span> and the vector <span class="math display">\[
\left [ \vec x \right ]_{\mathcal{B}}:= \vectorthree{c_1}{\hdots}{c_m}
\]</span> is called the <strong><span class="math inline">\(\mathcal{B}\)</span>-coordinate vector</strong> of <span class="math inline">\(\vec x\)</span></p>
</div>
<p>For example the coordinates of <span class="math inline">\(\vectortwo{-2}{4}\)</span> with respect the standard basis <span class="math inline">\(\mathcal{B}=(\vec{e}_1,\vec{e}_2)\)</span> is <span class="math inline">\(\vectortwo{-2}{4}\)</span> since <span class="math inline">\(\vectortwo{-2}{4}=-2\vec{e}_1+4\vec{e}_2\)</span> which written as <span class="math inline">\(\vectortwo{-2}{4}_{\mathcal{B}}=\vectortwo{-2}{4}.\)</span> Notice the coordinates of <span class="math inline">\(\vectortwo{-2}{4}\)</span> with respect the basis <span class="math inline">\(\mathcal{B}'=\left(\vectortwo{2}{0},\vectortwo{0}{2}\right)\)</span> is <span class="math inline">\(\vectortwo{-1}{2}\)</span> since <span class="math inline">\(\vectortwo{-2}{4}=(-1)\vectortwo{2}{0}+2\vectortwo{0}{2}\)</span> which written as <span class="math inline">\(\vectortwo{-2}{4}_{\mathcal{B}'}=\vectortwo{-1}{2}.\)</span></p>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.54 </strong></span>Consider the plane <span class="math inline">\(2x_1-3x_2+4x_3=0\)</span> with basis <span class="math display">\[
\mathcal{B}=\left(\vectorthree{8}{4}{-1}, \vectorthree{5}{2}{-1}\right).
\]</span> Let <span class="math inline">\([\vec x]_{\mathcal{B}} = \vectortwo{2}{-1}\)</span>. Find <span class="math inline">\(\vec x\)</span>. By definition of coordinates <span class="math display">\[
\vec x= 2\vectorthree{8}{4}{-1} +(-1)\vectorthree{5}{2}{-1}=\vectorthree{11}{6}{-1}.
\]</span></p>
</div>
<div id="lem-" class="theorem lemma">
<p><span class="theorem-title"><strong>Lemma 3.5 </strong></span> If <span class="math inline">\(\mathcal{B}=(\vec{v}_1,...,\vec{v}_n)\)</span> is a basis of a subspace <span class="math inline">\(V\)</span> of <span class="math inline">\(\mathbb{R}^n\)</span>, then</p>
<ul>
<li><span class="math inline">\([\vec x]_{\mathcal{B}}+[\vec y]_{\mathcal{B}}=[\vec x+\vec y]_{\mathcal{B}}\)</span>, for all vectors <span class="math inline">\(\vec x, \vec y\)</span></li>
<li><span class="math inline">\([k\vec x]_{\mathcal{B}}=k[\vec x]_{\mathcal{B}}\)</span>, for all vectors <span class="math inline">\(\vec x\)</span>, and all scalars <span class="math inline">\(k\)</span>.</li>
</ul>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>Let <span class="math inline">\([\vec x]_{\mathcal{B}}=c_1 \vec{v}_1+\cdots + c_n \vec{v}_n\)</span><br>
and <span class="math inline">\([\vec y]_{\mathcal{B}}=d_1 \vec{v}_1+\cdots + d_n \vec{v}_n\)</span> be the representation of <span class="math inline">\(\vec{x}\)</span> and <span class="math inline">\(\vec{y}\)</span> with respect to <span class="math inline">\(\mathcal{B}\)</span>. Then <span class="math display">\[
[\vec x]_{\mathcal{B}}+[\vec y]_{\mathcal{B}}
=\vectorthree{c_1}{\vdots}{c_3}+\vectorthree{d_1}{\vdots}{d_3}
=\vectorthree{c_1+d_1}{\vdots}{c_n+d_n}
=[\vec x+y]_{\mathcal{B}}
\]</span> where the last equality holds since <span class="math display">\[
\vec{x}+\vec{y}=(c_1+d_1)\vec{v}_1+\cdots (c_n+d_n)\vec{v}_n.\]</span> We leave the proof of the second part for the reader.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.55 </strong></span>Determine whether the vector <span class="math inline">\(\vec x = \vectorthree{1}{-2}{-2}\)</span> is in <span class="math inline">\(\text{span} V\)</span> of the vectors <span class="math inline">\(\vec{v}_1=\vectorthree{8}{4}{-1}\)</span> and <span class="math inline">\(\vec{v}_2=\vectorthree{5}{2}{-1}\)</span> and if so write the coordinates of <span class="math inline">\(\vec x\)</span> with respect to this basis of <span class="math inline">\(V\)</span>. We need to find scalars <span class="math inline">\(c_1\)</span> and <span class="math inline">\(c_2\)</span> such that <span class="math inline">\(\vec x=c_1 \vec v_1+c_2 \vec v_2\)</span>. Solving this system we find <span class="math inline">\(c_1=-3\)</span> and <span class="math inline">\(c_2=5\)</span>. Therefore we find, <span class="math inline">\([\vec x]_{\mathcal{B}}=\vectortwo{-3}{5}\)</span> where <span class="math inline">\(\mathcal{B}=(\vec v_1, \vec v_2)\)</span>.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.56 </strong></span>Consider the plane <span class="math inline">\(x+2y+z=0\)</span>. Find a basis of this plane. Find another basis <span class="math inline">\(\mathcal{B}\)</span> of this plane such that <span class="math inline">\([\vec x]_{\mathcal{B}}=\vectortwo{2}{-1}\)</span> for <span class="math inline">\(\vec x = \vectorthree{1}{-1}{1}\)</span>. We find a basis by letting <span class="math inline">\(z=t\)</span> and <span class="math inline">\(y=s\)</span> be free variables. Then <span class="math inline">\(x=-t-2s\)</span>. All solutions to the equation <span class="math inline">\(x+2y+z=0\)</span> are <span class="math display">\[
\vectorthree{x}{y}{z}
=\vectorthree{-t-2s}{s}{t}
=t\vectorthree{-1}{0}{1}+s\vectorthree{-2}{1}{0}.
\]</span> So a basis for the plane is <span class="math inline">\(\mathcal{B}=\left(\vectorthree{-1}{0}{1},\vectorthree{-2}{1}{0}\right).\)</span> Notice <span class="math inline">\(\vectorthree{1}{-1}{1}=(1)\vectorthree{-1}{0}{1}+(-1)\vectorthree{-2}{1}{0}\)</span> and thus <span class="math inline">\(\vectorthree{1}{-1}{1}_{\mathcal{B}}=\vectortwo{1}{-1}\)</span>. Thus this is not the basis we seek. However, notice <span class="math display">\[
\vectorthree{1}{-1}{1}
=2\vectorthree{x_1}{0}{-x_1}+(-1)\vectorthree{-2y_2}{y_2}{0}
\]</span> holds when <span class="math inline">\(y_2=1\)</span> and <span class="math inline">\(x_1=-1/2\)</span>. Also notice the vectors <span class="math inline">\(\vectorthree{-1/2}{0}{1/2}\)</span> and <span class="math inline">\(\vectorthree{-2}{1}{0}\)</span> span the plane and are linearly independent. Therefore we have the basis we seek, namely <span class="math display">\[
\mathcal{B}
=\left(\vectorthree{-1/2}{0}{1/2},\vectorthree{-2}{1}{0}\right).
\]</span></p>
</div>
<div id="lem-" class="theorem lemma">
<p><span class="theorem-title"><strong>Lemma 3.6 </strong></span> Let <span class="math inline">\(T\)</span> be a linear transformation from <span class="math inline">\(\mathbb{R}^n\)</span> to <span class="math inline">\(\mathbb{R}^n\)</span> and <span class="math inline">\(\mathcal{B}=(\vec{v}_1,...,\vec{v}_n)\)</span> a basis of <span class="math inline">\(\mathbb{R}^n\)</span>. The <span class="math inline">\(n\times n\)</span> matrix <span class="math inline">\(B\)</span> that transforms <span class="math inline">\([ \vec{x}]_{\mathcal{B}}\)</span> into <span class="math inline">\([T(\vec x)]_{\mathcal{B}}\)</span> is called the <strong><span class="math inline">\(\mathcal{B}\)</span>-matrix</strong> of <span class="math inline">\(T\)</span>, written as <span class="math inline">\([T(\vec x)]_{\mathcal{B}}=B [ \vec x ]_{\mathcal{B}}\)</span> for all <span class="math inline">\(\vec x\)</span> in <span class="math inline">\(\mathbb{R}^n\)</span> and <span class="math display">\[
B=
\begin{bmatrix}
[T(\vec v_1)]_{\mathcal{B}} &amp;  \cdots &amp; [T(\vec v_n)]_{\mathcal{B}}
\end{bmatrix}.
\]</span></p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>Since <span class="math inline">\(\mathcal{B}\)</span> is a basis of <span class="math inline">\(\mathbb{R}^n\)</span>, there exists scalars <span class="math inline">\(c_1, ..., c_n\)</span> such that <span class="math inline">\(\vec{x}=c_1 \vec{v}_1+c_2\vec{v}_2+\cdots + c_n \vec{v}_n\)</span>. Using the linearity of <span class="math inline">\(T\)</span> we find <span class="math display">\[
T(\vec{x})=c_1 T(\vec{v}_1)+c_2 T(\vec{v}_2)+\cdots +c_n T(\vec{v}_n).
\]</span> By <span class="math inline">\(\ref{lincoord}\)</span> we find <span class="math display">\[\begin{align*}
[T(\vec{x})]_{\mathcal{B}}
&amp; = c_1 [T(\vec{v}_1)]_{\mathcal{B}} + c_2 [T(\vec{v}_2)]_{\mathcal{B}} + \cdots +c_n [T(\vec{v}_n)]_{\mathcal{B}} \\
&amp; =
\begin{bmatrix}
[T(\vec v_1)]_{\mathcal{B}} &amp;  \cdots &amp; [T(\vec v_n)]_{\mathcal{B}}
\end{bmatrix}
[\vec{x}]_{\mathcal{B}}
\end{align*}\]</span> as desired.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.57 </strong></span>Find the matrix <span class="math inline">\(\mathcal{B}\)</span> of the linear transformation <span class="math inline">\(T(\vec x)=A \vec x\)</span> where <span class="math display">\[
A=\begin{bmatrix}
5 &amp; -4 &amp; -2 \\
-4 &amp; 5 &amp; -2 \\
-2 &amp; -2 &amp; 8
\end{bmatrix}
\]</span> with respect to the basis <span class="math inline">\(\mathcal{B}=\left ( \vectorthree{2}{2}{1}, \vectorthree{1}{-1}{0}, \vectorthree{0}{1}{-2} \right )\)</span>. By <span class="math inline">\(\ref{lem:bmatrix}\)</span>, <span class="math inline">\(T\)</span> with respect to <span class="math inline">\(\mathcal{B}\)</span> has the following matrix <span class="math inline">\(B\)</span>. <span class="math display">\[
\begin{bmatrix}
\left[T\vectorthree{2}{2}{1}\right]_{\mathcal{B}} &amp;
\left[T\vectorthree{1}{-1}{0}\right]_{\mathcal{B}} &amp;
\left[T\vectorthree{0}{1}{-2}\right]_{\mathcal{B}}
\end{bmatrix}
=
\begin{bmatrix}
\vectorthree{0}{0}{0}_{\mathcal{B}} &amp;
\vectorthree{9}{-9}{0}_{\mathcal{B}} &amp;
\vectorthree{0}{9}{-18}_{\mathcal{B}}
\end{bmatrix}
=
\begin{bmatrix}
0 &amp; 0 &amp; 0 \\
0 &amp; 9 &amp; 0 \\
0 &amp; 0 &amp; 9
\end{bmatrix}.
\]</span></p>
</div>
<div id="thm-" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.25 </strong></span>Let <span class="math inline">\(T\)</span> be a linear transformation from <span class="math inline">\(\mathbb{R}^n\)</span> to <span class="math inline">\(\mathbb{R}^n\)</span> with standard matrix <span class="math inline">\(A\)</span> and let <span class="math inline">\(B\)</span> be the <span class="math inline">\(\mathcal{B}\)</span>-matrix of <span class="math inline">\(T\)</span> where <span class="math inline">\(\mathcal{B}= (\vec{v}_1,...,\vec{v}_n)\)</span> then <span class="math inline">\(A S= S B\)</span> where <span class="math display">\[
S= \begin{bmatrix}
\vec{v}_1 &amp; \cdots &amp;  \vec{v}_n
\end{bmatrix}
.\]</span></p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>The proof is left for the reader.</p>
</div>
<div id="def-" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3.9 </strong></span>Two <span class="math inline">\(n\times n\)</span> matrices <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are called <strong>similar</strong> if there exists an invertible matrix <span class="math inline">\(S\)</span> such that <span class="math inline">\(A S= S B\)</span>.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.58 </strong></span>Determine whether the following two matrices are similar. <span class="math display">\[
A=\begin{bmatrix} 1 &amp; 2 \\ 4 &amp;3 \end{bmatrix}
\qquad \text{and} \qquad
B=\begin{bmatrix} 5 &amp; 0 \\ 0 &amp; -1 \end{bmatrix}\]</span> We are looking for a matrix <span class="math display">\[
S=
\begin{bmatrix} x &amp; y \\ z &amp; t\end{bmatrix}
\]</span> such that <span class="math inline">\(AS=SB\)</span>. Writing out we find <span class="math display">\[
\begin{bmatrix} 1 &amp; 2 \\ 4 &amp;3 \end{bmatrix}
\begin{bmatrix} x &amp; y \\ z &amp; t\end{bmatrix}
=
\begin{bmatrix} x &amp; y \\ z &amp; t\end{bmatrix}
\begin{bmatrix} 5 &amp; 0 \\ 0 &amp; -1 \end{bmatrix}
\quad \implies \quad
\begin{bmatrix} x+2z &amp; y+2t \\ 4x+3z &amp; 4y+3t \end{bmatrix}
=
\begin{bmatrix} 5x &amp; -y  \\ 5z &amp; -t \end{bmatrix}.
\]</span> This leads to <span class="math inline">\(z=2x\)</span> and <span class="math inline">\(t=-y\)</span> so that <span class="math inline">\(S\)</span> is any invertible matrix of the form <span class="math display">\[\begin{equation}
\label{simform}
\begin{bmatrix}x &amp; y \\ 2x &amp; -y\end{bmatrix}.
\end{equation}\]</span> Since <span class="math inline">\(S= \begin{bmatrix}1 &amp; 1 \\ 2 &amp; -1 \end{bmatrix}\)</span> is invertible and of the form in <span class="math inline">\(\eqref{simform}\)</span>, we can say, yes <span class="math inline">\(A\)</span> is similar to <span class="math inline">\(B\)</span>.</p>
</div>
<div id="thm-" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.26 </strong></span>If <span class="math inline">\(A\)</span> is similar to <span class="math inline">\(B\)</span> then <span class="math inline">\(A^k\)</span> is similar to <span class="math inline">\(B^k\)</span> for any positive integer <span class="math inline">\(k\)</span>.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>If <span class="math inline">\(A\)</span> is similar to <span class="math inline">\(B\)</span> then there exists an invertible matrix <span class="math inline">\(S\)</span> such that <span class="math inline">\(B=S^{-1}A S\)</span>. Then <span class="math display">\[
B^k=(S^{-1}AS)(S^{-1}AS)\cdots (S^{-1}AS)=S^{-1}A^k S
\]</span> which shows that <span class="math inline">\(B^k\)</span> is similar to <span class="math inline">\(A^k\)</span>.</p>
</div>
<div id="thm-" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.27 </strong></span> Two <span class="math inline">\(n\times n\)</span> matrices <span class="math inline">\(A\)</span>, <span class="math inline">\(A'\)</span> are similar if and only if they are matrices of the same linear transformation <span class="math inline">\(T\)</span> from <span class="math inline">\(\mathbf{R}^n\)</span> to <span class="math inline">\(\mathbf{R}^n\)</span> with respect to two bases for <span class="math inline">\(\mathbf{R}^n\)</span></p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>The proof is left for the reader.</p>
</div>
<div id="thm-" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.28 </strong></span>Similar matrices have the same rank.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>Let <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> be similar matrices. By <span class="math inline">\(\ref{simsamelin}\)</span> <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> represent the same linear transformation. Thus they must have the same rank.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.59 </strong></span>Are the following similiar matrices? <span class="math display">\[
A=
\begin{bmatrix}
-1 &amp; 2 &amp; 1 \\
2 &amp; 0 &amp; 1 \\
2 &amp; 2 &amp; 2
\end{bmatrix}
\qquad \text{and}\qquad
B=
\begin{bmatrix}
-1 &amp; 2 &amp; 1 \\
2 &amp; 0 &amp; 1 \\
1 &amp; 2 &amp; 2
\end{bmatrix}
\]</span> Since <span class="math inline">\(\text{rank}(A)=3\)</span> and <span class="math inline">\(\text{rank}(B)=2\)</span>, these are not similar matrices.</p>
</div>
<div id="thm-" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.29 </strong></span> Similarity of matrices is an equivalence relation.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>To show transitivity, assume <span class="math inline">\(A\)</span> is similar to <span class="math inline">\(B\)</span> and <span class="math inline">\(B\)</span> is similar to <span class="math inline">\(C\)</span>, then there exists invertible matrices <span class="math inline">\(E\)</span> and <span class="math inline">\(F\)</span> such that <span class="math inline">\(AE=EB\)</span> and <span class="math inline">\(BF=FC\)</span>. Then <span class="math display">\[
A=EBE^{-1}=E(FCF^{-1})E^{-1}=(EF)C(F^{-1}E^{-1})=(EF)C(EF)^{-1}
\]</span> which shows that <span class="math inline">\(A\)</span> is similar to <span class="math inline">\(C\)</span>. The proof of the reflexive property and the symmetric property are left for the reader.</p>
</div>
<p>By <span class="math inline">\(\ref{simequiv}\)</span>, a linear transformation represents a whole class of (similar) matrices. That is the collection of <span class="math inline">\(n\times n\)</span> matrices is partitioned into non overlapping sets of matrices, with all matrices in any such set being similar and representing the same linear transformation from <span class="math inline">\(\mathbf{R}^n\)</span> to <span class="math inline">\(\mathbf{R}^n\)</span>.</p>
</section>
<section id="coordinates-and-the-matrix-of-a-linear-map" class="level2" data-number="3.7">
<h2 data-number="3.7" class="anchored" data-anchor-id="coordinates-and-the-matrix-of-a-linear-map"><span class="header-section-number">3.7</span> Coordinates and the Matrix of a Linear Map</h2>
<p>Let <span class="math inline">\(V\)</span> and <span class="math inline">\(W\)</span> be finite dimensional linear spaces.</p>
<div id="def-" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3.10 (The Matrix of a Linear Map) </strong></span>Let <span class="math inline">\(T\in \mathcal{L}(V,W)\)</span> and let <span class="math inline">\(b_1=\{v_1,\ldots ,v_n\}\)</span> be a basis for <span class="math inline">\(V\)</span> and <span class="math inline">\(b_2=\{w_1,\ldots ,w_m\}\)</span> be a base for <span class="math inline">\(W\)</span>. Then the matrix of <span class="math inline">\(T\)</span> with respect to the bases <span class="math inline">\(b_1\)</span> and <span class="math inline">\(b_2\)</span> is <span class="math display">\[ \begin{bmatrix}
a_{1 1} &amp; \cdots &amp; a_{1 n} \\
\vdots &amp; \cdots &amp; \vdots \\
a_{m 1} &amp; \cdots &amp; a_{m n} \\
\end{bmatrix}
\]</span> where the <span class="math inline">\(a_{i j}\in \mathbb{F}\)</span> are determined by <span class="math inline">\(T v_k=a_{1 k}w_1+\cdots +a_{m k}w_m\)</span> for each <span class="math inline">\(k=1,\ldots ,n\)</span>.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.60 </strong></span>Consider the linear transformation <span class="math inline">\(T(f)=f'+f''\)</span> from <span class="math inline">\(\mathcal{P}_2\)</span> to <span class="math inline">\(\mathcal{P}_2\)</span>. Since <span class="math inline">\(\mathcal{P}_2\)</span> is isomorphic to <span class="math inline">\(\mathbb{R}^3\)</span> with isomorphism given by a <span class="math inline">\(3\times 3\)</span> matrix <span class="math inline">\(B\)</span>, how do we find this matrix <span class="math inline">\(B\)</span>? Let <span class="math inline">\(a+b x+c x^2\)</span>, then we write <span class="math inline">\(T\)</span> as <span class="math display">\[\begin{align*}
T(a+b x+c x^2)&amp; =(a+b x+c x^2)'+(a+b x+c x^2)'' \\
&amp; =b+2c x+2c=(b+2c)+2cx.
\end{align*}\]</span> Next let’s write the input <span class="math inline">\(f(x)=a+b x+c x^2\)</span> and the output <span class="math inline">\(T(f(x))=(b+2c)+2c x\)</span> in coordinates with respect to the standard bases <span class="math inline">\(\mathcal{B}=(1, x, x^2)\)</span> of <span class="math inline">\(\mathcal{P}_2\)</span> Written in <span class="math inline">\(\mathcal{P}_2\)</span> coordinates, transformation <span class="math inline">\(T\)</span> takes <span class="math inline">\([f(x)]_{\mathcal{B}}\)</span> to <span class="math display">\[
[T(f(x))]_{\mathcal{B}}=\vectorthree{b+2c}{2c}{0}=
\begin{bmatrix}
0 &amp; 1 &amp; 2 \\
0 &amp; 0 &amp; 2 \\
0 &amp; 0 &amp; 0
\end{bmatrix}
\vectorthree{a}{b}{c}
= \begin{bmatrix}
0 &amp; 1 &amp; 2 \\
0 &amp; 0 &amp; 2 \\
0 &amp; 0 &amp; 0
\end{bmatrix}
[f(x)]_{\mathcal{B}}
\]</span> The matrix <span class="math display">\[
B= \begin{bmatrix}
0 &amp; 1 &amp; 2 \\
0 &amp; 0 &amp; 2 \\
0 &amp; 0 &amp; 0
\end{bmatrix}
\]</span> is called the <span class="math inline">\(\mathcal{B}\)</span>-matrix of the transformation <span class="math inline">\(T\)</span>.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.61 </strong></span>Find the <span class="math inline">\(B\)</span>-matrix for the linear transformation given by <span class="math display">\[
T(M)=\begin{bmatrix} 1 &amp; 2 \\ 3 &amp; 4  \end{bmatrix} M - M \begin{bmatrix} 5 &amp; 0 \\ 0 &amp; -1  \end{bmatrix}M
\]</span> from <span class="math inline">\(\mathbb{R}^{2\times 2}\)</span> to <span class="math inline">\(\mathbb{R}^{2\times 2}\)</span>. Determine whether <span class="math inline">\(T\)</span> is an isomorphism and if not find kernel, image, nullity, and the rank of <span class="math inline">\(T\)</span>. We will use the standard basis of <span class="math inline">\(\mathbb{R}^{2 \times 2}\)</span>: <span class="math display">\[
\mathcal{B}=
\left (
\begin{bmatrix} 1 &amp; 0 \\ 0 &amp; 0  \end{bmatrix},
\begin{bmatrix} 0 &amp; 1 \\ 0 &amp; 0  \end{bmatrix},
\begin{bmatrix} 0 &amp; 0 \\ 1 &amp; 0  \end{bmatrix},
\begin{bmatrix} 0 &amp; 0 \\ 0 &amp; 1  \end{bmatrix}
\right )
\]</span> and we will construct the <span class="math inline">\(\mathcal{B}\)</span>-matrix column-by-column: <span class="math display">\[
\begin{array}{rl}
B &amp; =
\begin{bmatrix} \left [ T\begin{bmatrix} 1 &amp; 0 \\ 0 &amp; 0  \end{bmatrix} \right ]_{\mathcal{B}} &amp;
\left [T[\begin{bmatrix} 0 &amp; 1 \\ 0 &amp; 0  \end{bmatrix}\right ]_{\mathcal{B}} &amp;
\left [ T\begin{bmatrix} 0 &amp; 0 \\ 1 &amp; 0  \end{bmatrix}\right ]_{\mathcal{B}} &amp;
\left [ T\begin{bmatrix} 0 &amp; 0 \\ 0 &amp; 1  \end{bmatrix} \right ]_{\mathcal{B}}
\end{bmatrix}\\
\\
&amp;=
\begin{bmatrix} \begin{bmatrix} -4 &amp; 0 \\ 4 &amp; 0  \end{bmatrix}_{\mathcal{B}} &amp;
\begin{bmatrix} 0 &amp; 2 \\ 0 &amp; 4  \end{bmatrix}_{\mathcal{B}} &amp;
\begin{bmatrix} 2 &amp; 0 \\ -2 &amp; 0  \end{bmatrix}_{\mathcal{B}} &amp;
\begin{bmatrix}  0 &amp; 2 \\ 0 &amp; 4  \end{bmatrix}_{\mathcal{B}}
\end{bmatrix}
=
\begin{bmatrix} -4 &amp; 0 &amp; 2 &amp; 0\\
0 &amp; 2 &amp; 0 &amp; 2 \\
4 &amp; 0 &amp; -2 &amp; 0 \\
0 &amp; 4 &amp; 0 &amp; 4
\end{bmatrix}\end{array}
\]</span> with <span class="math display">\[
\text{rref}(B)=
\begin{bmatrix} 1 &amp; 0 &amp; -\frac{1}{2} &amp; 0\\
0 &amp; 1 &amp; 0 &amp; 1 \\
0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0
\end{bmatrix}.
\]</span> After eliminating redundant columns from <span class="math inline">\(B\)</span> we find a basis of <span class="math inline">\(\text{im} T\)</span> is <span class="math display">\[\left(\, \vectorfour{-4}{0}{4}{0},\vectorfour{0}{2}{0}{4} \, \right).\]</span> To find <span class="math inline">\(\ker T\)</span> we solve <span class="math inline">\(B \vec x=\vec 0\)</span> and using the <span class="math inline">\(\text{rref}(B)\)</span> we find <span class="math display">\[\left(\, \vectorfour{-\frac{1}{2}}{0}{1}{0},\vectorfour{0}{-1}{0}{1} \, \right)\]</span> to be a basis for <span class="math inline">\(\ker T.\)</span> Notice since the rank of <span class="math inline">\(T\)</span> is <span class="math inline">\(2=\text{dim} \text{im} T\)</span>, <span class="math inline">\(T\)</span> is not an isomorphism. Therefore, since <span class="math inline">\(\ker T\neq \{0\}\)</span>, <span class="math inline">\(T\)</span> is not an isomorphism.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.62 </strong></span>Find the matrix of the linear transformation <span class="math inline">\(T(f(t))=f(3)\)</span> from <span class="math inline">\(\mathcal{P}_2\)</span> to <span class="math inline">\(\mathcal{P}_2\)</span> with respect to the basis <span class="math inline">\((1,t-3,(t-3)^2)\)</span>. Determine whether the transformation is an isomorphism, it it isn’t an isomorphism then determine the kernel and image of <span class="math inline">\(T\)</span>, and also determine the nullity and rank of <span class="math inline">\(T\)</span>. The matrix of <span class="math inline">\(T\)</span> is <span class="math display">\[
B=\begin{bmatrix} [T(1)]_{\mathcal{B}} &amp; [T(x-3)]_{\mathcal{B}} &amp; [T((x-3)^2)]_{\mathcal{B}} \end{bmatrix}
= \begin{bmatrix}
[1]_{\mathcal{B}} &amp; [0]_{\mathcal{B}} &amp; [0]_{\mathcal{B}}
\end{bmatrix}
= \begin{bmatrix} 1 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 \\  0 &amp; 0 &amp; 0  \end{bmatrix}.
\]</span> Notice the vectors <span class="math inline">\(\vectorthree{0}{1}{0}, \vectorthree{0}{0}{1}\)</span> form a basis of the kernel of <span class="math inline">\(B\)</span> and <span class="math inline">\(\vectorthree{1}{0}{0}\)</span> is a basis of the image of <span class="math inline">\(B\)</span>. Therefore, the rank is 1 and the nullity is 2; and therefore, <span class="math inline">\(T\)</span> is not an isomorphism.</p>
</div>
<div id="def-matrix-of-a-vector" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3.11 (The Matrix of a Vector) </strong></span>Let <span class="math inline">\(b=\{v_1,\ldots ,v_n\}\)</span> be a basis for <span class="math inline">\(V\)</span> and let <span class="math inline">\(v\in V\)</span>. We define the matrix of <span class="math inline">\(v\)</span>, denoted by <span class="math inline">\(\mathcal{M}(v)\)</span>, to be the <span class="math inline">\(n\)</span>-by-1 matrix <span class="math inline">\(\begin{bmatrix} b_{1} &amp; \cdots&amp; b_{n} \end{bmatrix}^T\)</span>.</p>
</div>
<div id="thm-" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.30 </strong></span>If <span class="math inline">\(T\in \mathcal{L}(V,W)\)</span>, then <span class="math inline">\(\mathcal{M}(Tv)=\mathcal{M}(T) \mathcal{M}(v)\)</span> for all <span class="math inline">\(v\in V\)</span>.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>Let <span class="math inline">\((v_1,\ldots ,v_n)\)</span> be a basis of <span class="math inline">\(V\)</span> and <span class="math inline">\((w_1,\ldots ,w_m)\)</span> be a basis of <span class="math inline">\(W\)</span>. If <span class="math inline">\(v\in V\)</span>, then there exists <span class="math inline">\(b_1,\ldots ,b_n\in \mathbb{F}\)</span> such that <span class="math inline">\(v=b_1 v_1+\cdots + b_n v_n\)</span> so that <span class="math inline">\(\mathcal{M}(v)=\begin{bmatrix} b_{1} &amp; \cdots&amp; b_{n} \end{bmatrix}^T\)</span>. For each <span class="math inline">\(k\)</span>, <span class="math inline">\(1\leq k \leq n\)</span> we write <span class="math inline">\(T v_k=a_{1k}w_1+ \cdots + a_{m k} w_m\)</span> and so by definition of the matrix of a linear map <span class="math inline">\(T\)</span>: <span class="math display">\[
\mathcal{M}=\begin{bmatrix}a_{11} &amp; &amp; a_{1n}  \\ \vdots &amp; \cdots &amp; \vdots \\ a_{m1} &amp; &amp; a_{mn} \end{bmatrix}.
\]</span> By linearity of <span class="math inline">\(T\)</span>: <span class="math display">\[
\begin{array}{rl}
Tv&amp; =b_1 T v_1+\cdots b_n T v_n \\
&amp; = b_1 \left(\sum_{j=1}^m a_{j 1}w_j \right)+\cdots +b_n \left(\sum_{j=1}^m a_{j n}w_j \right) \\
&amp; =w_1(a_{11}b_1+\cdots + a_{1n}b_n)+\cdots + w_m(a_{m1}b_1+\cdots + a_{mn}b_n).
\end{array}
\]</span> Therefore, <span class="math display">\[
\mathcal{M}(T v)=
\vectorthree{a_{11}b_1+\cdots + a_{1n}b_n}{\cdots}{a_{m1}b_1+\cdots + a_{mn}b_n}
=\mathcal{M}(T)\mathcal{M}(v).
\]</span> where the last equality holds by definition of matrix multiplication.</p>
</div>
<p>Let <span class="math inline">\(\overline{u}=(u_1,\ldots ,u_p)\)</span> be a basis of <span class="math inline">\(U\)</span>, let <span class="math inline">\(\overline{v}=(v_1,\ldots ,v_n)\)</span> be a basis of <span class="math inline">\(V\)</span>, and let <span class="math inline">\(\overline{w}=(w_1,\ldots ,w_m)\)</span> be a basis of <span class="math inline">\(W\)</span>. If <span class="math inline">\(T\in \mathcal{L}(U,V)\)</span> and <span class="math inline">\(S\in \mathcal{L}(V,W)\)</span>, then <span class="math inline">\(ST\in \mathcal{L}(U,W)\)</span> and by the definition of matrix multiplication, <span class="math display">\[\begin{equation}\label{matrix multiplication}
\mathcal{M}(ST,\overline{u},\overline{w})=\mathcal{M}(S,\overline{v},\overline{w}) \mathcal{M}(T,\overline{u},\overline{v}).
\end{equation}\]</span></p>
<div id="thm-matrix-inversion" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.31 </strong></span>If <span class="math inline">\(\overline{u}=(u_1,\ldots ,u_p)\)</span> and <span class="math inline">\(\overline{v}=(v_1,\ldots ,v_n)\)</span> are bases of <span class="math inline">\(V\)</span>, then <span class="math inline">\(\mathcal{M}(I,\overline{u},\overline{v})\)</span> is invertible and <span class="math display">\[
\mathcal{M}(I,\overline{u},\overline{v})^{-1}=\mathcal{M}(I,\overline{v},\overline{u}).
\]</span></p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>In <span class="math inline">\(\ref{matrix multiplication}\)</span>, replace <span class="math inline">\(U\)</span> and <span class="math inline">\(W\)</span> with <span class="math inline">\(V\)</span>, replace <span class="math inline">\(w_j\)</span> with <span class="math inline">\(u_j\)</span>, and replace <span class="math inline">\(S\)</span> and <span class="math inline">\(T\)</span> with <span class="math inline">\(I\)</span>, getting <span class="math display">\[
I=\mathcal{M}(I,(\overline{v},\overline{u}))\mathcal{M}(I,\overline{u},\overline{v}).
\]</span> Now interchange the roles of the <span class="math inline">\(u\)</span>’s and <span class="math inline">\(v\)</span>’s, getting <span class="math display">\[
I=\mathcal{M}(I,(\overline{u},\overline{v}))\mathcal{M}(I,\overline{v},\overline{u}).
\]</span> These equations give the desired result.</p>
</div>
<p>For example, obviously, <span class="math display">\[
\mathcal{M}\left(I,\left(\vectortwo{4}{2},\vectortwo{5}{3}\right),\left(\vectortwo{1}{0},\vectortwo{0}{1}\right)\right)=\begin{bmatrix}  4 &amp; 5 \\ 2 &amp; 3 \end{bmatrix} .
\]</span> The inverse of the matrix above is <span class="math inline">\(\begin{bmatrix} 3/2 &amp; -5/2 \\ -1 &amp; 2\end{bmatrix}\)</span>. Thus, <span class="math display">\[
\mathcal{M}\left(I,\left(\vectortwo{1}{0},\vectortwo{0}{1}\right),\left(\vectortwo{4}{2},\vectortwo{5}{3}\right)\right)
=\begin{bmatrix} 3/2 &amp; -5/2 \\ -1 &amp; 2\end{bmatrix}.
\]</span></p>
<div id="thm-" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.32 </strong></span>Suppose <span class="math inline">\(T\in\mathcal{L}(V)\)</span>. Let <span class="math inline">\(\overline{u}=(u_1,\ldots ,u_n)\)</span> and <span class="math inline">\((v_1,\ldots ,v_n)\)</span> be bases of <span class="math inline">\(V\)</span>. Let <span class="math inline">\(A=\mathcal{M}(I,\overline{u},\overline{v})\)</span>. Then <span class="math display">\[\begin{equation}\label{change of basis}
\mathcal{M}(T,\overline{u})=A^{-1}\mathcal{M}(T,\overline{v})A.
\end{equation}\]</span></p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>In <span class="math inline">\(\ref{matrix multiplication}\)</span>, replace <span class="math inline">\(U\)</span> and <span class="math inline">\(W\)</span> with <span class="math inline">\(V\)</span>, replace <span class="math inline">\(w_j\)</span> with <span class="math inline">\(v_j\)</span>, replace <span class="math inline">\(T\)</span> with <span class="math inline">\(I\)</span>, and replace <span class="math inline">\(S\)</span> with <span class="math inline">\(T\)</span>, getting <span class="math display">\[\begin{equation}\label{rchange}
\mathcal{M}(T,\overline{u},\overline{v})=\mathcal{M}(T,\overline{v})A.
\end{equation}\]</span> In <span class="math inline">\(\ref{matrix multiplication}\)</span>, replace <span class="math inline">\(U\)</span> and <span class="math inline">\(W\)</span> with <span class="math inline">\(V\)</span>, replace <span class="math inline">\(w_j\)</span> with <span class="math inline">\(u_j\)</span>, replace <span class="math inline">\(S\)</span> with <span class="math inline">\(I\)</span>, and replace <span class="math inline">\(S\)</span> with <span class="math inline">\(T\)</span>, getting <span class="math display">\[\begin{equation}\label{lchange}
\mathcal{M}(T,\overline{u})=A^{-1}\mathcal{M}(T,\overline{u},\overline{v})
\end{equation}\]</span> by <span class="math inline">\(\ref{matrix inversion}\)</span>. Substitution of <span class="math inline">\(\ref{rchange}\)</span> into <span class="math inline">\(\ref{lchange}\)</span> yields <span class="math inline">\(\ref{change of basis}\)</span>.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.63 </strong></span>Prove that every linear map from <span class="math inline">\(\text{Mat}(n,1,F)\)</span> to <span class="math inline">\(\text{Mat}(m,1,F)\)</span> is given by matrix multiplication. In other words, prove that if <span class="math inline">\(T\)</span> is a linear transformation from <span class="math inline">\(\text{Mat}(n,1,F)\)</span> to <span class="math inline">\(\text{Mat}(m,1,F))\)</span>, then there exists an <span class="math inline">\(m\)</span>-by-<span class="math inline">\(n\)</span> matrix <span class="math inline">\(A\)</span> such that <span class="math inline">\(T B=A B\)</span> for every <span class="math inline">\(B\in \text{Mat}(n,1,F).\)</span> Let <span class="math inline">\((e_1,\ldots ,e_n)\)</span> be a basis for <span class="math inline">\(Mat(n,1,\mathbb{F})\)</span> and let <span class="math inline">\((v_1,\ldots ,v_m)\)</span> be a basis for <span class="math inline">\(Mat(m,1,\mathbb{F})\)</span>. For each <span class="math inline">\(k\)</span>, there exists <span class="math inline">\(a_{1k},\ldots ,a_{mk}\in \mathbb{F}\)</span> such that <span class="math inline">\(T e_k=a_{1k} v_1+\cdots a_{mk} v_m\)</span>. Define the <span class="math inline">\(m \times n\)</span> matrix <span class="math inline">\(A\)</span> as follows: <span class="math display">\[
A=\begin{bmatrix} T e_1 &amp; \cdots &amp; T e_n \end{bmatrix}.
\]</span> If <span class="math inline">\(B\in Mat(n,1,\mathbb{F})\)</span> there exists <span class="math inline">\(b_1,\ldots ,b_n\in \mathbb{F}\)</span> such that <span class="math inline">\(B=b_1 e_1+\cdots + b_n e_n\)</span>, and thus <span class="math display">\[
TB=T(b_1 e_1+\cdots + b_n e_n)=b_1 T e_1+\cdots + b_n T e_n= BA
\]</span> as desired. Notice the word “the” follows since <span class="math inline">\((v_1,\ldots ,v_m)\)</span> is a basis. In other words one bases have been chosen, the matrix <span class="math inline">\(A\)</span> is unique.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.64 </strong></span>Suppose that <span class="math inline">\(V\)</span> is finite-dimensional and <span class="math inline">\(S,T\in \mathcal{L}(V)\)</span>. Prove that <span class="math inline">\(S T\)</span> is invertible if and only if both <span class="math inline">\(S\)</span> and <span class="math inline">\(T\)</span> are invertible. Suppose both <span class="math inline">\(S\)</span> and <span class="math inline">\(T\)</span> are invertible. Then both <span class="math inline">\(S\)</span> and <span class="math inline">\(T\)</span> are injective and surjective. Thus, <span class="math inline">\(ST\)</span> is both injective and surjective showing <span class="math inline">\(ST\)</span> is invertible. Conversely, suppose <span class="math inline">\(ST\)</span> is invertible. Since <span class="math inline">\(\text{ker} T\subseteq \text{ker} ST =\{0\}\)</span> because <span class="math inline">\(ST\)</span> is injective, <span class="math inline">\(T\)</span> is also injective. Thus, <span class="math inline">\(T\)</span> is invertible. Since <span class="math inline">\(ST\)</span> is surjective, if <span class="math inline">\(w\in W\)</span>, then there exists <span class="math inline">\(v\in V\)</span> such that <span class="math inline">\((ST)v=w\)</span>. Rewriting <span class="math inline">\(S(Tv)=w\)</span>, showing <span class="math inline">\(S\)</span> is surjective. Thus, <span class="math inline">\(S\)</span> is also invertible.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.65 </strong></span>Suppose that <span class="math inline">\(V\)</span> is finite-dimensional and <span class="math inline">\(S,T\in \mathcal{L}(V)\)</span>. Prove that <span class="math inline">\(S T=I\)</span> if and only if <span class="math inline">\(T S=I\)</span>. Without loss of generality, we will show <span class="math inline">\(ST=I \text{im}plies TS=I\)</span>. Suppose <span class="math inline">\(ST=I\)</span>. Since <span class="math inline">\(I\)</span> is invertible, the previous exercise implies <span class="math inline">\(S\)</span> and <span class="math inline">\(T\)</span> are both invertible. Then <span class="math inline">\(ST=I \text{im}plies S^{-1}(ST)=S^{-1}I \text{im}plies T=S^{-1}\)</span>. Therefore, <span class="math inline">\(TS=S^{-1}S=I\)</span>.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.66 </strong></span>Suppose that <span class="math inline">\(V\)</span> is finite-dimensional and <span class="math inline">\(T\in \mathcal{L}(V)\)</span>. Prove that <span class="math inline">\(T\)</span> is a scalar multiple of the identity if and only if <span class="math inline">\(S T=T S\)</span> for every <span class="math inline">\(S\in \mathcal{L}(V)\)</span>. If <span class="math inline">\(T\)</span> is a scalar multiple of the identity, say <span class="math inline">\(T=\alpha I\)</span>, then for all <span class="math inline">\(v\in V\)</span>, <span class="math display">\[
S T v=S \alpha v= \alpha S v= TS v.
\]</span> Conversely, suppose <span class="math inline">\(ST=TS\)</span> for every <span class="math inline">\(S\in \mathcal{L}(V)\)</span>. Pick a basis <span class="math inline">\(v_1,\ldots ,v_N)\)</span> for <span class="math inline">\(V\)</span>. For <span class="math inline">\(m=1,\ldots ,N\)</span>, define linear maps <span class="math inline">\(S+m\in \mathcal{L}(V)\)</span> by<span class="math display">\[
S_m=v_n=\left\{ \begin{array}{rl} v_m &amp; \text{ if } m=n \\ 0 &amp; \text{ if } m\neq n \end{array} \right.
\]</span> Now if <span class="math inline">\(v=\sum \alpha_n v_n\)</span>, then<span class="math display">\[
S_m\sum \alpha_n v_n=\alpha_m v_m
\]</span> Thus the only vectors satisfying <span class="math inline">\(S_m v=v\)</span> are <span class="math inline">\(v=\alpha v_m\)</span> for some <span class="math inline">\(\alpha \in \mathbb{F}\)</span>. The condition <span class="math inline">\(S_m T=T S_m\)</span> gives<span class="math display">\[
S_m T v_m=T S_m v_m=T v_m
\]</span> and by the above observation <span class="math inline">\(T v_m=\alpha_m v_m\)</span>. Now consider another collection of linear maps <span class="math inline">\(A(m,n)\)</span> defined by<span class="math display">\[
A(m,n) v_m=v_n, \hspace{1cm} A(m,n)v_n=v_m, \hspace{1cm} A(m,n)v_k=0, \text{ when } k\neq m,n.\]</span> The condition <span class="math inline">\(A(m,n)T v_n=T A(m,n) v_n\)</span> gives <span class="math display">\[
A(m,n)T v_n=TA(m,n)v_n=T v_m=\alpha_m v_m
\]</span> and <span class="math display">\[
A(m,n)\alpha_n v_n=A(m,n)\alpha_n v_n=\alpha_nA(m,n)v_n=\alpha_n v_m.
\]</span> Whence <span class="math inline">\(\alpha_m v_m=\alpha_n v_m\)</span> that is, <span class="math inline">\(\alpha_m=\alpha_n\)</span> for <span class="math inline">\(m,n=1,\ldots ,N\)</span>; and thus <span class="math inline">\(T\)</span> is a scalar multiple of the identity.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.67 </strong></span>Prove that if <span class="math inline">\(V\)</span> is finite-dimensional with <span class="math inline">\(\text{dim} V &gt; 1\)</span>, then the set of non-invertible operators on <span class="math inline">\(V\)</span> is not a subspace of <span class="math inline">\(\mathcal{L}(V)\)</span>. Suppose <span class="math inline">\((v_1,\ldots ,v_n)\)</span> is a basis of <span class="math inline">\(V\)</span>, with <span class="math inline">\(n \geq 2\)</span>. Define the linear maps <span class="math inline">\(S\)</span> and <span class="math inline">\(T\)</span> by <span class="math display">\[S v_1=v_1, \hspace{1cm} S v_k =0, \text{ when } k\geq 2\]</span> <span class="math display">\[T v_1=0, \hspace{1cm} T v_k =v_k, \text{ when } k\geq 2.\]</span> Since <span class="math inline">\(S\)</span> and <span class="math inline">\(T\)</span> have nontrivial null spaces, they are not invertible. However, <span class="math inline">\((S+T) v_k=v_k\)</span>, for <span class="math inline">\(k=1,\ldots ,n,\)</span> so <span class="math inline">\(S+T=I\)</span>, which is invertible. Thus the set of noninvertible operators on <span class="math inline">\(V\)</span> with <span class="math inline">\(n\geq 2\)</span> is not closed under addition.</p>
</div>
</section>
</main> <!-- /main -->
<script type="application/ld+json">
    {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "Direct Knowledge",
    "url": "https://diretcknowledge.com",
    "logo": "http://directknowledge.com/assets/directknowledge-logo.svg",
    "foundingDate": "2017",
    "founders": [
    {
    "@type": "Person",
    "name": "David Andrew Smith"
    },
    {
    "@type": "Person",
    "name": "David A. Smith"
    } ],
    "address": {
    "@type": "PostalAddress",
    "addressLocality": "Fort Worth",
    "addressRegion": "Texas",
    "addressCountry": "United States"
    },
    "contactPoint": {
    "@type": "ContactPoint",
    "contactType": "customer support",
    "email": "contact@directknowledge.com"
    },
    "sameAs": [
    "https://youtube.com/@directknowledge",
    "https://github.com/directknowledge/"
    ]
    }
</script>
<script type="application/ld+json">
    {
    "@context": "http://schema.org",
    "@type": "WebSite",
          "name": "Direct Knowledge",
        "url": "https://directknowledge.com"
    }
</script>
<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']],
    processRefs: true,
    processEnvironments: true,
    tags: 'ams',
    packages: {'[+]': ['newcommand']},
    processEnvironments: true,
      macros: {
        N: "{\\mathbb{N}}",
        Z: "{\\mathbb{Z}}",
        qed: "{\\square}"
      }
  },
  svg: {
    fontCache: 'global'
  }
};
console.log("MaxJax Initalizing");
</script>
  
<script>
var xtimes = 1;
console.log(xtimes);
ActiveMaxJax = function() {
  if( xtimes == 1 ) {
    var script = document.createElement('script');
    script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
    script.async = true;
    document.head.appendChild(script);
    xtimes = 0;
    console.log(xtimes);
  } 
};
window.addEventListener("scroll", function() { ActiveMaxJax(); });
window.addEventListener("click", function() { ActiveMaxJax(); });
window.addEventListener("mousemove", function() { ActiveMaxJax(); });
window.addEventListener("keydown", function() { ActiveMaxJax(); });
window.addEventListener("touchstart", function() { ActiveMaxJax(); });
window.addEventListener("keydown", function() { ActiveMaxJax(); });
console.log("MaxJax Initialization Complete");
</script>
<script>
// Load the script after the user scrolls, moves the mouse, or touches the screen
document.addEventListener('scroll', initGTMOnEvent);
document.addEventListener('mousemove', initGTMOnEvent);
document.addEventListener('touchstart', initGTMOnEvent);
// Or, load the script after 2 seconds
document.addEventListener('DOMContentLoaded', () => { setTimeout(initGTM, 2000); });
// Initializes Google Tag Manager in response to an event
function initGTMOnEvent (event) {
	initGTM();
	event.currentTarget.removeEventListener(event.type, initGTMOnEvent);
}
// Initializes Google Tag Manager
function initGTM () {
	if (window.gtmDidInit) {
	  // Don't load again
	  return false;
	}
	window.gtmDidInit = true;
	
	// Create the script
	const script = document.createElement('script');
	script.type = 'text/javascript';
	script.onload = () => { 
	  window.dataLayer = window.dataLayer || [];
	  function gtag(){ dataLayer.push(arguments); }
	  gtag('js', new Date());
	  gtag('config', 'G-899QW82HQV');
	}
	script.src = 'https://www.googletagmanager.com/gtag/js?id=G-899QW82HQV';
	
	// We are still deferring the script
	script.defer = true;
	
	// Append the script to the body of the document
	document.getElementsByTagName('body')[0].appendChild(script);
}
</script>
<style>
    .theorem {
        background: linear-gradient(90deg,rgba(200, 217, 234, .5), rgba(200, 217, 234, .8));
        padding:6px 6px 2px 6px;
        border-left:1px solid rgba(0, 0, 255, 0.22);
        margin:12px 0px;
    }
    .theorem-title strong::after {
        content:'. ';
        margin-left:-4px;
        padding-right:5px;
    }
    .lemma {
        background: linear-gradient(90deg,rgba(188, 201, 168, 0.5), rgba(188, 201, 168, .8));
    }
    .corollary {
        background: linear-gradient(90deg,rgba(248, 197, 240, 0.5), rgba(248, 197, 240, .8));
    }
    .proposition {
        background: linear-gradient(90deg,rgba(248, 210, 219, 0.5), rgba(248, 210, 219, .8));
    }
    .definition {
        background: linear-gradient(90deg,rgba(210, 180, 140, .5), rgba(210, 180, 140, .8));
    }
    .example {
        background: linear-gradient(90deg,rgba(255, 255, 204, .5), rgba(255, 255, 204, .8));
    }
    .exercise {
        background: linear-gradient(90deg,rgba(250, 235, 199, 0.5), rgba(250, 235, 199, .8));
    }
    .proof-title {
        font-weight:600;
    }
    ol li::marker {
        content: "(" counter(list-item, lower-arabic) ") ";
     }
     .solution:after, .proof:after {
        margin-top:-44px;
        margin-bottom:64px;
        float:right;
        content: '\25A0';
     }
     .blockquote {
        font-weight: 500!important;
        color:#000000!important;
     }
</style>
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var filterRegex = new RegExp(/https:\/\/directknowledge\.com\/learning-linear-algebra\//);
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
    var links = window.document.querySelectorAll('a:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // target, if specified
          link.setAttribute("target", "_blank");
      }
    }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./vector-spaces.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Vector Spaces</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./inner-products-spaces.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Inner Products Spaces</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
      <div class="nav-footer-center">
        <ul class="footer-items list-unstyled">
    <li class="nav-item">
    <a class="nav-link" href="https://directknowledge.com">© Copyright 2023, All Rights Reserved. DirectKnowledge.com</a>
  </li>  
</ul>
      </div>
  </div>
</footer>
<script src="site_libs/quarto-html/zenscroll-min.js"></script>
<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
</body></html>